[
  {
    "original_url": "https://gdsdata.blog.gov.uk/e-claims-service-assessment/",
    "title": "E-Claims - Service Assessment",
    "summary": "The E-Claims service is a management and control system for the delivery of DCLG and DWP programmes to meet European Commission guidelines. The public facing component of the service allows users to apply for European Regional Development Fund (ERDF) or European Social Fund (ESF) money.",
    "body": "**Department / Agency:**  \nDCLG\n\n**Date of Original Assessment:**  \n8/06/2015\n\n**Date of Reassessment:**  \n11/12/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Original Assessment:**  \nNot Pass\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nH. Garrett (Original) / M. Brunton-Spall (Reassessment)\n\n**Service Manager:**  \nD. Watkinson\n\n**Digital Leader:**  \nP. White\n\n* * *\n\n## Reassessment Report\n\n**11th December 2015**\n\nThe E-Claims service has been reviewed against the 18 points of the Service Standard at the end of the alpha development.\n\nAfter consideration, the assessment panel have concluded that the E-Claims service is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe panel were very pleased to see such an improvement from the last assessment. The service team has clearly taken feedback to heart and has taken steps to improve the team and project. The service has strong and difficult regulations and requirements and is navigating those by understanding user needs and how users will use the system.\n\n_Point 1 - Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for the design of the service._\n\nThe team acknowledged that user research had started at a late point in the service’s development, when the design was already quite advanced. Since bringing a user researcher on board, the team have been meeting users on a regular basis, and are feeding insights from user research into the design of the service. The team have been researching with a wide range of users, both internal civil servants and external applicants. User research is planned and funded to continue through the beta phase. The team has been researching with all users to understand what support they might need, using a prototype of the service for accuracy, and have met with some users with the lowest levels of digital skills.\n\nThe team explained how assisted digital support doesn’t need to be provided to civil servant users using the administrative side of the service as part of their work. For the public facing side (applicants) the team explained how the application process itself requires some level of digital skill and access, and that applicants were from larger organisations led them to expect that users’ digital skills would generally be higher.\n\nThis was borne out by the team’s research. The team found that most support sought was to clarify content or seek extra information, and had made improvements to the digital service prototype to reduce these enquiries.\n\n_Point 10 - Be able to test the end-to-end service in an environment identical to that of the live version, including on all common browsers and devices, and using dummy accounts and a representative sample of users._\n\nThe team have been working to ensure that the system is hosted on a commercial cloud solution that enables them to automatically construct an environment when it is needed. While there is still some work to be done in this area to get it entirely automated, the expected lead time on needing an environment is measured in hours not weeks or months. Since the environment creation is automated, there is strong assurance that the environments are consistent and that testing performed in them matches the production environment.\n\n_Point 13 - Build a service consistent with the user experience of the rest of GOV.UK including using the design patterns and style guide._\n\nThe prototypes that have been developed are clearly much more in keeping with the government style than the original system, and have been iterated to meet the user needs of the intended users. While the interface is reasonably complex and contains complex language, the team provided assurance that the majority of users are expert users who understand the process already, and that user research is looking at ways to improve guidance content around the forms to aid users who run into difficulties.\n\n_Point 14 - Encourage all users to use the digital service (with assisted digital support if required), alongside an appropriate plan to phase out non-digital channels/services._\n\nThe team is aware of alternative channels, can measure them, and will be working to phase them out as soon as possible by promoting the digital service and subsequently switching off alternatives.\n\n**Recommendations**\n\n_Point 1 - Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for the design of the service._\n\nThe team should develop personas from their research with users in person, that cover the range of assisted digital support needs for this service. These should take into account the four different applicant-user types required to complete the service - Application Administrator, Claims Editor, Claims Reviewer and Procurement Editor.\n\nThe team should carry out more research in context, in people’s offices and workplaces, to understand the full range of support that users would seek, including from third parties and face-to-face. This should include working with third party support-providing organisations, such as universities and charities.\n\nThe team should ensure that there isn’t an over-reliance on focus groups, and group research sessions, making sure to meet people individually to understand the differences between users as well as the similarities.\n\n_Point 2 - Put a plan in place for ongoing user research and usability testing to continuously seek feedback from users to improve the service._\n\nThe team needs to ensure that feedback from user research that goes into the prototype is successfully able to be put into the main system. The prototypes success shows that the new design is important, but it was not clear how the team would be able to bring the design changes back into the main system.\n\n_Point 3 - Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility._\n\nThe lack of an identifiable service manager, as defined by the Government Service Design Manual, means that there is no single decision making point for the entire end-to-end service. The team has done an admirable job in attempting to diversify this role across a number of different positions, but the panel strongly recommend that the service appoint a single suitably skilled service manager with decision making responsibility.\n\nIt was also noted that some team members were contracted via different routes, making it unclear whether the entire team was funded for the duration of the service, through to live. We recommend that the team address this and ensure that a fully funded and well staffed multidisciplinary team is in place before the private beta.\n\n_Point 12 - Create a service that is simple and intuitive enough that users succeed first time._\n\nThe team were able to demonstrate users succeeding when using the service from a start page to the end of a transaction.\n\nIn the next steps the team should ensure this scenario is widened so it includes the whole experience, from the point of need, through to getting to the digital service, reading guidance and then onto the completion of an application or payment of a claim. The team should be sure to include in their support model for this service all routes of assisted digital support that their research shows that users need, including, if required, face-to-face support.\n\nThe supporting content on GOV.UK does not meet GOV.UK standards. The panel recommends that the team liaise with the DCLG content team and ensure that the service and supporting content is fully driven by user needs.\n\nAdditionally, the service duplicates information that can currently be found on GOV.UK. The panel recommends that before the beta assessment, the team discuss with the GOV.UK team to agree what content lives on GOV.UK and what content lives in the service. Additionally, the team should agree with GOV.UK how the user journey between the two should work.\n\n_Point 13 - Build a service consistent with the user experience of the rest of GOV.UK including using the design patterns and style guide._\n\nWhile there has been a content designer on the team, budget for their time is still to be confirmed for the next phase. The team should ensure this is in place so they can continue the good work already done in this area.\n\nThe same holds true for the supplier team who have been working on the front-end code in the prototype. This team need to be in place for the next phase so the quality that exists in that code, taken from user research, is brought into the main build.\n\nDesign of the service is currently handled by the user experience and user researcher on the team. This works for the current phase but the panel would expect to see someone with overall responsibility for the design on the team by the next phase (this could be an existing member).\n\n_Point 16 - Identify performance indicators for the service, including the 4 mandatory key performance indicators (KPIs) defined in the manual. Establish a benchmark for each metric and make a plan to enable improvements._\n\nThe team are measuring the performance of their own department’s telephone support, but should be sure to also measure any other routes of support for the required model of support for this service - for example face-to-face and third party support.\n\n**Summary**\n\nThe panel were very pleased to see the team again and to see the difference that has happened. The panel recognise that the team has worked hard on taking the feedback and working on it.\n\nThe service at alpha has demonstrated that there is a user need for a better way to claim and administer the grants, and that the demonstrated approach is much better than the existing systems, and that it therefore passes the alpha standard and can progress into building a beta that can be tested with real users.\n\n* * *\n\n## Summary of Original Report\n\n**8th June 2015**\n\nAfter consideration the assessment panel has concluded that the E-Claims service is not yet on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\n_User needs and research and creating a simple and intuitive service - service standard points 1, 8, 9, 10, 12, 19, 20_\n\nThere has not been sufficient user research during the alpha phase to understand user needs fully enough to proceed to beta. The panel were pleased to hear about the work done in discovery to talk to internal users of the service and find out more about their needs, but there has not been continued investment in user research. Specifically, there has been very little research with applicants, other than an initial workshop during discovery.\n\nOffline support is provided for users of the current service, but due to lack of evidence of user research it was unclear whether the proposed support would meet the needs of assisted digital users for this specific service.\n\nThe panel were pleased to see how the service team were using agile methods and techniques. This includes involving lots of internal users in show and tells and actively seeking feedback on work in progress from a wide group of internal users. However, this is not a substitute for seeing people using the service.\n\nAt this stage the full end-to-end transaction has yet to be tested with either users applying for or users administering funds, although the team have done some research with internal applicants on the process and have gathered feedback on the sections of the service developed so far. This research could be done by some lightweight prototyping to test out the full journey, this will save time in the long run as it will help bring out the major usability issues early on.\n\nThe panel appreciate that there are fixed deadlines for launching the new service, but this kind of research is imperative in ensuring that any problems in the journey are uncovered as soon as possible. At the current time it is not clear how the team can be confident that the service is simple and intuitive enough that users succeed first time, unaided.\n\n_Multidisciplinary team - service standard points 2, 13_\n\nThere isn’t a multidisciplinary team in place with all disciplines represented and these gaps in the team are reflected in the service. The team does not have a user researcher, content designer, product analyst or designer (or sufficient time from each of those disciplines) working on the service.\n\nThe content is written outside the team, and the team seemed reluctant to challenge content that has been signed off. Whilst the panel appreciate the complexities of the service and legal implications, the team should have the autonomy to feedback about the content. It is essential that the team have the research and evidence to inform these decisions and have the content design skills within the team to improve the content.\n\nThe team have been using the GDS design patterns and style guide and will be building their forms based on them. This should remove the need to design solutions for patterns of interaction which already exist and ensure the service is consistent with the rest of GOV.UK. It is essential however, that the team have enough time from a designer to assist in the creation of any new patterns and ensure the service as a whole is kept simple and intuitive by ensuring all decisions are directly informed by the outputs of user research.\n\n_Analysis - service standard points 7, 21, 22, 23, 24_\n\nDecisions appear to have been made outside of the control of the team that are not necessarily backed by data. For example, the plan is to support IE9 and above, and not older browsers. This decision was articulated in an initial requirements document, but it was not clear whether this was based on evidence. For instance was it based on the current usage of legacy back office systems or an analysis of potential users of the application service (business, charities, colleges)? The team did not appear to be able to direct these decisions about the service.\n\nIt is positive that the team plan to use Google Analytics to measure the performance of the service. However, the team need to understand how they will benchmark, measure and report on the key performance indicators of cost per transaction, completion rate, user satisfaction and digital take up.\n\n_Technology decisions - service standard points 5, 14, 15, 17_\n\nThe panel found it difficult to do a thorough assessment of the technology decisions due to the lack of user research to base them on. Technology decisions should be driven by user needs and ensure that the service is doing the hard work to make the service simple. The panel have therefore assessed what was presented, but understand that further research into the user needs may change the product direction.\n\nWhile it was good to hear that the team would like to open source the code, and has already seen the benefits of owning the IP so that suppliers can share code internally, the panel did not see any actual evidence that the team has started the process.\n\nWhile the panel understand the difficult reality of the team’s situation with appointing a supplier, the panel felt that appointing a database vendor to build the system means that the team are less able make informed decisions about vendor lock-in. The panel were presented with no evidence to indicate that the team had the skills or knowledge to challenge or guide the vendors correctly.\n\nThe panel were very pleased to note that the technical intention of the disaster recovery plan appeared to be very modern and appropriate to the requirements. The panel were also are pleased to see the hosting arrangements are equally modern and appropriate.\n\nThe panel were very concerned to note that the current deployment practices are not intending to continue through to live. The panel were unable to get a good understanding of how releases into production are intended to be done once the service is live, however it appeared that the team wanted to add significantly more governance and overhead in the future which would reduce the deployment velocity and prevent regular releases. The panel strongly recommend against taking this course of action.\n\n**Recommendations**\n\nThe service must address the following recommendations before the next assessment.\n\n- The team should ensure that the skills gaps within the team (user research, design, content design and analysis) are addressed as a matter of urgency.\n- The team should begin user research in the alpha stage, particularly with external applicants. An immediate first step could be to observe applicants using the interim forms that are already in place.\n- User research should be undertaken to begin understanding assisted digital user needs and potential barriers to using the digital service independently.\n- The team should test out the full end-to-end transaction in prototype form with both internal and external users and iterate that prototype based on those research findings. These findings should form the basis of a beta.\n- There was a concern that the governance structure described during the assessment is likely to prevent rapid iteration once the service is live. The team should look at how they can improve these processes which are in danger of slowing them down.\n- The team should make a plan to open source the code.\n- The team should meet with the Performance Platform team in GDS to agree how they will measure and report on the four KPIs.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/claim-personal-independence-payment-service-assessment/",
    "title": "Claim Personal Independence Payment - Service Assessment",
    "summary": "Personal Independence Payment (PIP) helps with some of the extra costs caused by long-term ill-health or a disability for those aged 16 to 64. Claim PIP is a digital service that will transform the way users claim PIP, combining telephone application and written application and evidence provision into a single service.",
    "body": "**Department / Agency:**  \nDWP\n\n**Date of Original Assessment:**  \n19/05/2015\n\n**Date of Reassessment:**  \n29/06/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Original Assessment:**  \nNot Pass\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nN. Williams\n\n**Service Manager:**  \nA. Holmes\n\n**Digital Leader:**  \nK. Cunnington\n\n* * *\n\n## Reassessment Report\n\n**29th June 2015**\n\nThe Claim PIP service has been reviewed against the 3 points of the Digital by Default Service Standard that were not passed at the original assessment.\n\nAfter consideration, the assessment panel have concluded that the Claim PIP service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service team have addressed the user research issues that were raised at the initial assessment on 8 May in relation to points 1 and 20. The panel were pleased to learn that:\n\n- The team have overcome internal barriers to in-home contextual research, and begun a programme of in-home research with 6 interviews planned per sprint.\n- The team have adopted a systematic and practical approach to representative coverage of the complex audience for this product, focusing on 12 varied and challenging conditions which cover a wide range of design challenges that the service must address, combined with more informal pop-up research to include people with other conditions.\n- Research has taken place with ‘friends and family’ also present, based on whether the user would normally complete this kind of application on their own or with support.\n- The lab research has been observed by a range of DWP staff, including PIP assessors. The panel felt that the feedback loop that this has established was very constructive and should be continued as the team move forwards into beta.\n\nOverall, the team's research plans for the project appear appropriate for the scale and complexity of the audience and the design challenge.\n\nThe panel also saw sufficient evidence that users can complete the service unaided and that this is yielding usable outputs for assessors. The 'scenario' based approach to questioning has been improved and 30 more users have completed the service. Users appear to understand this style of question more easily than they did the previous form, leading to better answers. The team now has a clearer understanding of the amount of time it takes users to complete the service (average of approximately 45 mins) and is aware of the current difficulties within the service, which the team are keen to iterate and improve.\n\n**Recommendations**\n\nThe panel recommend that the team continue resolving the pain points within the service. The team are currently working on some of these, including the progressive disclosure patterns, a save and resume pattern and the in-form navigation design, and the ‘review details’ page.\n\nThe panel recommend that the team persists with its current research approach - with the representative subset of the audience that has been identified, and the continued involvement of wider DWP colleagues. There will be much more to discover, and more design changes to make, which the panel will look forward to reviewing at the next assessment.\n\n* * *\n\n## Summary of Original Report\n\n**19th May 2015**\n\nAfter consideration the assessment panel has concluded that the Claim PIP service is not yet on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service currently falls short against three points of the standard, as detailed below. There is more work to do in these areas before the panel could confidently say Claim PIP is on track to meet the Digital by Default Service Standard.\n\nUnderlying all three points is a need for deeper and broader user research. While the service team have developed a good, convincing and evidenced set of high level user needs (drawn from a large body of prior research) and established that the project is viable and worthwhile, as yet it is not proven that a digital service backed with assisted digital support can address these needs.\n\nGiven the nature of this service, and the extensive range of physical, cognitive and psychiatric conditions that could impact the design in many different and unpredictable ways, the bar needs to be set particularly high for user research and assisted digital provision for this service.\n\n**Point 1** - _Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for digital and assisted digital service design._\n\nThe research conducted in the alpha was limited. The single researcher working on the project completed a commendable amount of work during the short time available (and in spite of purdah constraints), but it was nevertheless insufficient to understand this diverse and complex user base. The notable gaps in the research were:\n\n- The end-to-end prototype journey was tested with just 10 users.\n- There was no significant or detailed exploration of how the diverse range of conditions in the audience will impact on the design (or designs).\n- There was no contextual or in-home research to explore completion of a digital application in the environment in which that application would actually be completed (which is likely to be of some significance given the nature of the users).\n- There were no paired research sessions to explore ’friends and family’ involvement.\n\n**Point 9** - _Create a service that is simple and intuitive enough that users succeed first time, unaided._\n\nWith the limited lab testing sample, the overall research conclusion was that none of the respondents would have been able to complete an accurate or sufficient application to allow their case for PIP to be properly assessed (users can complete the service but their answers are deficient). The alpha was therefore unable to prove that the approach in the current prototype meets the user needs in this audience, or provides a viable way forward for the product. We believe a solution can be found; the team will need to spend more time designing and testing options and challenge harder the underlying assumption of a single, long questionnaire equivalent to the existing paper-based form.\n\n**Point 20** - _Put a plan in place for ongoing user research and usability testing to continuously seek feedback from users._\n\nThe research proposals for beta are appropriate, but they do not go far enough. The team need to address the internal DWP barriers to in-home and contextual product research conducted by DWP staff. If they cannot be overcome, there may be a need to consider using external researchers, or locating respondents with relevant conditions who are not customers (i.e. who have not applied and are not proposing to apply). The aim should be to build a significant body of data based on contextual research to sit alongside the data from lab-based usability testing and remote research.\n\nThe research plan should look to segment the sample at a more granular level against the various conditions (or their effects, if this is a more appropriate approach) and systematically recruit against this segmentation. Friends and family should be included appropriately. And more generally, greater numbers of respondents are needed, to more thoroughly encompass the diversity of this audience.\n\nThere may be a need to increase the number of researchers on the team so that the expanded research activity that this product requires can be delivered.\n\n**Recommendations**\n\nIn addition to the above points, the panel suggest that you develop your plans for coding in the open. Though not necessary for the alpha reassessment, it will be important for the beta assessment that you have released all of your code unless there are robust and convincing arguments for not doing so.\n\nAssumptions on assisted digital funding need to be more fully fleshed out, as according to your research report around 70% of existing Disability Living Allowance (DLA) claimants were helped to complete their DLA form by third-parties, including charities and support organisations. Given the complexity, length and invasive nature of the service, user research for the Claim PIP service might show that support routes such as these are required to meet user needs. If so, the service team must ensure that this support provision will be sustainably funded (including any support not delivered by government).\n\n**Summary**\n\nThe panel were impressed by the team, the passion for the service and its users, the agility in adapting methods, and the amount of work the team has done in the short time the project has been running. The service is a particularly tough research and design challenge given the user base. The panel have every confidence that the team can address these issues and pass a reassessment, given more time.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/dvla-webchat-service-assessment/",
    "title": "DVLA Webchat - Service Assessment",
    "summary": "The webchat tool will allow users to interact online with a DVLA advisor to assist them in their online transaction or to provide information to answer an enquiry. The tool will offer live, real-time responses.",
    "body": "**Department / Agency:**  \nDVLA\n\n**Date of Assessment:**  \n4/11/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Gould\n\n**Service Manager:**  \nJ. Hewson\n\n**Digital Leader:**  \nO. Morley\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the DVLA Webchat tool is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nDVLA webchat is the first tool (rather than citizen facing service) to be assessed by Government Digital Service using a service standard assessment. This made the assessment somewhat unusual for both the assessment panel and the service team - particularly as the team’s focus is on integrating a proprietary tool from the supplier into DVLA services. For this reason the panel was particularly interested in how supplier/tool agnostic the approach was - in other words how easy it would be to swap out one webchat tool supplier for another in the future if required. Whilst the panel still retains some concerns, the general approach is satisfactory.\n\nA comprehensive list of recommendations are set out below to guide the team as it prepares for and develops the beta phase of the tool's development. The service team must work to meet the recommendations set out below before the beta assessment.\n\n_User research_\n\nThe team demonstrated a good grasp of the context of the problem, and volumes of incoming calls which they aim to address with the webchat tool.\n\nThe team have used a range of research techniques so far, including focus groups, surveys, lab-based research and contextual research. They have successfully identified several key groups of users who the tool is aimed at, and particularly picked up on its benefits for deaf users. The panel were encouraged by the team’s identification of the contexts in which users will engage with the tool.\n\nThe survey itself presents cause for some concern and is by it’s nature leading. It offers only 3 options, and should be viewed as confirming business need, rather than establishing a user need. Although out-of-scope for the webchat tool, the real research question should be why users can’t find what they need online and have to resort to further contact in the first place.\n\nThe team showed solid user personas including web usage and support needs and demonstrated an ability to separate true user needs from business needs.\n\nThe team presented a comprehensive plan for research up to April 2016 and has identified a need to research what answers customers expect and require.\n\n_Design_\n\nThe team demonstrated how paper prototypes were used to get an initial understanding of the problems and to explore what users expect. The team has tested a variety of approaches for the call-to-action to initiate the chat tool. However, these have all relied on an icon or imagery. Different designs have been mocked-up for the chat interface, although these haven’t been worked into the prototype or tested with users yet.\n\nIn beta the team need to interrogate the chat interface in a lot more detail; relying on the default behavior of the supplier’s solution may not be the best approach to meet user needs.\n\n**Recommendations**\n\n_The team_\n\nThe current structure and remit of the team appears to be set up to deliver a programme of work, including the webchat, rather than the tool specifically. The panel would recommend splitting the larger team into teams focused on specific products. This will allow the team to develop the product at a cadence suitable for them rather than a wider programme. The panel does not believe that a common cadence will work in the beta phase.\n\nSimilarly the current approach to sprints and ceremonies should be changed to support the development of the tool. Whilst the team is nominally working on four week sprints (which the panel believes are too long for the current development phase), two weekly showcases and retrospectives suggest that two weekly sprints would be more appropriate. Rationalising a smaller team to focus specifically on the integration of the tool will allow the team to build cadence more appropriately.\n\nWhilst the team were able to indicate that they had considered the possibility of changing to an alternative provider of webchat services in the future, the panel will want to be satisfied at beta assessment that this approach is truly platform-agnostic and capable of being easily adapted to an alternative solution provider. A workable migration strategy needs to be developed, demonstrating how platform agnostic the the approach is, and how easy it would be to swap out one solution for another.\n\n_User research_\n\nWhilst the team has demonstrated a solid basis of user needs, the panel recommends the team reworks these into recognisable user needs - the importance being that people on the team (and wider stakeholders) need to be able to see what real people really say and why they say it.\n\nFurther to this, the panel would not recommend using the survey as proof of user need for reasons stated previously.\n\nFor the next phase the team is recommended to:\n\n- Engage with the internal users who will be answering webchat queries. This is a large scale change for the people whose day job will be to answer the queries.\n- Research what happens when webchat is not available. It’s important to gain an understanding of what users expect to happen if they are unable to use the tool.\n- Address what happens if a problem can't be solved in chat, looking at how long this process takes before handoff, and what the user reaction is when this happens.\n\n_Design_\n\nAlthough the team had tested many variations of the call-to-action, it had not been tested without an icon or imagery. It is recommended that the team test a text-only call-to-action as this follows the advice in the service manual.\n\nAs variations on the chat interface have not been tested it is recommended the team test different ways of accessing and interacting with the chat agent.\n\nOpening new windows to display the chat interface is not recommended as this introduces usability issues, especially with users with low digital skills, or users on mobile or assistive technology devices. If the team decide to use this route there must be strong evidence demonstrating that users of these devices are succeeding to use the tool.\n\nThe chat interface will need to be strenuously tested for accessibility issues, over a variety of assistive technologies. The team has already worked with the Deaf Association and should continue to work with similar groups to observe users with different needs and abilities using the tool.\n\nOnly services hosted on GOV.UK are permitted to use the crown and typeface. Users need to be able to verify that they are talking to government through trusted channels, so it is recommended that the service is accessed via a service.gov.uk subdomain.\n\n_Technical_\n\nThe webchat solution is based on a product that has been acquired through the Digital Marketplace after various options were considered during discovery. The product is not open source and does not use open standards for data interchange. As such, suitable diligence during all phases of the project is recommended to avoid being trapped by vendor lock-in. DVLA needs to prove that business critical data can be exported without loss and in a useful way that could be used to transition customer contact histories to another solution before going into a large scale beta with real users. This recommendation is vital if other projects in the call centre also begin integrating with the supplier as part of a unified Customer Relationship Management (CRM) effort within DVLA.\n\nSince the tool’s back-end is provided by the supplier's platform, minimal software development has been required in-house to integrate the tool into DVLA’s service flows. However, some customisation has been performed, largely by the supplier's team working with DVLA. The DVLA team assures us they own the intellectual property and that some supplier development capability will be built up in house to take ownership of these changes. The panel expects this to happen during beta.\n\nCustomisations to the platform, and changes to markup and styling of the chat window are made via the supplier's admin interface. This raised some concern around the level of version control available and testing that could occur, to ensure bugs or regressions aren’t introduced by any changes or supplier's regular release process. The team stated a testing environment was available, and that manual testing takes place on each new release. We recommend the service team look at approaches to test the chat window functionality in an automated way.\n\nThe service team intends to publish supplier customisations, metadata, markup, and styles on GitHub where possible for other teams to re-use if they need a similar chat solution. The panel expects this to happen before beta assessment.\n\nThe assessors noted that the pop-up chat window is currently not served by a GOV.UK service domain URL. This raised some concern around user trust, and whether the New Transport typeface and the crown logo could be used were this to remain the case. DVLA should approach the supplier and investigate if a custom domain ending in service.gov.uk can be used to serve the chat window (such as via a CNAME in DNS) and if not, confer with GDS around correct use of these assets and branding.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/pensions-tracing-service-service-assessment/",
    "title": "Pensions Tracing Service - Service Assessment",
    "summary": "The Pensions Tracing Service provides a trace facility for customers to contact work based and personal pensions providers using The Pensions Regulator database.",
    "body": "**Department / Agency:**  \nDWP\n\n**Date of Original Assessment:**  \n27/4/2015\n\n**Date of Reassessment:**  \n30/6/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Original Assessment:**  \nNot Pass\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nT. Scott (Original) / S. Wood (Reassessment)\n\n**Service Manager:**  \nD. McLaughlin\n\n**Digital Leader:**  \nK. Cunnington\n\n* * *\n\n## Reassessment Report\n\n**30th June 2015**\n\nAfter consideration, the assessment panel have concluded that the Pensions Tracing Service is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe Pension Tracing Service team have shown a good understanding of the needs and challenges their users face sourcing information on the pensions they may have. The development of a single overarching user need (‘As a user I need to find contact details for my pension funds so that I can contact them to gain access to my pension’) has helped to focus the hard work on building a simpler service.\n\nThe service team have developed a deeper understanding of the current pension environment and understand the technological challenges in connecting users to the different scheme administrators.\n\nThe Pension Regulator (TPR) is now fully engaged and working collaboratively with the service team to deliver a reliable and straightforward solution to share the details of pension schemes they hold.\n\n_User needs and research_\n\nThe team have continued research with users, completing more testing and listening in to more calls to gain insight into their users’ needs. It is good to see more defined user needs and this has already been reflected in the name of the service ‘Find contact details of a pension’; this matches the outcome a user would expect. It was also good to see that research at this stage has not been limited to just the services themselves but those that support users in the government and beyond. These insights are key to the success and take-up of this service. Some insights, such as almost 20% of users searching for more than one pension, will help to shape the design of the service appropriately, others such as the needs of older and lower digitally skilled users will continue to be a challenge.\n\nThe focus for research in the beta development stage should be around measuring the success of users in contacting scheme regulators with follow up calls and interviews. Ideas like using diaries are good for providing detailed insights.\n\n_The team and delivery_\n\nThe team is well equipped with a good balance of different skills and roles. The move to Newcastle and co-locating has clearly increased the team's confidence and helped in engaging stakeholders. The further development of the relationship with TPR has helped to influence their roadmap for technology, and ensured that information is accessible and being cleansed with feedback from the current service. This will increase the accuracy of the schemes database. All the standard roles are represented in the team, and the team is sized well for the type of service being delivered. The addition of a dedicated analyst will help to set benchmarks and give useful insights once the service is more readily available.\n\nThe approach to agile is commendable, flexing a variety of approaches (SCRUM and Kanban) dependant on the type of work at hand. The new BA is helping to bring focus to this and the team now have a better understanding of the speed of delivery. The latter part of the alpha has focused on a technical solution using a more SCRUM approach while working with TPR to understand how data is shared. The team are using JIRA to track their development and using weekly design checkpoints to ensure consistency across the service.\n\n_Technology, information and security_\n\nThe digital service is a highly complex but it is good to see the recent focus around the backend of the service, this being the most technical aspect. Guidance from the DWP digital blueprint has been used to to build the service; the team is feeding back into the blueprint and challenging it where appropriate. The next technical challenge will be around integrating TPRs web services to provide live data, good progress has been made understanding in analysing the quality and scope of the data that will be available.\n\nLegislation for this service requires that a name and e-mail address is taken from each user but not used for any purpose within the service itself; this adds unnecessary complexity to user journeys and creates additional concerns around securely storing these details. Challenging and changing this legislation will be important in simplifying the service for users and the team alike.\n\nThe information presented to users will be a subset of the data from TPR, with the addition of some business logic to fine tune the number of results, and present a clearer list to users. Where this logic sits eventually (with DWP or TPR), still needs to be decided. The data will be shared using RESTful JSON APIs, and some thought has been given towards potentially building these in a way that can be re-used by third parties.\n\nThe service is not currently business critical but some security aspects have been put in place to strengthen it; as a public register of information the level of security is appropriate. There are business continuity plans in place for increased traffic to contact centres. There are no sensitive aspects to the code, so effort should be made to code in the open and share as much as possible with the rest of DWP, government community and third parties.\n\n_Design and experience_\n\nHaving both user experience and content designers on the team has ensured that the design of the service is consistent with the rest of GOV.UK. Some of the content may not follow guidelines; and while this was sufficient for the alpha prototype, this should be addressed during the beta phase.\n\nMultiple layouts have been tested with users, leading to a simplified design that aids navigation through the service, and allows users to move back and forth between searches and results. There may be need to refine the results further. Some searches still end in users being directed to the existing service and the hand off is not very clear or smooth. The expectation of some users was to see the value of their pension at the end of the search, but work on the content has helped to realign users expectations.\n\nSome work now needs to take place to plan with the GOV.UK content teams; having a soft landing page for the service is useful for the prototype but could be repetitive for users. It may be better to reduce the number of users entering the service by clearly stating on GOV.UK where users searching for private and public service pensions can find help.\n\n_Measuring success_\n\nMeasuring the success of users through the service is vital to understanding the impact of changes to the design. The service team has a good understanding of the current service and are able to map that clearly with time to completion, dropouts and success rates. The aim for the early part of the beta is to complete follow up interviews to measure the success users have in contacting pension scheme administrators. Efforts to make the data comparable across different channels should continue to show where this digital service is impacting the current telephony service.\n\nFor the beta there needs to be a measure of when contact details are incorrect and more work to demonstrate how the service presents information to the Performance Platform rather than taking a ‘wait and see what others do’ approach.\n\n**Recommendations**\n\nDuring the beta development of this service the team should consider the following:\n\n- If legislation does not change, the service should ensure that the user’s name and contact details are collected within the service, and that the user will not be required to add these details again when contacting the pension scheme administrator.\n- Develop a feedback mechanism that is easy for users to advise when contact details are incorrect.\n- Link up with the user research that is happening with the GOV.UK team on pensions and continue research into the end-to-end journey for users (follow up interviews, diaries etc.)\n- Work with other organisations to encourage the use of the digital channel as the first place to search rather than over the telephone.\n- Ensure user research extends to the complete user journey (through to users contacting scheme administrators).\n- Understand the impacts of this service not being available across the rest of the business.\n- Continue the open and flexible approach to technology and code in the open.\n- Tracking searches that return no results will be important to understanding how real users search.\n- Measure the usage levels across the different channels of the service to measure its effectiveness.\n\n**Summary**\n\nIn a short period of time the service team have delivered a considerable amount of work. They are now joined up closely with The Pension Regulator and have a firmer understanding of the dependencies in their differing work streams. It’s encouraging to see that the team continues to work in an agile manner, flexing different approaches for the specific tasks at hand. By co-locating the team appear more aligned and confident. With the challenge of changing legislation ahead, which the panel supports, and delivering this service during that period, the team have a lot to deliver in the beta stage. The panel are confident that the team have made a good start to that process.\n\n* * *\n\n## Summary of Original Report\n\n**27th April 2015**\n\nAfter consideration the assessment panel has concluded that the Pensions Tracing Service is not yet on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe Pension Tracing Service team did not show sufficient evidence of a full understanding of the issues that users face when trying to find lost pension details. The service team have completed a great deal of usability and user testing with the GOV.UK front end tool kit, mocking up potential layouts for the service.\n\nPlans for the delivery of the service are built upon The Pension Regulator agreeing and delivering access to their database. While the assessment panel were reassured that this would happen, there was no agreement in principal on the timescales or the method of delivery.\n\nThere had been little work done in building a technical solution for the service, instead relying on the future delivery of a DWP common platform. This is a risky strategy for there may be delays to that delivery. While there have been conversations with The Pension Regulator, there is no agreed plan to deliver the data.\n\n_User Needs and the Team_\n\nThe service team have completed a great deal of research with 18 users in a lab environment and pop up testing with users in a local library. All were rated against the digital inclusion scale with some showing low digital capability. The service team also listened in to calls at the contact centre to develop a greater understanding of the language of users and the operation behind the current service. Most of the users for the service will be aged 45 and above, with the users being directed to the service from many other sources. The service team were unable to articulate a defined user need this service is looking to meet, but were able to identify a number related to the service, for example “how much money will I have when I retire?” or “do I have a lost pension?”. The research so far has shown that users do not understand the difference between pension plans.\n\nThe team are well placed to deliver a service, being colocated and having the different skills needed to deliver a digital service. The panel was pleased to see that a content designer is now part of the team. Analytical support will be provided by a central department team, however it would be advisable to colocate these specialists. The leadership of the service follows the Scrum type methodology, however the panel were unsure exactly how the decision making process will work day-to-day. The team are following related ceremonies of Scrum, with daily stand-ups and show and tells for stakeholders encouraging weekly knowledge sharing among the team. Priorities are set in the sprint by the product owner with the priority of delivering the Minimum Viable Product (MVP).\n\n_Security, Privacy, Tools and Standards_\n\nThe data that drives the service is not owned by the service team, but rather by The Pension Regulator, and currently there are no straightforward ways to improve the database. The plan is to use an Application Programming Interface (API) to access the data, which The Pension Regulator will design and provide to the service team. This arrangement will require the regulator to match user search data and deliver a reliable and fast connection to the API. The agreement between the organisations has yet to be made, although this is fundamental to the service and the functionality it will be able to provide.\n\nThe service will be built upon the upcoming DWP blueprint platform for digital services. This platform has yet to be delivered and the team are working ahead of the delivery. The demonstrated service was built using the GOV.UK front end tool kit using static information. The team were unable to demonstrate connecting an API for the search (even if they hosted that API themselves). The service will only be presenting information and will present a low security risk. The service plans to use open technology tools and platforms (HTML, JSON, Java and rest APIs) which will allow the team to adapt the service quickly, and use automated testing and continuous integration. There is a plan to share the code for potential reuse, and there are no expected barriers to this.\n\nThere is a Senior Information Risk Owner (SIRO), and the delivery manager is currently the information asset owner until the service goes live, at which point the service manager will assume this responsibility. There are currently no plans to store any data from the service (although the demo gave the option to ‘save’ results which will need further exploration). As such security plans are appropriate. Cookies will be kept just for the session, however there are some thoughts to sharing a reference number for searches with users who may need to follow up enquiries by telephone. If the option to improve the database exists, this information could be fed in. There is no identified need for verification of identity.\n\n_Design_\n\nThe prototype has been built using the GDS prototyping kit and therefore has the correct base style for GOV.UK pages. It has also been iterated based on user research. However the prototype diverges from GOV.UK style in many places (e.g. line lengths, extensive use of togglable help and hidden information, page numbers, back buttons, multiple Next buttons per page), and the language used is that of pensions specialists and DWP rather than that of mainstream users. It is hard to design, prototype and test the main task of finding the right item in the database without real data or knowledge of how the matching algorithm will work. The team has not explored a range of ways for users to find their information.\n\n_Assisted Digital and Digital Take-up_\n\nThere was some useful testing of the prototype service with users who have low digital literacy, however it was not clear from the research what the support needs were for those who have difficulty using digital, and the impact of potentially disadvantaging them by pushing them to another channel. It was encouraging to see that the team had identified some third party providers (such as Age UK and Citizens Advice Bureaux (CAB)) who also provide pension support, but there had been little or no dialogue with those providers to better understand the scope of users needs and what is currently being provided by them, nor a plan in place for Beta. This should have happened before the end of the Alpha. There was a presumption at the assessment that assisted digital would be provided centrally by DWP through the current infrastructure (Jobcentres for example). However it is not clear that users will expect or want to use those channels for support, nor was there a plan in place to test them. The potential future reliance on telephone support conflicts with the expected growth in the demand for the service, potentially making the triage of those with assisted digital needs harder.\n\nThe digital take-up of the current service is around 77% with a plan to increase that to 80%. This does appear challenging enough based on potential future demands. The team believe there is a potential limit to the use of the digital service as the searches for information become more complex or difficult to trace. It is important for the team to understand the barriers to users in the current service, and make steps to ensure that the digital service is the first place users are directed to; from there they can access other channels as needed.\n\n_Analysis and benchmarking_\n\nCurrently there is no remote analytics tool in use on the mock-up service, however the lab testing environment has proven useful in identifying issues with the service, leading to subsequent iterations. The baseline Key Performance Indicators (KPIs) have been set from the prior email based service. This is a useful place to start, however one of the stated aim of the service is to reduce the dependence on the contact centre for the most straightforward searches, so more thought should be given to this in the Beta. The current measure of completion is difficult to quantify because the service can not be certain that all users make successful contact with their pension providers. This is something the service team should work on in the future. It was good to see that the service team had made contact with the Performance Platform team, and there are discussions taking place to build a dashboard.\n\n**Recommendations**\n\nThe team should look more closely at a number of key areas:\n\n- The team must make a firm agreement with The Pension Regulator to provide the data in an agreed format.\n- Investigate if The Pension Regulator development team and the DWP Pensions Tracing Service team can be colocated and work together off one backlog.\n- The need to start building the solution to address technical risk even if this will be replaced so that the team can demonstrate the ability to deliver the product.\n- The need to rebalance the delivery team (there are currently 3 business analysts feeding in to 2 developers).\n- Research should be completed with third party assisted digital providers to understand the needs of assisted digital support, not limited to testing of the on-screen elements of the service.\n- User research should conclusively provide a coherent user need in which to judge the success of the service. The naming of the service should be in line with the user need and what outcome the user will have.\n- Testing of the service needs to go beyond the front end tool kit and prescribed scenarios. It would be useful to have a copy of the database to search with, so real users can find real results.\n- Explore other ways of presenting this information, including working with the GOV.UK team. A finder supported by a guide may be better provision for the user than a separate service.\n- If a service is appropriate, look at how to help users actually find their pension i.e. contact with pension providers.\n- All design and content design needs to be reviewed against GDS design patterns and content design style guide.\n\n**Summary**\n\nEncouragingly the service team has built their approach on the agile manifesto using a mixture of Scrum and kanban to deliver the prototype. The efforts to continuously test the service with users has begun to reveal the complexity of user's needs around understanding pensions.\n\nThe central issue the assessment team identified was the ability to access and improve the database the service is being built upon. If this stays the same the team will not be able to improve the quality of results for users going forward. There is a potential risk to service stability and availability from being reliant on a third party. Also, if the needs of the users or the service change, it will be very difficult to change the methods of accessing the data, and this will lead to a reduced ability to develop features. Not having control of the database could potentially lead to a higher contact rate with the telephone contact centre, something this service is looking to reduce.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/nhs-111-service-assessment/",
    "title": "NHS 111 - service assessment",
    "summary": "NHS 111 is a service that gives patients the ability to triage themselves as an alternative to the NHS 111 telephone number. The service uses a 'symptom checker' system using clinical content approved by the British Medical Association and the Royal College of GPs.",
    "body": "**Department / Agency:**  \nDH / NHS\n\n**Date of Assessment:**  \n03/07/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nA. Lister\n\n**Service Manager:**  \nT. Yates\n\n**Digital Leader:**  \nA. Bye\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the NHS 111 service is on track to meet the Digital Service Standard at this early stage of development.\n\n**Overview**\n\nThe team demonstrated a thorough understanding of the clinical and technical complexities of what is essentially a self-diagnosis service with substantial associated risks. The team is fully aware of the potentially life-threatening impact of an error or fault.\n\nThe delivery team is complete in terms of skills and experience and appropriately funded to take the service into beta development.\n\nThe methods of working evidenced by the team are in line with agile best practice set out in the Government Service Design Manual.\n\n**Reasons and Recommendations**\n\n_User needs_\n\nGiven the purpose of the NHS 111 telephone service is well understood by the majority of its users, giving the digital service the same name may confuse users. The purpose of a digital service should be obvious from its name. Although it’s anticipated that the digital service will operate alongside the current telephone service, the team should consider how it will differentiate the two and create a specific identity for users unaware of the phoneline.\n\nThe assessment panel felt that ‘waiting times in A&E’ and ‘parking at the hospital’ would not be at the forefront of users’ minds. The headline need from the panel’s personal experiences of NHS 111 seemed to be “I’m not well, do I need medical attention? If so, what type and where/when can I get it?”\n\nThe service team understood that an online service would likely appeal to users with mental health issues, and users wishing for extra privacy. The service team should also address the possible extra challenges an online service will present to these users.\n\nA thorough research plan, focussed entirely on users rather than potential savings and channel shift, is essential to further development of the service. The team needs to give this careful consideration and should not underestimate the scope of the research required.\n\nIn addition to independent users, considerable work is required to identify and evidence the needs of users who will need support to use the on-screen service (aka assisted digital users). The presence of the existing telephone service is not appropriate support for users trying to use the digital service. Helping those who’d otherwise be unable to use the service needs to be considered in some detail. Support must be specifically designed for the users of this service.\n\nThe service team must ensure that the process of finding the service, and then seeking and receiving help to complete it, does not cause excessive delay in the receipt of potentially critical clinical advice.\n\nThe service should also be clear about the difference between training NHS staff to help users develop their digital skills (‘digital inclusion’), and providing the immediate support that some users will need to complete the service (‘assisted digital’).\n\n_Service design_\n\nThe service needs to be designed to consider the journey from the point of need for medical help to the fulfilment of that need. The team has been doing good work testing with real users in medical centres but this needs to be widened to consider the steps outside of using a computer to access the service.\n\nSeveral content designers and a content lead are part of the team and they are responsible for the content being in plain english. The content lead has a clinical background so is empowered to challenge that aspect of the language. The team also has a creative director who is responsible for the end-to-end design and three of their developers specialise in front-end development.\n\nThe service is not on GOV.UK so does not need to meet the GOV.UK design consistency requirements set out in the Digital Service Standard.\n\n_Iteration and improvement_\n\nAlthough all of the necessary skills and components are in place for iteration and improvement - and a ‘pass’ has been awarded - the complexity of the clinical rules will impact the ability to actually do this. The team needs to formulate a test and release approach that ensures that the public facing service remains accurate and comprehensive at all times within the context of rapid iteration.\n\n_Test the end-to-end service_\n\nIn terms of the accuracy and usefulness of the service, objective research is unlikely to be possible without ‘the whole thing’ being in place, including support for users who can’t use the on-screen service independently. There is no simple, deliverable Minimum Viable Product. This presents a substantial challenge given the massive complexity of the underlying clinical rule base.\n\nAbstracting users with specific conditions that match the portion of the service available at any given time will not reproduce the stressful and emotional context in which this service would be used.\n\n**Summary**\n\nThe assessment panel recognised that the team is working with hugely complex clinical rules and a service that can actually mean life or death for its users. The team is well resourced and has the right skills and experience to produce and iterate a valuable, useful and usable service. The panel looks forward to seeing how the team addresses the recommendations made as a result of this assessment.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | No |\n| 11 | Yes | 12 | No |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/guaranteed-minimum-pension-alpha/",
    "title": "Guaranteed Minimum Pension - Alpha Assessment",
    "summary": "The Guaranteed Minimum Pension service will allow&nbsp;Pension Scheme Administrators to calculate a member’s guaranteed minimum pension after [contracting-out ends](https://www.gov.uk/government/publications/new-state-pension-information-for-employers-and-trustees-with-open-contracted-out-defined-benefit-pension-schemes).",
    "body": "**Department / Agency:**  \n[HM Revenue & Customs (HMRC)](https://www.gov.uk/government/organisations/hm-revenue-customs)\n\n**Date of Assessment:**  \n27 October&nbsp;2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. Knight\n\n**Service Manager:**  \nN. Cranston\n\n**Digital Leader:**  \n[M. Dearnley](https://www.gov.uk/government/people/mark-dearnley)\n\n* * *\n\n## Assessment Report\n\n### Summary\n\nThe panel consider the Guaranteed Minimum Pension (GMP) service to be on track to meet the Digital Service Standard at this early stage of development.\n\n### Detail\n\nThe panel were impressed by the work presented by the service team. There was evidence the team are prioritising user needs and working in an agile manner. The panel were pleased to hear the team has such a good balance of roles and skills at this stage of development.\n\nThe alpha presented was a front-end demo and the team had thought through their approach to the architecture of the service. As part of their approach the team are planning to use some existing services, such as Government Gateway and HMRC environments.\n\nThere is no requirement to make provision for assisted digital users for non-transactional services, such as this calculator. If the service expands to become transactional, the team must develop assisted digital support to meet user needs.\n\n### Recommendations\n\nThe team should use the private beta phase to continue to develop the service. In particular, the panel recommends the team:\n\n- research the name for the service with users, considering a more self-descriptive name;\n- continue to test pension specific terminology with users;\n- as planned, monitor the potential demand for a bulk service during the private beta to provide evidence for a decision on whether to include this option in future iterations;\n- develop an approach to handling errors (for example when a user enters correct details but the system can’t return a result) and to dealing with queries from users on the data the service provides;\n- deliver and test messaging for times when the service is not available (e.g. between 3am and 5am or during planned outages);\n- test and consider what other services or GOV.UK information users of this service may want to be directed to;\n- clarify their deployment process;\n- ensure that there are members of the team with WebOps skills in the next phase;\n- consider the interim approach of a squid proxy, and its security implications, while the DES API is not available and confirm what the approach for this will be in public beta;\n- ensure that they are evaluating code for sharing;\n- implement Analytics and discuss (as already scheduled) a page for this service with the Performance Platform team;\n- ensure that they are able to report the cost per transaction of the service;\n- although the changes in 2016 will drive some users to this service, the team should use user research to develop a plan to actively promote the new service and increase digital take-up.\n\nDesign feedback will be shared separately.\n\n* * *\n\n## Digital by Default Service Standard Criteria\n\n| **Criteria** | **Result** | **Criteria** | **Result** |\n| 1 | Pass | 2 | Pass |\n| 3 | Pass | 4 | Pass |\n| 5 | Pass | 6 | Pass |\n| 7 | Pass | 8 | Pass |\n| 9 | Pass | 10 | Pass |\n| 11 | Pass | 12 | Pass |\n| 13 | Pass | 14 | Pass |\n| 15 | Pass | 16 | Pass |\n| 17 | Pass | 18 | Pass |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/service-manual-service-assessment/",
    "title": "Service Manual - Service Assessment",
    "summary": "The guidance in the service manual provides the information to help teams meet the digital service standard.",
    "body": "Core users of the service are:\n\n- Teams delivering services in government (for example, developers, user researchers, service managers)\n- People supporting teams to deliver services in government (for example, portfolio managers, people teams, procurement teams)\n- Suppliers to government\n\nThe manual is also used by:\n\n- People working in digital in other governments (for example the US and Australia)\n- People working in local government and Parliament\n- And more widely than that, for example people working in digital outside outside of a government or public sector context\n\nThe new product will replace the guidance contained in the existing service manual.\n\n**Department / Agency:**  \nCO / GDS\n\n**Date of Assessment:**  \n17/11/2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nT. Dolan\n\n**Product Manager:**  \nH. Garrett\n\n**Digital Leader:**  \nC. Ferguson\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Service Manual is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service team have been conducting extensive user research, during both discovery and the alpha stage of the project. A variety of different research techniques have been used, and many prototypes for testing have been created. It was impressive that nearly 200 users, including those from beyond GDS and the immediate digital community, have provided input to this critical guidance resource during alpha. The team have also adapted the proposition of the service manual based on this feedback, including seeking practical examples to include from across government. Research will continue until the end of the financial year and is expected to include a diary study.\n\nA full, empowered, multidisciplinary team is in place, with clear separation of roles. Five content designers are working under a managing editor. The team is co-located and working using agile techniques (Kanban wall, Trello boards, daily standups, retros) that they have adapted over time based on the needs of their project.\n\nPrototyping was done in github/heroku during alpha and evaluated their beta platform based on the discovered end user and publisher needs. The team will be working on the core GOV.UK publishing platform, which concerned the panel before confirming that the team are capable of making their own amendments to the codebase should GOV.UK’s roadmap change. Security is being considered well for a project at this stage. Compromising any bespoke tools would not also compromise GOV.UK. New code is being made open where appropriate. A proportionate beta support model is being currently considered.\n\nGOV.UK design principles are being used well. The team have added new patterns where these were absent from the standard content toolkit, researching and iterating each as they go. Content designers are revising all guidance and there is sufficient commitment for the move to beta.\n\nThe team are supported by a part-time performance analyst who is helping with the design of custom metrics, such as successful searches and bounce rates. They are being used for benchmarking against the current service before launching features during beta. The team has contacted the performance platform and will be working with them to identify which aspects are relevant to be made public.\n\n**Recommendations**\n\nThe team were able to talk well about many aspects of their work, but will need to concentrate on bringing clearer examples of evidence to the beta assessment. While a user researcher has been committed for beta, no actual research plan was shown to the panel. Questioning led to this being discussed by the team ad-hoc during the assessment.\n\nThe panel would like to see the team be better able to succinctly articulate the user needs for the service, and to demonstrate how their research work generated insights that evolved the team’s understanding of those needs. It was not shown to the panel how separate research outputs led to similar needs that could be safely consolidated into an epic. During beta, difficult prioritisation choices will need to be made, and higher granularity may be needed - for example clearly supporting and engaging users who might unwittingly hamper project delivery.\n\nThere has been no shortage of user research during alpha, and Kanban methods are appropriate during this exploratory phase. However, a more structured roadmap is likely to be needed in order to ensure all of the major strategic questions and risks are addressed in time for the beta assessment.\n\nThe team are making good progress in engaging with the rest of government and ensuring they have a stake in the new service standard. The team mentioned that they were aware from research that the Service Manual is also used in departments as a tool to communicate with wider stakeholders, for example traditional technology and governance functions. In beta it will be important for the team to have demonstrated clearly the research they have done with these users, and how the insight gained has influenced the service.\n\nThe team have benefitted from close association with senior leaders in GDS, and this has allowed them to proceed without a dedicated service manager. This should be kept under review as the organisation changes over the months towards beta.\n\n**Summary**\n\nThe team have done well to recognise that the service manual has evolved to be a document that has a life across the whole of Government. They should be commended for the volume of engagement and research they have undertaken on such a critical resource to the transformation of public services.\n\nContinue to seek out best practice across digital teams within Government, find the ad-hoc tools departments have created to support the assessment process and use them as indicators of unmet goals. Take the manual out ever further across public service, and carry on bringing back insights to inform GOV.UK in turn.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/civil-service-learning-course-booking-service-assessment/",
    "title": "Civil Service Learning (Course Booking) - Service Assessment",
    "summary": "Civil Service Learning (CSL) runs an outsourced learning portal for around 450,000 users. The main provision is to host generic learning products and enable face to face course bookings. It was designed around 4 years ago and is sub-optimal. CSL is committed to deliver a service that meets Digital by Default standards. The transformation is complex, so to de-risk delivery as the learning contract with current learning providers draws to a close in early 2016 they service team decided to make improvements to the current booking service first.",
    "body": "**Department / Agency:**  \nCO / CSL\n\n**Date of Assessment:**  \n11/11/2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Assessment:**  \nNot pass\n\n**Lead Assessor:**  \nA. Maddison\n\n**Service Manager:**  \nJ. Fitzpatrick\n\n**Digital Leader:**  \nC. Bullock\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Civil Service Learning (Course Booking) service is not yet on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe Civil Service Learning team clearly has the desire and capabilities to deliver a great service, developing, testing and iterating prototypes that address the well defined user needs, but unfortunately is constrained by business needs.\n\nThe team is well structured, with a good balance of skills; it is clearly focussed on continuously improving the way it works, having already made a number of successful, vital improvements in the short time given to it. Changes to planning sessions, decoupling of booking and learning (albeit driven by a business deadline that prevents booking being developed and iterated appropriately), and successfully challenging the supplier are all positive examples of the team being empowered. The team is also fully engaged with the user research and hopefully this level of involvement continues as the service develops.\n\nCrucially, the team is led by a dedicated, enthusiastic service manager who is clearly empowered - allowing the team to make these vital decisions. The governance of the alpha is appropriately light touch. The relationship between the service manager and SRO is highly effective, and the SRO is fully engaged.\n\nThe main concern of the panel was that the redevelopment of the course booking feature of the Civil Service Learning site is being driven by a business need - the end of the existing contract, with a very tight, rigid deadline - rather than by user needs. This is drastically constraining the way the team works.\n\nThe user needs are well understood, as a result of good work undertaken during the discovery phase. However, the findings are being used to prioritise \"re-skinning\" and re-development of an existing set of features, rather than testing approaches to meeting the user needs.\n\nDue to time constraints the team have not managed to do a lot of usability testing. As a result many decisions regarding the design of the solution appear to have been made because they are an experienced research/design team - rather than because ideas have been tested and iterated.\n\nThe physical separation of CSL and the supplier resulted in some concerns for the panel. The process around sign-off of designs prior to implementation by the supplier reduces the ability to get the rapid feedback from users needed to iterate. Research and design taking place in a separate location from the development introduces significant communication overheads. The supplier and CSL team are struggling to engage with the agile working practices together. The panel is concerned about the visibility of what gets deployed, speed of deployment and management of that process. Additionally, some of the supplier’s particular approaches - for example, around a heavy emphasis on manual testing and a lack of continuous integration capabilities - are very concerning.\n\n**Recommendations**\n\n_User Research_  \nMore usability testing of the current prototype needs to be carried out, particularly in user lab sessions. This will enable a focus on meeting the core user needs and exploring some of the complex interaction patterns, rather than replicating features of the existing system.\n\nThe team must to ensure they conduct research with more varied users, for example:\n\n- from the ‘front line’ (for example, staff at the border, in prisons, and in call centres)\n- with access needs (at least 8% of civil servants have a declared disability)\n- those who fall at the bottom end of the Digital Inclusion Scale\n\nAn additional resource to carry out recruitment of the users described above would help carry out the research work to a level which would meet the criteria required.\n\nContinuing to link up with the work being done by the CTS team would further help reach out across government.\n\nWhilst assisted digital support does not need to be provided for internally-facing services, if the scope of the service changes the user base, the team may need to undertake research with assisted digital users and design, test and provide appropriate support.\n\nThe current service excludes a lot of civil servants who either do not have the ability to use it, or who work in departments that prevent access to online learning, either through network restrictions or simply through the age of the IT equipment and software available to them. The team should consider how it could help those who currently struggle to access the service and increase take-up across the civil service.\n\n_The Team_  \nManaging work across the CSL team and the supplier needs significant improvement, with communication needing to become more dynamic. The panel would want some assurance that the outputs of research and design get fed back into development.\n\nThe supplier must become more engaged in the agile process, working with CSL as a single team. Sprints, planning sessions, and daily stand-ups should be aligned, with representatives of both in attendance.\n\n_Analytics_  \nThere is good use of data, for example, from Google Analytics, but the panel is concerned that the use of Management Information (MI) requires various handovers, and is focussed on reporting up to senior management. The panel recommends that the CSL and supplier teams integrate more closely with the MI team, such that data can be used more effectively to improve the service.\n\n_Design_  \nSome new design patterns have been created for the service. Once further user research and iteration has happened, these should be contributed back to the wider government design community.\n\n_Open Source_  \nNo additional components of this platform are currently open source, and there is no policy to open source components. The panel requests that the team develop an open source policy, and open source components from the beginning of the project. It will be significantly easier to open source components now, rather than later in the project.\n\n_Open Standards_  \nThe panel recommend that the booking system should prevent suppliers being able to upload proprietary document formats, in line with government policy on the use of open document formats.\n\n**Summary**\n\nThe Course Booking component of Civil Service Learning is unfortunately constrained by business driven timescales, and this is impacting on the team’s ability to deliver a user-centred prototype. However, the team clearly has the leadership, desire and capabilities to develop, test and iterate services in line with the standards we would expect at this stage.\n\nWith appropriate time to develop and iterate designs based on feedback from significantly increased research and testing, the team would be more than capable of delivering a great, user-centred service based on the well researched user needs.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | No |\n| 3 | Yes | 4 | No |\n| 5 | Yes | 6 | No |\n| 7 | Yes | 8 | No |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | No |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/dvla-webchat-service-assessment/",
    "title": "DVLA Webchat - Service Assessment",
    "summary": "The assessment looked at a web-chat tool that DVLA developed to put on online services. Web-chat allows the customer to select the option of direct live online communication with a DVLA advisor instead of having switch channels to telephone the call centre, or submit an e-mail enquiry.",
    "body": "This alpha assessment was based on a prototype and the service team demonstrated the tool attached to the ‘Take a registration off a vehicle’ service. This was simply to provide context on how the tool will be used, but the service itself was not assessed just the web-chat tool.\n\n**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n4/11/2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Gould\n\n**Service Manager:**  \nJ. Hewson\n\n**Digital Leader:**  \nO. Morley\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the DVLA webchat tool is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThis is the first tool (rather than citizen facing service) to be assessed by Government Digital Service against the service standard. This made the assessment a bit unusual for both the panel and the service team - particularly as the team’s focus is on integrating a proprietary tool from Salesforce into their services. For that reason the panel was particularly interested in how supplier/tool agnostic the approach was - in other words how easy it would be to swap out one web chat tool supplier for another in the future if required. Whilst the panel still retains some concerns, the general approach is satisfactory.\n\nA comprehensive list of recommendations is set out below to guide the team as it prepares for and develops the beta phase of the project. The service team must work to meet the recommendations set out below before the beta assessment.\n\n_User Research_\n\nThe team demonstrated a good grasp of the context of the problem, and volumes of incoming calls which they aim to address with the web chat tool.\n\nThe team have used a range of research techniques so far, including focus groups, surveys, lab-based research and contextual research. They have successfully identified several key groups of users who the tool is aimed at, and particularly picked up on its benefits for deaf users. The panel was encouraged by the team’s identification of the contexts in which users will engage with the tool.\n\nThe survey itself presents cause for some concern and is by it’s nature leading. It offers only 3 options, and should be viewed as confirming business need, rather than establishing a user need. Although out-of-scope for the webchat tool, the real research question should be why the users can’t find what they need online and have to resort to further contact in the first place.\n\nThe team showed solid user personas including web usage and support needs and demonstrated an ability to separate true user needs from business needs.\n\nThe team presented a comprehensive plan for research up to April 2016 and has identified a need to research what answers customers expect and require.\n\n_Design_\n\nThe team demonstrated how they had used paper prototypes to get an initial understanding of the problems and to explore what users expect. The team has tested a variety of approaches for the call-to-action to initiate the chat tool. However, these have all relied on an icon or imagery. Different designs have been mocked-up for the chat interface, although these haven’t been worked into the prototype or tested with users yet.\n\nIn beta the team need to interrogate the chat interface in a lot more detail; relying on the default behavior of the supplier’s solution may not be the best approach to meet user needs.\n\n**Recommendations**\n\n_The team_\n\nThe current structure and remit of the team appears to be set up to deliver a programme of work, including the webchat, rather than the tool specifically. The panel would recommend splitting the larger team into teams focused on specific products. This will allow the team to develop the product at a cadence suitable for them rather than a wider programme. The panel does not believe that a common cadence will work in the beta phase.\n\nSimilarly the current approach to sprints and ceremonies should be changed to support the development of the tool. Whilst the team is nominally working on four week sprints (which the panel believes are too long for the current development phase), two weekly showcases and retrospectives suggest that two weekly sprints would be more appropriate. Rationalising a smaller team to focus specifically on the integration of the tool will allow the team to build cadence more appropriately.\n\nWhilst the team were able to indicate that they had considered the possibility of changing to an alternative provider of webchat services in the future, the panel will want to be satisfied at beta assessment that this approach is truly platform-agnostic and capable of being easily adapted to an alternative solution provider. A workable migration strategy needs to be developed, demonstrating how platform agnostic the the approach is, and how easy it would be to swap out one solution for another.\n\n_User Research_\n\nWhilst the team has demonstrated a solid basis of user needs, the panel recommends the team reworks these into recognisable user needs - the importance being that people on the team (and wider stakeholders) need to be able to see what real people really say and why they say it.\n\nFurther to this, the panel would not recommend using the survey as proof of user need for reasons stated previously.\n\nFor the next phase the team is recommended to:\n\n- Engage with the internal users who will be answering webchat queries. This is a large scale change for the people whose day job will be to answer the queries.\n- Research what happens when webchat is not available. It’s important to gain an understanding of what users expect to happen if they are unable to use the tool.\n- Address what happens if a problem can't be solved in chat, looking at how longthis process takes before handoff. What is the customer reaction when this happens?\n\n_Design_\n\nAlthough the team had tested many variations of the call-to-action, it had not been tested without an icon or imagery. It is recommended that the team test a text-only call-to-action as this follows the advice in the service manual.\n\nAs variations on the chat interface have not been tested it is recommended the team test different ways of accessing and interacting with the chat agent.\n\nOpening new windows to display the chat interface is not recommended as this introduces usability issues, especially with users with low digital skills, or users on mobile or assistive technology devices. If the team decide to use this route there must be strong evidence demonstrating that users of these devices are succeeding to use the tool.\n\nThe chat interface will need to be strenuously tested for accessibility issues, over a variety of assistive technologies. The team has already worked with the Deaf Association and should continue to work with similar groups to observe users with different needs and abilities using the tool.\n\nOnly services hosted on GOV.UK are permitted to use the crown and typeface. Users need to be able to verify that they are talking to government through trusted channels, so it is recommended that the service is accessed via a service.gov.uk subdomain.\n\n_Technical_\n\nThe webchat solution is based on a Salesforce product which has been acquired through Digital Marketplace after various options were considered during discovery. Salesforce is not open source and does not use open standards for data interchange. As such, suitable diligence during all phases of the project is recommended to avoid being trapped by vendor lock-in. DVLA needs to prove that business critical data can be exported without loss and in a useful way that could be used to transition customer contact histories to another solution before going into a large scale beta with real users. This recommendation is vital if other projects in the call centre also begin integrating with Salesforce as part of a unified Customer Relationship Management (CRM) effort within DVLA.\n\nSince the tool’s back-end is provided by Salesforce’s platform, minimal software development has been required in-house to integrate the tool into DVLA’s service flows. However, some customisation has been performed, largely by a Salesforce team working with DVLA. The DVLA team assures us they own the intellectual property and that some Salesforce development capability will be built up in house to take ownership of these changes. The panel expects this to happen during beta.\n\nCustomisations to Salesforce.com’s platform, and changes to markup and styling of the chat window are made via the Salesforce admin interface. This raised some concern around the level of version control available and testing that could occur, to ensure bugs or regressions aren’t introduced by any changes or Salesforce's regular release process. The team stated a testing environment was available, and that manual testing takes place on each new release. The service team should look at approaches to test the chat window functionality in an automated way.\n\nThe service team intends to publish Salesforce customisations, metadata, markup, and styles on GitHub where possible for other teams to re-use if they need a similar chat solution. The panel expects this to happen before beta assessment.\n\nThe panel noted that the popup chat window is currently not served by a GOV.UK service domain URL. This raised some concern around user trust, and whether the New Transport typeface and the crown logo could be used were this to remain the case. DVLA should approach Salesforce and investigate if a custom domain ending in service.gov.uk can be used to serve the chat window (such as via a CNAME in DNS) and if not, confer with GDS around correct use of these assets and branding.\n\n**Summary**\n\nThe panel would like to thank the team for presenting a comprehensive view of the development of the tool and how they plan to deploy it across multiple DVLA services. The panel was impressed by the team’s knowledge and approach and looks forward to seeing them at a future beta assessment.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/pay-penalty-online-service-assessment-2/",
    "title": "Pay Penalty Online - Service Assessment",
    "summary": "The purpose of the Online Enforcement Penalty Payment Service is to provide customers who incur fines with the ability to pay those fines online, in addition to the present offerings of paying by credit/debit cards via DVLA’s Contact Centre or posting a cheque to the Agency.",
    "body": "**Department / Agency:**  \nDfT / DVLA\n\n**Date of Original Assessment:**  \n22/09/2015\n\n**Date of Reassessment:**  \n26/10/2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Original Assessment:**  \nNot pass\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nR. Gye\n\n**Digital Leader:**  \nO. Morley\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Pay Penalty Online service is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nIt was great to hear about the contextual research the team had done, visiting a local library and a sheltered housing scheme to meet low skilled users. The team spoke to these users explicitly about the assisted digital support they would seek for this service.\n\nThere are plans in place for ongoing contextual research with low skilled users to further develop understanding of support needs. The team found that low skilled users often found the device and pre-start page navigation to be the most challenging parts of their user journey.\n\nThe team are investigating different methods to integrate their service with the vehicle tax and off-road notification services to help users meet the ultimate need of driving their vehicle legally.  \nThe team should continue to iterate and test how best to meet this need with users of the service.\n\n**Recommendations**\n\nResearch further with users to understand the full range of support providers they would seek support from. This will enable the team to put together a sustainable, iterable and measurable model of support that covers all users.\n\nRecruit users who cover personas specifically created by the service team for this service. This will give full confidence that the full range of user needs is being understood.\n\nCover support needs whenever researching with users with any level of digital skill, confidence or access - not just those with the lowest levels. This will give a fuller idea of the volume of support required and acknowledges that even someone at 9 on the digital inclusion scale may seek or need support with this (or any) service.\n\nEnsure the model of support covers the full user journey, from before they reach the start page, and including general challenges with technology and web navigation.\n\nWork with the DVLA payments platform team to formalise ways to share research and to get research feedback into the payment platform backlog.\n\nIt would be helpful to hear more about how the research is integrated into the wider product team so that findings can be shared more easily. To facilitate this we would recommend the researcher working on this service spends more time physically located with the rest of the team.\n\nOnce the team have completed additional research across the personas that have been identified, it would be good to understand more about what has been learnt in relation to people’s attitudes towards tax, and how these findings have influenced future iterations of the service, and been shared across other product teams in DVLA.\n\n**Summary**\n\nIt was great to hear about the research that the team have done since the last assessment, the panel would like to thank the service team for their time and well-informed answers to their questions, they look forward to seeing how the service develops.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/pay-penalty-online-service-assessment/",
    "title": "Pay Penalty Online - Service Assessment",
    "summary": "The purpose of the Online Enforcement Penalty Payment Service is to provide customers who incur fines with the ability to pay those fines online, in addition to the present offerings of paying by credit/debit cards via DVLA’s Contact Centre or posting a cheque to the Agency.",
    "body": "**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n22/09/2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Assessment:**  \nNot pass\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nR. Gye\n\n**Digital Leader:**  \nO. Morley\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded the Pay Penalty Online service is not yet on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe assessment team were impressed by the knowledge and enthusiasm of the service team who have achieved a lot in a short period of time.\n\nThe team are working in an agile way, have all disciplines represented in their team and the service has been iterated quickly at this early stage of development. The major technology decisions were appropriate and well explained during the assessment.\n\nHowever, there was not enough evidence that the team had done the right types of research during discovery to understand user needs; particularly the service team haven’t yet spoken to users who have low or no digital skills. The research plan for the next few months is focussed on usability testing which isn’t always the most suitable method, particularly at this early stage.\n\nThe DVLA payment platform is a significant part of the service, and research must show users completing the service end-to-end, including pages the team have less control over, and ‘unhappy’ paths through the payment platform.\n\n**Recommendations**\n\n_User needs and user research_\n\nThe team have so far seen all users fail to complete the ultimate user need - driving a vehicle legally - even if the penalty has been paid. The team should investigate easier integration with taxing a vehicle or making a SORN notification as part of the service.\n\nThe frequency of research and continued commitment to usability testing is not in question. The team have usability testing sessions booked in and budgeted for until December. They have also used pop-up research techniques to test very early ideas and designed and analysed the results of two surveys (one postal and one online) as part of discovery and alpha. But we are less interested in the quantity of user research that has been undertaken, but rather in the quality and coverage.\n\nThe over reliance on usability testing at the expense of other research methods, particularly during a discovery and alpha is something that we recommend is addressed before coming back for a reassessment on points 1 (user needs) and 2 (commitment to continued research). We recommend arranging more contextual research to better understand user needs and perhaps some of the bigger issues around compliance that might be involved. We recommend the service team talks to the user research community if they need any further advice. They may also find the guidance on the user research methods hackpad and the user research blog useful.\n\nThe team need to ensure they are speaking to a representative group of users of the service, including users with low or no digital skills to understand their needs for support. The team had plans to visit the Citizens Advice Bureau to talk to them about how they might reach assisted digital users, but this visit hasn’t happened yet. We would expect the service team to have done research to understand the needs of assisted digital users at this stage of development.\n\n_The team_\n\nCurrently user research seems to be conducted by a separate (albeit connected) team, with reports written and fed into the service team. While it was great to hear that the service team were observing usability testing, we recommend that the user researchers regularly sit with the team to get a better idea of what should be researched, and analyse research with the wider service team, led by the researcher.\n\n_Test the end-to-end service_\n\nThe team must test (both as part of QA and user research) on a wide range of mobiles and tablets, and should consider designing mobile-first.\n\n_Patterns and style guide_\n\nThe designers on the team should contribute to cross-government design discussions, and publish changes to current style on the Hackpad. They should contribute new patterns.\n\nDVLA should look at how to manage styles across services, both from a user interface and development standpoint.\n\n_Performance data_\n\nThe team should work with the DVLA payment platform to understand how to track users through the complete service.\n\nThe team need information on current cost per user for the existing cheque and phone channels.\n\n_Make all new source code open and reusable_\n\nThe team have a plan to open source the subsets of the code they are able to. We encourage them to do this sooner rather than later, and expect to see the code in an open repository before their beta assessment.\n\n_Dependencies_\n\nThe team is aware that dependencies on the payments platform and the legacy workflow solution are critical. Prioritisation of the changes required by Pay a Penalty Online to the shared DVLA Payments service may be at risk due to conflicts with other programmes. This is likely to be a significant schedule risk for the service.\n\n_Technology and change_\n\nThe Digital Service Standard requires that teams are able to make changes quickly. If payment policy rules are to change often then the service must be tested to support this need. Reliance on any particular technology as a proxy for this activity is not helpful. Specifically calling out a rules engine product (drools) as a solution to the user need to be able to react to frequent complex change is unhelpful.\n\nRules in rules engines are just programming languages, with no more ability to change safely than any other. If the change is trivial there are many ways to enact them (a spreadsheet, a properties file, a table). If the change is complex no technology makes the change simple. Use whatever technology is appropriate (taking account guidance about openness) but any particular service quality, especially ability to change, has to be built into the service through design and test activity and cannot be acquired through any specific technology.\n\n**Summary**\n\nThe panel would like to thank the service team for their well-informed answers to our questions, we look forward to hearing about what the service team learn from their research and seeing how the service develops.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/amend-my-driver-record-change-of-address-service-assessment/",
    "title": "Amend My Driver Record Change of Address - Service Assessment",
    "summary": "The AmDR service is responsible for managing all services and channels required to enable drivers to update the details held on their driver record. This includes: change of name/address; replace a lost/stolen licence; renewals and adding/removing entitlements (including passing a test); accounting for 9m transactions per year  \nThe transformation of these services begun with ‘Change the address on your Driving Licence’, which is currently delivered via online, telephone and paper channels.",
    "body": "**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n23/09/2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Assessment:**  \nNot pass\n\n**Lead Assessor:**  \nJ. Hughes\n\n**Service Manager:**  \nD. Ashford\n\n**Digital Leader:**  \nO. Morley\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Amend My Driver Record - Change of Address service is not yet on track to meet the Digital Service Standard at this early stage of development because there has been no user research with users of low digital skills, which is required under point 1 of the standard. The service will need to be re-assessed against point 1 once that work is completed. The panel is looking forward to completing the assessment as soon as the team are ready to do so.\n\n**Reasons**\n\nThe reason the service has not passed at this stage is that there has been no research with users with low digital skills - this is a requirement for point 1 of the service standard for alpha assessment. The team told us that although there are plans in place to carry out research with some users with low digital skills, this has not yet been carried out. This is important because it will enable the team to understand those users’ needs for support and start to make decisions during the beta phase about how, specifically, to meet those needs.\n\nThe service has also not passed point 8 – although there are plans to share code within DVLA, and the team expressed a willingness to make its source code open and reusable, there is no plan in place to do so beyond the DVLA. The team needs to put in place a plan to make all new source code open and reusable, not just within DVLA but also publicly.\n\nThe service passed all other points of the service standard, however the panel has some recommendations to ensure that the service will meet the requirements for a beta assessment.\n\n**Recommendations**\n\nThe panel makes the following recommendations:\n\n_Point 1_\n\nThe team has made good use of existing customer insight data, is doing user research in the DVLA’s research lab, and also at other locations. However the research so far has been focused on script-based scenario testing, with a large reliance on extrapolating findings from customer preferences and feedback on the existing service. This is useful but not sufficient to give the team a full understanding of user needs. This was reflected in the description of the user need the service is designed to meet, which is expressed in terms of meeting legal requirements, rather than real-life user needs that prompt them to use the service. The team should carry out frequent observational testing, where users are not given a script or asked about preferences, but are instead asked to use the service as though they would if they were using it themselves. This will help the team to gain a deeper understanding of user needs in relation to the service.  \nThe team should ensure that when testing with low skilled users they not only assess their interaction with the digital service but also understand the nature and extent of likely assisted digital needs, and feed this back into the development of the service.\n\n_Point 5_\n\nThe team is relying on the development of a platform elsewhere in the organisation - the platform and the service are being developed at the same time. The teams will be colocated but we recommend that the organisation ensure that it has put in place appropriate governance to manage and oversee the interdependencies between these two programmes of work.\n\n_Point 12_\n\nThe service has met the requirements for alpha assessment – the service is using GOV.UK design patterns and style guide, and to that extent it is consistent with other services on GOV.UK. However the panel has some detailed recommendations to help ensure that the service is as straightforward as possible for people to use [the further recommendations were included in an annexe].\n\n**Summary**\n\nThe service meets the requirements for all but 2 of the service standard points for alpha, and we have made recommendations in some areas for the team to focus its efforts to ensure they have a successful beta assessment. The service will need to be re-assessed against points 1 and 8 in order to fully meet the requirements for alpha assessment.\n\nThe team contains all the right skills and is the first that will be fully staffed by DVLA staff rather than external providers. The team has put in place the ways of working that are required for agile delivery. The team clearly demonstrated that there is an opportunity to increase digital take-up and user satisfaction in comparison with the existing service, referencing data and user feedback about the existing service. The team is already at a well advanced stage in deciding its performance metrics for the service, and will be able to benchmark the new service against the existing service.\n\nThe team needs to move from script-based testing and preference-based interviews, to observational user research, and should implement the design recommendations arising from the assessment.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | No |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/amend-my-driver-record-change-of-address-service-assessment-2/",
    "title": "Amend My Driver Record Change of Address - Service Assessment",
    "summary": "The AmDR service is responsible for managing all services and channels required to enable drivers to update the details held on their driver record. This includes: change of name/address; replace a lost/stolen licence; renewals and adding/removing entitlements (including passing a test); accounting for 9m transactions per year  \nThe transformation of these services begun with ‘Change the address on your Driving Licence’, which is currently delivered via online, telephone and paper channels.",
    "body": "**Department / Agency:**  \nDfT / DVLA\n\n**Date of Original Assessment:**  \n23/09/2015\n\n**Date of Reassessment:**  \n23/10/2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Original Assessment:**  \nNot pass\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Hughes\n\n**Service Manager:**  \nD. Ashford\n\n**Digital Leader:**  \nO. Morley\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Amend My Driver Record - Change of Address service has now met the requirements of those points, and is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe team has now carried out user research with users with no and low digital skills, as required by point 1 of the standard.\n\nThe team has now taken a strong and proactive approach to meeting with users of this service who may need assisted digital support. They have got out into the real world to visit users in their own contexts, namely in sheltered housing and in public libraries. The team said that meeting users in these venues enabled them to meet the full range of users with support needs for their service.\n\nThe team met users with all levels of digital skills, confidence and access - ranging from 1 to 9 on the digital inclusion scale - asking all of them about their support needs. All users expressed preferred support options, but the team understood that only those users who need it must have appropriate support options available for them. Users able to complete the service independently should be encouraged to do so.\n\nThe team researched with 23 users who they believed would need assisted digital support. This was carried out using a working prototype of this specific service, and with the specific aim of understanding support needs. The team found that nearly half of these users might seek assisted digital support from friends and family; around a third might call the DVLA, and; around 1 in 10 would go to a third party organisation for face to face support.\n\nThe team found that even the lowest skilled users were able to complete the service unaided once they had been taught how to use the technology and navigate to the start page. The team acknowledged that assisted digital support for the service must include supporting users with such elements of their user journey - ie before they get to the start page, and including general challenges with technology.\n\nThe team now has a plan in place to make source code open and reusable, and the team told us that DVLA as a whole is now proposing to adopt this process. The process will include additional controls, reflecting the organisation’s recent shift to using in-house teams - code will be produced in a private repository, available for re-use within the organisation. It will then be reviewed by security experts prior to its public release.\n\nThe introduction of this process is a positive step forward and seems an appropriate approach to the requirement for the team, provided there is a presumption of publishing built in to the process, and assuming the process can be built effectively into teams’ work processes and schedules.\n\n**Recommendations**\n\nIn respect of point 1, the team should continue to carry out observational research with users with low or no digital skills, and users with high digital skills, to deepen the understanding of user needs throughout the beta stage.\n\nThis should include researching with users seeking support from friends and family to understand their support needs, understanding that friends and family support is not appropriate for government to rely on and appropriate alternatives must be in place. This will enable the team to include these users when putting together a model of support for the service to test in public beta.\n\nThe team should put together a model of support to meet the support needs of users who genuinely need it, with other users being encouraged to use the on-screen service independently.\n\nIn respect of point 8, the team should keep the new process for reviewing and releasing code under review, and continue to develop the process throughout the beta stage of the project.\n\n**Summary**\n\nThe panel would like to thank the team for their attendance at the assessment meeting today, and for the team’s positive response to the panel’s previous recommendations. Congratulations on meeting the standard and good luck in taking the service forward into the beta stage.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/business-properties-rental-information-alpha/",
    "title": "Business Properties Rental Information - Alpha Assessment",
    "summary": "The Business Properties Rental Information service allows users to submit information about a business property to the Valuation Office Authority (VOA); something that users are required to do under statutory regulation.",
    "body": "**Department / Agency:**  \n[Valuation Office Agency (VOA)](https://www.gov.uk/government/organisations/valuation-office-agency)\n\n**Date of Assessment:**  \n31 July 2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nH. Christian\n\n* * *\n\n## Assessment Report\n\n### Summary\n\nThe service team are aiming to digitise the way users submit information about a business property to the Valuation Office Authority (VOA); something that users are required to do under statutory regulation.\n\n### Detail\n\nThe service team are aiming to digitise the way users submit information about a business property to the Valuation Office Authority (VOA); something that users are required to do under statutory regulation.\n\nThis is the first of the digital projects the VOA are undertaking. The panel welcome the VOA’s wider transformation agenda and encourage early thoughts to look at the ways VOA can join up with other departments. One example would be with the Land Registry, to look at the transactions and information that make up the services that government provides.\n\n#### User Research\n\nDuring the discovery and alpha phases, the team have researched the user experience of the current process and identified the major pain points. The team have prototyped both the online form and the offline letter to test ideas and potential solutions. The panel was really impressed with the detailed and knowledgeable information and the demonstrations that the team provided to explain this work.\n\n#### Technology\n\nThe appropriate safety and security measures are in place and the service team clearly explained their technology decisions. The team talked through the preparatory work the developers carried out to understand how they would work with HM Revenue and Customs (HMRC) when building the service on the Tax Platform. The panel were impressed with the approach the VOA team has undertaken to spike their technical solutions in parallel with their design solutions.\n\n#### Digital Uptake\n\nThe team have made creative efforts to reach potential users who might not be able to complete the transaction independently, both directly and by building relationships with third parties. This includes VOA contact centre staff, agents, councils, small business organisations and charities. The team have identified potential support needs for users that are unfamiliar with the requirement or that have English as a second language, and the team have plans to explore needs further in beta. The team are keeping an open mind about whether their existing support provision will fully meet user needs and are exploring working with wider HMRC support.\n\n#### The Team\n\nThe panel was impressed with the way the team is working within the VOA. The team has reduced the number of boards they are reporting to from four to one. There is a strong level of engagement and enthusiasm for the work of the digital team across VOA, with show and tells being extremely popular.\n\nThe team have removed unnecessary questions and information from the new online form and the panel encourage them to continue this work throughout beta.\n\nThe team has already engaged with the performance platform team and have some well considered ideas for measuring the service and reporting data to the performance platform.\n\n### Recommendations\n\nThe team should work closely with HMRC’s Tax Platform team to understand and implement HMRC’s policy to open source by default and code in the open. There are currently no firm plans in place to make all new source code (or specific subsets of the source code) open and reusable. The panel expect evidence of this to be demonstrated at the beta assessment.\n\nIt is important for the team to develop an understanding of the HMRC tax platform and how it works before a beta assessment. In particular, for the team to understand service level agreements (SLA) provided by the platform team, and incident handling and escalation processes. It is also important for the team to understand any trade-offs being made because of the constraints imposed by use of the platform, and the appropriate routes and approaches to requesting new features or flexibility.\n\nThe panel was impressed with the design work on the prototype and particularly the engagement with the wider [government design community on hackpad](https://designpatterns.hackpad.com/). There are some small pieces of design feedback and potential ideas to test, which the panel will send in a separate document to this report.\n\nThe team have received some support from a content designer but recognise this is a gap. The team are planning to recruit for this role and the panel strongly recommend that a content designer is in place at the earliest opportunity. The panel expect to hear how a content designer has worked with the team to improve the form during the beta phase.\n\nThe panel welcome the team’s plan to speak to more users during beta. This will ensure the team are making design decisions based on research and data. This includes understanding more about the needs of users that are unable to use the online form and testing the support and assisted digital approach that will be provided.\n\nIn addition to testing the above, the panel will expect to see a more developed plan for digital take-up at the beta assessment.\n\n### Conclusion\n\nThe assessment panel would like to thank the VOA team for their enthusiasm and their knowledgeable and well thought out questions to our answers. We were really impressed with the team’s approach and look forward to seeing how it develops during the next phase of development.\n\n* * *\n\n## Digital by Default Service Standard Criteria\n\n| **Criteria** | **Result** | **Criteria** | **Result** |\n| 1 | Pass | 2 | Pass |\n| 3 | Pass | 4 | Pass |\n| 5 | Pass | 6 | Pass |\n| 7 | Pass | 8 | Not Passed |\n| 9 | Pass | 10 | Pass |\n| 11 | Pass | 12 | Pass |\n| 13 | Pass | 14 | Pass |\n| 15 | Pass | 16 | Pass |\n| 17 | Pass | 18 | Pass |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/alcohol-wholesale-registration-scheme-alpha/",
    "title": "Alcohol Wholesale Registration Scheme - Alpha Assessment",
    "summary": "The Alcohol Wholesale Registration Scheme service will allow alcohol wholesalers to apply to HMRC for registration in compliance with the [AWRS rules](https://www.gov.uk/guidance/the-alcohol-wholesaler-registration-scheme-awrs).",
    "body": "**Department / Agency:**  \nHM Revenue & Customs&nbsp;(HMRC)\n\n**Date of Assessment:**  \n6 July 2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nA. Lister\n\n**Service Manager:**  \nA. Chadwick\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment Report\n\n### Outcome of service assessment\n\nThe Alcohol Wholesale Registration Scheme is not yet meeting 3 points of the Digital by Default Service Standard for the reasons outlined below.\n\nHowever, given the limited scope of the service presented at the assessment (a service allowing wholesalers to apply to join the register, as opposed to an end-to-end service for confirming wholesalers’ legitimacy), and the early stage of development, the assessment panel concluded that the service is sufficiently on track to meet the standard and can therefore proceed to private beta.\n\n### Panel's Assessment\n\nThe panel is&nbsp;content to allow the service to proceed based on the following:\n\n- There is a valid, overarching user need for the service, and strong evidence that it is something the industry actively wants.\n- There is a well-formed, skilled, multi-disciplinary and agile team in place which is working according to the methods in the service manual.\n- The service team was able to demonstrate that it has used the GDS design patterns and has made many changes to the service during the alpha development, based on learnings from user research, and is providing healthy challenge back to the business about what information HMRC actually needs from alcohol wholesaler.\n- The service team are using the proven technologies that the department is familiar with to deliver the on-screen service - taking advantage of, and contributing to, common components used across HMRC.\n\nHowever, the panel have a number of concerns about the service which the team will need to address in order to pass a beta assessment.\n\nUser Needs\n\nWhile the team has conducted some valuable research during the alpha including remote and contextual research, the work done to date does not go far enough and the panel felt there were gaps in the team’s knowledge of the audience, and of the range of circumstances in which the service might be used. Specifically:\n\n- The criteria used in user recruitment were from the perspective of the service team rather than users, and were all functions of size (e.g. number of directors, number of premises). The existence or relevance of other dimensions has not been explored (e.g. internet confidence, English as a second language). There may be further dimensions among the estimated 20,000 alcohol wholesalers in the UK, yet to be discovered, which may have important implications for service design.\n- A significant part of the audience will be new alcohol wholesalers, estimated to be 4,000 per year (generally these are wholesalers of other products who diversify or switch to alcohol). No research has yet been conducted with this segment.\n- Recruitment for research has been conducted internally by a colleague who is not a user researcher and who has found users via trade associations, Google searches and cold calling. This is not a good way to get a representative or reliable research sample.\n- The quantity of research has been too small to give sufficient confidence about the decisions the team is making (i.e. the sample size and coverage is too small given the expected eventual user base).\n- The team has identified a single, high-level need for the service that focuses on proprietors of alcohol wholesale businesses. The team needs to break this down into more detailed users’ needs, consider the varying needs of different kinds of employee who might apply on behalf of the proprietor, and include the wider users of the service such as the risk assessors who will work with the information once collected.\n\nTaking these factors together, there are likely to be significant skews and gaps in the representativeness of the sample up to this point, and hence in the robustness of the findings.\n\nUser Research\n\nThe plans for research at the beta stage are focused around sole proprietors. The expectation is this focus will help to uncover needs among those who are unable to use the product without help from others. However, there was not a firm or determined plan to achieve the aspiration of between 30 - 50 respondents for the phase.\n\nOpen Source Code by Default\n\nThe team explained that their planned approach would be to publish code selectively, when it is \"ready\". The panel felt this was not aligned with the policy of open source by default and coding in the open.\n\n### Recommendations\n\nIn order to pass the beta assessment, it is vital that the team address the following recommendations.\n\nUser Needs\n\n- Ensure there is sufficient user research time assigned to the service’s development. We recommend that at least one full time researcher works on the service.\n- Conduct more and deeper research, using professional recruitment methods to find a broader range of users (including those who will need assisted digital support to use the service) and understand their needs. This may include direct contact between researcher and trade associations, or the use of an external recruiter as appropriate.\n- Develop a more thorough and well considered segmentation of the audience against relevant criteria, and ensure that research is done specifically with users with the lowest level of digital skills, and that suitable recruitment methods are used to find users (i.e. not just those with an online presence).\n- Continue the contextual research activity, to explore audience make-up, user needs and use of the service in context.\n- Increase the number of users seen per iteration of the product. Consider methods that will allow face-to-face contact with respondents during product testing.\n\nUser Research\n\nDevelop a firm research plan for beta which outlines:\n\n- research questions\n- research methodologies\n- target segments among the audience\n- recruitment methods\n- researcher resource\n- research outputs\n- timescales\n\nOpen Source Code by Default\n\n- Publish all source code, excluding only those parts of the code for which there is a compelling security reason to protect it.\n\nCreate a Simple and Intuitive Service\n\n- Ensure the service includes support routes that address the needs of users who will not be able to complete the service independently, including creating and accessing an email account.\n\n* * *\n\n## Digital by Default Service Standard Criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | No |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/fitness-2-drive-service-assessment/",
    "title": "Fitness 2 Drive - Service Assessment",
    "summary": "The Drivers Medical service is currently responsible for managing all services and channels required to enable drivers to:",
    "body": "- tell DVLA about a relevant medical condition, or\n- renew their existing medical driving licence.\n\nDrivers have a legal obligation to inform DVLA of a medical condition which could affect their ability to drive safely and a list of the relevant conditions is available on the DVLA website. GPs also have a duty of care to inform their patients of this legal obligation when they are diagnosed with a relevant condition.\n\nDVLA is beginning the transformation of these services on a condition by condition basis, starting with those conditions which attract the highest volumes.\n\n**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n05/10/2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. McEvoy\n\n**Service Manager:**  \nD. Ashford\n\n**Digital Leader:**  \nO. Morley\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Fitness 2 Drive service is on track to meet the Digital Service Standard at this early stage of development.\n\nHowever, the panel notes that the service brought in for alpha assessment is limited in scope and there are some areas which the team will need to focus on in private beta development and which will need to be addressed before the service comes back for a beta assessment: At present the service only covers two relevant medical conditions; it does not allow users to be notified digitally of a revoked licence; and the service does not appear to have been considered as part of DVLA’s wider family of similar driving licence services which share a basic user need of \"I need a driving license in order to drive a vehicle legally\" (e.g. first time applications and renewing or updating a licence).\n\n**Reasons**\n\nThe Fitness 2 Drive service provides a digital way for users to tell DVLA about a medical condition which could affect their ability to drive safely; or renew an existing medical licence they hold due to having a medical condition. For alpha the digital service is only available to users with diabetes or glaucoma.\n\nThe service takes users through a series of questions designed to help DVLA understand the nature of the user’s medical condition and its potential impact upon their ability to drive safely. Once a user submits their answers, DVLA send a decision letter back to the user via post informing them of the outcome. This process can take up to 9 months. The panel noted the lack firm plans to build a way to notify users of revoked licences within the digital journey.\n\n_User needs and research_  \nThe team used a number of different sources of insight to identify user needs and develop a good understanding of the service’s users. The assessment panel was very impressed with the work the client insight team members did during discovery to explore user needs, which included carrying out 63 focus groups across 48 towns and cities as well as interviewing users and surveying people calling DVLA’s contact centre about the existing service.\n\nThe team were able to describe user needs at a granular level with a good understanding of the emotions the underlying drivers. However, as the team moves into beta, it would be good to see them revisit the insight from the focus groups to develop a high level user need for the service.\n\nThe service has worked hard to find and meet with potential users of the service who might struggle to use the service independently - including those with the lowest levels of digital skills, confidence or access. The team estimates that 42% of their users will need assisted digital support of some kind (around 250,000 support transactions per year), and that a significant amount of that support will need to be face-to-face. The team had learned that the support for this service needs to be sensitive to its potentially emotional nature (users may have their driving license revoked) and needs to appoint someone to lead the assisted digital work.\n\nThe service team had done well to look beyond just those users making direct contact with their department, working with charities to reach users who would go to them for support. More than 100 users who’d need support were included in the team’s focus groups, and 19 were met with face to face. The team believes the range of users met to be representative of the service’s broad user base. The service team talked with them specifically about their support needs, as well as testing the on-screen elements of the service.\n\nThere is a group of users identified by the team who have a condition which they need to notify the DVLA about and are aware of the service but have not used it. The team has plans to reach this group using various communication and education channels including signposting through other DVLA and government services and working with GPs and charities. However, there is a risk that the size of this group is significant, and the team continue to conduct research into these users and the best ways of addressing their needs.\n\n_Service design_  \nThe team doesn’t believe digital channels are appropriate for informing users that they no longer qualify to drive legally. This hypothesis should be validated with careful interaction and content design, and tested with users, particularly in light of the importance of giving users an outcome as quickly as possible to manage the risk of users continuing to drive when they have a condition that could affect their ability to do so safely. The outcomes of such research will be very useful to the wider design community and should be shared.\n\nThe team have not yet considered this service as part of DVLA’s wider family of similar driving licence services which share a similar high level user need related to getting a license to be able to drive legally. During beta development the team should consider how these services relate to each other.\n\nThe service has phone support options to call upon from the department, and is exploring face to face options. The team said users would rely on face-to-face support from friends and family, but as this support is neither sustainable nor measurable, alternative support options must be in place for these users.\n\nTwo of the charities that the team is working with to research user needs (Diabetes UK and the International Glaucoma Association) have agreed to provide face-to-face support for free and on an ongoing basis.\n\nThere are some instances where the team have not used GOV.UK design patterns initally, going on to implement them later after research. The team should, where possible, save design and research effort by using established design patterns. If these patterns don’t work well for your users and their needs, it’s always valuable to test alternatives, and then share the findings with the government design community.\n\n_Tools and Approach_  \nThe team have taken a pragmatic approach - using technology that will be familiar to staff at DVLA from other services under development and in production. Utilising DVLA’s existing contract to provision infrastructure is reasonable though the panel would encourage the team to develop with portability in mind and evaluate other hosting options as part of the ongoing service evolution.\n\n_Privacy and Security_  \nThe team plan to take steps to minimise the personal data that will flow through the service, using features of the underlying DVLA API. There is no data stored beyond the short-lived (encrypted) session within the service as all state is held in the underlying DVLA systems. Personal data is transferred out of the system via email into another DVLA system - the network design appears to secure this transport. Care must be taken during implementation to ensure that this is achieved in practice. GOV.UK Verify will be used to check identity before giving users access to their data. The team also have a subject matter expert working with them to ensure that their non-repudiation requirements will be met.\n\n_Coding in the Open_  \nThe team are committed to open sourcing the code for the service from the outset.\n\n_Using Open Standards and Common Platform_  \nThe service makes sensible use of a number of platforms and APIs, including GOV.UK Verify, DVLA’s own API for licences and the Ordnance Survey API. Feedback is captured using the GOV.UK Feedback mechanism and performance indicators will be reported via the Performance Platform.\n\n_Testing the end to end service_  \nThe team are committed to setting up a continuous integration pipeline from the outset and will have separate environments to facilitate development, integration and testing in an environment identical to live. Statistics from other DVLA services have been used to identify common browsers and devices - these have been used in research and will be used to test the service.\n\n_Digital Take Up_  \nThe team said that the current paper service costs £30 per transaction and that their research showed that 45% of users (250,000 transactions per year) would choose the paper service ahead of the digital service.\n\nHowever, the team’s two year digital take up target was just 55% and does not envisage any users who would prefer paper will switch to digital in that time. The team also has no plans to phase out the current paper service, in line with DVLA policy to retain paper channels until research shows that removing it does not exclude users. This equates to a service that meets users’ expensive preferences ahead of the user needs that the team’s own research has identified. These users are left to a more expensive and inferior service.\n\n**Recommendations**\n\nIn preparation for beta assessment, it will be vital that the team addresses the following recommendations.\n\n_User needs and research_\n\n- Revisit the insight from the focus groups to develop a high level user need for the service.\n- Continue to research and design for these users and explore the best ways of addressing their needs.\n- Carry out research with these users to understand the barriers to using the digital channel (either independently or with assisted digital support).\n- Carry out research to understand if any users would be excluded if required to complete the service digitally (either independently or with assisted digital support). \n- Continue to research with users who would seek support from friends and family to understand their needs and enable appropriate design of support.\n\n_Multidisciplinary team_\n\n- Identify who will be undertaking the AD Lead role.\n\n_Point 12 - Service design_\n\n- Conduct research into delivering negative results or outcomes digitally to users. \n- Consider this service as part of DVLA’s wider family of similar driving licence services and how they relate to each other. \n- Ensure appropriate face to face support is available to all users who need it (i.e. potentially beyond the coverage provided by Diabetes UK and the International Glaucoma Association).\n- As part of delivering a good end to end service, consider what is required beyond when the user submits their medical information in the online journey (e.g. the reports pushed into the legacy case management system and the paper notifications back to users).\n- Use GOV.UK design patterns where appropriate and feed back on any findings relating to these patterns to GDS and the Government design community.\n\n_Point 14 - Digital take-up and measures_\n\n- Refocus digital take up thinking onto users’ needs, not preferences.\n- Plan to encourage users who would choose non-digital channels ahead of the digital service, to help them overcome barriers (as researched by the team) and complete the service digitally (either independently or with assisted digital support).\n- Develop plans for increasing digital take up beyond the 55% of users who have a stated preference for digital and an appropriate plan to phase out non-digital channels in the longer term.\n- Move beyond measuring the web journey in isolation to measuring the end-to-end duration, accuracy and dropout for the whole service, i.e. user’s first interaction with DVLA to receiving a decision.\n\n**Summary**\n\nThe service is on track to meet the digital-by-default service standard. The team have done some good work during alpha to understand user needs. The existing drivers medical service licence is paper based, very long and difficult to understand. There was clear evidence that the digital service is significantly simpler and clearer for users covered by the two conditions targeted for alpha. The alpha has been developed in an agile way and the team was able to demonstrate that improvements have been made to the design of the service to meet user needs. The team provided examples of working with policy to simplify the design of the service in response to feedback from users. The panel would encourage the team to continue this work.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | No |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/charity-commissions-digital-services-service-assessment/",
    "title": "Charity Commission’s Digital Services - Service Assessment",
    "summary": "The service will allow a person authorised to act on behalf of a charity to make a change to the charity’s governing document so that it can operate more effectively.",
    "body": "**Department / Agency:**  \nThe Charity Commission\n\n**Date of Assessment:**  \n22/5/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. Harrington\n\n**Service Manager:**  \nC. Cooke\n\n**Digital Leader:**  \nC. Cooke\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the Charity Commission's Digital Service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\n_User needs_\n\nThe service team have a good understanding of their users and their needs. This has been gathered through a range of user research methods with feedback already being used to iterate and improve the service.\n\n_The team_\n\nThe alpha phase has been used well to understand options for delivery and it was good to hear that the team had considered the options available to them. There is a multidisciplinary team in place, with technical skills from the software provider. The team are working using agile processes and have developed the alpha in four sprints. It was positive to hear that there was a cycle of sprint planning, daily stand-ups, showcases and retrospectives.\n\n_Security_\n\nUnfortunately the authentication mechanism in use is not fit for purpose (see recommendations below).\n\n_Privacy_\n\nThe team have a good understanding of the data they are capturing and the bulk of it is intended to be part of a public register; there are no obvious privacy concerns surrounding the data currently captured. The data sensitivity assessment currently in progress should inform future direction. Some concerns are outlined below.\n\n_Tools_\n\nThe team have made pragmatic choices that let them iterate fast within the alpha - the tool chosen to design and capture form submissions has a low learning curve and reasonably flexible deployment and support options (on premise, Infrastructure as as Service (IaaS) or hosted by vendor). While the tool is proprietary, the system uses XML to interface with downstream systems and this would allow for a migration at a later date if needed. The tool supports acting as a Security Assertion Markup Language (SAML) service provider, so should be interoperable with an improved authentication mechanism.\n\n_Standards_\n\nThe software provider product allows sharing of resources between customers, and the team have taken advantage of the GOV.UK toolkit which skins the product for government services. Use of XML for data interchange is also a sensible choice. There is a need to work on standards for identity assurance and authentication (see recommendations).\n\n_Improving the service_\n\nThe team have been able to rapidly iterate the service during the alpha phase meaning multiple variants have been tested with users. There is a backlog of prioritised work which has been created as the service has been tested and iterated. The decision was made to make changes weekly so that versions could be tested with multiple users. Changes were made by the team using the graphical user interface (GUI) provided by the software provider. A change to a form does not stop a user from completing a transaction, and does not require service downtime.\n\n_Design_\n\nThe team has made great progress in understanding user needs and iterating the service based on user needs and research. The team has significantly improved the flow and content design of the service and has good ideas for how the service can be made better during the beta phase.\n\n_Assisted digital and digital take-up_\n\nThe team have not considered assisted digital at this stage. No testing has been done with assisted digital users and there has been no consideration of assisted digital support. Just because the existing service is already online only does not mean that no one is getting or needs help to use it.\n\n_Analysis and benchmarking_\n\nThe existing service has analytics in place and the team have used this to gain insight and influence the design of the new service. Analytics has been installed on the alpha and is ready to be used in the beta phase. The team are engaged with the Performance Platform. There is historic data available which could be used on the Performance Platform.\n\n**Recommendations**\n\n_User needs_\n\nThe team should investigate what the actual service or services should be (just the two transactions presented or incorporate all changes to charities). This will effect the name of the service and how it is represented on GOV.UK.\n\nDuring the alpha, many of the issues found were around language use. During the next phase it is important to make sure that recommendations about language can be acted upon. The team should also consider widening the research scope to include login and internal case-workers, so that the whole user journey can evolve to a point where it is fast and straightforward.\n\nThe team has identified a significant proportion of professional agents that would use the service. Research needs to be carried out with the user group to understand if their needs are different and if the service being developed is appropriate for them.\n\n_The team_\n\nCurrently, many members of the team take on two or more roles. This has been fine for the alpha phase but as the product develops to integrate with the back-end system and take on more services there must be a clearer separation between key roles.\n\n_Security and privacy_\n\nThe authentication mechanism is not fit for purpose as there is a single shared credential for an entire organisation. This poses severe risks to privacy, transaction non-repudiation and the reputation of the service. A solution that does not rely on shared credentials needs to be put into place as a matter of urgency. Until a solution is in place the team has no assurance of the identity of the individual transacting and therefore cannot determine their authority to transact without an out of band i.e. non-digital step. We were pleased to see the team is aware of the shortcomings of the authentication mechanism and has planned a review of this.\n\nAs the service is highly dependent on third party software and hosting, the team should take care to procure this in a sustainable way. Timely security updates, security monitoring, service and data resilience will need to be considered in any procurement.\n\nWe understand that currently the changes requested by service users generate casework which is dealt with by Charity Commission staff and that there is a desire to eliminate casework from “low risk” transactions. A thorough analysis of the threats to the system will be needed to achieve this, and it seems likely any work on this would need to proceed in tandem with, or after dealing with, the authentication mechanism.\n\n_Tools_\n\nThere is a danger of becoming locked-in to the software provider’s tool. To avoid this we would recommend:\n\n- Ensuring that the capability to use the tool to design and modify forms exists within the organisation rather than via supplier staff - these members of staff would play a key role in evaluating alternatives and conducting any future migration.\n- Ensure that the infrastructure is well understood by a group of technical staff within the Charity Commission to facilitate running the contract with the supplier and operational support.\n- Continue to evaluate the software provider and consider other suppliers if they do not meet your needs - we are keen to see the evaluation report which is a planned outcome of the alpha phase at the beta assessment.\n\n_Standards_\n\nThere is an ongoing stream of work within GDS on registers. As the service, overall, manages updates to a register, there’s potential to contribute to, and benefit from, the experience of other bodies that maintain similar registers.\n\nThe \"Cross Government Organisation and Authority Management Working Group\" includes a number of interested parties across government with identity assurance requirements to process transactions on behalf of organisations. It is possible that GOV.UK Verify could meet a part of these needs.\n\n_Improving the service_\n\nCurrently the service is hosted on a single machine by the software provider. While this has been fine for alpha, the team should ensure they understand what is needed for running a service at beta.\n\n_Design_\n\nThere will need to be significant work on the visual design style and HTML coding in the beta to fully conform to the service design manual and design patterns. The team will need to include a front-end developer that can quickly iterate the code and make changes to the template.\n\nThe service must work well on mobile, preferably through the adoption of a 'mobile first' approach and there should be automated browser testing as well as manual testing to make sure the service works correctly and is rendered properly. We would expect there to be accessibility testing on the service and for recommendations to be incorporated.\n\nThe team should continue to iterate the content design and language of the service. A content review will be supplied separately.\n\n_Assisted digital and digital take-up_\n\nThe team need to understand their assisted digital users and how support is currently being received. The team should put together a model of support that is designed to meet the identified support needs of users who need it. As discussed at the assessment, voluntary associations would be a good place to start this research with, to find users with the lowest levels of digital skills and confidence. This report might also provide a useful starting point for analysis of assisted digital needs.\n\nThe team should carefully review what is expected at beta before the next assessment.\n\n_Analysis and benchmarking_\n\nThe team should consider the key performance indicators (KPIs) which will be a measure of success for the service, in addition to the four KPIs stated in the manual. It is also recommended that the discussions with the technology supplier about the ability to undertake multivariate (A/B) testing are continued.\n\n**Summary**\n\nIt was particularly good to see the alpha phase being used to rapidly build a product to show the art of the possible in just 4 weeks. The team have also done some great work to bring the business along on the journey. The panel are confident of the team’s ability to pick up on the recommendations in this report and progress in beta.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | No | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/secure-communications-service-assessment/",
    "title": "Secure Communications - Service Assessment",
    "summary": "Secure Communications allows third parties to send information securely to DWP. The current scope of the service allows GP surgeries and Macmillan nurses to send medical information to the department.",
    "body": "**Department / Agency:**  \nDWP\n\n**Date of Assessment:**  \n14/5/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nD. Williams\n\n**Service Manager:**  \nR. Woods\n\n**Digital Leader:**  \nK. Cunnington\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Secure Communications service is on track to meet the Digital by Default Service Standard at this early stage of development. However, the panel identified some areas where the service needs to demonstrate considerable improvement before coming in for a beta assessment. These are outlined in the recommendations below.\n\n**Reasons**\n\n_User needs and user research_\n\nThe service is currently a proof of concept demonstrating how GPs and Macmillan nurses can submit DS1500 forms online to DWP. Currently this can be done by post or by emailing a Word document version of the form if they are registered to do so. The service team had insight into user needs here and had established that the current process leads to a large number of delays due to forms being lost in the post or through referral back to the issuer due to errors and/or illegibilty.\n\nThe needs that the service is currently addressing were identified from a mixture of desk research, focus groups, in depth interviews and ‘day in the life of’ visits to 20 GP surgeries. The team showed evidence of how they used feedback to determine a web-based service was desired by users. The team have gathered evidence of the need to make the process quicker for both the patient (where time sadly really is of the essence) and for the GP - one observation was that for a GP even 10 seconds saved is worthwhile. The team showed some knowledge of as yet unmet user needs, some of which they expected to address shortly, others were awaiting prioritisation in the backlog.\n\nThe team have plans to use lab testing and to further engage with GPs through the British Medical Council (BMC) and the forum on DWP, and possibly with patients though these mediums (with perhaps Macmillan nurses acting as a proxy due to the sensitivity of the subject). Analytics will be employed when the online form comes into use.\n\nThe team showed how they have made some changes following evidence gathered from research.\n\n_The team_\n\nThe team have a dedicated team with one empowered lead service manager. It is likely that the team will expand in the beta stage and be divided into two, with each focussing on separate but strongly linked tasks. The team demonstrated an understanding of how these tasks will be coordinated.\n\nThe team is using agile and provided evidence of adhering to the key principles including adapting processes as required. They are using Scrum and working in two-week sprints.\n\n_Security, privacy, tools and standards_\n\nThe team are visible within the ‘security community’ at DWP by having representatives attend their show & tells; the team also update their CESG forum. In addition, the DWP identity team regularly visit and often are embedded within the team. The team have regular communications with security transactions team for risk discussions. The overall strategy is to be \"noisy\" so as to encourage engagement with other departments.\n\nThe DWP data protection team have been engaged and assessments are ongoing.\n\nThere is an intention to make the code available (excluding NHS code) and the team would be happy for it to be used. Senior management are aware of this and the team expect to be able to proceed. The service will need to evidence making code available under an appropriate open source licence at the beta assessment.\n\n_Design_\n\nThe design of the service is still very much a work in progress which is understandable at this alpha stage. There has been end-to-end testing with GPs and this will continue as the panel would expect.\n\nOn the current hardcopy form there is a requirement to capture the patient’s National Insurance number, and as user feedback suggests this is frequently not known by the user, the team will be challenging this.\n\nThere is a reliance on an external designer but as this is not a dedicated resource this is a vulnerability.\n\n_Assisted digital and channel shift_\n\nThe service team has demonstrated that assisted digital (AD) support does not need to be provided at this time. If the scope of the service changes the user base, the team may need to undertake research with AD users and design, test and provide appropriate AD support which meets user needs.\n\n_Analysis and benchmarking_\n\nPrototyping has involved end-to-end testing with GPs and there have been four versions to date. The team separated smart card and form journeys, and have tested the data gathering element (i.e. the form) more extensively. Lessons were learned by observation and incorporated into the process.\n\nThe team intend to use Nagios and possibly Google Analytics. There is the aspiration to use analytics to verify user research, however this is dependant on users accessing and using the service during beta.\n\nThe team have thought about how to measure success in addition to the 4 mandated key performance indicators (KPIs).\n\nBenchmarking will be problematic as data on the current service is poorly defined; however efforts are being made to engage with operations managers in order to make measurements so as to establish a baseline.\n\n**Recommendations**\n\n_User needs and user research_\n\nPoint 1 - Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for digital and assisted digital service design.\n\nPoint 2 - Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.\n\nPoint 20 - Put a plan in place for ongoing user research and usability testing to continuously seek feedback from users.\n\nConcentrate on planned user research with actual users and ensure the service is regularly tested end-to-end.\n\nIntegrate new designs that have tested well into the service and test these with users.\n\nContinue to involve the whole team in user research and help the team understand the user needs this service will be meeting.\n\n_The team_\n\nPoint 2 - Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.\n\nThe team mentioned a plan for beta to reorganise into two teams. This should reduce the prioritisation tensions between the DS1500 piece of work and the smartcard piece of work, and allow for more focus on user experience. The panel supports this approach.\n\nRecruit a full-time designer and a full-time content designer to work with the service team. This a complex and sensitive service and without proper analysis and design, the user experience will not move past an online replica of the existing paper form. The designer and content designer (when recruited) should work alongside the team, get involved in user research and feed into the design and flow of the service.\n\n_Assisted digital_\n\nPoint 10 - Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it.\n\nPoint 11 - Plan (with GDS) for the phasing out of any existing alternative channels, where appropriate.\n\nCarry out further research to identify users with assisted digital needs and develop proposed support to meet user needs and the assisted digital standard.\n\n_Design and content design_\n\nPoint 9 - Create a service that is simple and intuitive enough that users succeed first time, unaided.\n\nPoint 13 - Build a service consistent with the user experience of the rest of GOV.UK by using the design patterns and the style guide.\n\nThe service team should work with DWP teams and NHS teams to ensure user journeys around the service provide the best experience for users.\n\nThe designer and content designer (when recruited) should collaborate with the content community at GDS and across government to ensure that the service adopts the style patterns and best practice endorsed by its application in comparable, successful services.\n\nDuring the next assessment, the service team should be prepared to show more examples of how evidence gathered from user research and testing has informed the service design.\n\n_Analytics, benchmarking and reporting_\n\nPoint 7 - Establish performance benchmarks, in consultation with GDS, using the 4 key performance indicators (KPIs) defined in the manual, against which the service will be measured.\n\nPoint 18 - Use analytics tools that collect performance data.\n\nPoint 21 - Establish a benchmark for user satisfaction across the digital and assisted digital service. Report performance data on the Performance Platform.\n\nPoint 22 - Establish a benchmark for completion rates across the digital and assisted digital service. Report performance data on the Performance Platform.\n\nPoint 23 - Make a plan (with supporting evidence) to achieve a low cost per transaction across the digital and assisted digital service. Report performance data on the Performance Platform.\n\nPoint 24 - Make a plan (with supporting evidence) to achieve a high digital take-up and assisted digital support for users who really need it. Report performance data on the Performance Platform.\n\nWork with the GDS performance platform team to have a dashboard measuring performance against KPIs publicly available when you are ready for public beta. The panel recommends that the team consider measuring abandoned versus successful submissions in addition to the mandatory KPIs.\n\n_Open standards and common government platforms_\n\nPoint 16 - Use open standards and common government platforms (e.g. GOV.UK Verify) where available.\n\nThe PDFs generated in the service should be PDF/A to comply with open standards. The team should familiarise themselves with the government Standards Hub.\n\nThe team mentioned that many GPs use off-the-shelf software to manage patient records, but are yet to approach the software providers to discuss any possible integrations. Even a very simple API to pre-populate the patient’s name and address could save valuable GP time and improve the user experience.\n\n_Make source code open and reusable_\n\nPoint 15 - Make all new source code open and reusable, and publish it under appropriate licences (or give a convincing explanation as to why this can’t be done for specific subsets of the source code).\n\nContinue the work to open source code.\n\n_Testing the end-to-end service_\n\nPoint 17 - Be able to test the end-to-end service in an environment identical to that of the live version on all common browsers and devices. Use dummy accounts and a representative sample of users.\n\nEnsure the service has been penetration tested.\n\n_User data and security_\n\nPoint 3 - Evaluate what user data and information the service will be providing or storing, and address the security level, legal responsibilities, and risks associated with the service (consulting with experts where appropriate).\n\nThe team should continue to review the target security level to ensure that it is not too low, nor, importantly, too high. Given the specific fraud risks around this service, the team should consider if, for example, multiple smartcard authentications is excessive.\n\n_Testing end-to-end_\n\nPoint 17 - Be able to test the end-to-end service in an environment identical to that of the live version on all common browsers and devices. Use dummy accounts and a representative sample of users.\n\nThe team should follow-up with the Health & Social Care Information Centre (HSCIC) to better understand the future roadmap for NHS staff authentication, particularly with regard to use of a broad range of devices and browsers.\n\n_Testing with the minister_\n\nPoint 26 - Test the service from beginning to end with the minister responsible for it.\n\nThe team are aware of the need to test the service with the minister responsible for it and plan to do so before the service moves into live.\n\n**Summary**\n\nThe panel were impressed with the cohesion and skill set within the team. The team demonstrated a passion and dedication to providing the best possible solution for users, and a deep understanding of the benefits for the patients who ultimately will be the main beneficiary during a very difficult time.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | No | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | No | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | No | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | No | 22 | No |\n| 23 | No | 24 | No |\n| 25 | Yes | 26 | Yes |\n\n<aside class=\"sidebar\" role=\"complementary\">\n  <section class=\"widget about_widget\"><h3>About the data blog</h3>\n<p>A blog about the tools and techniques used by GDS for data analysis.<br>\n<a href=\"https://gdsdata.blog.gov.uk/about/\">Find out more</a>.</p>\n</section><section class=\"widget categories-2 widget_categories\"><div class=\"widget-inner\">\n<h3>Categories</h3>\n<label class=\"screen-reader-text\" for=\"cat\">Categories</label><select name=\"cat\" id=\"cat\" class=\"postform\">\n\t<option value=\"-1\">Select Category</option>\n\t<option class=\"level-0\" value=\"140\">Analytics Strategy  (1)</option>\n\t<option class=\"level-0\" value=\"8\">Data insights  (15)</option>\n\t<option class=\"level-0\" value=\"7\">Data science  (26)</option>\n\t<option class=\"level-0\" value=\"79\">Digital Service Standard  (4)</option>\n\t<option class=\"level-1\" value=\"97\">   Service manual  (2)</option>\n\t<option class=\"level-0\" value=\"113\">Events  (7)</option>\n\t<option class=\"level-0\" value=\"108\">Google Analytics  (17)</option>\n\t<option class=\"level-0\" value=\"106\">Google Sheets  (11)</option>\n\t<option class=\"level-0\" value=\"114\">Implementation  (5)</option>\n\t<option class=\"level-0\" value=\"118\">Other  (3)</option>\n\t<option class=\"level-0\" value=\"110\">Other tools  (4)</option>\n\t<option class=\"level-0\" value=\"5\">Performance Platform  (52)</option>\n\t<option class=\"level-0\" value=\"109\">Python  (1)</option>\n\t<option class=\"level-0\" value=\"126\">R  (1)</option>\n\t<option class=\"level-0\" value=\"112\">Tableau  (2)</option>\n</select>\n\n<script type=\"text/javascript\">\n/* <![CDATA[ */\n(function() {\n\tvar dropdown = document.getElementById( \"cat\" );\n\tfunction onCatChange() {\n\t\tif ( dropdown.options[dropdown.selectedIndex].value > 0 ) {\n\t\t\tlocation.href = \"https://gdsdata.blog.gov.uk/?cat=\" + dropdown.options[dropdown.selectedIndex].value;\n\t\t}\n\t}\n\tdropdown.onchange = onCatChange;\n})();\n/* ]]> */\n</script>\n\n</div></section><section class=\"widget text-5 widget_text\"><div class=\"widget-inner\"> <div class=\"textwidget\">\n<br><a href=\"https://www.gov.uk/performance/prototypes\">Data Science Prototypes</a>\n</div>\n\t\t</div></section><section class=\"widget text-4 widget_text\"><div class=\"widget-inner\"> <div class=\"textwidget\">\n<br><a href=\"http://gdsdata.blog.gov.uk/?p=728\">View all Service Assessments and Self Certifications</a>\n</div>\n\t\t</div></section> <section class=\"widget recent-posts-2 widget_recent_entries\"><div class=\"widget-inner\"> <h3>Recent posts</h3> <ul>\n\t\t\t\t\t<li>\n\t\t\t\t<a href=\"https://gdsdata.blog.gov.uk/2016/12/08/we-want-to-understand-more-about-our-readers/\">We want to understand more about our readers</a>\n\t\t\t\t\t\t</li>\n\t\t\t\t\t<li>\n\t\t\t\t<a href=\"https://gdsdata.blog.gov.uk/2016/11/09/understanding-more-from-user-feedback/\">Understanding more from user feedback</a>\n\t\t\t\t\t\t</li>\n\t\t\t\t\t<li>\n\t\t\t\t<a href=\"https://gdsdata.blog.gov.uk/2016/11/02/setting-up-a-performance-framework-for-the-uk-parliament-website/\">Setting up a performance framework for the UK Parliament website</a>\n\t\t\t\t\t\t</li>\n\t\t\t\t\t<li>\n\t\t\t\t<a href=\"https://gdsdata.blog.gov.uk/2016/10/14/introduction-to-performance-analysis-for-digital-and-technology-fast-streamers/\">Introduction to performance analysis for Digital and Technology fast streamers</a>\n\t\t\t\t\t\t</li>\n\t\t\t\t\t<li>\n\t\t\t\t<a href=\"https://gdsdata.blog.gov.uk/2016/08/25/absolutely-fabulous-testing-a-pointer/\">A/Bsolutely fabulous testing - a pointer</a>\n\t\t\t\t\t\t</li>\n\t\t\t\t</ul>\n\t\t</div></section> <section class=\"widget feed_email_widget-6 feed_email_widget\"><div class=\"widget-inner\"> <h3>Sign up for updates</h3>\n    <div class=\"subscribe icons-buttons\">\n      <ul>\n                  <li>\n            <a href=\"https://public.govdelivery.com/accounts/UKGOVUK/subscriber/new?topic_id=UKGOVUK_6816\" class=\"email\">Email</a>\n          </li>\n                <li>\n          <a href=\"https://gdsdata.blog.gov.uk/feed/\" class=\"feed\">Atom</a>\n        </li>\n      </ul>\n      <div class=\"clear\"></div>\n    </div>\n  </div></section> </aside>\n<footer class=\"group js-footer\" id=\"footer\" role=\"contentinfo\">\n\n      <div class=\"footer-wrapper\">\n        \n\n        <div class=\"footer-meta\">\n          <div class=\"footer-meta-inner\">\n            <nav>\n  <ul id=\"menu-footer\" class=\"menu\">\n    <li class=\"menu-all-government-blogs\"><a href=\"https://www.blog.gov.uk\">All GOV.UK blogs</a></li>\n    <li class=\"menu-all-government-blog-posts\"><a href=\"https://www.blog.gov.uk/all-posts/\">All GOV.UK blog posts</a></li>\n    <li class=\"menu-gov-uk\"><a href=\"https://www.gov.uk\">GOV.UK</a></li>\n    <li class=\"menu-all-departments\"><a href=\"https://www.gov.uk/government/organisations\">All departments</a></li>\n    <li class=\"menu-all-topics\"><a href=\"https://www.gov.uk/government/topics\">All topics</a></li>\n    <li class=\"menu-all-policies\"><a href=\"https://www.gov.uk/government/policies\">All policies</a></li>\n    <li class=\"menu-cookies\"><a href=\"https://www.blog.gov.uk/cookies\">Cookies</a></li>\n  </ul>\n</nav>\n\n            <div class=\"open-government-licence\">\n              <p class=\"logo\"><a href=\"https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/\" rel=\"license\">Open Government Licence</a></p>\n              <p>All content is available under the <a href=\"https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/\" rel=\"license\">Open Government Licence v3.0</a>, except where otherwise stated</p>\n            </div>\n          </div>\n\n          <div class=\"copyright\">\n            <a href=\"https://www.nationalarchives.gov.uk/information-management/our-services/crown-copyright.htm\">© Crown copyright</a>\n          </div>\n        </div>\n      </div>\n    </footer><!--end footer-->\n\n<script src=\"https://gdsdata.blog.gov.uk/wp-content/themes/gds-blogs/build/govuk_template/assets/javascripts/govuk-template.js?0.10.0\" type=\"text/javascript\"></script><script type=\"text/javascript\" src=\"https://gdsdata.blog.gov.uk/wp-includes/js/wp-embed.min.js?ver=4.6.1\"></script><script>\n  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');\n\n  ga('create', 'UA-40442074-1', 'blog.gov.uk');\n  ga('send', 'pageview');\n  </script><script>\n    // Event tracking\n    jQuery(function($){\n      $('body').on('click', '.ho-digital-email', function(){\n        ga('send', 'event', 'contact', 'email', 'hodigitalsheffield@digital.homeoffice.gov.uk');\n      });\n    });\n    </script>"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/access-to-work-service-assessment/",
    "title": "Access to Work - Service Assessment",
    "summary": "Access to Work is a service that provides practical advice and support to people with disabilities or mental health conditions and their employers to help them overcome work-related obstacles resulting from disability. The service provides a discretionary grant that contributes to the additional employment costs resulting from disability that the employer would not normally be expected to cover.",
    "body": "**Department / Agency:**  \nDWP\n\n**Date of Original Assessment:**  \n30/07/2015\n\n**Date of Reassessment:**  \n16/09/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Original Assessment:**  \nNot Pass\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nM. Sheldon (Original) / J. Gould (Reassessment)\n\n**Service Manager:**  \nL. Mortimer\n\n**Digital Leader:**  \nK. Cunnington\n\n* * *\n\n## Reassessment Report\n\n**16th September 2015**\n\n**Reasons**\n\nThe team demonstrated a good understanding of the users of the service and their needs. The team articulated their findings, revisiting their discovery, that this isn't simply an application service process but an ongoing customer management service. The team has made a solid start to researching user needs for support, particularly through relevant third parties, and they plan to start testing face-to-face support with a charity in private beta.\n\nThe team has thought carefully about working with partners to support applicants and has begun building those working relationships.\n\nThe service team demonstrated both the latest production and development versions of the service. The panel felt that these demonstrations showed that the team are working to good research based and user-centric design principles.\n\n**Recommendations**\n\nThe service team should continue to address ongoing recommendations from the original alpha assessment, including:\n\n- Continued research with users who are applying on behalf of someone who is unable to apply.\n- Ongoing confirmation that third party support routes are sustainably in place.\n- Ensuring that assisted digital support is free to users.\n- Developing plans for increasing digital take up and an appropriate plan to phase out non-digital channels in the longer term.\n\nThe digital service should not be seen as a standalone add-on to the assessment service and payment process. The service must be viewed as a whole, and the end-to-end user journeys considered. At the beta assessment the panel will expect to see the full service and screens provided to agents, as this has such a significant impact on the journey of the applicants.\n\nThere was some confusion about what the Minimum Viable Product (MVP) was amongst the assessment panel. For clarity, the panel believe the MVP should be the end-to-end service, not just the initial application process. At beta assessment, the panel would expect to see a working end-to-end service that allowed users to make an application and case officers to process the application to a live customer. The panel will also expect to see the user journey for reapplications.\n\nDuring the private beta we recommend that the team monitor how many applications require follow-up calls to provide clarification to the information provided through the online application. As the service is iterated and improved we would expect fewer applications to require follow-up.\n\nThe team should continue to explore user needs for support in more detail by thinking ahead to the requirements for a live service, for example, whether availability of support meets user needs for people in work.\n\nThe team demonstrated some interesting design findings on accessibility. We recommend these are shared within DWP and the cross government design community.\n\n* * *\n\n## Summary of Original Report\n\n**30th July 2015**\n\nAfter consideration the assessment panel has concluded that the Access to Work service is not yet on track to meet the Digital Service Standard at this early stage of development. However, we believe that meeting the standard and progressing to a beta phase is well within the capabilities of the team.\n\n**Reasons**\n\nThe service team and their working practices are excellent, especially at such an early phase. The team is led by a skilled service manager, and the team are building using agile, iterative and user-centred methods. The team were able to show, with evidence, that they are following the principles and guidelines set out in the service standard.\n\nWith ongoing user research, during discovery and alpha, the team have spoken to many users of the current service; from job seekers, employees and employers, to advisors and staff in other departments and support organisations. This research suggested that more than 50% of the potential users would need assisted digital support and the team have focused efforts on finding and representing those users.\n\nFor the alpha phase the team have built an online form that complements the current Access to Work phone service. This form does not replace any part of the service, but aims to reduce the time spent gathering information during the application phase. The assessment panel agreed that following this approach has considerably reduced the scope for the design of the end-to-end service. In addition, the information provided detailing the intent behind the project focuses on strategic and policy led outcomes, not the needs of users.\n\nOne of the key challenges with the current telephone service is the difficulty advisors and users have in finding a time to communicate. This causes delays and failures during the application process. The online form does not make this simpler, clearer or faster. Users still have no opportunity to specify preferred dates or times for contact. Their chances of missing the three call attempts from an advisor remain the same.\n\nA primary user need identified by the service team is to allow people reapplying to reuse information already given, so as to not waste time. Another need focused on offering flexibility for users who can't apply themselves or need expert support. The online form does not address either of these user needs or others identified.\n\n**Recommendations**\n\nTo meet the service standard at alpha phase we recommend that the service team:\n\n- Return to a discovery phase and research how meeting the needs of users informs the design of a digital by default service.\n- Map out from end-to-end the current user journey and back-end administration processes. Identify the pain points and failure demand and focus on addressing those. For example, by offering an appointment booking solution to help users and advisors.\n- Research the type of support users will need and design prototype support aimed at meeting these needs.\n- Research with users who are applying on behalf of someone who is unable to apply.\n- Research users' understanding of the service's name \"Access to Work\".\n- Confirm that third party support routes are sustainably in place.\n- Ensure that assisted digital support is free to users.\n- Develop plans for increasing digital take-up and an appropriate plan to phase out non-digital channels in the longer term.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/apply-for-a-budgeting-loan-service-assessment/",
    "title": "Apply for a Budgeting Loan - Service Assessment",
    "summary": "The Apply for a Budgeting Loan service is designed to provide a quick and easy application process for users who need an interest free loan to help them with an unexpected expense.",
    "body": "**Department / Agency:**  \nDWP\n\n**Date of Assessment:**  \n20/10/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nD. Williams\n\n**Service Manager:**  \nZ. Gould\n\n**Digital Leader:**  \nK. Cunnington\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the Apply for a Budgeting Loan service is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service team demonstrated an intent to digitise the entire service and not to simply replicate the current paper form in an online format. Indeed it was encouraging that the team have challenged policy in order to remove steps that aren't material to the decisions, and the paper forms will be amended to take these into account.\n\nThe team have clearly recognised the importance of user research as a critical part of the project, and demonstrated a good understanding of the user needs. The involvement of the current team and others in user research is positively recognised, as is the intention to immerse all new team members in the future. The panel were impressed that the team are using feedback from support centres to inform user stories.\n\nThe team have also undertaken research with some assisted digital (AD) users, and have identified that they may have a slightly different set of needs and realised the importance of further research into different groups of AD users in beta.\n\nAlthough there seemed some confusion regarding the cost per transaction, there is a clear understanding of the other 3 KPIs. We felt that this is pretty advanced thinking at an alpha stage in our experience.\n\nThe team have considered and mitigated a number of external and internal threats to the service, and minimised the data captured and retained on the service.\n\nThe team demonstrated good stakeholder engagement and communication, and show & tell sessions have received positive feedback particularly with regard to user testing informing better understanding of user needs.\n\nThe team has made an impressive start to research with AD users, and have clearly understood the importance of supporting this user group. Demonstrating commitment to the off-screen service, AD is an ongoing feature of the team backlog. The panel would encourage the team to continue to showcase this work across the department, including at show & tells.\n\nIn order to gain the best picture of AD user needs, a variety of methods and routes have been followed. A survey with partner organisations was used as a way to reach those who support users, but also users themselves. Through this work, the team were able to identify local welfare rights and support groups, housing associations/charities and the Citizens Advice Bureau as key routes for support. Further research over the phone, through third parties and in pop up format has given the team an early indication of the AD population and possible support routes to test. The team showed a good understanding of the differing needs of both working and pension age users, mapping both groups on the digital inclusion scale.\n\nBuilding on the evidence so far, further research will be carried out at local community and Sure Start centres, Age UK, Citizens Advice Bureau and Jobcentres across various sites. The team also plan on pursuing research with their internal home visits team and joining up with other services within the department, who may be able to offer research opportunities and share knowledge.\n\nIt was very encouraging to see the team proactively looking for AD users in places they currently go for support, and approaching this with a 'user first' attitude.\n\nThe team have a digital take-up plan based on current research findings, and should continue to develop this as they understand more about user behaviours, support needs and digital skills.\n\n**Recommendations**\n\nThe panel has some concerns as the service moves into the beta stage, and has the following recommendations on how to address these.\n\n**Point 1** - _Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for the design of the service._\n\nThe emphasis on user research has been impressive, and there is a good understanding of user needs. However, the methods used in discovery when speaking with end-users were more attitudinal than behavioural - for example, pop-up groups exploring what people thought of GOV.UK. The panel recommends that for the research in beta and going forward, that the research methodology focuses on gathering behavioural data, i.e. what people do, rather than what they say.\n\nIt might be helpful to users to investigate a method for calculating the loan amount based on responses to previous questions.\n\nThe team have collected valuable evidence around the use of third parties for support, and must feed this into department-wide review of services to ensure this support is made sustainable. In addition, research suggested that pensioners ‘felt embarrassed’ about needing help to complete an online application, and so wanted to get this help from friends and family. As support from friends and family is not sustainable, the service must continue to put in place AD support to meet the needs of this group of users.\n\n**Point 2** - _Put a plan in place for ongoing user research and usability testing to continuously seek feedback from users to improve the service._\n\nLab based user research should also provide the opportunity for more targeted sampling of users. The panel recommends that the recruitment briefs demonstrate that research is being carried out with users who have recently applied for a budgeting loan so that they are able to proceed through the service with a personally relevant context of use. The sample should also continue to include users with lower digital confidence, and users with AD needs, and the panel recommends that some of the testing is done on handheld devices.\n\nAs stated in point 1, the panel recommends that research methods are focussed on gathering behavioural data. From this perspective, it would still be appropriate to consolidate the evidence around user needs with some more behavioural evidence. For example, contextual research in the homes of applicants would provide more grounded, behavioural data around the user needs.\n\n**Point 3** - _Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility._\n\nA content designer needs to made available for a minimum of 3 days per week.\n\nIt was of concern that the content designer had only observed one round of user research during discovery, as user research should be informing content as well as interaction design.\n\n**Point 4** - _Build the service using the agile, iterative and user-centred methods set out in the manual._\n\nThe governance issues are seemingly overbearing, potentially distracting for the service manager, and may impact on the success of the project. There are risks attached to being used as a ‘guinea pig’ for other business areas.\n\n**Point 6** - _Evaluate what tools and systems will be used to build, host, operate and measure the service, and how to procure them._\n\nThe team are considering the use of Redis and there are pros and cons of such an approach. It's difficult to introduce a Redis cache without dealing with the single point of failure it can bring about, Redis leans towards consistency rather than availability and a master/slave setup can inevitably produce outages so the design needs to be well thought out. The other approach being considering is to use hidden HTML fields which is the panel's preferred approach as it keeps the cluster entirely stateless and therefore more scalable.\n\nThe team need to consider error handling from the back-end system, as this is partly asynchronous. If synchronous there may be a latency issue whilst ensuring the message is successfully delivered to the back-end DRS systems and the team need to consider how this will impact on peak performance and this needs to be addressed in load testing. If asynchronous the team need to consider retries/timeouts and error reporting. The user should not be left thinking they have submitted a form when in fact it has not been properly processed.\n\nThe team have opted to use Mongo DB as a back-end store and the panel's recommendation, as the team do not have much experience with Mongo, is to think very carefully about the sharding key. This key distributes the data amongst the nodes and can lead to very poor performance as the dataset gets bigger if it is not designed properly. The team should consider getting advice from Mongo DB schema design service and test the sharding under load with a full database.\n\n**Point 7** - _Evaluate what user data and information the digital service will be providing or storing, and address the security level, legal responsibilities, privacy issues and risks associated with the service (consulting with experts where appropriate)._\n\nThe team's security architect has recommended an appliance called ShapeShifter which constantly moves the HTML and JavaScript around in order to prevent bots from attacking the site. It's hard to see how the service could successfully guarantee the integrity of the design across devices if code is constantly changing. Presumably it changes form names and tracks this at the back-end. If this is the case, it must be stateful, thereby making the site more difficult to scale. The panel's recommendation is to tread very carefully and ensure adequate performance testing is in place including the appliance if it is used, and address whether or not this device introduces state as this will make scaling more difficult. The panel were also unsure as to what this is hoping to achieve if the service already has DDOS protection at the front-end.\n\n**Point 8** - _Make all new source code open and reusable, and publish it under appropriate licences (or provide a convincing explanation as to why this cannot be done for specific subsets of the source code)._\n\nThe team should make servie code more widely available and also to those outside government.\n\nThe team should also ensure the new development team are aware of the need to document code at the start of the beta.\n\n**Point 9** - _Use open standards and common government platforms where available._\n\nThe panel would encourage the team to investigate and monitor the progress of the GDS Platform as a Service (PaaS) and Notifications projects.\n\n**Point 13** - _Build a service consistent with the user experience of the rest of GOV.UK including using the design patterns and style guide._\n\nThe panel strongly feel that the team needs to have a front-end developer in the team for beta. There is also a need for more time from a content designer, as mentioned in point 3.\n\n**Point 14** - _Encourage all users to use the digital service (with AD support if required), alongside an appropriate plan to phase out non-digital channels/services._\n\nThe team should continue to gather 'turn-down' reasons to help inform improvements to guidance provided to applicants using the online form.\n\n**Point 16** - _Identify performance indicators for the service, including the 4 mandatory key performance indicators (KPIs) defined in the manual. Establish a benchmark for each metric and make a plan to enable improvements._\n\nThe panel discussed a ‘light-touch’ diary study of the full end-to-end user journey which could be used to inform contextually appropriate performance measures.\n\n**Summary**\n\nThe panel were impressed with the cohesion and knowledge within the team. The team all demonstrated a passion and dedication to providing the best possible solution for service users, and a commitment to continue gaining further insight into their needs.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | No |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | No | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/electronic-visa-waiver-service-assessment/",
    "title": "Electronic Visa Waiver - Service Assessment",
    "summary": "The Electronic Visa Waiver (EVW) process was introduced as an alternative to a visa for nationals of Oman, Qatar and UAE in January 2014. The EVW process requires users to submit information via an online form up to 48 hours prior to travel which then enables them to travel to the UK without a visa, meaning they don’t need to attend visa interviews, submit biometrics, etc. The information gathered through the EVW form is sent for checks prior to the scheduled travel, however there is no feedback to the applicant and it is not a decision making process.",
    "body": "**Department / Agency:**  \nHO\n\n**Date of Assessment:**  \n14/10/2015\n\n**Assessment stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Thornett\n\n**Service Manager:**  \nJ. Dos Remedios\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of Service Assessment**\n\nAfter consideration the assessment panel has concluded the Electronic Visa Waiver service is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe team have used a throwaway prototype to design, test and iterate the new service in a way that has allowed to learn quickly about what users need from this service and how to improve the user experience as quickly and simply as possible. The way the team were able to use the prototype kit to do this was exactly how it was originally envisaged. It would be good for the team to blog about this experience for other teams in government to learn from.\n\nHaving previously worked on the Registered Traveller service in Home Office the team are comfortable working with agile methods and are looking to reuse many components previously built for other services. The new Electronic Visa Waiver service also integrates with a backend caseworking service that was designed for the Registered Traveller service — bringing further benefits to the end-to-end business process and not just the front-end user experience.\n\nThere is no need to provide assisted digital support as the users are non-British citizens overseas. If the scope of the service changes, the team may need to provide assisted digital support. Further information on assisted digital policy is available in the government service design manual.\n\n**Recommendations**\n\n- The team should collect data from the existing Electronic Visa Waiver service being used in United Arab Emirates, Quatar, and Oman, in order to provide some benchmark performance information for the replacement service. This should include suitable benchmarks for the 4 mandatory KPIs where possible, and other performance information relevant to the service. For instance, the number of applications per year, number of people offloaded per year etc. This will be particularly important for considering expected levels of performance for the new service when it is rolled out to additional countries beyond private beta. \n- It would be great to see the team blog about their experience of improving the form design. This discussion from the W3C about collecting name data seemed quite appropriate. Other teams in government, such as at the Foreign and Commonwealth Office, might learn from this.\n- As the team develop the service for private beta it will be important to measure the success of the bilingual user experience approach being used — whereby English and Arabic instructions are present on screen at the same time. It is important to test the effectiveness of this approach on appropriate devices across mobile, tablet and desktop. It is likely to be of benefit to other government services to understand if this approach provides a good user experience and if it could be adopted into government design patterns in the future.\n\n**Summary**   \nThe panel would like to thank the service team for the excellent work they have done so far to develop a service based on the needs of users, using good agile techniques to integrate user research into the iterative design process.\n\nThe team had prepared well for the alpha assessment and we look forward to seeing how the service progresses into the next phase of development.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | No |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/family-visa-routes-service-assessment/",
    "title": "Family Visa Routes - Service Assessment",
    "summary": "Family Visa Routes is an online service for foreign nationals in the UK who wish to extend their stay in the UK on family grounds (i.e. their partner, spouse, or parent has permission to stay in the UK and they wish to be allowed to stay with them).",
    "body": "**Department / Agency:**  \nHO\n\n**Date of Assessment:**  \n2/10/2015\n\n**Assessment stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Barlow\n\n**Service Manager:**  \nD. Mills\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of Service Assessment**\n\nAfter consideration the assessment panel has concluded the Family Visa Routes service is on track to meet the Digital Service Standard at this early stage of development.\n\nThere are some areas which the service team will need to focus on in private beta development which will need to be addressed before the service comes back for a beta assessment.\n\n**Reasons**\n\n_Research and user needs_  \nThe team has made a strong start to their research effort, collecting a body of research data over several months, travelling around the country and finding routes through intermediaries to access this complex and potentially difficult-to-reach audience. The audience is clearly a challenging one to design for:\n\n- diverse demographic and cultural breakdown \n- widely varying confidence and ability in use of the internet\n- the widespread use of formal and informal intermediaries\n- a range of attitudes towards the process and the institutions involved (caution, wariness, fear, etc.) \n- time pressures to apply\n\nThe data gathered during this fieldwork had informed the development of a detailed set of user needs, a set of personas, and the development of the financial part of the prototype.\n\nThe team has an understanding that the service, for many users, does not begin on screen. People speak to those they trust within their local community groups and use them as their first point of guidance around what they need to do next, and how to access and use the on screen service. Based on this, user research has happened in Leeds and Bradford, evidencing how users interact with their community. More of this research should be undertaken during beta, in a systematic way. As above, this research should happen in users’ own environments.\n\nThe team were able to demonstrate that they were working in an agile way and that the alpha was being developed iteratively in response to user needs.\n\nThe service is being designed and tested to ensure it’s simple and intuitive for users. The design is consistent with GOV.UK and the team have also created some good new interaction patterns.\n\nThe team has made a good start to understand user needs for assisted digital support, in particular, conducting research within local communities to gain an understanding of needs, and the factors that impact them. They have identified that some users will not turn to government for support as they fear this may impact their application - as this has been identified as a key concern, the team must continue to explore these barriers and complete further research with assisted digital users during beta.\n\nThe service has a challenging 80% digital take up target to meet, and will explore promotion of the digital service through key identified community groups in order to meet this target.\n\n**Recommendations**\n\n_Research and user needs_  \nWhile the team has made a strong start to user research during the alpha, there are some area which need to be addressed before coming back in for a beta assessment:\n\n- develop a robust and systematic profile or segmentation of the audience, based on qualitative and quantitative data, which includes attitudinal and demographic dimensions\n- develop a research plan which addresses each audience sector to increase the range and depth of research data\n- use independent third parties as necessary, to systematically recruit participants from across these audience sectors, including those who are hard-to-reach or who are wary of taking part in Home Office research\n- recruit potential-applicants (and their intermediaries) to take part in user research - to reduce the effect of the inevitable pre-learning of the process by existing applicants\n- ensure that research locations are chosen so that they do not form a barrier to participation (e.g. some sectors may be wary of coming to Home Office premises)\n- refine and validate the user need statements and personas using wider research data (currently the personas are based on single interviews rather than on recurring patterns of need and behaviour seen across multiple interviews)\n- recruit further users with the lowest level of digital skills\n- explore a full range of support options, based on the wide range of assisted digital user needs already identified (and including any new ones) and complexity of the service\n\n_Sustainability of support_  \nSupport provided by third parties or friends and family, must be sustainable. The service must ensure that assisted digital support will be funded through the service, and that people will not have to pay providers for support or, for example, through premium rate telephone numbers.\n\n_Technical_  \nThe team are reusing internal components from other visa application processes. Many of the components are shared with other teams in Home Office Digital. None however are open source. There is a program reluctance to share code for security/fraud prevention reasons. Whilst the team appreciates these concerns, the panel would ecourage a much stronger commitment to open source across the program. Even if the actual rules are kept closed source, the underlying engine could be opened. Additionally patterns around adapters to external systems - for example payment providers - could be shared.\n\n_Team_  \nThe existing platform is being reused for this system, which provides most of the infrastructure and deployment capabilities. Having recently undergone a procurement of the technical team there is a concern about platform ownership and continuity. Additionally the analyst role was shared with other services and the service manager role was being filled on a temporary basis. This needs to be addressed to ensure a more sustainable team is in place for the beta.\n\n_Design_  \nThe service uses several outdated design patterns - such as the progress bar, application menu and user flow - which is due to the team reusing components from the other visa application processes. This is fine in alpha, but during beta the design needs to be updated to reflect the latest cross-government design patterns. The team has also created some good new interaction patterns (such as the ‘return to application’ flow) which the panel would encourage them to contribute to the cross-government design hackpad.\n\n**Summary**\n\nThe service is on track to meet the service standard. The team have done some good work during alpha to understand user needs. The existing family visa application is paper based, very long and difficult to understand. There was clear evidence that the digital service is significantly simpler and clearer for users. The alpha has been developed in an agile way and the team was able to demonstrate that improvements have been made to the design of the service to meet user needs. The team provided examples where they have worked with policy to simplify the design of the service in response to feedback from users. We would encourage the team to continue this work.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/emergency-travel-documents-service-service-assessment/",
    "title": "Emergency Travel Documents Service - Service Assessment",
    "summary": "An emergency travel document (ETD) enables you to get back to the UK or your country of residence from wherever you are if your passport is not available for one reason or another. It is only usable for a defined journey which is written into the document: when you get back, the document is withheld by Border Force and later destroyed by the Passport Office (HMPO). It is more expensive than a passport and so is usually for emergencies. The service has a very wide user base, including:",
    "body": "- people who have lost their passport when travelling\n- expatriates who have to return home urgently and find their passport has expired\n- children of expatriates who have never had a British passport but need to travel urgently to the UK\n- prisoners about to be expelled from a country\n- people involved in a crisis situation abroad\n\n**Department / Agency:**  \nFCO\n\n**Date of Original Assessment:**  \n21/07/2015\n\n**Date of Reassessment:**  \n21/09/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Original Assessment:**  \nNot Pass\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nL.Scott (Original) / M. Knight (Reassessment)\n\n**Service Manager:**  \nR. Sayce\n\n**Digital Leader:**  \nA. Daniels\n\n* * *\n\n## Reassessment Report\n\n**21st September 2015**\n\nThe Emergency Travel Documents Service has been reviewed against points 1, 2, 3, 6, 12 and 14 of the Service Standard which were not passed at the original assessment.\n\nAfter consideration the assessment panel has concluded that the Emergency Travel Documents should proceed to private beta.\n\n**Reasons**\n\nThe service does not yet meet point 3 of the standard because some key roles were missing from the team currently delivering the service. The panel believes that the service is now ready to proceed to gather more feedback from a limited private beta, in line with the conditions set out below.\n\nThe service team presented the details of the recent assisted digital user research done with the Age Concern centre close to Alicante in Spain. The panel were impressed with the efforts that the team has made to identify user needs for support, and to test the service with users who are, by the nature of the service, not UK based at the time of use. The team are participating in a cross-government group to share findings and identify best practice for researching assisted digital users overseas, which will contribute towards greater consistency for British users needing government support from abroad. It was noticeable that the assisted digital work done had delivered a better service for all users, not just assisted digital users, and the panel would like to encourage the team to continue this good work in the next phase.\n\nSome concerns remain over the way the team had approached the alpha. The aim in alpha stage should be to prototype and explore approaches to meeting user needs, rather than to produce production ready code and functionality. The panel were also concerned at the balance of the team. In particular, the panel was concerned about the way that development resource was prioritised, and other important skill sets were not present throughout the alpha (for example, content design, design and user research).\n\nThe panel looks forward to seeing some of the improvements mentioned in the assessment (for example, the removal of the need to enter duplicate information to book an appointment at the end of the flow). As the team move forward into beta, the panel would encourage the team to continue to test and iterate the current journey in addition to adding new features, as well as balancing the skills available to the team.\n\n**Recommendations**\n\nThe service should address the following recommendations ahead of the beta assessment.\n\n_Private beta_\n\n- The private beta must be limited in scope by users and time, with an overall plan to be agreed with GDS before entering the private beta.\n\n_User research_\n\n- The team should create a plan for future user research, including assisted digital research. This should include face to face research in the UK with potential users to compliment the existing WhatUsersDo work. Participants must include less experienced travellers, people with low and no digital skills who are likely to need assistance, and people with a range of disabilities and access needs. The research must cover finding the new service, and test the service on the device the potential user is likely to have access to while travelling.\n- The team must carefully test any support for ‘proxy’ applications before including it in the private or public beta. This could introduce significant confusion into an otherwise simple service.\n- In addition to completing and acting on the planned research with Age Concern in Alicante, we recommend the team does research in countries where access to digital services can be more problematic, for example by continuing with the plans for sessions in Addis Ababa and Islamabad.\n- At this early stage, the team is considering different design options for assisted digital support, largely based on existing support through consulates and contact centres. As the service develops, the team must demonstrate how support is being designed and iterated to meet user needs.\n\n_The team_\n\n- The Service Manager should prioritise the recruitment of design and content design resource for the team for private beta and future phases. Borrowing patterns from other services or having a designer ‘look in’ on the service are not substitutes for these necessary skill sets, and this will become more important in future phases. These designers should actively participate in user research.\n\n_Tools and systems_\n\n- The team should reconsider their decision to send personal data by email in the clear; sending this by email poses a risk to the security of the data. The team should instead consider sending a receipt only.\n- The team should note that the GOV.UK APIs that they rely on are unsupported, and as a result may break or change without notice. The service should have plans in place to identify if this happens and also consider what the impact on users might be if the APIs change significantly.\n\n_Simple and intuitive service_\n\n- The team work on the content of the service with a content designer. Particular issues include poor validation messages, content not to GOV.UK style, and long headings.\n- The team review the design feedback document that will be sent separately. Particular issues include frustrating summary screen, validation that can be distracting, and handling of approximate information.\n\n**Summary**\n\nThis is a complex service and it was great to see the work that has gone into developing it. The panel hope that the pass at alpha and the recommendations above encourage the team on their journey towards a beta assessment. The panel look forward to hearing about the private beta when the team return for the beta assessment.\n\n* * *\n\n## Summary of Original Report\n\n**21st July 2015**\n\nAfter consideration the assessment panel has concluded that the Emergency Travel Documents Service is not yet on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\n_User needs and user research_\n\nPoint 1 - Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for the design of the service.\n\nPoint 2 - Put a plan in place for ongoing user research and usability testing to continuously seek feedback from users to improve the service.\n\nPoint 12 - Create a service that is simple and intuitive enough that users succeed first time.\n\nThe service team has identified the top user need for the service (I need to travel on a booked journey without a passport) and have identified improvements to be achieved and current pain points e.g. reducing waiting time in the consulate. The vision for the future service (to apply online, be verified remotely, digital photos, pay online, receive an emergency travel document (ETD) at departure destination) is compelling.\n\nHowever, the panel could not see how the team had used research and discovery to evidence and validate these needs and pain points. We reviewed the report from IFF, which suggested that users feel reassured attending the consulate, and showed little appetite for a digital service. More research is needed to understand the needs of users, and ensure that the service design meets these.\n\nRelying on remote, scenario-based user research means the team aren’t exposed to the needs of their genuine users, and that the users doing the testing are not fully engaged with the service (e.g. where they select a country at random).\n\nThe team have also not researched specifically with lower-skilled or lower-confidence users, or those with assisted digital needs. As such the prototype service lacked informed assisted digital support routes to test and iterate, instead relying on users requiring assisted digital support to use the inferior paper service.\n\nThe alpha is the time to get a deep understanding of users and their needs, and the landscape for transforming the digital service. The service team has spent much of the alpha building the real service, missing the objective of an alpha. The service team hasn’t used the alpha to explore many of the identified user needs.\n\nThe prototype demonstrated seemed to focus on feature completeness rather than building something that would help the team learn about their users. The panel were unclear why many paths of the journey were built if they weren’t being tested at alpha. The panel would recommend the service team investigate using the GOV.UK prototyping kit. This would deliver a more functional prototype that is more realistic than the client-side javascript solution demoed.\n\nThe prototype does not yet include the most complex elements, such as payments and photo upload. The team had surveyed previous users and had an understanding that digital confidence decreased when abroad, with particular concerns around the potential data costs of completing a form online.\n\nThe team has iterated the prototype frequently, although much of this was addressing smaller content changes. Many identified needs have been left for beta development. The team has identified some user groups to engage with in beta, e.g. farmers in Africa and expats in Spain. We’d encourage far more of a focus on non-scenario based research. A user researcher joining the team is essential.\n\nThe team were concerned that the service planned to stop using the prototype and only use production code going forward. Prototyping and testing regularly with users is an important part of the process for the entire development of a service. Whilst testing with production code may appear to save time, it increases the risk of building the wrong thing, and it slows down the time taken to iterate changes for user research.\n\nSignificant portions of the service overlap with two existing services - passport renewals and lost and stolen passports. The panel would have liked to have seen more evidence of the team having engaged with these existing services and incorporating their findings from user research. The service team mentioned they had engaged in trying to share code, but at alpha stage learning about existing research and design patterns would be more valuable.\n\n_The team_\n\nPoint 3 - Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.\n\nUnderstandably for a small team, there are many overlapping roles. There are however key roles (including design, content design, user research and data analysis) that are not represented on the team, with responsibility being shared for theses between the product manager (FCO) and the business analyst (supplier side).\n\nA user researcher, working at least 3 days a week, is currently missing, and is a vital role on a service team. This would reduce the reliance on an outsourced user research company and help address some of the concerns the panel had around the research methodologies used. Having a user researcher on the team would have helped the service team better target their research in alpha.\n\nCurrently a content editor at FCO reviews the content. A content designer should be working more closely with the service team to design content to ensure the service meets user needs, rather than providing a proof read at the end of the process. The service has particular challenges around supporting applications from people applying on another person’s behalf - we recommend further research in this area.\n\nThe service uses the GDS design patterns and toolkit, however there are small inconsistencies that will need to be addressed. The panel will send through design recommendations separately, as well as a review of the service’s content.\n\n_Technology_\n\nPoint 6 - Evaluate what tools and systems will be used to build, host, operate and measure the service, and how to procure them.\n\nThe panel believes the front-end of this application is over-engineered. The team should reconsider the technology choices used and build for progressive enhancement. For example, the use of an isomorphic front-end complicates the build and will make it more difficult to iterate.\n\nThe majority of the journey could be delivered as HTML, with JavaScript used to enhance aspects (e.g. validation). There is no need to deliver the entire journey using JavaScript. No allowance was made for users who have JavaScript enabled but don’t receive it.\n\nThe architecture includes a Scala backend. The choice of language itself is not unreasonable in this case, but Scala is a very difficult skill to recruit for and makes it more difficult to move from an incumbent supplier, so the team should weigh this against potential recruitment problems.\n\nThere are a number of services that need to be called in order to complete a transaction or submit an application, e.g. create a PDF, send an email, insert into the case management system. There is no plan to keep data consistent between these services or deal with a partial failure. If one of the services fails this has an affect on the whole transaction, e.g. the case management system fails but the email confirmation succeeds. This needs to be addressed.\n\nAt the moment there is no data store on the server and it is important to address audit of applications. Mismatches between the case management system and the web front-end will otherwise be very difficult to identify.\n\n_Digital take-up_\n\nPoint 14 - Encourage all users to use the digital service (with assisted digital support if required), alongside an appropriate plan to phase out non-digital channels/services.\n\nThe panel did not hear a compelling reason for the lack of a plan to increase digital take-up to 100%. In particular, it was not clear why there shouldn’t be an ambition to remove the paper channel (where anyone needing help accessing the digital service would be supported via the assisted digital channel, and understanding that paper is not an appropriate assisted digital support route).\n\n**Recommendations**\n\nThe panel recommends that the service address the following:\n\n- Hire a user researcher to work alongside the service team.\n- Carry out research with actual end users of this specific service. We recommend asking users who are already in the consulate waiting for their documents to be processed.\n- Research all user journeys, including the least happy path.\n- Using appropriate recruitment methods, carry out research with users with all levels of digital skills and confidence (including those who would seek support from third parties or friends and family) to inform the design of both the on-screen service and any assisted digital support.\n- Ensure ongoing research to account for extra service complexity as new features are added.\n- Collaborate with the Home Office to learn from the user research carried out for the ‘lost and stolen passport’ service.\n- Hire a content designer to work alongside the service team.\n- The panel were concerned about mailing large amounts of personal data being sent between the embassy and to the recipient in the clear. The panel recommend sending notifications only and that users log in to get the data. The panel noted that this step is short term until the case management system is in place. It might be better to mock the interface to the case management system for testing and omit the email stage.\n- The session caching server will hold very sensitive data, by default the server is designed to exist within a trusted environment. Security around this store needs to be defined.\n- Reconsider the technology choices for the front end. Build for progressive enhancement. The team should discuss this further with GDS.\n- Consider using the GOV.UK prototyping kit for future prototypes.\n- Consider the licence you need to open your source code.\n- Establish a plan to achieve 100% digital take-up.\n\n**Summary**\n\nThere are positives to the work the team has done so far, for example, the team showed empathy with the distress many users would be experiencing, especially if they were in need of an emergency travel document as a victim of crime, and as mentioned earlier the vision for the future service is compelling.\n\nIt was also positive to see the collaboration in the team and to hear how all team members understood the value of their work and how it relates to the overall vision, and were able to contribute ideas and suggest change.\n\nThe panel were pleased to hear that the team have already put a lot of thought into how they will measure success, and are speaking to the Performance Platform to share data in the open.\n\nHowever, as detailed above there are a number of areas where the team should carry out further work, in the alpha stage, to ensure that the service is well positioned for beta development, and delivers a high quality service which will meet user needs.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | No | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/tax-free-childcare-service-assessment/",
    "title": "Tax-Free Childcare - Service Assessment",
    "summary": "The service will use this report to inform continued development in the interim until they plan to move to private beta development in autumn 2016 when a further assessment will take place.",
    "body": "Tax-Free Childcare is a new Government service, offering support to working parents with their childcare costs. The purpose of the service is to either help parents back into work or to increase their existing hours. The service is intended to be digital by default, with parents applying via an online tool (assisted digital support and an alternative channel will be provided for assisted digital and digitally excluded users). Once eligibility has been confirmed, a childcare account will be opened for each child, into which parents and third parties can pay money. For every £8 paid into the childcare account, the Government will contribute £2 (up to a limit of £500 per quarter) – the money can then be used to pay registered childcare providers. The service is intended to be operational as a private beta version in Autumn 16.\n\n**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n10/8/2015\n\n**Assessment stage:**  \nAlpha\n\n**Result of Assessment:**  \nNot Pass\n\n**Lead Assessor:**  \nM. O'Neill\n\n**Service Manager:**  \nC. Pike\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## **Assessment Report**\n\nThe Tax Free Childcare service has been reviewed against the 18 points of the Digital Service Standard.\n\n**Outcome of Service Assessment**\n\nAfter consideration the assessment panel has concluded that the Tax Free Childcare service is not yet on track to meet the Digital Service Standard, however the service is at an early stage of development and does not plan to begin private beta until Autumn 2016. We recommend the service team take account of, and address the feedback below, before returning for a full alpha assessment by early summer 2016 when the service will be closer to beginning the next phase.\n\n**Reasons**\n\nThe service team had done good work on starting to put together components of the eventual service and to engage with user testing right from the start. The service manager was able to present a clear statement of their role and the team structure. It was clear that the service manager was committed to the successful delivery of the service.\n\nThe team were able to set out how they were tackling core challenges around delivering a secure and safe product, and how they would ensure the right mix of delivery skills. The team were working with colleagues across HMRC to build knowledge, skills, services, and to speed-up delivery.\n\nThe reasons for the not pass fall into two parts at this stage.\n\nFirst, the team did not present an end-to-end service. The team should be able to describe what the gaps are and how they plan to address them. The team will need to continue working on a start page, as when users of a service could potentially remove themselves from existing benefits (such as Universal Credit) a clear narrative from the start is key. The lack of a content editor, a user/customer experience lead, and a front-end developer are issues that need to be resolved urgently.\n\nThe user testing was well done, but the team need to be able to evidence that they are engaging with a representative sample of users, and that the issues around the start page do not distort the testing. Similarly, the team should be able to demonstrate how the telephone channel works and how this relates to the overall service operation, for example, when the digital service is down.\n\nSecondly, further work is needed around the technology used to deliver the service. The technology architecture is highly complex and has many parts to it. The team need to be able to explain and understand the relationship between the back-end technology and the front-end and how open standards will be used.\n\n_Point 1_\n\nAlthough the service team have conducted regular research, a broader spectrum of potential users should be covered to ensure the service meets their needs and to identify any potential pain points. Testing with users currently claiming Working Tax Credits or Universal Credit is also important as part of understanding the end-to-end journey. The team did not provide evidence of research with assisted digital users, and it was unclear whether the proposed telephone support would meet their needs. In addition, the difference was not clearly presented between the need to provide appropriate support for users who are unable to use the service independently, and accessibility testing of the on-screen service.\n\nTesting to date had been with the sections of the front-end, and it was unclear how users would engage with the service as a whole. Each of the individual parts, application and account, were described individually, but not as part of a whole user journey, which made the user testing process unclear.\n\n_Point 3 and 13_\n\nWhile the team has had input from content designers at GDS and HMRC, this was not from anyone installed as part of the team. The team have not had involvement from either a designer or a front-end developer. There need to be people on the team responsible for the overall consistency of the service and its design and content. This will provide the ability to prove that the service works for users along the whole path of each journey. This is especially important in a service with many entry-points and with journeys crossing multiple channels involving as many different areas of the business.\n\nWithout front-end developers, the team cannot have confidence that the code delivered to web browsers works for service users on the devices and browsers they use, or in a way that is robust and easy to change; or to be confident in deploys and quick iteration.\n\n_Points 5, 6, 9 and 10_\n\nThe public facing front end service has important dependencies on the back-end. The service team are not able to make rapid or frequent changes to the back-end, and have not yet scoped and derisked this.\n\nThe service as presented at alpha only covers the front-end. The choice of back-end technology and the overall architecture, both logical and technical, was not covered by the team. It was unclear how much of the service would be HMRC intellectual property.\n\n_Point 11_\n\nThe service was presented as a series of components rather than as an end-to-end service, and disaster recovery was recognised to be at a very early stage of planning. Because the service is not end-to-end it is unclear what the service disruption risks are, and what the response needs to be.\n\n_Point 12_\n\nThe service does not yet have a coherent user journey to reflect the impact that using the service could have on other benefits. For example, the service currently lacks a start page to provide user context. The team recognise that this is a core need and this reflects the key importance of content and user experience designers.\n\n**Recommendations**\n\n_Point 1_\n\nThe team should undertake research with a range of users including those on Universal Credit or Working Tax Credits. Ideally this would not all be scenario-based testing to ensure the feedback received is robust.  \nThe team must undertake research with assisted digital users to identify user needs for support. The team must explain how these needs have been considered in design of the support, including why any support routes (e.g. face to face) have been discarded as an option.\n\n_Points 3 and 13_\n\nThe team are recruiting a content designer and a user experience designer; these are key roles and they need to be in place (and to have had a chance to iterate the service) before reassessment.\n\n_Points 5, 6, 9 and 10_\n\nThe team need to be able to explain the service architecture choices in sufficient detail for alpha. This includes being able to set out how the technology and platform choices relate to HMRC and government wide standards and approaches. Without understanding the end-to-end service there is a substantial increase in the risk of commissioning a beta based on assumptions.  \nWhile the team may not be able to change the back-end, they should understand the risks and mitigations with the service architecture. The team should set out how they are using open standards.\n\n_Point 11_\n\nThe team should be able to set out what Service Level Agreements already exist, i.e. with NS&I, and how the service will provide for users during times of disruption. This is an alpha so the approach should be descriptive at this stage, but backed up with evidence as appropriate.\n\n_Point 12_\n\nThe team should test methods of including greater context for users, which will allow them to understand impacts on other benefits (for example, by building and testing a start page). This is an alpha so it will change but without a start page and more context it is hard to see it as a service as opposed to a set of service components.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | Yes |\n| 3 | No | 4 | Yes |\n| 5 | No | 6 | No |\n| 7 | Yes | 8 | Yes |\n| 9 | No | 10 | No |\n| 11 | No | 12 | No |\n| 13 | No | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/legalisation-service-service-assessment/",
    "title": "Legalisation Service - Service Assessment",
    "summary": "Legalisation is the official confirmation that a signature, seal or stamp on an official UK public document is genuine. Confirmation is given by attaching a certificate (called an apostille) to the original document. Foreign authorities often ask that documents are legalised before they can be used for official purposes in their country.",
    "body": "**Department / Agency:**  \nFCO\n\n**Date of Assessment:**  \n06/10/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Thornett\n\n**Service Manager:**  \nA. Hamilton\n\n**Digital Leader:**  \nA. Daniels\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the Legalisations Service is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service team provided strong, thorough evidence that they are taking an agile, iterative, approach to the design of the service. In particular the panel were impressed with the use of a prototype at the alpha stage to learn about user behaviour and to iterate some of the more complex design aspects of the service.\n\nThe service manager is very well engaged with the development team and is able to ensure that internal and external stakeholders are being kept up to date with progress.\n\nThe technology choices are embracing open source and all code is being made available in the open via Github. The panel appreciated the documentation provided ahead of the assessment via an open wiki - not only was this beneficial for the assessment but provided further evidence of the team’s commitment to building their service in the open.\n\nThe team are missing several important skill sets - notably user research, design and content design. The team acknowledged these gaps and have made efforts to fill these areas from within, or by borrowing time from people in GDS. However, these are necessary skill sets for the design and development of a successful digital service and we believe the team will need to find a better solution as the development moves into beta.\n\nDespite having little insight into assisted digital user needs, the service are making a start on mapping out potential support user journeys. They are considering a telephone service to support users and ways around inputting an email address, which is currently mandatory. They are also looking into how they could extend the scope of their current call centre capacity to include potentially longer hours, and further options such as web chat.\n\nWithout completing this user research, the service are unable to identify user needs and therefore cannot say whether or not any proposed support will meet those needs. The team are aware that they must have more insight into assisted digital user needs in order to have confidence in their proposed options. They should contact the GDS assisted digital team for support in this area.\n\n**Recommendations**\n\n_Understanding user needs_\n\nOverall the panel were impressed with the level of research that had been conducted in such a short time, with limited resource.\n\nThe team has appointed IFF Research to conduct some of the exploratory research, and although the results have proved useful (in particular the development of personas), it would be helpful in the future to have less reliance on external research companies, and put the budget towards a dedicated user researcher within the team. There is also a danger of being over reliant on remote research through WhatUsersDo, however we are aware that the team is supplementing this through additional face-to-face research.\n\nThe team has not been successful in conducting any user research with assisted digital users in this early stage. We appreciate that finding assisted digital users who are needing documents to be legalised is difficult but without this insight at an early stage it will be very difficult for the team to ensure that the service is accessible to all types of users.\n\n- The service must put in place a robust plan to identify assisted digital user groups, and be proactive in reaching these users, rather than relying on users to contact the service through existing routes.\n- Additionally, when the service extends to cover businesses, the team should work with the GDS assisted digital team, who can support with ongoing work around assisted digital for businesses and links to other services and departments.\n- The team must conduct research with users with the lowest level of digital skills to understand their barriers to using the service, and their support needs for this service.\n- The team must be proactive in reaching assisted digital users, going out and conducting research face-to-face, rather than relying on those users who contact the service currently.\n- The team should contact GDS for support on assisted digital for individuals and businesses.\n\n_Design_\n\nThe service has some complex interactions, particularly relating to document checking. Whilst the team had made good efforts to iterate and explore these areas, including attending GDS workshops, the panel believes that having a designer work on the service would greatly improve the outcome and reduce complexity.\n\nWe acknowledge that the team has constraints on budget, but strongly recommend that a designer work on the service going forward, for a minimum of 3 days a week.\n\nWhilst the team had rightly focused attention on the document checking portion of the service, the panel recommends that other areas also be considered and complexity reduced wherever possible - such as asking for repeated information or to reconfirm number of documents being requested.\n\n_Technical architecture_\n\nThe technical architecture of the service is well thought through and follows principles of modularity. It also satisfies a common approach to support iterative development and continuous delivery.\n\nThere are monitoring tools and technologies in place. However, extensive use of containers would require additional attention to monitor health and state of containers and their hosts.\n\nThe team is planning to use PostgreSQL database as a shared resource for all services. This decision will make an impact on technical design. As the team is planning to keep these decision under review it would be useful to have a further dialogue on the technology approach when moving into beta development.\n\n**Summary**\n\nOverall the team are making good progress at this stage of development, demonstrating a good understanding of the principles of agile, iterative service design and development. The team appear to be working well together and the panel look forward to seeing the progress they will make as they start building the beta service.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | No |\n| 3 | No | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/report-a-food-problem-service-assessment/",
    "title": "Report a Food Problem - Service Assessment",
    "summary": "This service allows consumers to report a food problem they have experienced or seen (e.g. rat in restaurant, dirty hands serving food, foreign object in food), and does the hard work of getting that report to the local food safety/environmental health team responsible for food businesses in the area.",
    "body": "**Department / Agency:**  \nFSA\n\n**Date of Assessment:**  \n07/10/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nD. Williams\n\n**Service Manager:**  \nC. Hammond-Aziz\n\n**Digital Leader:**  \nJ. Pierce\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the Report a Food Problem service is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe panel was pleased to see that the service team have top level support and have been allocated the required budget and resources.\n\nThe team have recognised the importance of user research as part of the project and demonstrated a good understanding of the user needs. The panel were impressed with the findings that there is a public assumption that the FSA is responsible for dealing with food problems - which isn’t actually the case - and with this in mind it is gratifying that the team are taking action to provide a service that falls outside of the agency’s remit.\n\nThe panel felt that there had been excellent discovery research and a clear definition of users. It was very interesting that the team want to encourage consumers to be empowered to report food problems directly to the business and are working on ways of building this. The team have also undertaken research with some assisted digital users, have identified that they may have a slightly different set of needs, and realised the importance of further research into different groups of assisted digital users in beta.\n\nThe panel were impressed that the team had gathered insights from social media and service contact.\n\nThe team have given thought to analytics and what to measure, and the tools required to do so. Although there seemed some confusion regarding the cost per transaction, there is a clear understanding of the other three Key Performance Indicators (KPIs). In the panel's experience, this is pretty advanced thinking at an alpha stage.\n\nThe team have considered and mitigated a number of external and internal threats to the service, and minimised the data captured and retained on the service.\n\n**Recommendations**\n\nThe panel do have some concerns as the team move into the beta stage, and the panel's recommendations on how to overcome these are outlined below:\n\n**Point 2** - _Put a plan in place for ongoing user research and usability testing to continuously seek feedback from users to improve the service._\n\nThe panel feel that having a user researcher in a team for two days a week is not enough, and suggest that one is allocated for a minimum of three days a week.\n\n**Point 3** - _Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility._\n\nThe team are lacking key roles. Existing members of the team have been carrying out multiple roles but for a beta the team will need the expertise that a competent content designer and interaction designer can bring.\n\n**Point 4** - _Build the service using the agile, iterative and user-centred methods set out in the manual._\n\nThe team should obtain an agile coach to help the team as it grows in order for it to become a truly agile, collaborative and co-located service development team. In addition the team don't appear to have sprints, stand-ups, stories, retrospectives or indeed a clear process that involves research, design and product owners making decisions about what to change. We suggest that the introduction of these would help the team achieve its goals in the beta.\n\n**Point 5** - _Build a service that can be iterated and improved on a frequent basis and make sure that you have the capacity, resources and technical flexibility to do so._\n\nThe ease of changing content via the admin interface presents some risk, as you can make major changes to the service with little tracking and visibility to other members of the team. You will need to mitigate this, either with technical measures (e.g. automated logging of changes), or with well defined process and convention.\n\n**Point 7** - _Evaluate what user data and information the digital service will be providing or storing, and address the security level, legal responsibilities, privacy issues and risks associated with the service (consulting with experts where appropriate)._\n\nWhilst the team have considered the risks to the service and the data collected, the panel suggest that the team assess the volumes and aim to move to non-manual ways of dealing with fraud if necessary.\n\nAs the citizen-facing part of the service captures data and does not present it back to the citizen, the team should consider separating out the citizen-facing and agent-facing parts of the system, so that a compromise of the citizen-facing part of the service would not expose the stored data.\n\n**Point 10** - _Be able to test the end-to-end service in an environment identical to that of the live version, including on all common browsers and devices, and using dummy accounts and a representative sample of users._\n\nThe panel suggest that the team undertake a true private beta with a narrow user group who can be researched closely; for example, a single local authority.\n\n**Point 12** - _Create a service that is simple and intuitive enough that users succeed first time._\n\nThe service needs a start page that clearly states what this form is and isn't for, and suggests alternative services if appropriate.\n\nThe team need more research into what users think is the end of the service and to fully understand what outcome users really want, i.e. do they need feedback or have they reported the issue to the right body?\n\nWatching users search for a service provides valuable insight into the context of the user needs.\n\n**Point 13** - _Build a service consistent with the user experience of the rest of GOV.UK including using the design patterns and style guide._\n\nUsing the design patterns might help save time as these have been developed after extensive research. This is not about using GOV.UK styling, but more about using the interaction patterns, coded elements and form design guidance that are tried, tested and proven to work.\n\nThe panel encourage the team to engage with the cross government design community as there is much to learn in both directions.\n\nThe team should consider using the front-end toolkit where possible, as it could save time and offers a lot of accessibility advice for free.\n\n**Point 14** - _Encourage all users to use the digital service (with assisted digital support if required), alongside an appropriate plan to phase out non-digital channels/services._\n\nThe service should provide really clear guidance about which service to use and what to do about issues.\n\n**Point 15** - _Use tools for analysis that collect performance data. Use this data to analyse the success of the service and to translate this into features and tasks for the next phase of development._\n\nIn addition to measuring and analysing completion rate on the service, the panel would encourage the team to find ways to measure the quality or utility of the reports downstream, at the local authority, and keep this metric in mind when iterating the service.\n\n**Summary**\n\nThe panel were impressed with the cohesion and knowledge within the team. The team demonstrated a passion and dedication to providing the best possible solution for users, and a commitment to continue with gaining further insight into user needs. This was one of the best alpha assessments that the panel has seen, and the panel look forward to seeing the team again at the next assessment stage.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | No | 4 | No |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | No | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/apprenticeship-applications-employer-posting-service-assessment/",
    "title": "Apprenticeship Applications (Employer Posting) - Service Assessment",
    "summary": "This digital service provides greater ownership over the advertising of a vacancy and selection of a candidate to employers who want to recruit apprentices/trainees, whilst also facilitating collaboration with providers who support them in the process. It will provide:",
    "body": "• clear information about apprenticeships/traineeships and the employer’s responsibilities in offering them  \n• a simple and fast way to create, advertise and manage apprenticeship/traineeship vacancies  \n• tools to help manage candidate applications effectively and support outcome notification  \n• a faster and more cost effective process for quality assuring vacancies\n\n**Department / Agency:**  \nBIS / SFA\n\n**Date of Assessment:**  \n20/08/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nT. Scott\n\n**Service Manager:**  \nG. Tucker\n\n**Digital Leader:**  \nE. Stace\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the Apprenticeship Applications (Employer Posting) service is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\n_User needs_\n\nThis new service, which allows employers and providers to post jobs, will compliment the existing application service. The evidence presented showed that the service will make it easier for providers and employers to advertise and collaborate on available apprenticeship and trainee roles. User research has shown that both groups have different needs and the service is being designed to meet them.\n\nThe well researched personas have been validated through user testing which is opened up for the entire service team to observe and feedback on. Testing starts with a hypothesis based on the personas, leading to a rough design that gets built, allowing for rapid real feedback. During the alpha, the team have taken an adaptable approach to research and testing that will become increasingly regular during the beta phase.\n\nThe team have made a good start in identifying needs for support, by speaking to users from all user groups, by working closely with the existing helpdesk, and through an offline survey to providers and employers. The team has proposed the use of existing support routes, but understands that they must identify the needs of potential users, not just current users, and may need to iterate the support to bring it into line with those needs, and Digital Service Standard requirements. The team confirmed that the support will be sustainable and free to the user. The team has identified suitable actions for the next phase, including an increased focus on support needs for employers.\n\nThe current service is digital only; providers must upload through an existing website, but not all providers use the current service because of the high quality control and ease of publishing on external platforms. The team are aware of the need to build a service that is easy to use and requires minimal support through other channels. There are many improvements to the current journey that will help users.\n\n_The team_\n\nThe team have the ensured there is flexibility to allow for the different user tasks, whilst not designing the service around particular groups. The team are ensuring the service is being built to allow providers and employers to collaborate through a non-linear process and improve the capacity to change or edit the data, while at the same time reducing the need for quality checks that might fail later in the process.\n\nThe team are well placed to deliver the service with all the expected roles in place. There is some dependence on external suppliers but this is shifting as recruitment continues, and the service has provision in place if this changed suddenly. The product manager has a wide depth of knowledge from the agency, and experience through the delivery of the Apprenticeship Applications exemplar service. The team have used an adaptable approach to agile in the alpha, based around spikes for testing proofs, but will be moving to a Scrum based sprint cycle in the beta. Regular show and tells engage stakeholders, and individual team members share best practice as part of clans within the agency. The service team is also responsible for maintaining of the current service, which will help with the many dependencies between the different aspects of the service.\n\nThe team share information through a wiki, managing the Proof of Concepts (POCs) and defining the success criteria for spikes and stories. Work is prioritised against releasing a minimal viable service as soon as possible along with availability of team members. The team are co-located in a single room enabling quick feedback. The regular meetings with the SRO ensure that the service is focused on delivering user needs.\n\n_Security, privacy, tools and standards_\n\nThe team has considered the technical integrations needed for the service, and during the alpha, have carried out a number of technical proof of concepts to derisk the next phase of the beta.\n\nThe panel were pleased to note that the team are looking at the platforms used on the exemplar service, and not only reusing the appropriate ones, but were looking to use platform as a service (PaaS) and software as a service (SaaS) tools where appropriate.\n\nIdentity is the biggest security issue likely to face the service during beta, and the team has worked to understand the landscape and the issues the service is likely to face. A focus should be maintained on appropriate protection of the data stored as well.\n\nThe team are making code open, keeping private only the details that open up the service to risk. The service is reusing code drawn from the current application service. It was encouraging to see discussions with other government services that are providing similar services.\n\nWhile the prototype has mainly been focused on the desktop users using Chrome, the team have the means to test the service on a wide variety of devices and conditions in the beta. Observing users in their own environment will reveal a wide range of devices and browsers need to be supported. The plans for service outage follow those used on the application service, mitigation is in place if individual components do not function as expected through graceful failure.\n\nIt was good to see that testing with users was tasked based, and focused on derisking and know pain points. Early testing of the service’s design has led to changes in the presentation of current vacancies, moving from a tabbed list to a filter with categories based on user feedback while also highlighting any important tasks to publish vacancies. The design of the vacancy page allows providers and employers to see how the details will be presented to the candidate early on in the process. Plans are in place to begin to automate the quality assurance process to ensure a higher quality of postings are placed on the site, and to reduce some of the frustrations users find in the current workflow. The use of a WYSIWYG editor is new to GOV.UK services, and tested well with employers and providers (showing similarities to job application sites).\n\n_Analysis and benchmarking_\n\nThe team have gathered analytics from the current web service and call data relating to posting a role, matching any insights to the user research and testing. This has highlighted pain points around the Quality Assurance (QA) process and the differing needs of employers and providers. The service has engaged with the performance platform team, and discussions have started on the additional measures for the service to present on the platform.\n\n**Recommendations**\n\nDuring the next phase, there is more work to be done on the end-to-end user journey for users who don’t have digital skills or access, for example, considering how email approvals and confirmations will be handled. The providers are supporting some employers through their own processes; this needs careful examination to ensure that as employers are encouraged to post directly, they have the appropriate support they need. The plan to undertake research with potential SME and micro employers should help to test assumptions that proposed support will meet the needs of new users in future.\n\nFurther thought needs to go into encouraging current users who are used to and expect telephone support, to shift to self-serve through the new service.\n\nThere are some shared roles across the services within the agency, which has worked during the alpha period. The team need to ensure that shared resources, such as dev-ops and performance analysts, that are not dedicated part of the team, are available when needed.\n\nSharing a backlog with an already live service can be difficult. The flexibility in owning the entire service can help quick development, but thought should be given to how to prioritise and communicate the priorities to the different stakeholder groups.\n\nThe new WYSIWYG design for inputting data for applications may help infrequent service users, but will need testing with frequent users who upload multiple applications. The service will likely need to work on non-JavaScript enabled browsers; you must ensure that this is possible.\n\n**Summary**\n\nThe approach the team has taken to the alpha phase of this new service demonstrate that the learnings from the application service are central to the delivery. It’s very encouraging that the team are have a strong focus on meeting their users needs. It was good to see the strength of relationships between the team members in the assessment and the enthusiasm for delivering the service.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/referral-capture-service-assessment/",
    "title": "Referral Capture - Service Assessment",
    "summary": "The Referral Capture service is an online service that will allow the citizen to report people who are potentially committing benefit fraud",
    "body": "The department loses £3.6bn to fraud and citizen error each year, and so the department has had to get smarter about preventing and detecting fraud. Although the department are proactively developing new ways of preventing fraud within the system, we still currently rely on the citizen to tell us about incidences of fraud that we are currently unable to detect. Whilst we will eventually be able to prevent some of this fraud in the future through more sophisticated data matching and other means, there will always be situations we will never be able to identify without public assistance, e.g. cash in hand cases.\n\n**Department / Agency:**  \nDWP\n\n**Date of Assessment:**  \n26/10/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \npass\n\n**Lead Assessor:**  \nJ. Gould\n\n**Service Manager:**  \nB. Leggett\n\n**Digital Leader:**  \nK. Cunnington\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the Referral Capture service is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service team is well defined, has demonstrated a good understanding of user needs, are working in an agile iterative manner, and clearly have strong ownership of the development of the service.\n\n_User needs_\n\nThe team have used a number of different sources of insight to identify user needs and develop an understanding of the service’s users. These include desk research, talking to frontline staff on the telephony channel, a survey of users ringing the hotline, and pop-up and lab-based testing. The team were able to describe user needs with a clear understanding of the complex range of emotions and drivers underlying them. The team were also able to demonstrate an understanding of some of the contextual issues that influenced target users, including being part of a close-knit community, and lower literacy levels.\n\nThe team have begun to feed this understanding of service users into the design of the service, and are iterating regularly, with design iterations driven by feedback from both pop-up and lab-based user research.\n\nThe team had a good understanding of service users’ likely support needs, having conducted research with actual users of the service, including those with low confidence and low digital skill levels, and those seeking support from third parties. The team estimates that around 20% of users will need support of some kind. The team has identified that anonymity, privacy and flexibility were the key benefits of the on-screen service over alternative channels.\n\nThe team has identified that confidence is the key barrier both to users migrating to the on-screen service from alternative channels, and to independent service completion.\n\n_User research_\n\nUser research has been successfully established as an integral part of the sprint cycle, with team members conducting and observing pop-up and lab-based research, taking part in analysis, and findings from user research feeding into the backlog. The team is actively aware of, and looking at, how to recruit users for specific user journeys through an external recruitment agency. The recruitment for user research is also targeted to include representative users, such as those on low incomes and those with lower digital literacy.\n\nThe team has ongoing research plans to recruit two users who need assisted digital support per lab session, testing the on-screen service.\n\n_Iterating and improving the service_\n\nThe team has built a prototype during their alpha and is now looking to begin implementation of the real solution. This has been sensibly scoped not to include transformation of the legacy backend system, which is being dealt with in another project running across DWP.\n\n_Tools and systems_\n\nThe technical architecture of the beta will be based on guidance from DWP’s Digital Blueprint. The team is empowered to change elements of this ‘standard stack’ when justified. A feedback loop is being honed to ensure the Digital Blueprint is updated with DWP’s evolving understanding of how services are best implemented.\n\n_Managing data_\n\nThe application being developed by the team will not store any data except in-session, however, details of claimed benefit fraud are passed on to backend systems, which presents information security and fraud risks. The team has a good understanding of these backend systems and processes and the risks involved, which are largely unchanged by the new digital project, and satisfied the assessors that the risk appetite is understood and accepted by stakeholders in DWP.\n\n_Open source_\n\nDWP is currently working on their open source policy. The team were keen to make code open source, and understood the benefits and challenges involved in working in the open.\n\n_Service availability_\n\nThe team shows a clear understanding of the implications of the new service being taken offline and has ensured the capacity exists to handle users diverted to other channels.\n\n_Creating a simple and intuitive service_\n\nThe team is iterating on-screen service design in response to research and testing with low-skilled and low confidence users. The team are also considering how to make sure the research and improvements made to the digital service can be used to benefit the telephone and paper versions.\n\n_Consistency with GOV.UK_\n\nThe content design is high quality with excellent use of plain English. This represents a significant  \nimprovement over the old form. The panel identified some specific suggestions to improve the design during the assessment that will be forwarded separately.\n\n_Digital take-up_\n\nThe team has communication plans in place to help users overcome barriers to adopting the digital service.\n\n**Recommendations**\n\n- Whilst the service is being developed as part of DWP’s Fraud and Error strategy, the framing and messaging on the service is entirely focussed around reporting fraud. Given the emotive and sensitive nature of the service, it is recommended that the team explore the language used and whether it could make more applicable to users wanting to report errors.\n- The team discussed plans to gather feedback from users at the end of the service. It is recommended that the methods used reflect what the team already understands about their users and their needs.\n- The team has currently worked on two user journeys; some of the remaining user journeys are complex, such as those where the user would be expected to provide details of the person they are reporting and their partner. It is recommended that the team tests these journeys with specifically recruited users that match these scenarios and that testing is based on user-generated information where possible rather than hypothetical scenarios provided to users.\n- The team must do more work to understand how users who are not online at all will find out about the service’s assisted digital support options.\n- The team must do more work to understand how users needing assisted digital support will receive an equally high quality service as those using the on-screen service independently.\n- The team should also be sure to avoid over-reliance on talking to users who are currently phoning the department to use this service, as these users are likely to be more confident and less isolated.\n- The team must ensure that ongoing research plans include working with users who will need support to fully understand their needs, and a model of support is designed to meet those needs during beta.\n- The team should help make the case to DWP for a positive outcome on their policy around open sourcing of software.\n- The service will ultimately form part of a wider transformation of DWP’s legacy estate when FRAIMS is replaced. The team should continue to be mindful of this when implementing the beta so their solution can flex when this work takes place.\n\n**Summary**\n\nThe panel were impressed by the team’s positive commitment to building the service and their early integration of user research into their work. The panel looks forward to reviewing the service at a more mature stage in its development at a future assessment.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/employer-routed-funding-service-assessment/",
    "title": "Employer Routed Funding - Service Assessment",
    "summary": "The Employer Routed Funding service provides a single digital journey to take employers and training providers from initial interest in recruiting an apprentice, through to the completion of the apprenticeship. This includes:",
    "body": "- control of funding provision and payments\n- comparison and selection of training providers\n- choosing the standard their apprentice will complete\n- choosing the assessment organisations\n\nThe digital service will offer assisted digital provision to help Employers who have low digital skills.\n\n**Department / Agency:**  \nBIS / SFA\n\n**Date of Assessment:**  \n28/09/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nS. Wood\n\n**Service Manager:**  \nG. Tucker\n\n**Digital Leader:**  \nE. Stace\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the Employer Routed Funding service is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons and Recommendations**\n\nThe Employer Routed Funding service is part of the overall Apprenticeship Reform Programme. This will deliver a new funding system that will give employers control of apprenticeship funding. The service will provide a single digital journey that will allow employers to search for an appropriate set of rules for the apprenticeship, and give employers greater control over apprenticeship funding. The service will take employers and training providers from initial interest in recruiting an apprentice, through to completion of the apprenticeship. This will include: control of funding provision and payments, comparison and selection of training providers, choosing the standard that the apprentice will complete, and choosing the assessment organisations. The digital service will offer assisted digital provision to help employers who have low digital skills. The overriding aim is to shift the emphasis from providers. During the alpha service standard assessment, the assessment panel looked at the following areas.\n\n_User needs_\n\nThe service team has clearly identified the user needs that will underpin the service. The policy intent, (for employers to have more control over the training providers they use) is a user need for some employers but possibly not all, as some will be satisfied with the current situation. Care must be taken here not to create pain points where none exist at the moment. However, this cannot be fully tested yet as the policy around funding is yet to be finalised. The panel was pleased to see that over 70 users had been interviewed during discovery. Commendably, the team had carried out additional surveys with both employers (approximately 350 responses) and providers (approximately 250 responses).\n\nEmployers will be the main users of this service and it was good to see that testing and research was primarily taking place at employers’ premises. It was also encouraging to hear that, despite the obvious difficulties, all the team were taking part in user research.\n\nThe team has made a very positive start to assessing user needs for assisted digital support, particularly given that it can be difficult to identify businesses that don’t have digital skills or access. During their research, the team identified several companies that would require support, and have estimated a 5% ongoing need for support once the service is established. They will continue to work with these companies in beta, as well as engaging with Remploy. The team is considering all options for support and will start to solidify this in beta\n\n_The team_\n\nThe panel recognises that the service manager is experienced, knowledgeable, and highly competent, and the team is multidisciplinary and is only supplemented in one or two areas by a supplier. The team is clearly working in an agile environment; sprints that were originally three weeks long have been shortened and are now weekly. In part this was possible because the prototypes are no longer being built using HTML, with Axure being used instead. We would expect fortnightly sprints to become the norm once “real” code is used again, not least because short sprints can become relentless, and may not allow for sufficient thinking time. Show & tells are well attended, and the expected techniques are taking place. The service manager attends many, but not all, of the stand-ups, but this is not an issue as the team is highly competent and take turns in leading them.\n\nIt was confirmed that assisted digital support will be paid for by the service, and that people will not have to pay providers for support.\n\n_Technology_\n\nThe panel was pleased to learn that fraud vectors have already been investigated, and that validation is already being carried out by the agency. Plans are being put into place for the service to plug into these. The agency’s data controller has been involved throughout the alpha phase. It was noted that the back-end service has already been involved in two successful service standard assessments, and there appears to be a depth of technical skill within the team.\n\n_Design_\n\nWhile perfectly acceptable for the alpha to be built using Axure, the panel noted non-standard layout and decorative elements, such as pictograms, which will need to be addressed during beta. Also, while it appeared that the alpha prototype was iterated frequently on the basis of user feedback, the panel felt the team had consider only a limited range of options. This risks the prototype not being the best possible option for the beta.\n\n_Content design_\n\nWe were pleased to learn that the team had identified a number of content design issues during the alpha, especially with regard to the variety of different user needs for information and for start points to their interaction with the service. The team had already iterated their terminology within the service, but the change from ‘Standard’ to ‘Apprenticeship’ is a concern. The service currently uses the word ‘Apprenticeship’ to mean two different things; both as a specific instance of an apprenticeship (a job with training, also used by the candidate journey), and as the choice of a type of apprenticeship. We strongly recommend that the team stop using the same word in two ways and find another word or phrase to describe the things formerly called ‘framework’ or ‘standard’, then test that word with employers and providers. The panel noted that the team have yet been able to conduct significant research on the funding model; the panel suspect that the word ‘funding’ may also prove to be problematic, as it suggests a payment to the employer rather than the involvement of the employer in choosing the training provider who will receive the payment. Given there is one certainly problematic term, and one that is potentially problematic, the panel recommends the creation of a ‘controlled vocabulary’, a list of all the service related nouns that are currently in use, to check that each noun is being used uniquely, and to help in testing the nouns with employers.\n\n_Analytics_\n\nThe team is already making use of enquiries received by the helpdesk to inform the design of the user journey. A web metrics service is in place, but this might change. The team is still teasing out which Key Performance Indicators (KPIs) are needed, and is working with the GDS Performance Platform team to identify these. The user researcher will be responsible for assisted digital analysis. However, as there is no equivalent existing service, it will be difficult to establish benchmarks.\n\n_Service development_\n\nThere is always a risk that the end of the alpha phase merely evolves into the beta service. Serious consideration should be given to taking the start of the private beta phase as an opportunity to draw a line under the work to date, and design the new service from scratch. Services should be based upon what has been learned, not what what has been built.\n\nThe team should regularly engage with the GDS Design Team throughout beta, and it is advisable that this engagement starts as soon as the beta is underway. The service is complicated insofar as there are a number of user groups (employers, training providers, government staff, apprentices), some of whom will be perfectly happy with the existing model and could therefore be confused.\n\nWe also recommend the service take advantage of the wider GOV.UK design community. There are other government services in development that have similar features and user needs. For example, Digital Marketplace, Choose and Book (NHS), and Performance Tables (DfE). The team should collaborate with these and other services to establish common patterns that all can benefit from. GDS can support you in this.\n\nThe terms “apprentice” and “apprenticeship” mean different things to different people and did cause the panel some confusion. More work will be required to ensure users aren’t similarly confused when the service returns for the beta assessment.\n\n**Summary**\n\nThe panel would like to congratulate the service manager and the team on passing the assessment. The team appears highly competent and is clearly working well. It was good to see that there is a member of the policy team involved, and that lessons and observations from user research sessions are helping to inform policy decisions. Equally it was good to hear that all members of the team took part in user research sessions. The panel looks forward to seeing the team again at the beta assessment.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/schools-performance-tables-service-assessment/",
    "title": "Schools Performance Tables - Service Assessment",
    "summary": " **Department / Agency:**  \nDfE",
    "body": "**Date of Assessment:**  \n28/5/2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. Harrington\n\n**Service Manager:**  \nI. Thomson\n\n**Digital Leader:**  \nL. Diep\n\n* * *\n\n## **Assessment Report**\n\nThe Schools Performance Tables service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Schools Performance Tables service is on track to meet the Digital by Default Service Standard at this early stage of development. There are however a number of recommendations in this report which the team must take into account for the beta phase.\n\n**Reasons**\n\n_User needs:_\n\nThe panel were impressed with the approach and results gained by the UX Lead and the team in a short time. The service manager was able to explain clearly who the service was for, and enumerate the target personas. A sensible plan and amount of funding was declared for continual iterative research through beta. It’s helpful to keep in mind the changing needs of user research as the development matures. Initially more ethnographic and wide-ranging research - ideally in situ - should be carried out. This should then make way for more focussed work on the interface and interaction as the key assumptions re. user needs get filled in. The panel were pleased to hear that DfE plan on dedicating a space for a user research lab, but this will need sustained attention if it’s to be completed in time to be useful for this service.\n\n_The team:_\n\nThe team is not co-located however they appear to be working well to deal with this, spending at least 2 days per sprint face to face. User research has also been conducted in different locations to ensure all the team are able to take part. The team is working using Agile methodologies and there is good separation of roles in most cases. The panel were concerned that too much is expected of the UX Lead in the team who is responsible for both user research and the design of the service. (See recommendations)\n\n_Security, Privacy, Tools and Standards:_\n\nThe team appear very familiar with the actions and conversations that need to happen when operating a digital service. They are taking conscious steps to avoid lock-in, and carefully evaluating their choices with technology options. There are a lot of unknowns still, e.g. how the service will be operated; but the team are aware of what they don’t know and have plans about how to address this.\n\nThe team was very knowledgeable about what standards they can support, and are building the service with a view to it being an API that can be consumed, rather than something which consumers might need to scrape to do something with the data.\n\n_Improving the service:_\n\nAt alpha the team have been able to rapidly change and deploy the product and multiple variants have been tested with users.\n\n_Design:_\n\nThe service team are aware of design problems with the service and are in the process of iterating the service based on solid user research. The panel are confident the UX Lead is well placed to push the design of the project forward and is engaging with the design community around government. Although the panel are confident the service team has the ability to deliver a good service which meets the design criteria – the current alpha service does not meet Service Standard Point 13 ‘Build a service consistent with the user experience of the rest of GOV.UK by using the design patterns and style guide.’\n\n_Assisted digital and digital take up:_\n\nThe existing service is 100% digital and the new service will also be fully digital. Since the service is not transactional, assisted digital is not a component that the panel assessed.\n\n_Analysis and benchmarking:_\n\nThe team had tested different designs with users in the alpha phase and fed this research in to the build of the product. The existing service does have analytics on it which provides an insight into its use but only the out of the box metrics are tracked.\n\n**Recommendations**\n\n_User needs:_\n\nThere is concern that there is too great an overlap between the design and research roles. The design challenges in this service will be significant, with a great deal of information to convey clearly. The primary user research should inform which features are critical to ‘minimally-viable’ first release of the service. The panel recommend testing with fewer on-screen elements, essentially to start testing with a much more pared down interface and user flow (carrying forward the learnings from the alpha).\n\nEvery element on screen has to be justified with primary research. The current prototype gives the impression that every idea has been included, and that the available data is driving what elements are included, rather than a user-centred approach. The panel do not recommend testing with non-working elements. Efficient testing, happens when a thin, horizontal slice through the interaction is prioritised for one user group (e.g. searching for local schools for parents), and then other key user persona groups included. Alternative interactions / layouts / interface paradigms should be explored to discover which works best for the needs, experience, expectations, and mental models of your user persona groups. For example, the informational and emotional needs of parents using this service will likely be meaningfully different than for school governors.\n\n_The team:_\n\nThe team needs a full time designer and full time user researcher. Currently design and user research are a single role. The service has different user groups and user needs and for these to be properly met there needs to be more design input.\n\n_Security, Privacy, Tools and Standards:_\n\nThe panel would urge the team to look at how they intend to make the source code for the service available. Doing this earlier rather than later makes it considerably easier. In particular, be aware of separating out configuration from implementation, as described in [https://gds.blog.gov.uk/2014/10/08/when-is-it-ok-not-to-open-all-source-code/](https://gds.blog.gov.uk/2014/10/08/when-is-it-ok-not-to-open-all-source-code/). The panel would also like to encourage communication between this team and other parts of government that are developing services using Microsoft technologies, such as how to consume and extend the frontend toolkit. Publishing the code and highlighting it via blogging can help those conversations happen.\n\n_Improving the service:_\n\nAs the team move in to beta they should ensure they can iterate and improve the service at the same speed as they have in alpha. At the alpha assessment there were some incomplete features which may or may not help meet user need. At beta the team should ensure they focus on the key points of the service to deliver the most benefit to users.\n\n_Design:_\n\nA separate email will be sent by the design assessor outlining areas that need improvement in relation to Service Standard Point 13. Also see previous comments relating to the composition of the design team.\n\n_Analysis and benchmarking:_\n\nThe team should install analytics on the beta service to capture data about how the service is being used and to give insight for improvements and changes. The service should be measuring on-screen events and goals to better understand and see how users are making these journeys. (e.g a user comparing two schools might follow a path of: &nbsp;home→ search results→ individual view→ compare.)\n\nThis is a non transactional service, however the service is still able to display cost per session, user satisfaction, and a suitable completion rates (for frequent tasks as identified from the analytics) on their Performance Platform dashboard in addition to any other metrics identified by the service team.\n\nAs part of the Beta development to remove the duplication of effort across government, the team should investigate a closer integration with the Performance Platform - for example using their code for the visualisations on the Schools Performance Tables, or using the Performance Platform to actually serve the graphs and charts as components within the service.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | No | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/advocate-defence-payments-service-assessment/",
    "title": "Advocate Defence Payments - Service Assessment",
    "summary": "The Legal Aid Agency administers the Legal Aid budget for England and Wales. Advocate Defence Payments looks to replace the existing paper process for barristers and solicitor advocates submitting claims for Crown Court cases.",
    "body": "**Department / Agency:**  \nMoJ\n\n**Date of Assessment:**  \n21/5/2015\n\n**Assessment stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nS. Wood\n\n**Service Manager:**  \nS. Hollands\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the Advocate Defence Payments service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe panel found that the Advocate Defence Payments team demonstrated a sound understanding of the task they have embarked upon. Together the team confidently and competently demonstrated that they understood many of the issues that they faced and showed that they were flexible enough in their approach to be able to respond to user needs that are emerging from the research. For example, having spoken to around 60 people the team identified a new user type – the claim chaser.\n\nThe team is working with two broad groups of users who work at different ends of the service: advocates’ clerks and Legal Aid caseworkers. The assessment panel liked the plans to bring the two groups together to avoid the “them and us” culture. The panel would like to see the outcome of this when the Advocate Defence Payments team returns for their beta assessment.\n\nThe panel also liked that there was a desire in the team to test users in their offices - where they do their day-to-day work.\n\nThe panel were pleased to hear that the accreditor had been engaged at an early stage of the delivery.\n\nThe panel also liked the way that the Advocate Defence Payments team recognised that their service was part of a wider transformation programme. On that same note, the panel were pleased to know that the team will be talking to other MOJ colleagues about approaches to remove the need for a \"wet signature\". Clearly more work needs to be done here, but the Advocate Defence Payments team recognise this.\n\nAlthough engagement with the GDS Performance Platform has been tentative, the panel believe that the team have time to rectify this. The panel were interested to hear that the Legal Aid Agency has its own internal dashboard, as well as that the team thought about the need for KPIs over and above the standard four that GDS recommends.\n\nThe Advocate Defence Payments team had started by simply replicating the existing paper form. While this is not unusual, it does mean that issues with that form are carried over to the online service. However, the panel were assured that the team recognised the flaws in this approach and explained how they intended to tackle them.\n\nAdditionally, the role of the business analyst (BA) seemed to be underplayed in the delivery team. The panel has found that government too often confuses the role of a BA with that of a subject matter expert. Translating user needs into actionable user stories and acceptance criteria that a dev team can work on is a vital element in the role of a BA. At the beta assessment, the panel will be looking for stronger evidence as to the effectiveness of this position.\n\nThe service did not pass point 10 of the Digital by Default Service Standard due to a lack of research into assisted digital (AD) users and their needs. There was a lot of reference to the fact that 7.5% of claims in one particular week were handwritten submissions and this was taken as a start point for AD research during the beta build phase. But during the alpha build, no AD users had been identified, much less engaged with.\n\n**Recommendations**\n\n_Assisted digital_\n\nThe team must identify users who require AD support (including from third parties) in order to complete the service, and the number of users involved. Then the panel would need to see that a support plan has been put in place based on that research and that the support is being tested and iterated. The team must develop a fuller understanding of likely costs of providing support, for all providers (including third parties) and across all support routes.\n\n_User needs and research_\n\nThere is a need to address cultural issues at some advocates’ offices, specifically the reticence of clerks to ask their bosses for missing information. At the moment, this means that incomplete claims are being submitted, resulting in payment delays to the advocates. It could be that the online service helps to overcome this issue and is something the assessment panel look forward to hearing about at the beta assessment.\n\nRegarding the \"Case Chasers\", the panel recommend further work with this group to ensure that their needs are both understood and met.\n\n_Design_\n\nThe panel recommend that the team keep the scope minimal for their minimum viable product. In particular, identify which features it would be impossible to launch without and focus on those. Avoid implementing features where there’s not a clear user need. The team should also hold off on creating a global experience language until the product is more mature.\n\nThe panel also recommend that the team identify and remove unnecessary questions, working with a BA to fully understand why questions are being asked. For example, if you need to confirm a user is over 18, you can just ask them to confirm instead of requesting a date of birth.\n\nThe panel also suggest moving away from replicating the paper form. Instead, testing whether this works best as one long page (as it is currently) or split into individual questions (see [www.gov.uk/register-to-vote](http://www.gov.uk/register-to-vote)). The team should consider their choice of form fields carefully. For example, change drop-downs with 8 items or fewer to radio buttons. For your giant drop-downs, look into other ways your users can make this choice.\n\nFor the beta assessment, the assessment panel will be looking for evidence that the topic of \"wet signatures\" has been fully explored and solutions tested.\n\n_Technical_\n\nThe panel recommends that the nature of the data and the interaction with untrusted end users requires some thought around security and fraud prevention. End users will more than likely (borne out by research) be using operating systems that are near end-of-life and vulnerable to viruses and so on. The panel believe it will be crucial to see the team de-risk these client interactions.\n\nAdditionally, the panel think that the security approach taken for the alpha is well thought out - however a decision on the correct solution for this dataset will need to be taken soon and also, more broadly, the team should see if there are ways of reducing the dataset stored.\n\n_The Team_\n\nIt was noted by the panel that the role of the BA was not shown on the slide about the team structure. Although it was accepted that this was an oversight and that the BA is indeed well placed to challenge the business requirements, this is an important function in a delivery team. The panel believe that it is important to ensure that the BA is not just a subject matter expert (all too common in government), but is also someone who is skilled in writing user stories and acceptance criteria that capture the product owner’s requirements and that developers can understand.\n\n**Summary**\n\nTo conclude, the team showed the sort of passion and commitment that the panel like to see. The team clearly believe in what they are doing and want to do the best for the users of their service - both in advocates’ offices and in the Legal Aid Agency. The panel encourage the service to continue their good work, mindful of the recommendations made.\n\nA successful alpha review is not a guarantee of success. But it is a clear indicator that a service is on the right track. The panel look forward to seeing the service team again at the beta assessment sometime in the future.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/personal-tax-account-alpha/",
    "title": "Personal Tax Account - Alpha Assessment",
    "summary": "Personal Tax Account will equip HMRC customers to more effectively take ownership of their HMRC affairs in one place through their own secure digital account, which they can access when they want to, and as often as they want to.",
    "body": "**Department / Agency:**  \n[HM Revenue & Customs (HMRC)](https://www.gov.uk/government/organisations/hm-revenue-customs)\n\n**Date of Assessment:**  \n28 April 2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nA. Lister\n\n**Service Manager:**  \nM. Kinsella\n\n**Digital Leader:**  \n[M. Dearnley](https://www.gov.uk/government/people/mark-dearnley)\n\n* * *\n\n## **Assessment Report**\n\nThe Personal Tax Account service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n### Outcome of service assessment\n\nAfter consideration the assessment panel have concluded the Personal Tax Account service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n#### Reasons\n\nThe concept of a single source of personal tax information and one place to provide updates and make changes was supported by user research data - there was an evidenced user need for the information to be in one place.\n\n#### User needs and user research\n\nThe team has begun exploring a very complex landscape of user needs. It was demonstrated that many potential service users have fear of HMRC and encouraging them to voluntarily engage with the department will be challenging. But at the same time the user needs statements indicate that users wish to obtain relevant information \"so that I don’t get into debt or miss out money I’m entitled to\".\n\nThe user needs statements which the service team had developed were supported by evidence from user research.\n\nThe user research which has been conducted seemed to be reasonably substantial &nbsp;in terms of the number of users that had been seen - for example 10 rounds of usability testing in Discovery and Alpha. However, while many of these interviews included an element of semi-structured discussion, &nbsp;there was a lack of any contextual or ethnographic research, which means there may be gaps or inappropriate emphases in the user needs statements. There were also considerable gaps in the demographic coverage of the research - there did not seem to be any systematic breakdown of the audience, and key audience dimensions (e.g. age, English as second language, etc) had not been researched.\n\nThe team were able to illustrate how the prototype had evolved in response to usability testing findings - for example a salary figure had been added in response to user feedback. But the prototype which had been developed in the Alpha contained minimal functionality - there are &nbsp;considerably more features lined up for inclusion in forthcoming work and the Personal Tax Account will link through to other HMRC ‘products’ where users can actually take actions, for example paying tax or applying for a refund.\n\n#### The Team\n\nThe team is generally robust but the user-research plan will need additional resource.\n\n#### Security, privacy, tools and standards\n\nInitial thinking around technologies, security and privacy has begun and will follow HMRC’s established patterns. However, the prototype shown did not demonstrate the complete end-to-end service.\n\n#### Improving the service\n\nThe team understood and have implemented an effective approach to iterating the service.\n\n#### Design\n\nThe prototype shown appeared to follow the correct design patterns and interactions.\n\n#### Assisted digital and channel shift\n\nAlthough the team had identified a potentially very high number of assisted digital users, they had done insufficient research with users with no digital skills and access to be able to demonstrate an understanding of user needs for assisted digital support.\n\nDue to the estimated number of assisted digital users, it’s important that this work is done promptly during development of the service. This will be needed to ensure that funding is available for appropriate support that meets the standard. The plan for beta sounds reasonable but there is a lot of work to do and the team needs to be further ahead with their understanding of assisted digital user needs for this service.\n\n#### Analysis and benchmarking\n\nIt’s anticipated that the service will use HMRC’s Google Analytics licence and conversations have begun with the GDS Performance Platform team.\n\n#### Testing with minister\n\nAlthough this is an Alpha, the current Minister is aware of the service.\n\n### Recommendations\n\n#### User needs and research\n\nThe user research ambition (as expressed in the Beta research plan) is substantial. &nbsp;It has to be: the audience for the Personal Tax Account is wide ranging and complex. The user research conducted so far has unavoidably been relatively narrow in coverage due to resource constraints - just one researcher (although the amount of research achieved despite this is commendable). Given the gaps in coverage, and given the importance to HMRC’s long term strategy of the success of Personal Tax Account with customers, it is important that research resources commensurate with the scale of the challenge are provided. The assessment panel would suggest that at least one other full time researcher is provided to the project.\n\nThe end-to-end user journeys need to be tested with users as part of this work - from the Personal Tax Account front door right through to the end-point of paying tax, applying for a refund etc. The testing should include navigational issues like getting back to the Personal Tax Account at the end of the journey and, if appropriate, moving between different ‘products’ without the need to go via the ‘home page’.\n\nGiven the importance of the Personal Tax Account - it fits with user needs in terms of knowing liabilities and entitlements, feeling in control, having information in one place, receiving personalised messages; &nbsp;and it will become the focus or start point for all online personal tax interactions with HMRC - it would seem that these extended transactions must be subservient to the navigational and interaction expectations created for users by the Personal Tax Account. At beta assessment the panel will wish to understand the research evidence for how effectively these transactions have been integrated into the tax account interaction, in terms of consistency, simplicity and seamless integration.\n\nIt was clear from the discussion with the service team that the Personal Tax Account is high profile for the business and a lot of business objectives are riding on it. In such circumstances, there may be a danger that the product becomes bloated and unwieldy. It is strongly recommended that the content and configuration of the product continues to be driven primarily by user needs as evidenced through research. This will maximise the chances of product success.\n\n#### End to end service\n\nAs the service moves into Beta development, an iteration of the potential end-to-end service must be made available for research at the earliest opportunity.\n\nThe service team didn't present much evidence to show that users were succeeding in using the service first-time, unaided. This was mostly due to the lack of definition around what ‘successfully using the service’ would actually mean for a user (and how to measure it). As the service moves through beta, having a clear understanding of what constitutes a successful interaction will become increasingly important for understanding whether the service is working or not. The service team needs to be able to define what a successful user interaction is for the Personal Tax Account service, especially given the complexities with having multiple services that sit within it.\n\n#### Technical And The Team\n\nThe extent of this service was a little unclear. The Personal Tax Account will be an account to access many other HMRC services. The responsibility for the design patterns used across these services and how they integrate may impact on the resources that this team needs. There is a need for the team to demonstrate how the interactions between the Personal Tax Account and the services that sit within it will be managed.\n\n#### Assisted digital\n\nThe assisted digital component(s) of the service needs substantial work. The assumption that the ‘as is’ processes and services will be sufficient needs to be challenged. The assessment team appreciates that HMRC is embarking on a significant transformation but the volume of potential assisted digital users - approaching 10 million - necessitates specific provisions and funding. Given that assisted digital is almost one third of the total user-base, significant channel shift will not be achieved without the necessary support.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | No | 10 | No |\n| 11 | No | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | No | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/money-to-prisoners-service-assessment/",
    "title": "Money to Prisoners - Service Assessment",
    "summary": "The Money to Prisoners service will enable the friends and families of prisoners to send them money via online secure forms. The Ministry of Justice will also implement the necessary business change, and provide the necessary guidance, to allow friends and family to submit payments via bank transfer.",
    "body": "**Department / Agency:**  \nMOJ\n\n**Date of Assessment:**  \n16/4/2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nA. Listor\n\n**Service Manager:**  \nT. Duarte\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the Money to Prisoners service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe assessment panel were pleased to see that the Ministry of Justice team had used the knowledge and insight gained from delivering the Prison Visit Booking Service as a solid foundation for building this closely related service. The user needs of those sending money to prisoners and those administering funds in prisons were well evidenced.\n\nThe panel also found that the team’s approach to development was genuinely agile and initial ideas around the service’s features and interactions looked promising.\n\nAlthough meeting user needs is at the heart of the development, reducing costs to users and government is a substantial driver, as demonstrated by this service.\n\n_User needs_\n\nInitial research had evidenced the need for a simple and inexpensive way to send money to prisoners. The speed of the transaction is important and the need for vigilance in terms of amounts, frequency, senders, etc, was found by the panel to be well understood.\n\n_The team_\n\nThe assessment panel have found Ministry of Justice digital teams to be well formed and complete and the delivery team for this service was no exception. The service team demonstrated a clear and healthy understanding of Agile methods, showing the ability for the team to communicate clearly with one another, to change their own process based on feedback and for the Agile methodology used to represent the teams ability to work, not constrain it. It was clear to the panel that the team valued healthy face to face communication over story definition and handoff by tool.\n\n_Security, privacy, tools and standards_\n\nThe service team’s technology choices were in line with the Technology Code of Practice and the panel found that the team demonstrated a clear understanding of the risks that need to be addressed during the beta.\n\nThe service team were able to articulate the reuse of existing patterns appropriately, and while the panel would have liked to have seen more work on prototyping some of the security mechanisms, it was clear that the service manager and the technical architect were well aware of the security challenges that remained to be dealt with in the beta.\n\nThe assessment panel were also very pleased to see that pragmatic and realistic decisions had been made about the technology choices, selecting technologies based on their appropriateness for use rather than any government specific security solutions. The assessment panel noted that the ability of the team to deploy at any time and to automatically provision environments was considered important to the team.\n\nThe panel were also pleased to see that the team was choosing to release the code from the Alpha so that other people could learn from it and that the team had a clear policy of open by default for the beta code, with a clear explanation of the sort of code that would be held back.\n\n_Design_\n\nThe prototype service used the proven GOV.UK design patterns but it was noted that the design approach was responsive rather than mobile-first.\n\n_Analysis and benchmarking_\n\nThe core KPIs along with integration of analytics were well understood. However, the initial service will focus on payments from users’ bank accounts and since this component will happen completely outside the service it will be difficult to measure. The panel thought that the team had some good initial thoughts on proxy metrics that would indicate success in this area.\n\n**Recommendations**\n\n_User needs_\n\nThe assessment panel appreciated the difficulty identifying and engaging with those sending money to prisoners, but thought that the research sample needed to be broader than just those who visited prisons. For example, those user groups whose only engagement with the prison service is sending money are an important audience segment.\n\nThe panel also felt that the service team needed to ensure that during research sessions, users are presented with a range of costs for each payment method. The highest costs should be the current actual fee, the lowest, the projected minimum fee. In particular, the assessment panel would like to see evidence of the team conducting research with costs which are unsupported by current policy (such as free card payments and charged for bank transfers) in order to either challenge policy or provide evidence to support the policy in place.\n\nThe service team mentioned that current policy was to pass the charge of card payment on to the user. The assessment panel would suggest that research should be done to understand what would be the preferred method of payment for users if cost were not a factor. This may give evidence to challenge or support the policy in place.\n\nThe panel believe continued ethnographic research is essential. This will help the team understand how users find and manage the details they need to make payments, eg prisoner number.\n\n_Team_\n\nThe panel advised that the team make sure that the hands-on development resource does not become overwhelmed by the management, analysis and administration functions feeding into it.\n\n_Security, privacy, tools and standards_\n\nThe panel believe that detailed scoping and analysis of the security implications of the broader service should be initiated at the earliest opportunity. Although the minimum viable product will not include card payments, deferring the complexity around this will cause problems if/when this feature is required.\n\nThe panel also felt that demonstrated security analysis function needed some clear planning around long term use, especially as the dataset grows and the simple interface is no longer able to meet the desired needs.\n\nThe panel challenges the team to investigate what is possible around integration with the legacy systems. The team should do the hard work to make the tool simple, and while the legacy integration is a very difficult piece of work, the panel felt that the team has ruled out integration without fully exploring the problem space. The panel would hope that, at beta assessment, the team would be able to clearly explain why swivel chair integration is the option that is cost effective, and to articulate a clearer longer term strategy for a fully integrated system.\n\n_Design_\n\nThe panel think that the service team should consider a mobile first approach for the beta service. Research evidence has demonstrated that the majority of potential users would engage with the service on mobile devices. The panel appreciates that the initial service will be very much focussed on users setting up payments from their bank accounts. However, the introduction of card payments will accelerate the need for a mobile-first design.\n\n**Summary**\n\nThe assessment panel felt that the service team has begun developing a very promising service that meets user needs and will improve efficiency in getting money to those in prison. More generally, the Ministry of Justice continues to demonstrate a delivery-focussed approach to meeting user needs by developing services in a truly agile way. The assessment panel looks forward to seeing the service for Beta assessment.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/company-accounts-and-tax-online-alpha/",
    "title": "Company Accounts and Tax Online - Alpha Assessment",
    "summary": "Company Accounts and Tax Online will allow the smallest companies with the simplest tax affairs who are unrepresented to file their Company Tax return, accounts and computations. It will be a digital online product which will be a quicker and easier service to use and will allow the user to file to HMRC and Companies House at the same time.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n17/3/2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nL.Scott\n\n**Service Manager:**  \nM. Duffield\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## **Assessment Report**\n\nThe Company Accounts and Tax Online service has been reviewed against the 26 points of the Service Standard at the end of alpha development.\n\n**Outcome of service assessment**  \nAfter careful consideration the panel has concluded that the Company Accounts and Tax Online service is on track to meet the Digital by Default Service Standard at this early stage of development. The assessment panel noticed several areas where the service needs to demonstrate considerable improvement before coming in for a beta assessment. These are outlined in the recommendations below.\n\n**Reasons**\n\n**User needs and user research**  \nThe service allows small companies to file accounts to HMRC and Companies House and aims to encourage far more companies to file jointly with both agencies. The team had insight into user needs here - they acknowledged that while jointly filing was beneficial to both users and government, some users preferred to file separately, and had good reasons for doing so.\n\nThe needs that the service is currently addressing were identified from a mixture of legislative requirement, customer feedback, and business needs. The team showed some evidence of how they used customer feedback and survey methodology to determine a web-based service was desired by users. They have gathered evidence of dissatisfaction and distrust with the current service (HMRC fields 4,844 calls a month). The team showed some knowledge of as yet unmet user needs, some of which they expected to address shortly, others were awaiting prioritisation in the backlog.\n\nThe alpha service demonstrated only accommodates a small-subset of users (micro-entities as defined by the EU). The service team have used targeted research to find users of this type, there are very few, and only 2 users of this type have tested the service in its current form. The service team have expanded the remit of the service and expect more companies to be able to participate in testing from end-April. Meanwhile they have been using clickable wireframes to test sections of the service in lab-based research.\n\nThe team have carried out 56 lab tests on partial aspects of the service with real users over the last 15 months. Satisfaction is being benchmarked and is reported as improving.\n\nThe team showed how they have made some changes following evidence gathered from research.\n\n**The team**\n\nThis is an unusual set-up with 2 multi-disciplinary teams working together, in 2 different organisations in 2 locations. The service team explained that they are working as one team, with one empowered lead service manager at HMRC.\n\nThe team is using agile, although it is suffering from the legacy of the waterfall structure previously used at HMRC. The team hopes to work around that. They are using scrum, working in sprints with a shared backlog and have a common codebase. Elements of agile theatre are in use, eg stand-ups and retrospective. The team introduced kick-offs to give the whole team context behind the project.\n\nThe service has been in development for over a year, which is unusual - we’d expect an alpha assessment at a much earlier stage of the project. The user research has ramped up recently and the team seemed confident that the pace of delivery of iterative improvements would increase.\n\n**Security, privacy, tools and standards**\n\nThe team have addressed the security and accreditation of the service and are working closely with 2 SIROs. There are no concerns, aside from the length of data retention, which the team are still working on. The service team are using the tax platform and HMRC is the data controller. The service doesn’t set any cookies other than the one covered by the tax platform. HMRC have produced a white paper called ‘Coding in the Open’. The service team is opening up some source code and are using various open standards.\n\nThe service can be run locally and there is also a QA environment which is used during testing with users. The service has re-used the existing Companies House API, which has been pen tested.\n\nThe service has adopted the tax platform’s disaster recovery process. They have planned for outages of core Head of Duty systems. They have considered the impact of downtime on users. There is a chance that users will incur penalties for late submissions. This will be handled by a wider HMRC recovery process, where affected users will have their accounts retrospectively corrected. There is also provision to defer filing deadlines in the scenario of an unplanned, lengthy downtime.\n\nThe team described a 48-hr deployment process, from ticket to live. The team are keen to make this faster - possibly by removing the dependency on the WebOps team on the tax platform.\n\nThe alpha period of development has been unusually long. The team expect the pace of delivery to quicken over the next phase. The capability to iterate the service during this early stage of development is there.\n\n**Design**\n\nThe service team has struggled to find suitable users, despite targeted attempts, and so has not been able to show evidence for users completing the service end-to-end, unaided. However, the team showed how they have tested elements of the service, and how they have made the scenarios more realistic. For example, they originally relied on dummy data for users to populate the form with. They now invite users to bring their actual past tax accounts. This has uncovered another need that the service team are aware they need to address - users are bringing inaccurate data with them from actual accounts.\n\nThe assessment panel heard that the design and user experience of the service is still very much a work in progress - completely understandable at this alpha stage. The panel recommend the service team gets in touch with other HMRC services (e.g. Inheritance Tax) to see if they can use common patterns.\n\n**Assisted digital and channel shift**\n\nDuring the alpha stage, the team targeted 1800 users thought to have assisted digital needs. They telephoned people who had never filed online and took them through a questionnaire to determine the level of assisted digital support they may require. From this, the team projected they would have 2% of their users with potential assisted digital needs. This does not marry up with wider HMRC and Companies House research which indicates ~30% of users with AD needs. The team acknowledge this, and plan to carry out further targeted research during beta. They have identified 65,000 companies with potential assisted digital needs.\n\nProposed assisted digital provision is by telephone, drop-in to offices and bi-annual focus groups. The geographical spread of this face-by-face support wasn’t clear during the assessment. The assisted digital support is free at point of use.\n\nThis service will replace the previous Adobe product and supports mandatory online filing which was introduced some year ago by HMRC. Filing online is not mandatory for Companies House.\n\n**Analysis and benchmarking**\n\nThe team have tagged the service with Google Analytics. There is an aspiration to use analytics to verify user research - this is dependent on users accessing and using the service during beta.\n\nThe team have thought about how to measure success. In addition to the 4 mandated KPIs, they will be measuring drop-outs (although they need expert help to work out how to do this); how long people stay on certain pages; how long the submission takes; how often people are accessing help (to improve the design).\n\n**Recommendations**\n\n**User needs and user research - point 1, point 2 and point 20**\n\nConcentrate on planned user research with actual users and ensure the service is regularly tested end-to-end.\n\nIntegrate new designs that have tested well into the service and test these with users.\n\nContinue to involve the whole team in user research and help the team understand the user needs this service will be meeting.\n\nThere are 3 full-time user researchers on the team - we’d strongly encourage that other research methods are used as well as lab-based testing, to reach many more users.\n\nRe-consider the journey for users who cannot use the service (currently identified in 4 stages), and hand them off to the most useful place to meet their need. The list of third parties for tasks not supported by the service should be considered within the scope this service (even if the content lives on GOV.UK).\n\n**The team - point 2**\n\nThe team should consider how they can operate effectively when split across two locations, in two organisations. They should be able to demonstrate how this does not impede delivery at their beta assessment.\n\nRecruit a full-time content designer to work with the service team. This is a content-heavy service and users have complex tasks to complete. There is a high volume of content, instructional text and micro-copy. The content designer should be working alongside the team, getting involved in user research and feeding in to the design and flow of the service.\n\nRecruit a full-time performance analyst to work with the service team. Due to the complexity of service, the service team need a dedicated analytics person to get into shape before public beta. The multiple possible user journeys means that a complex set of goal filters will need to be built to capture drop off and pain points.\n\n**Assisted digital - point 1 and point 10**\n\nCarry out further research to identify users with assisted digital needs and develop proposed support to meet user needs and the assisted digital standard.\n\n**Design and content design - point 9 and point 13**\n\nThe service team should work with GOV.UK teams and HMRC content teams to ensure the user journeys around the service provide the best experience for users.\n\nThe content designer (when hired) should collaborate with the content community at GDS and across government to ensure that the service adopts the style patterns and best practice endorsed by its application in comparable, successful services.\n\nDuring the next assessment, the service team should be prepared to show more examples of how evidence gathered from user research and testing has informed the service design.\n\nWork with the Inheritance Tax team on the design and user experience of the form. They encountered similar challenges and have some well-researched solutions.\n\nMore detailed front end design recommendations and observations will be sent separately.\n\n**Analytics, benchmarking and reporting - points 7, 18 and 21-24**\n\nAs well as recruiting a performance analyst, the team should work with HMRC exemplar services to get a better understanding of how the use of data can inform service development.\n\nWork with the GDS performance platform team to have a dashboard measuring performance against KPIs publicly available when you are ready for public beta. The assessment panel recommend the team measure successful submissions in addition to the KPIs.\n\n**Open standards and common government platforms - point 16**\n\nThe PDFs generated in the service should be PDF/A to comply with open standards. The team should familiarise themselves with the government standards hub.\n\nThe service will need IDA for Business. The team should engage with the GDS team working on this to feed in their needs.\n\n**Make source code open and reusable- point 15**\n\nThe service team should continue the work to open their source code.\n\n**Testing the end to end service - Point 17**\n\nEnsure the service has been penetration tested.\n\n**Testing with the Minister - point 26**\n\nThe team have demoed the service to the Chancellor. To fully pass this criteria, before the live assessment, the minister needs to complete the service themselves, as if they were a user.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | No | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | No | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | No |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/marriage-allowance-alpha/",
    "title": "Marriage Allowance - Alpha Assessment",
    "summary": "The Marriage Allowance service will allow a customer with unused personal allowances to transfer a set amount (£1060 in 2015/16) to their spouse or civil partner, to reduce the couples overall tax bill.",
    "body": "**Department / Agency:**  \n[HM Revenue & Customs (HMRC)](https://www.gov.uk/government/organisations/hm-revenue-customs)\n\n**Date of Assessment:**  \n20 March 2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nM. Etherington\n\n**Digital Leader:**  \n[M. Dearnley](https://www.gov.uk/government/people/mark-dearnley)\n\n* * *\n\n## **Assessment Report**\n\nThe Marriage Allowance service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded the Marriage Allowance service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThere is a strong multidisciplinary team in place who have been working in an agile way to iterate the alpha prototype based on research. The team spoke knowledgeably about the digital service and explained the changes made to the transaction based on research, for example content changes to make it clearer which details users needed to enter and the information users would need at the start of the transaction.\n\nThe team have the appropriate safety and security measures in place and are able to iterate the transaction on a very frequent basis. They have plans in place to quickly iterate the digital service during private beta based on data and feedback about how users are using the service.\n\nThe service team explained their plan to invite users to complete the transaction during the private beta phase from the current database of almost 200,000 users who have registered their interest. The service team should not invite more than 200,000 users to complete the private beta service. &nbsp;Once they reach the 200,000 invites threshold the service must pass a beta assessment, which will ensure that all users can access the service directly from GOV.UK.\n\n**Recommendations**\n\n**Point 9: Create a service that is simple and intuitive enough that users succeed first time, unaided**\n\nWhilst the team have completed research and usability testing on the individual elements of the service which they have developed, they haven't fully tested the transaction end-to-end. The assessment panel recognise that this is the first digital service that has integrated with verify at such an early stage, and as such verify doesn't currently have their prototyping solution for alpha research documented in a way that teams can find and use it easily.\n\nThe assessment panel suggest that the service team collaborate with the verify team on ongoing needs for research and prototyping resources and expect the team to research the full end-to-end journey before private beta launch, so that they can make any changes needed based on this research and are confident that the service is simple and intuitive enough that users succeed first time, unaided.\n\nThe assessment panel had some concerns about the service having an optional calculator section contained within the transaction. The GDS pattern is for calculators to exist as self-contained features on GOV.UK, which reduces confusion and complexity within the transaction. However, the timeframes involved mean that creating a standalone marriage allowance calculator on GOV.UK before the launch of the private beta wouldn’t be possible, so as discussed during the assessment, we have some interim design recommendations for the calculator that we'll send through in a separate document. The assessment panel strongly recommend that the team test these designs with users before inviting users to access the private beta service.\n\n**Point 10: Put appropriate assisted digital (AD) support in place that’s aimed towards those who genuinely need it**\n\nThe team had accessed HMRC-commissioned research (including some specifically about the Marriage Allowance digital service). This is a great starting point, but the team should avoid making assumptions about users’ AD support needs, and carry out specific research. This must be with users of the service. The team are already working with third parties to test the digital service and this could potentially extend this to include this AD research. The team will need to consider the sustainability of support that users get from third party suppliers for later service development phases.\n\nThe team are planning on inviting users who registered their interest online to access the private beta, but weren’t planning to include users with the lowest levels of digital skills and access. They had thought about potential telephony channel support for users with sufficient skills and access to already be trying to use the digital service. The team must also plan to specifically test, measure and iterate the AD support required across all channels (including face to face), for users not already online.\n\n**Point 1:**  **&nbsp;Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for digital and assisted digital service design.**\n\nWhilst user research has been carried out during alpha, including engaging with third parties Age UK and Tax Help for Older People, the research plan for private beta does not guarantee that insights are captured from a sample representative of all potential users of the service. The team should put in place a plan for involving more people in user research than just those who have signed up using the marriage allowance registration service.\n\nIn particular, effort should be made to ensure people of State Pension age are involved in research during private beta, as it is estimated that a third of users eligible for marriage allowance will be also be eligible for State Pension.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | No | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/epayments-service-assessment/",
    "title": "ePayments - Service Assessment",
    "summary": "ePayments allows users to repay a benefit overpayments online using a debit or credit card through a hosted card payment service.",
    "body": "**Department / Agency:**  \nDWP\n\n**Date of Assessment:**  \n30/04/2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nR. Grove\n\n**Service Manager:**  \nK. Bruckshaw\n\n**Digital Leader:**  \nK. Cunnington\n\n* * *\n\n## **Assessment Report**\n\nThe ePayments service has been reviewed against the 26 points of the Service Standard at the end of the alpha stage.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded that the ePayments service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service has successfully met the alpha standard for a Digital by Default service. Key areas of success were as follows.\n\n**Point 2** - _Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility._\n\nThe service manager has a strong understanding of transformation, the importance of controlling the end-to-end service (i.e. the letter, not just the online journey), and the challenge of change. This perspective will be critical in the future.\n\nThe team described challenges which had been made on existing policy, which is good as a principle and should continue throughout the process. Simplification of policy will lead to improvements in the user journey.\n\n**Point 6** - _Build the service using the agile, iterative and user-centred methods set out in the manual._\n\nThe team have a good approach to agile methodologies, running biweekly sprints and evaluating tools and techniques as the project matures. The team now have access to an agile coach, ensuring standards and disciplines are maintained.\n\n**Point 13** - _Build a service consistent with the user experience of the rest of GOV.UK by using the design patterns and the style guide._\n\nThe team have made a good start in terms of the design of the service, and by using the front end tool kit, are on the right track. This work should be continued. The panel would advise the team to join the GDS Hackpad and engage with GDS on any design principles that they may have views on.\n\n**Point 16** - _Use open standards and common government platforms (e.g. GOV.UK Verify) where available._\n\nThe team is working alongside HMRC to share understanding and lessons learned. It will be critical to continue this relationship in order to ensure users have a common experience between services, and to ensure efficient use of taxpayer money.\n\nThe service is working alongside the GDS Platforms team to understand what benefits can be delivered to DWP ePayments. In addition, the team is ensuring technology is loosely coupled, thereby enabling a potential future switch to any common government technology. This will derive potential future benefits for both parties.\n\n**Recommendations**\n\n**Point 1** - _Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for digital and assisted digital service design._\n\nThe team has made good use of existing channels of insight to validate the user needs (such as the customer satisfaction survey), and also followed up by listening in to calls at the contact centre, and with pop-up research. There was a missed opportunity however to carry out discovery research with target users as the user needs themselves were generated during a workshop rather than through discovery research itself. The focus of research during discovery should be on the identification of user needs through research with target users; the panel felt the leap to pop-up testing of a prototype happened before a full understanding of the target user group was reached. This research could have included contextual research with target users to understand their experience of finding themselves in debt to the government, and the steps in their journey to repay this debt. This would have grounded the understanding of how other channels of communication, such as the letter, perform as a call to action, and given a richer service level understanding of the user needs.\n\n**Point 3** - _Evaluate what user data and information the service will be providing or storing, and address the security level, legal responsibilities, and risks associated with the service (consulting with experts where appropriate)._\n\nThe team should ensure that a cookie policy is in place before the beta assessment.\n\n**Point 8** - _Analyse the prototype service’s success, and translate user feedback into features and tasks for the next phase of development._\n\nThe customer feedback survey must be built and owned by the team. There should be no restriction on the questions asked, and the data should come directly to the product owner so that specific concerns can be understood.\n\n**Point 9** - _Create a service that is simple and intuitive enough that users succeed first time, unaided._\n\nThe physical letter from the service needs extensive work to be as simple as possible. It should be user tested and worked on by the content designer who also works on the digital element of the service. For beta, a much simpler and easy to follow letter should be shown, with evidence of user-centric design.\n\nThe service currently is only useful for users who know their exact balance via letter and are able to pay the full balance. It is critical that the team conduct user research into other functionality which users may require (e.g. account balance, partial payment and regular payment). These should then be implemented for beta, unless there are mitigating circumstances (e.g. prohibitive cost). If this is the case, then this evidence must be brought to the beta assessment.\n\n**Point 10** - _Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it._\n\nThe statistics provided by the team show the importance of assisted digital (AD) to this service, therefore this will be a key focus of the beta stage. The team must engage users who have not directly approached the service (e.g. look at existing customers who have debt but have not phoned up etc.) as these may be the most at need. This should be added to the teams overall understanding of user needs.\n\nThe overriding feeling from the team was that AD support would be completed by phone. This may be true, however the sample tested so far must be expanded to more actual users of the service and there should be no pre-existing ideas of a solution from the team before they understand what the user wants help with and why. Evidence will be needed at beta to show why the service has chosen a particular solution and why it is the best solution for their users.\n\nSustainability is a key concern. The team did not feel support was needed from third parties for AD services, but the team need to understand what is already being provided. For example, Citizens Advice Bureaux (CAB) have an existing relationship; how much help are they offering to users? If this is happening, how is this funded? This must be understood and provision put in place to support ongoing support of AD, based on the user needs understanding which the team define. This will be examined at the beta assessment.\n\n**Point 13** - _Build a service consistent with the user experience of the rest of GOV.UK by using the design patterns and the style guide._\n\nAlthough the design of the service met the standard, there must be an ongoing commitment to content, as this was an area of concern for the panel. Examples of where this needs to be addressed are in the name of the service (when viewed out of context), and the reference to both the National Insurance number and the reference number seemed unnecessary. A content designer will be able to help with both this and the letter redesign.\n\n**Point 14** - _Make sure that you have the capacity and technical flexibility to update and improve the service on a very frequent basis._\n\nBeing able to improve the service on a very frequent basis will be an essential part of running the Beta. The team should work to make the process of updating the service as simple as possible. The team should look to automate the current manual deployment process, as this will reduce the possibility of error and to make it quicker to roll out updates and improvements.\n\n**Point 15** - _Make all new source code open and reusable, and publish it under appropriate licences (or give a convincing explanation as to why this can’t be done for specific subsets of the source code)._\n\nThe assessment team at the beta assessment will be looking to see that steps have been taken to publish code for the public to view and use.\n\n**Point 18** - _Use analytics tools that collect performance data._\n\nThe team currently have an analyst drawn from a central team. This person will become increasingly important as the service progresses into beta and beyond for translating user behaviour, and should ideally be co-located with the team. It would be advisable to bring some analytical evidence to the beta assessment (e.g. goals, funnels and figures).\n\n**Point 20** - _Put a plan in place for ongoing user research and usability testing to continuously seek feedback from users._\n\nFor the beta stage, the plan for iterative research as an embedded part of the sprint cycle is extremely positive. However, it is important that the formative part of this research is with target users of the service so that there is a more robust understanding of their mental model and how they think about their debt. This will lend greater confidence to design decisions such as language, labelling and grouping of steps, and will also ensure a greater service level understanding of the end-to-end journey for users. Pop-up research would be more appropriate in the latter stages of the design process when refining interaction design detail.\n\n**Point 21, 22, 23 & 24** - _Establish a benchmark for user satisfaction across the digital and assisted digital service. Report performance data on the Performance Platform; Establish a benchmark for completion rates across the digital and assisted digital service. Report performance data on the Performance Platform; Make a plan (with supporting evidence) to achieve a low cost per transaction across the digital and assisted digital service. Report performance data on the Performance Platform; Make a plan (with supporting evidence) to achieve a high digital take-up and assisted digital support for users who really need it. Report performance data on the Performance Platform._\n\nThe team did not show a full set of benchmarked Key Performance Indicators (KPIs) and had not engaged with the Performance Platform team. This must be corrected before the team return for beta assessment. Additionally, the team should look at how they can provide metrics and KPIs from non-digital channels to the Performance Platform during the beta stage.\n\n**Summary**\n\nThe team have made a strong start to developing a solution and building an Alpha service. That work must now be reviewed, with some areas developed going forward and some areas to be entirely reconsidered. This is a fully appropriate approach moving into beta, and is how the best services develop.\n\nThe service manager will be crucial going forward, and they clearly understand the importance of a strong team and hold influence over the end-to-end service. This was excellent to see and should be recognised as a strength.\n\nIt was very positive to see engagement with both HMRC e-Payments and the GDS Platforms team, this must continue on both fronts to ensure the team are providing the best possible, best value for money solution. As well as learning from both HMRC and GDS, the panel would expect the service to be inputting guidance and requirements into these teams too.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | No | 8 | Yes |\n| 9 | No | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | No | 22 | No |\n| 23 | No | 24 | No |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/pay-hmrc-alpha/",
    "title": "Pay HMRC - Alpha Assessment",
    "summary": "This service will allow users to make payments to HMRC online via credit and/or debit card.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n6 October 2014\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nA. Lister\n\n**Service Manager:**  \nO. McGuire\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## **Assessment Report**\n\nThe HMRC Payment Service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the HMRC Payment Service is on track to meet the Digital by Default Service Standard at this early stage of development. However it will be necessary to address a number of areas in order to successfully pass a Beta assessment.\n\n**Reasons**\n\n**User needs**  \nA basic understanding of user needs was demonstrated. The service team will need to address the recommendations below in order to meet the service standard at a Beta assessment.\n\n**The team**  \nThe majority of the roles necessary for a multidisciplinary delivery team were present. Webops resource is managed as an internally supplied service. The team has drawn upon content design expertise from GDS and the wider HMRC resource pool.\n\n**Security, privacy, tools and standards**  \nAn accredited CLAS consultant is working closely with the team, using the same approaches and methods as the core tax platform.\n\nNo end to end testing has happened with the fully coded production-like service.\n\n**Design**  \nThe team is able to draw on the correct people, however the absence of a dedicated content designer and front-end developer may prove challenging as delivery cadences are productionised. HMRC’s decision not to bespoke the current commercial components of the service has resulted in some&nbsp;inflexibility but an HTML5 API will be made available early next year. It was also recognized that the current commercial service does not meet basic WCAG 2.0 AA accessibility standards.\n\n**Assisted digital and digital take up**  \nThe service team know that their users are often time poor, and in need of confidence and clarity, and understood that assisted digital users are even more likely to be so. Although the service team are still quite early in their thinking about specific assisted digital support for this service, an outline approach and plan for user research for these aspects was identified, and understood to be essential for progression to Beta on GOV.UK.\n\nThe service had some early thoughts on a digital take up plan, and were expecting data on comparative channel volumes within a few days. General cross-HMRC plans for winding down non-digital channels where possible were referenced, but it was acknowledged that a more service-specific plan would be required to meet the service standard at Beta assessment.\n\n**Recommendations**\n\n**User needs**  \nIt’s vital that the opportunity to create a service that better meets user needs isn’t lost. To do this, future user-research needs to be conducted with a broader range of users with ‘real’ code rather than flat HTML wireframes.\n\nSpecifically, before the service returns for a Beta assessment, it’s essential that:\n\n- stronger user stories are developed\n- a ‘real’ fully coded service is used for testing\n- a broader, more representative user research sample is recruited\n- user research is not weighted towards the user satisfaction questionnaire at the end of the service  \nall paths through the service are evaluated - including those which include, or conclude with, error messages/pages\n\nResearch into the current service is needed. This will help the team:\n\n- understand the current user experience and its challenges\n- quickly identify potential improvements for early development\n\n**The team**  \nSeparation of the webops function from the core team is a concern. This needs to be challenged with the objective of securing dedicated webops support for the service. Similarly, content design needs to be integral to development and not a ‘finishing off’ exercise.\n\n**Security, privacy, tools and standards**  \nFor the Beta assessment, the components identified as open source need to be made available.  \nA coherent and actionable approach to service downtime is required. This includes communication with te GOV.UK service desk.\n\n**Design**  \nThe prototype presented was flat HTML. Although the design was largely consistent with GOV.UK requirements it’s essential that the actual working code is presented at future assessments. We would also expect to see the service working well on a range of browsers and devices.\n\nWe would like to see the HTML5 version of the current commercial interface, until then more needs to be done to bring the current component up to standard.\n\nAccessibility and assistive technologies have not been considered. Based on experience with a broad range of digital services, the assessment team recommends that future iterations adopt a baked-in approach to accessibility. Retrofitting for assistive technology users is complex, time-consuming and inevitably, a compromise.\n\nThe team will need to discuss with the GOV.UK team how start pages will work for the service.\n\n**Assisted digital**  \nThe service team should carry out specific research with assisted digital users of their specific service (including those with the lowest skills among their user base) to discover their numbers and their needs of assisted digital support. The service team should design a model of assisted digital support based on the research, and test and iterate it to ensure the support is meeting user needs and volumes.\n\nThe service should develop user personas for their assisted digital users and be able to explain their user journeys through the service, including estimated numbers of assisted digital transactions for each channel required.\n\nThe service team should be able to explain plans to ensure assisted digital support for their service is both sustainably funded and free to the user. Assisted digital support should be clearly visible to users from the start page of the service.\n\n**Digital take up**  \nThe service team should contact the digital take-up team at GDS to review planning and ensure all is being done to reduce avoidable non-digital contact from potential users using non-digital channels to contact HMRC about the service.\n\n**Metrics/KPIs**  \nFor a technical-change led project, it is critical that the service manager has a strong understanding of the KPIs of the system being replaced, and how that is expected to change with the replacement system.\n\n**Summary**  \nThe assessment team was encouraged by the progress made to date and content that the service is on the right track. It’s clear that strong foundations have been laid for an outstanding digital service. However, it’s essential that recommendations outlined above are implemented to ensure that this service fully meets user needs and realises its potential to generate operational and financial savings\n\n* * *\n\n**Digital by Default Service Standard criteria**\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | No | 8 | Yes |\n| 9 | Yes | 10 | No |\n| 11 | No | 12 | No |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | No | 18 | Yes |\n| 19 | Yes | 20 | No |\n| 21 | No | 22 | No |\n| 23 | No | 24 | Yes |\n| 25 | No | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/defence-solicitor-service-assessment/",
    "title": "Defence Solicitor - Service Assessment",
    "summary": "The Defence Solicitor service provides custody teams with a one click request for a duty defence solicitor. The product creates a two-way connection between custody software systems, the Legal Aid Agency's duty rota, and then to contracted law firms.",
    "body": "**Department / Agency:**  \nMOJ\n\n**Date of Assessment:**  \n27/2/2015\n\n**Assessment stage:**  \nAlpha review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor**  \nN. Williams\n\n**Service Manager:**  \nW. Rowan\n\n**Digital Leader:**  \nM. Coats\n\n**Assessment Report**\n\n**Outcome of service assessment**  \nThe Defence Solicitor service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development. After consideration the assessment panel have concluded the service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**  \nThe assessment panel were convinced of the need for this valuable service, which will bring significant improvement to a 12 year old phone-based chain of communication between multiple parties involved in assigning a defence solicitor to a detainee. The service team explained clearly that it will bring direct benefits of: time and cost savings for custody officers and the defence solicitor call centre; a more convenient system for solicitors; a removed bottleneck in the form of busy phone lines; and a reduced risk of inaccurate information from re-keying information. The service team anticipate further, indirect benefits such as the ability for custody officers to make better informed judgments about waiting times, and consequently for more detainees to access legal help - but it was less clear to the panel that these are measurable hypotheses given the other variables involved.\n\nThe service team have achieved a lot in a short time, are empowered and well set up with the right mix of skills, and understands and are following the approach set out in the service manual.\n\nThe team’s technical design is strong - the panel found it refreshing to see a team conceiving of their service as being primarily an invisible API, favouring partnership with vendors of existing custody suites above building a new separate interface. The panel was impressed that the service have already got commitment from the 3 vendors of custody software to integrate with the new service. Their answers to the questions about data protection and security were also reassuring to the panel. Additionally, the adoption of open source code from the outset was excellent.\n\n**Recommendations**\n\n**User research**  \nThe assessment panel felt there were gaps in the service team’s understanding of:\n\n- The entirety of the user needs which the service must support across a complex service and communication chain.\n- How the new system will affect the amount and type of information which currently moves among participants via the phone system, and how the experience and behaviour of the participants may be affected as a result.\n- How the benefits which users like about the existing system might be replicated and retained in the new system.\n\nTo address these gaps, the panel believes that there should be a greater focus on uncovering - through research - clear, experience-driven user needs for each participant.\n\n(A notional example of an experience-driven user need for a custody officer might be: “As a custody officer I like to maintain some rapport with the detainee and get them to the cell in a cooperative frame of mind, if I can. My information gathering therefore needs to be quick and easy, so that I can focus on them, and help them not to get too restless or agitated.”)\n\nBy beta assessment, the service team should make sure they are able to answer the following research questions:\n\n- How might the new system impact on the information-gathering moment when detainee is standing in front of the custody desk, and how can the design accommodate the pressing needs of this moment?\n- What changes might there be to the information which flows as a result of shifting to an online system and how might they affect the ultimate behaviour of the participants, eg new or unanticipated delays?\n- How will you ensure that the online system fits into call centre workflow and that no new delays are introduced?\n- If improving the reciprocal information flow between custody officer and solicitor is a key objective, how will the system ensure this?\n- How will resistance to new technology among solicitors affect their interaction with the product and the process? How should the design respond to this?\n- What costs (time, money and otherwise) will adoption of the new system impose and how will they be offset against the costs and benefits of the existing system?\n- How will the team continue to explore and bottom out the issue of local variation?\n- How will the risks of a skewed sample be mitigated in the team’s recruitment of research respondents? (As we mentioned in the meeting, a reliance on undirected selections by police contacts may lead to unintentional bias)\n\nIn the Alpha, usability research did not result in any changes to the design due to time constraints. During the next phase, the service team should make sure they plan for taking a more structured approach to research, user needs development and design iteration. The team’s research plan needs to set out the different segments of the audience, the number of respondents of different types that will be drawn from each segment, the research methods that will be used, and any regional dimension. It should also lay out plans for getting the new system to a point where it can be tested by custody officers in real situations, in the presence of detainees.\n\n**Assisted digital**  \nThe panel clarified that the service team only need to provide assisted digital support for solicitors, as the end users of the only public-facing part of the service. Duty solicitors have contracted with the Legal Aid Agency to engage electronically, so there will be no user requirement to provide assisted digital support for this group as they will already have online skills and access. The service team will develop their research into own (ie non-duty) solicitors during Beta development to identify user needs and likely demand for support. The team also need to develop a plan to test proposed assisted digital support to show that it meets user needs.\n\n**Design and content**  \nWhile the web-based user interface for custody officers is likely to only be needed short term, the interfaces for the call centre and solicitors are critical parts of the service. The panel saw numerous issues with the prototypes, and will send a snagging list separately. The panel accept that it’s early days for this service, but there were many avoidable deviations from GOV.UK style (like use of camel case) and a lack of design thinking apparent in decisions such as the order and titles of columns. As the service moves forwards the team will need to do much more work on the design and content of all three user interfaces, testing frequently with users. The assessment panel suggest the team conduct a design review with GDS designers before the beta assessment.\n\n**Measurement**  \nAt the next assessment the panel will expect clarity about the service team’s KPIs and metrics and, where possible, benchmark figures for comparison against the current service. The panel believes that it might be beneficial to appoint a dedicated performance analyst in the team - or at least, make sure it is part of one of the team members’ roles to proactively analyse performance metrics in every sprint, feeding the outcomes back into the each iteration. The assessment panel will also expect the service team to have worked with GDS to have a performance platform dashboard available.\n\n* * *\n\n## **Digital by Default Service Standard criteria**\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/inheritance-tax-alpha/",
    "title": "Inheritance Tax - Alpha Assessment",
    "summary": "Inheritance Tax Online is a digital service to help customers understand what they need to do after someone has died with specific regard to their Inheritance Tax and Probate affairs. The two processes are closely linked as legislation requires that HM Courts and Tribunals must not grant Probate before Inheritance Tax has been paid or that it has been determined that none should be paid. Where customers need to make an application for Probate, the service will enable them to make an online tax return and with the ultimate ambition of allowing the customer to make a combined Inheritance Tax and Probate return to appear to the customer as one digital service.",
    "body": "Users of this service have often recently suffered a bereavement of a close relative, the nature and timing of the process usually results in customers approaching the service for the first time and in circumstances that they are not familiar with.\n\n**Department / Agency:**  \nHMRC\n\n**Date of Original Assessment:**  \n26 January 2015\n\n**Date of Reassessment:**  \n12 March 2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Original Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nN. Williams\n\n**Service Manager:**  \nT. Charlton\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Reassessment Report\n\nThe Inheritance Tax Online service has been reviewed against the points of the Service Standard not passed at the original Alpha Review assessment.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Inheritance Tax Online service is on track to meet the Digital by Default Service Standard at this early stage of development.  \n  \n**Reasons** The service team have made significant progress in simplifying the process for users, splitting the form into two distinct registration and information-gathering steps to eliminate the confusion of a confirmation screen part way through the journey, and introducing logical branching so that users are only shown the questions they need to answer depending on their circumstances. The service team have also applied more scrutiny to each question and its need to be there, eliminating the unnecessary form fields the assessment were concerned by at the original assessment. The content design is much clearer and more user-centric, and consistent with the GOV.UK style guide.\n\n**Recommendations**\n\nNone in addition to the previous assessment. (Previous recommendations regarding the beta phase still stand).\n\n**Summary**\n\nThe assessment panel were very grateful for the service team’s positive engagement with the feedback from the previous assessment, and were pleased and impressed by the improvements the team have made in short order. The assessment panel have every confidence that the team will continue to improve the design and content as they develop the beta service and test it with users.\n\n* * *\n\n## Original Assessment Report\n\nThe Inheritance Tax Online service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded that, in spite of many positives and being generally headed in the right direction, the Inheritance Tax Online service is not yet meeting the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe assessment panel felt that although good work had been completed in developing the prototype thus far, the service does not yet pass on points 9 and 13 of the standard. In particular, the assessment panel would like to see more evidence that the service team are challenging the underlying assumptions of the existing paper-based form and trying out approaches to the overall design of the service which are more radically different from one another than the small iterations they have been making so far.\n\nOverall, the assessment panel were pleased with the way the service is being built to address valid user needs. The team developing the service has the skills, knowledge and working practices to apply the principles and approach set out in the service manual, and is led by an empowered Service Manager. The assessment team were confident that the Inheritance Tax Online team is well set up and are working together to deliver iteratively. The team are working autonomously with the full support of the business and in close collaboration with the back-end project the service depends on.\n\nThe assessment panel were confident that the service team understand the needs the service must meet. The team has a strong culture of gathering and using evidence from user research and analytics, with a regular rhythm of testing and feeding the results of that testing back into the service development each sprint. In addition, all members of the team are observing and participating in user research.\n\n**Recommendations for Alpha Review reassessment**\n\nThe panel have every confidence that the service will pass a re-assessment provided they address the following recommendations.\n\n**Design and Content design - points 9 and 13**\n\nThe challenge the service team face is predominantly about making a complex process simple, and the panel recommend that they ensure they have sufficient content design input - at the moment this feels under resourced. The panel think that an additional, dedicated content designer working closely with the designer and user researchers would help them to be bolder about challenging the underlying assumptions of the existing form and process. For example, by only asking users for the information really needed at the point when it is really needed, keeping help text short and minimal, and trying different approaches to structuring the content.\n\nThe panel raised specific concerns during the meeting about the user journey and interaction design - most notably the confirmation and reference number step after creating a case, which feels like the end of a journey not the middle; and the very long step 7 where the user is asked to provide valuation data for the estate and an additional UI pattern is introduced. The service team should try out approaches to the overall design of the service which are more radically different than the small iterations they have been making so far (for example, splitting it into separate, linked transactions instead of one linear form and see if that’s better for users). The panel also suggested they service team look at how some of the exemplar services have tackled similar challenges in their multi-step transactions.\n\n**Recommendations for beta**\n\n**The team - point 2**\n\nThe service team are currently supported with a high percentage of contractors. At beta assessment we would expect to see a plan in place to address this balance and build a sustainable multidisciplinary team that can continue to own, operate and improve the service when live.\n\n**Assisted digital and digital take-up - points 10 and 11**  \n  \nThe team have done some initial user research and have developed some basic assumptions around potential assisted digital user needs (including creating a persona) and expected volumes. For the beta assessment, the panel will expect to see that these hypotheses have been tested rigorously through user research and that support is developed that meets the needs of users of this specific service.\n\nResearch must be undertaken with a broad cross-section of all potential users, including those who would currently pay for an intermediary to complete the form. Any support relied on in the voluntary sector must be sustainably funded by the service so this should be explored before the beta assessment, ready for testing assisted digital support in public beta.\n\nBy the beta assessment, the service team must have developed a clear plan for digital take-up, based on user research and analytics.\n\n**Make source code open and reusable - point 15**\n\nFor beta assessment the panel expect to see steps taken for this project to be coded in the open, with all code published in open repositories. Where this is not possible there should be a convincing explanation as to why.\n\n**Next Steps**\n\nThe service team should follow any recommendations made in this report and see the Government Service Design Manual for further guidance. In order for the service to proceed, the panel require a reassessment against the not passed criteria.\n\n**Summary**\n\nThe service team were well prepared for the assessment and gave thorough answers to the panel’s questions. Overall the panel was pleased with the work undertaken on the service so far. With some additional development on the prototype, the panel believe the service is well on its way to meeting the requirements of the standard. It is clearly needed and will make for a much less painful experience for users than the paper-based services it is replacing.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | No | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/civil-service-fast-stream-service-assessment/",
    "title": "Civil Service Fast Stream - Service Assessment",
    "summary": "This is a digital service to support a multi-stage recruitment and selection process for candidates wishing to apply for the Civil Service Fast Stream and Early Talent Programmes. The Fast Stream is an annual programme recruiting around 1,000 graduates to join the Civil Service as a talent pipeline for future SCS roles, plus outreach and positive action internship activities to encourage applications from under-represented groups such as those from lower socio-economic backgrounds, black and ethnic minority backgrounds and those with registered disabilities.",
    "body": "**Department / Agency:**  \nHMRC/CO - Civil Service Resourcing\n\n**Date of Original Assessment:**  \n13/2/2015\n\n**Date of Reassessment:**  \n30/3/2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Original Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Barlow\n\n**Service Manager:**  \nS. Morton\n\n**Digital Leader:**  \nM. Dearnley / P. Maltby\n\n* * *\n\n## **Reassessment Report**\n\nThe Civil Service Fast Stream has been reassessed against points 1, 2, 20 and 10 of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the Civil Service Fast Stream service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service team were able to demonstrate to the panel that they had adapted their approach to user research and assisted digital and had made sufficient progress against the recommendations made following the alpha assessment.\n\n**_User Research - Points 1 and 20_**\n\nThe panel found that the service team had responded energetically and positively to the initial alpha assessment feedback on research. A significant body of research fieldwork was conducted in the six weeks since the original assessment. Three weeks after, a research plan was produced outlining how the team would begin to address the research issues raised at the assessment. It was clear at the reassessment that the initial research outlined in that plan had been carried out.\n\nThe 24 user research interviews conducted in that period represent a significant body of work. Key diversity-related user groups - ethnic minorities and people from lower socio-economic backgrounds - have been targeted and accessed (79% of the sample was from ethnic minorities, 46% were from lower socio-economic backgrounds).\n\nImportantly, the respondents were not existing fast-streamers or people already in the Civil Service: they were all people outside, and hence unfamiliar with Civil Service culture and terminology.\n\nUseful findings were obtained in this research, some of which were generic and some of which were directly related to diversity issues (e.g. the need for applicants to feel confident that the diversity questionnaire was unconnected to the application form - that diversity information will not influence chances of success).\n\nThe plans in place for continued research in Beta seemed to maintain a focus on the issues raised in the original assessment - namely, ensuring that the bulk of respondents are not from within the Civil Service, and that there is effective targeting of people in the key diversity groups.\n\n**_The Team - Point 2_**\n\nThe service team informed the panel that a full time user researcher had been appointed until the end of May. To ensure that this is sustained, this role will be included in the broader procurement process which was being planned for beta.\n\n**_Assisted Digital - Point 10_**\n\nThe service team have completed research to better understand demand and assisted digital needs for their service. The service is working with partners to use a broader range of research techniques to understand assisted digital needs. While more research is required in beta to test initial findings, this research is being used to inform the assisted digital support that is required. It is important that this work continues during beta development.\n\nAlthough initial findings suggest that assisted digital demand will be low, the panel believe it is important that the service complete further research to ensure that the needs of potentially diverse and hard to reach groups have been fully understood and met. This should include thoroughly testing, and challenging where required, any previous assumptions on assisted digital needs of users.\n\n**Recommendations**\n\n**_User Research and the Team_**\n\nBuilding on the plan already produced for Beta, the assessment panel felt that there needed to be additional focus on:\n\n- Testing the full integrated journey - registration and online tests (including any e-mails or other comms which feature in this) in one sitting with the same respondent (or in more than one sitting if multiple sittings are also realistic)\n- Broadening out the research audience to include disability more broadly - not just in relation to ‘adjustments’ - to ensure that diversity is addressed in a wider sense. (e.g. in relation to general accessibility)\n- Ensuring that the bulk of respondents are people who have not been seen before in the research\\>\n\n**_Assisted Digital_**\n\n- Continue to work with specialist partners to make sure the service has understood the assisted digital support needs of harder to reach groups\n- Carry out further research with AD users to confirm demand for AD support and test initial findings\n- Adapt plans for assisted digital support to meet assisted digital users’ demand and needs on all required channels\n\n**Summary**  \nThe digital service will play an important role to ensure that the Fast Stream programme attracts a broad and diverse range of people. The panel believe that the service team have made some significant changes to their approach to user research and assisted digital since the last assessment. The service has passed the alpha assessment and is ready to move to beta development. The panel believe that it is important that this work is sustained in beta to ensure the service meets the potentially broad and complex range of user needs.\n\n* * *\n\n## **Original Assessment Report**\n\nThe Civil Service Fast Stream service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nIn spite of many positives and being generally headed in the right direction, the Civil Service Fast Stream service is not yet meeting the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\n**_User Research and the Team - Points 1, 2 and 20_**\n\nThe user research conducted in Discovery and Alpha is not sufficient for the service to move onto Beta development.\n\nGiven the need to ensure the service is accessible to a more diverse user group, a significantly broader, deeper and more deliberate research effort is required.\n\nThe service team should conduct research with a larger, more balanced and more thorough sample. The weighting of the existing sample towards people already in the Civil Service, and towards people who have successfully passed through the existing system (i.e. existing fast-streamers) means that it is likely to be skewed. The experience of people in the target audience who do not (or probably would not) get through the application process should also be properly understood. There may be some of these people among the students who have been interviewed during Discovery and Alpha. However, only three students during Discovery and 10 during Alpha is not enough to ensure the needs of a wide audience are fully understood.\n\nThere has been no segmentation of the target audience in relation to specific Diversity issues. Other than contact with three fast streamers with dyslexia, there had been no targeted diversity related research (e.g. focussing on ethnic or socio-economic background).\n\nMore generally there has not been enough user research. With three professional researchers on the team, a return of 17 respondents across 6 sprints is relatively low for this stage in the development.\n\nNone of the researchers are currently working full time in this role. It may be necessary to consider a full time user researcher. The lack of focus in the research and the low volume of user contact mean there are likely to be significant gaps in the team’s understanding of the issues, both in relation to user needs and &nbsp;to interface issues.\n\n**_Assisted Digital - Point 10_**\n\nThe service team have focused on the accessibility of the digital service and have made assumptions about potential users’ skills and access based on candidates who currently complete the fast stream application (which is 100% digital). There is a reliance on existing surveys which ask users set questions on whether any adjustments are required.\n\nThe service team needs to carry out research to understand whether there are any broader assisted digital needs or barriers to using the service and to plan for developing assisted digital support in Beta. This requirement is only unnecessary if there is demonstrable proof from user research that there are no users with assisted digital needs.\n\nNote also that assisted digital support is only required for the public facing parts of the service, not for internal candidates.\n\n**Recommendations for Alpha Review reassessment**\n\n**_User Research_**\n\n- Increase the focus on user research, taking into account the issues raised above\n- Produce a research plan which addresses the research issues raised above. The plan should include reference to how research will be used to explore and resolve the diversity questions issue. i.e. different design approaches explored with a cross section of the audience to identify the approach which best balances user needs (objectivity, trust) with business needs (understanding the impact of the online application process on diversity objectives).\n- Consider increasing the user research resource as necessary\n\n**_Assisted Digital_**\n\n- Complete user research to understand the demand and needs of assisted digital users\n- Use broader range of research techniques to ensure the service team fully understand potential barriers to using the digital service\n- Develop a plan based on feedback to provide assisted digital support which meets user needs\n\n**Recommendations for Beta**\n\nWhile these are not required for the alpha reassessment, they should be considered during beta development and before coming in for a beta assessment.\n\n**_Technical_**\n\n- There are issues with the nature and depth of questions asked of users and the corresponding implications on the data the system would hold. The service team should consider whether the application could capture these anonymously and divorce the socio-economic data from the application itself.\n- When it comes to designing and implementing the beta platform there will need to be team member(s) with the necessary skills to own a high level system architecture of a beta system, with all its back office interactions, ahead of the procurement. The concern is that there is no technical architect on the team to perform this piece of work, and especially heading into a procurement this may be problematic in ensuring the correct thing is purchased.\n- The program needs to be able to articulate the correct security level and ensure the system meets those requirements and does not include security features that go beyond this.\n- There was some outdated requirements on the system architecture diagram (GSi / IL levels) which the team need to ensure they are able to migrate to the current structures (PSN / Official / etc).\n\n**_Design_**\n\nWe will provide more detailed recommendations on design separately. High-level recommendations are:\n\n- Remove the Diversity and Socio-economic sections to a separate, genuinely anonymous survey. This will address users’ concerns that diversity and socio-economic data is not being used to assess their application, as it won’t be possible for you to do so\n- Split everything into individual questions – approx one question per screen. Keep the 5 broad stages for navigation, but have several screens in each. Test this approach with users. We saw it test very well for [Register to vote](http://www.gov.uk/register-to-vote). It makes each question and any validation messages clearer and more focused. It also makes it easier to branch questions and remove steps that are not applicable\n- Replace check-boxes with questions – for example ‘Do you have a registered disability? Yes/No’ Do this unless the checkbox is required to accept T&Cs or similar. In this case, use a simple statement ‘By registering, you agree to accept the terms and conditions’. This is legally equivalent but requires one fewer click\n- Rather than explaining eligibility criteria up-front, ask the user a question. If the user is eligible, you don’t need to explain the criteria. If they’re not eligible, explain the criteria to show how they failed. If you need more information to decide, reorder the questions so you have the information in the order you require. Ask eligibility questions up-front to reduce the number of users who put in significant effort before getting screened out\n- Welsh language: consider instead adding a single page in Welsh which allows Welsh-speaking users to request Welsh-language support. Assess the takeup of this support and overall cost against the cost of providing a Welsh translation\n\n**_User Research_**\n\nThere may be other issues which are relevant to the Diversity agenda and to the service generally which should be addressed in the research plan. For example, in relation to the online tests which feature in the application:\n\n- How will the team use research to explore how the tests play out in the application process in relation to diversity? Are some groups more likely to fail because of the format?\n- How will the team use research to disentangle ‘genuine’ failure in these tests from failure which is an artifact of poor online implementation?\n- Which parts of the audience would be addressed in researching these issues, bringing diversity (learning differences, ethnic and socio-economic background etc. ) and other relevant audience dimensions into play?\n\n**Next Steps**\n\nThe service team should follow any recommendations made in this report and see the [Government Service Design Manual](https://www.gov.uk/service-manual/digital-by-default) for further guidance. In order for the service to proceed the assessment panel require a reassessment against the not passed criteria.\n\n**Summary**\n\nOverall the panel were impressed with the way that the team were working at this early stage in the development of the service. While more user research is required, the team demonstrated that they were able to work in an agile way and were able to quickly respond to user needs.\n\nThe panel also felt that the service had taken the right approach technically. The service demonstrated that it has the technical flexibility to deploy code quickly. Security and privacy risks have been carefully evaluated and appropriate steps had been taken to minimise risk. The service was also built using open source and open standards throughout.\n\nThe panel felt the service were taking the right approach to the design of the alpha and demonstrated that they were improving the service in line with user needs. However, more in depth user research is required to ensure that the service meets user needs, particularly those of from diverse user groups.\n\nThe current design asks users to provide large amounts of socio-economic information. It is important that the service continues to challenge and push back on this where user research demonstrates that the current design does not meet user needs.\n\nThe service is heading in the right direction but more work is required on user research and assisted digital support.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/immigration-health-surcharge-service-assessment/",
    "title": "Immigration Health Surcharge - Service Assessment",
    "summary": "The Immigration Health Surcharge is a key measure of the Immigration Act 2014. Temporary, non-EEA migrants coming to the UK for more than six months will be required to pay this fee in order to access the NHS before they are granted leave to enter/further leave to remain in the UK.",
    "body": "**Department / Agency:**  \nHome Office\n\n**Date of Assessment:**  \n21/1/2015\n\n**Assessment stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. Harrington\n\n**Service Manager:**  \nS. Cooper\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## **Assessment Report**\n\nAfter consideration, the assessment panel has concluded that the Immigration Health Surcharge service is on track to meet the Digital by Default Service Standard at this stage of development. The service team has a working prototype which is helping them learn about the user needs that they are trying to meet. Different designs have been tried out and the rhythm of the team in terms of iterating and learning is established.\n\nThe assessment panel is, however, concerned by the amount of work required to meet the standard at Beta within the challenging timeframes the project has, the handoffs between different channels and services that the user will experience and the assisted digital support.\n\n**Reasons**  \n**User needs**  \nTo date, the project has been driven by policy and technical needs, rather than user needs. In recent months, the service team has invested considerable effort into investigating user needs, and it is evident that this work is paying off. It is also clear that much remains to do, in terms of iteration, and more significantly in terms of reaching a representative sample of an extremely diverse audience.\n\nBy definition, the assessment panel believes that to become user centred, this team has to reach out to its audience, and elevate their needs to sit above technical and policy constraints.\n\n**User Research**  \nThe disconnect between policy and implementation is a concern for the assessment panel. In particular, the perceived need for secrecy which has hampered the user research portion of the project and prevented months of potential learning from happening. The waterfall-nature of policy leading to implementation with no feedback loop/involvement earlier is a frequently-seen problem.\n\n**The team**   \nThe assessment panel was pleased to see that there is a multidisciplinary team in place and that, while development is contracted, there is a close working relationship between the Home Office and their contractors. A user researcher and designer were added to the team after the project started and the team now appears to be in a better place for this. The team have three product owners, a product manager and a service manager and which could create confusion around ownerships but the team seem to be working well with this.\n\nThe team is starting to work in an Agile way, although was hampered by RUP being used at the start of the project.\n\n**Security, Privacy, Tools and Standards**  \nThe service team is developing at a low security level, and will be deploying to a higher security level. The assessment panel was happy to hear of this. The panel thought it would be good to see the team blog about this, to encourage other parts of government/suppliers to have conversations with their accreditors/security people about the feasibility of this approach.\n\n**Service design and GOV.UK style**  \nThe service team has taken the GOV.UK style guide and started to implement the visual style, but input from a content designer is needed. This will require several iterations with user research to ensure each page is understood. Some browser testing has been carried out on mobile, but this needs to be formalised. The team has not carried out work to make the service accessible, and the assessment panel would expect this to be done before becoming a public beta.\n\n**Assisted Digital and Channel Shift**  \nThe service team identified 3 or 4 assisted digital users among the 26 users they spoke to during their testing which is positive at this stage of development. However, very little has been done to plan how assisted digital users will be tested outside of the premium service and how support will be free at the point of use for the user except support from family members.\n\nThere is no non-digital way to complete this transaction so the service should expect 100% digital take up.\n\n**Analysis and Benchmarking**  \nThe team has iterated on the service since the original alpha designs and it is clear that user research has led this process. The team has met with the Performance Platform and should now focus on the collection of the KPI data and the instrumentation of their analytics solution.\n\n**Testing with the Minister**   \nThe team has already demoed to the Minister and will continue to show iterations of the product.\n\n**Recommendations**\n\n**User needs**  \nAs identified above, the team should continue their user research and identify and test with a representative sample of users. Testing at premium centres alone is not representative . End-to-end testing of how the service integrates with the other Home Office services is also essential as this could be a particularly difficult experience for the user.\n\n**The team**  \nThere is a multidisciplinary team in place but there is no one with clear responsibility for assisted digital or analytics. Having specialists in these areas could help the further iteration of the product and the provision of assisted digital support.\n\n**Security, Privacy, Tools and Standards**  \nThe team has procured a vendor with an existing platform in this space. As a result, little of the product will be open-sourced. This is troubling from a lock-in perspective. The team owns the IP, but a future migration to a new supplier would essentially mean starting from scratch, rather than having a code base that they own and can have someone else improve. The assessment panel recommends that the entire team (in particular, the service manager, policy people and procurement) be familiar with the guidance on choosing technology.\n\n**Improving the service**   \nThe team should quickly fix the deployment aspect of this project. The assessment panel identified no clear idea of the deployment pipeline for getting code developed in a low security environment deployed to a high security environment in a fast, repeatable manner. The assessors were also sceptical about the need for:\n\nmandatory downtime for application deployments. Downtime of up to 1 hour was mentioned; the assessment panel believes that it should be closer to seconds if necessary at all, and zero-downtime deployments should be the goal, particularly with an always-on, global service  \na rules engine to host a calculator service. The assessment panel normally encounters this in situations where deploying software to production is viewed as a risky, complicated practice. Deploying updates to rules is seen as less risky. The assessment panel believes that this is a false dichotomy, and deploying software to production should be an everyday occurrence.\n\nRelated to the deployment concerns, the assessment panel would like to be convinced that there is scope for continuous iteration and improvement of the service. There did not appear to be an analytical capability available to the team to enable learning and improvement to happen.\n\n**Design**   \nThe service team should look at the design patterns hackpad to ensure the service is conforming to the latest approaches of applying the GOV.UK style (for example, progress bars often confuse users more than they help so GOV.UK services avoid them unless shown to improve the service).\n\nA content designer needs to work through the service and make sure that the content is in line with the GOV.UK style.\n\nThe assessment panel recommends that the service team contacts a GOV.UK proposition manager to ensure correct start pages and information will be on GOV.UK. The idea of a ‘ready reckoner’ (which the panel did not see in the assessment) would normally fall under the remit of the GOV.UK team and not the service.\n\nAn accessibility audit of the service needs to take place, and changes implemented, before going to public beta.\n\nThe assessment panel expects to see iterations of the content and UI of the service before public beta with proof that it is getting easier for users to complete the transaction. There must be data analytics in place and a plan to improve the service past public beta and in live running of the service.\n\n**Assisted Digital and Channel Shift**  \nThe team needs to focus on the assisted digital support for this service, particularly as the service is wholly online, meaning that inadequate support would leave users excluded from the service. Currently the only support is a premium rate phone service, which is not suitable. Support must be free at the point of use for the user. As well as the usual beta requirements, the team must also explain at the beta assessment what else has been learnt about AD users from further user research sessions (including with charities such as Citizens Advice Bureau) and demonstrate how support has then been specifically tailored to meet their needs. The team should also clarify how much assisted digital support will be required, as some of the quoted figures conflicted. The service must confirm that users who currently rely on friends and family for their assisted digital support will have a sustainable and appropriate alternative available. The team must clarify how assisted digital support for the end-to-end user journey will be tested, measured and iterated.\n\n**Analysis and Benchmarking**  \nFollowing the prototype, the team should focus on the installation and configuration of analytics to ensure that useful data is collected once the service goes into beta. In addition to collecting the mandatory KPIs for the service assessment, the team should consider what the important metrics are for the service and how these will help them to continually iterate it.\n\n**Testing with the Minister**   \nContinue sharing iterations with the Minister.\n\n**Summary**  \nThe assessment panel thought the team presented well and has passed the alpha assessment. It is clear that the service team are working in a much better way than when the project started and the assessment panel was pleased to hear examples of user research influencing the design and flow of the service. The assessment panel do, however, think there is much to do before the beta assessment and while not insurmountable, the demanding schedule of this project makes it difficult. The team should follow the recommendations above and take the time required to ensure they meet all the points of the standard for beta before coming in for another assessment.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/contracts-finder-service-assessment/",
    "title": "Contracts Finder - Service Assessment",
    "summary": "Contracts Finder will be the central repository for government contract information referring to future opportunities, current opportunities, awarded contracts and pre-procurement engagement with the market. The terminology for these states is currently being tested. The website will provide enough relevant business opportunity information for buyers and suppliers to able to manage and act on this and interact directly with each other using a number of channels. Contracts Finder will also present contract information to other interested parties and will provide features that will facilitate the publication of government contracts and their associated expenditure.",
    "body": "**Department / Agency:**  \nCO / CCS\n\n**Date of Original Assessment:**  \n5/9/2014\n\n**Date of Reassessment:**  \n9/1/2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Original Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nD. Vaughan\n\n**Service Manager:**  \nP. Sinclair\n\n**Digital Leader:**  \nP. Maltby\n\n* * *\n\n## **Reassessment Report**\n\nThe Contracts Finder service has been reviewed against the points of the Service Standard not passed at the original Alpha Review assessment.\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded the Contracts Finder service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**** &nbsp;**\n\nFollowing the reassessment of the service, the assessment panel felt that good progress has been made to address various concerns since our last review.\n\nThe prototype has continued to be developed in an agile way with a multidisciplinary team with an empowered service manager. The service team have begun to conduct lab-based user research sessions with both government buyers and suppliers to government. These lab-based sessions are intended to continue through the next phase of development.\n\nThe service team have chosen a digital analytics package and is intending to appoint a performance analyst to help measure how the service is performing to identify any improvements that are needed.\n\nThe service team intend to publish the majority of the code for the service under an appropriate open licence.\n\n**Recommendations**\n\nThe following recommendations should be acted upon before the service returns for a beta assessment.\n\n**Look and feel - Service Standard point 13:**\n\nIn order to meet point 13 of the service standard for the beta assessment, Contracts Finder must have a consistent user experience with the rest of GOV.UK. You should use the GOV.UK design patterns and style guide published in the Service Manual and engage with the government service design community who have tackled many similar design patterns.\n\n**Use of digital analytics tools and collection of performance data - Service Standard points 8 and 18:**\n\nThe person appointed as performance analyst should work with the service manager to identify priority data points and ensure analytics is implemented to capture these. The service should engage with the GDS Performance Platform and with the community of performance analysts to learn and share best practice.\n\n**Continue to test the service with users - Service Standard point 20:**\n\nThe service team should continue with its intention to test the service with users using lab-based sessions throughout future phases of development. This should include usability testing with people with disabilities. **&nbsp;**\n\n**Engage with GDS on opening up the service’s code - Service Standard point 15:**\n\nThe team should engage with GDS to help choose an appropriate open licence for the publishing of their service’s code.\n\n**Summary**\n\nThe panel was pleased to see the progress since the last assessment particularly in relation to the lab-based research sessions.\n\n* * *\n\n## **Original Assessment Report**\n\nThe Contracts Finder service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Contracts Finder service is not yet on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe assessment panel felt that although good work had been done on the service so far, it had not yet been proved that it would meet user needs. While progress had been made on production of the prototype, it wasn’t possible for the service team or assessment panel to judge whether the prototype was a success or simple enough for users to use unaided - points 8 and 9 in the Service Standard.\n\nOverall, the assessment panel were pleased with the way the service is being built. They are agile, multidisciplinary team with an empowered Service Manager. They’ve conducted user research on a range of users including government buyers, suppliers to government and other people and organisations who might find the data useful.\n\nThe service is being built in a way which allows improvements and changes to be made on a very frequent basis with an appropriate amount of thought to the tools and processes that they are using. They’ve already engaged with the GDS Performance Platform team and are planning on testing the service with the minister later in development.\n\nThe team demonstrated that there are no eligible assisted digital users for this service so the service standard does not require assisted digital support to be provided.\n\n**Recommendations**\n\nThe following recommendations should be acted upon and must be satisfied before the re-assessment.\n\n**Test the prototype service with users - Service Standard points 1, 8, 9 and 20**\n\nThe prototype’s end-to-end user journeys should be tested with the service’s users including buyers, suppliers and others as appropriate. Knowledge gained during this should be used to validate the success of the prototype and help inform the ongoing development.  \nA plan for ongoing usability testing should be put in place to continually seek feedback from users. The outcomes of this should feed into the beta development.\n\n**Roles in the team - Service Standard point 2:**\n\nWhile the service is being developed with a multidisciplinary team the presence of a number roles are unclear. The service should consider including access to a Data Analyst within the team to assist with understanding how the service is being used and recommending improvements. It was also unclear whether the team contained a User Researcher with a focus on usability testing of the service.\n\n**Look and feel - Service Standard points 13 and 17:**\n\nThe service should be designed to be consistent with the user experience of the rest of&nbsp;[GOV.UK](http://gov.uk/) using the design patterns and style guide published in the Service Manual. This currently isn’t the case.  \nThe service should also ensure it works regardless of the browser’s capability using progressive enhancement - some elements of the prototype currently only work with JavaScript enabled.\n\n**Opening up code - Service Standard point 15:**\n\nThe service team should consider how they can make all the new source code open and reusable, including which licences are appropriate.\n\n**Use of Digital Analytics Tools point 8:**\n\nThe service team should install a digital analytics tool and identify a person who has clear responsibility for analysing the data with a view to identifying insights that can be used to inform service design going forward.\n\n**Next Steps**\n\nYou should follow any recommendations made in this report and see the&nbsp;[Government Service Design Manual](https://www.gov.uk/service-manual/digital-by-default) for further guidance. In order for the service to proceed we require a reassessment against the not passed criteria.\n\n**Summary**\n\nOverall the assessment panel was pleased with the work undertaken on the service so far. With some additional development on the prototype and appropriate usability testing, we believe the service is well on its way to meeting the requirements of the standard.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | No | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |\n\nPoint 13: Although the service does not have a consistent user experience with the rest of GOV.UK, this should not impede the service from continuing through to the next phase of development as long as this issue is resolved prior to the beta assessment."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/check-your-state-pension-alpha/",
    "title": "Check Your State Pension - Alpha Assessment",
    "summary": "The Check Your State Pension (previously Digital National Insurance & State Pension) service provides individuals with a view of their State Pension entitlement and when it can be claimed from, and will allow individuals to understand where they have missed National Insurance qualifying years, and&nbsp;the consequences of this. It will help individuals to understand the impact of paying additional National Insurance Contributions (NICs) on their State Pension, and will allow them to pay additional NICs to make up missed qualifying years if they so chose.",
    "body": "**Department / Agency:**  \nDWP / HMRC\n\n**Date of Assessment:**  \n22/1/2015\n\n**Assessment stage:**  \nAlpha review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nA. Lister\n\n**Service Managers:**  \nJ. Bramfitt-Wanless (DWP) &&nbsp;T. Chatterjee (HMRC)\n\n**Digital Leaders:**  \nK. Cunnington (DWP) &&nbsp;M. Dearnley (HMRC)\n\n* * *\n\n## Assessment Report\n\nThe Digital National Insurance & State Pension service has been reviewed against the 26 points of the Service Standard at the end of alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded that the Digital National Insurance & State Pension service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service is at a very early stage of development. The joint DWP/HMRC team showed a number of HTML/JavaScript wireframes, explained how the team worked, and outlined future plans for research and development.\n\n_User needs_\n\nThe team has begun to explore very complex user needs using a range of research methods, creating a thorough body of research. The whole team appears engaged with the research process, and buys-in to driving the project forwards through contact with users.\n\n_The team_\n\nMost of the roles required to develop the digital service are present within the team. However, as the service develops, more in-depth technical knowledge will be essential. Three aspects of the team’s make-up and activity did cause concern:\n\n- The perceived need for two service managers - services need one leader.\n- The actual amount of development that had been achieved - the wireframes shown represented a very modest amount of work for a junior interaction designer rather than the output of a more complete agile delivery team.\n- The absence of a dedicated designer on the team to replace the designer who left in December, however assurances were given that recruitment was underway.\n\n_Security, privacy, tools and standards_\n\nIt’s expected that the service will use hosting, technologies and services from HMRC’s common platform and there were no immediate concerns about the team’s approach to security, tooling or standards.\n\n_Improving the service_\n\nThe service has assured funding and resource through to a public beta release.\n\n_Design_\n\nThe wireframes demonstrated are largely in line with the GOV.UK toolkit and the need to work closely with the GOV.UK design team was understood.\n\n_Assisted digital and channel shift_\n\nThis was a weaker area for the team. Although assisted digital (AD) was understood as a component part of the overall service, there was some suggestion that the team had a range of approaches and solutions in mind without sufficient evidence of actual user needs.\n\n_Analysis and benchmarking_\n\nThis will prove extremely challenging as the effectiveness of the service is measured in terms of the action taken by users based on the information the service has provided. Most, if not all, of this activity will take place somewhere else. Potential measurements and methods of capture are being explored and the service already has use of HMRC’s Google Universal Analytics service. Engagement with the GDS Performance Platform team has also begun.\n\n_Testing with the minister_\n\nSteve Webb, Minister of State for Pensions, is actively engaged and interested in the service.\n\n**Recommendations**\n\n_User needs_\n\nThere was a degree of uncertainty about the ultimate purpose of the product. Possibilities included:\n\n- To provide information only.\n- To trigger further information gathering, decision making or action (which will happen elsewhere and could be about retirement income more generally - not just State Pension).\n- To support decision making or action within the product in relation to State Pension.\n\nIt is recommended that the research plan for beta addresses these issues, to understand, for example:\n\n- How users think about retirement income and retirement planning.\n- The natural sequence of actions that users might take when they start exploring and considering their retirement income.\n- How this sequence maps onto this product and the other products or services which might also be used as part of this wider journey.\n\nThis is likely to require additional research to supplement the proposed lab testing. This could include contextual research, depth interviews or other exploratory methods. In addition to end consumers, it might also usefully involve other players in this space e.g. people from the pensions industry, independent financial advisers (IFAs) etc. It may also be worthwhile to share and exchange knowledge with other GDS researchers currently involved in other pensions related projects, e.g. OiX Pensions Finder, HMT Guaranteed Guidance.\n\n_The team_\n\nThe need for two service managers is questionable - this needs careful and objective consideration before the service returns for a beta assessment. The velocity and nature of the team’s production needs to be addressed - value for money is one of the core success measures in agile delivery. The service needs to complete the recruitment of a dedicated designer.\n\n_Improving the service_\n\nIt’s vital not to defer complexity, especially if that complexity generates value. The team should make an objective evaluation of the backlog and consider what has been deferred and why.\n\n_Assisted digital and channel shift_\n\nIt’s vital that the AD&nbsp;service provided is designed around real users and their needs, and that support connects the user directly to the digital service rather than to alternative phone or paper-based services. Research must include understanding what support users get from outside the department’s own offering, such as from friends, in libraries or at Age UK. At beta assessment, the team will need to:\n\n- Evidence the needs of AD&nbsp;users of this specific service, how and where those needs were captured, and how the design of the AD&nbsp;support meets those needs.\n- Provide a plan for implementing the AD&nbsp;component(s) of the service (including on Verify), and demonstrate how user research will continue feeding back into future iterations.\n\n_Analysis and benchmarking_\n\nThe service presents substantial challenges in terms of what success looks like. The team needs to explore all of the touchpoints users may have with other services that could be indicators of what happened next; how the information provided by the service provoked action.\n\n**Summary**\n\nThe team demonstrated a genuine and sustained commitment to identifying and proving user needs and a good understanding of agile delivery methods. The panel looks forward to seeing the service again at the beta assessment.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/register-for-marriage-allowance-alpha/",
    "title": "Register for Marriage Allowance - Alpha Assessment",
    "summary": "The Register for Marriage Allowance service will allow users to register their interest in applying to transfer £1,060 of their personal tax allowance to their spouse or civil partner.  \nUsers will register their name and email and HMRC will send them an invite to apply. The service will also provide information to help users determine whether they are eligible and likely to benefit.",
    "body": "**Department / Agency:**  \n[HM Revenue & Customs (HMRC)](https://www.gov.uk/government/organisations/hm-revenue-customs)\n\n**Date of Assessment:**  \n12 January 2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nM. Etherington\n\n**Digital Leader:**  \n[M. Dearnley](https://www.gov.uk/government/people/mark-dearnley)\n\n* * *\n\n## Assessment Report\n\nThe Marriage Allowance (Registration) service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n### Outcome of service assessment\n\nAfter consideration we have concluded the service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n### Reasons\n\n- The team have carried out a significant amount of research, more than proportionate to the scope of the service and stage of development. This research, however, will also be valuable for the development of the transactional service itself, which is closely related to the registration service and will be developed by the same team.\n- The appropriate safety and security measures are in place.\n- The team have iterated the alpha service based on findings from user research, for example, changing the eligibility content to make it clearer.\n\n### Recommendations\n\n- Contact the GOV.UK content team to discuss the start page content, so that future research can be done using a prototype more representative of how it will look on GOV.UK.\n- Research. Look at expanding the research to include research with individuals as well as couples. Look at alternative recruitment methods so as not to bias the sample, and get a representative spread of age. &nbsp;Test understanding of users into what they expect from signing up, and test email copy as part of that. Volume of users is less important than getting a good spread of all users.\n- Design. A small sample of users have used the prototype and it was shown the service is simple enough to use first time. But there are a few misuses of GOV.UK design patterns and other items which should be addressed as soon as possible. We will send over more detailed design feedback separately to this report.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | N/A\\* | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | N/A\\* | 12 | N/A\\* |\n| 13 | Yes | 14 | Yes |\n| 15 | N/A\\* | 16 | N/A\\* |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | N/A\\* | 22 | N/A\\* |\n| 23 | N/A\\* | 24 | N/A\\* |\n| 25 | N/A\\* | 26 | N/A\\* |\n\n| **Details of criteria that are not applicable to this service** |\n| \\*Not applicable due to the relatively small scope of the registration service and because the registration service will only be available on GOV.UK until the main transactional service is publicly available on GOV.UK. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/surveillance-2014-service-assessment/",
    "title": "Surveillance 2014 (Animal and Plant Health Authority) - Service Assessment",
    "summary": "The service provides a digital channel for Private Veterinary Services (PVS) to submit sample information to APHA and to track reports generated from their submissions and testing requirements. Digital submissions are more readily processed than paper forms, and offer the opportunity to capture more accurate data for disease surveillance.",
    "body": "**Department / Agency:**  \nDEFRA / APHA\n\n**Date of Original Assessment:**  \n25/11/2014\n\n**Date of Reassessment:**  \n19/1/2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Original Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nL. Scott (Original) / S. Wood (Reassessment)\n\n**Service Manager:**  \nK. Line\n\n**Digital Leader:**  \nJ. Pierce\n\n* * *\n\n## Reassessment Report\n\n**19th January&nbsp;2015**\n\nThe Surveillance 2014 service has been reviewed against four points of the Service Standard (10, 13, 17, 18) at the end of alpha development.\n\n**Outcome of service reassessment**\n\nAfter consideration the assessment panel has concluded that the Surveillance 2014 service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\n**Point 10** - Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it.\n\nThe team had identified potential users of assisted digital (AD) support and had developed a good understanding of needs, using research findings to develop an AD&nbsp;persona. The team has a good plan to expand user research in beta and to test assumptions around numbers and likely support required. Initial proposals for support seem appropriate based on findings so far, and the team confirmed that the support would be funded.\n\nThe service should continue with their plans for beta; to continue with AD&nbsp;user research, to test their hypothesis, and to start to develop support. The team should also test the digital service with people who have lower confidence and digital skills.\n\nThe assessment panel was impressed with the great strides the service team has made in this area. The panel noted with approval the plans to test in trade associations and in smaller practices. It was also understood by the panel that AD will be brought into mainstream user research sessions.\n\n**Point 13** - Build a service consistent with the user experience of the rest of GOV.UK by using the design patterns and the style guide.\n\nThe assessment panel appreciated&nbsp;that the service team:\n\n- Was hiring an interaction designer to build the front-end using the GOV.UK toolkit.\n- Was keeping the content designer on during the beta.\n- Recognised that the language used in the alpha (which was consistent with the current paper form) was not necessarily the language of the users,&nbsp;and planned to address&nbsp;this.\n- Planned to reorder the information within the service to better match users’ own experience of interacting with a sick animal.\n\nThat said, the service has more of the look of a digitised paper form as opposed to GOV.UK service. Indeed, the assessment panel noted that the title itself - Surveillance 2014 - needs to be looked at, if only for the fact that it sounds a year out of date and is not self-explanatory.\n\n**Point 17** - Be able to test the end-to-end service in an environment identical to that of the live version on all common browsers and devices. Use dummy accounts and a representative sample of users.\n\nThe service team was able to confirm that the service had been tested in GDS recommended browsers. However, this only involved five users using&nbsp;desktop computers. This approach appears to be based on an assumption that users would not want to submit sample information in the field, even if a mobile or tablet alternative was available.\n\nThe service demo started after the login process. The login component of the service&nbsp;needs to be demonstrated at the beta assessment, along with the payment process using dummy logins if necessary.\n\n**Point 18** - Use analytics tools that collect performance data.\n\nIt was noted that the service team currently uses an analyst who sits outside of the core team. The risk is that collecting performance data results in Management Information (MI) reports, at the expense of analysis. The service team is working with the GDS Performance Platform team and that it plans to look beyond the four Key Performance Indicators (KPIs) that GDS recommends.\n\nThe panel&nbsp;was especially impressed to hear that one of the KPIs included tracking where users made mistakes when filling in information, with the aim of&nbsp;making the service more usable in future.\n\n**Recommendations**\n\nThe assessment panel recommends that the service:\n\n- Works closely with the GOV.UK design team and takes part in the GDS design community.\n- Continues user research into AD&nbsp;to realise the extent to which this is required.\n- Expands user research to the veterinary practice staff as often these are the people who enter the data.\n- Continues its AD&nbsp;research and, as above, extends this to small veterinary practices and their staff (who might be more likely to be using the new digital service).\n- Gives serious consideration to building the beta along responsive design principles (build for mobile and tablet first), i.e. to&nbsp;build for the future. Do not assume that users would always prefer to submit information about samples via a&nbsp;desktop computer.\n- Conducts user research with younger users to explore the preferred mobile working practices of frequent smartphone and tablet users.\n- Conducts further research into what fields are mandatory and why optional fields are required (if fields&nbsp;are optional, what is the cost to the user if these&nbsp;fields are left blank?).\n- Explores how many questions can be removed, or the answers inferred from previous replies (\"do the hard work to make it simple\").\n- Brings an analyst into the core team so that they can take part in sprint planning and research sessions. This will help avoid data being used solely for MI reports, which can be the case if the analyst is separate from the team.\n- Improves the scannability of the client address by changing its layout; tests whether users prefer it to appear on every single page.\n- Provides species-specific questions, and hides everything not directly relevant to the options already selected (this might help users prioritise the top symptoms).\n- Challenges its assumption that existing users will find it reassuring that the service mimics the paper form, as&nbsp;the benefits of this will only exist during the transition period. The longer the time period after the transition, the more new users you'll have who will only be familiar with your online service, and the more the online service will be judged on its own usability.\n- Substitutes plain English for technical jargon wherever possible to help users quickly log the information necessary to send their sample (e.g. ‘farm animal health tracking’ for ‘surveillance’, ‘sample information’ for ‘submission’, ‘to help us improve future testing’ for ‘test validation’).\n\nFinally, when the service team returns for the beta assessment it must also demonstrate&nbsp;the:\n\n- Login page\n- Payment element\n\n**Summary**\n\nThe service team&nbsp;showed a welcome level of passion and commitment. The team&nbsp;clearly believe in the work they are&nbsp;doing and evidently want to do their best for the users of the&nbsp;service. As the team&nbsp;works in a more commercially competitive environment than most other government services, they&nbsp;will clearly be aware that if new service does not meet with customers’ approval, then they have alternative service providers available to them. The service therefore&nbsp;has a clear requirement to provide users with an excellent service.\n\nA successful alpha review is not a guarantee of success,&nbsp;but it is a clear indicator that a service is on the right track. The panel looks forward to seeing the team again for the service's beta assessment.\n\n* * *\n\n## Summary of Original Report\n\n**25th&nbsp;November 2014**\n\nThe Surveillance 2014 service has been reviewed against the 26 points of the Service Standard at the end of alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel concluded that the Surveillance 2014 service is not yet on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe panel decided that the service was not yet at the stage expected to proceed to Beta development. While many things are on track, and the direction seems good, there are a number of criteria on which the service did not pass.\n\n10. Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it.\n\nTo move into Beta, the service team needs to have carried out research with assisted digital users, to have a plan for assisted digital in Beta, and to have considered how to provide a sustainable service that’s free for assisted digital users. This requirement is only unnecessary if there is demonstrable proof from user research that there are no users with assisted digital needs.\n\n13. Build a service consistent with the user experience of the rest of GOV.UK by using the design patterns and style guide.\n\nThe service needs to look and behave consistently with GOV.UK. It should follow the GOV.UK design patterns and style guide. If the service team feels it has a better approach, or the provided design patterns don’t meet user needs, the service team should contribute to the service design community and&nbsp;suggest a new pattern. The panel would expect an Alpha to more closely resemble a GOV.UK service visually, and much of the microcopy within the Alpha service was not to GOV.UK style.\n\n17. Be able to test the end-to-end service in an environment identical to that of the live version on all common browsers and devices. Use dummy accounts and a representative sample of users.\n\nTo move into beta, the core service needs to be working end-to-end. The service team must demonstrate a working prototype that meets user needs and has tested well in user research.\n\n18. Use analytics tools that collect performance data.\n\nTo move into beta development, a firm plan for performance data capture must be in place and an analytics package installed. The service team must demonstrate they have the ability to interpret data analytics to identify needs, solve problems and improve the service.\n\n**Recommendations**\n\nWe recommend that the service team focus on the following ahead of alpha reassessment.\n\n- Ensure that a designer, content designer and analyst are available to work with the service team during this early stage of development.\n- Complete a fully working prototype to test the core service with users (this could be restricted to the most popular journey).\n- Test the service end-to-end, from submission by veterinarians to uploading of results by laboratory staff.\n- Make a plan for the service being taken offline and show how this will be tested. Demonstrate how the effect on users will be managed (see&nbsp;[Uptime and availability](https://www.gov.uk/service-manual/operations/uptime-and-availability)).\n- Carry out a full design review using the GDS resources. As discussed earlier, the service doesn’t follow the GOV.UK front-end toolkit (see&nbsp;[Design patterns](https://www.gov.uk/service-manual/user-centred-design/resources/patterns/index.html),&nbsp;[GOV.UK elements](http://govuk-elements.herokuapp.com/),&nbsp;[Design patterns wiki](https://designpatterns.hackpad.com/GOV.UK-design-patterns-0eUk1OdHvql),&nbsp;[What your service should look like](https://www.gov.uk/service-manual/user-centred-design/service-user-experience.html),&nbsp;[Resources for&nbsp;designers](https://www.gov.uk/service-manual/designers)).\n- Work with the GOV.UK content team to ensure that content and microcopy help the service meet user needs and stick to GDS style (see&nbsp;[Resources for content designers](https://www.gov.uk/service-manual/designers)).\n- Carry out research to identify any users with assisted digital needs (see:&nbsp;[Researching assisted digital users](https://www.gov.uk/service-manual/assisted-digital/assisted-digital-user-research.html)).\n- If assisted digital users are found, carry out research with those users and plan to carry out regular research during Beta (see:&nbsp;[Researching assisted digital users](https://www.gov.uk/service-manual/assisted-digital/assisted-digital-user-research.html)).\n- If assisted digital needs are identified, make a plan for how the service will address those needs, to provide a free, sustainable service for assisted digital users (see&nbsp;[Assisted digital](https://www.gov.uk/service-manual/assisted-digital/index.html)).\n- Choose an analytics package and install it in the service (see&nbsp;[Analytics tools](https://www.gov.uk/service-manual/making-software/analytics-tools.html)).\n- Start working straight away with the GDS Performance Platform team to agree extra KPIs to measure success. Start work on a public dashboard to display service performance (see&nbsp;[Measurement](https://www.gov.uk/service-manual/measurement)).\n- Open up code as a default.\n- Look again at GOV.UK Verify. The service team&nbsp;must show concrete evidence to support not going with GOV.UK Verify. Other services in similar situations, such as the Rural Payments, are using Verify. The fact that many of the service users have a Government Gateway account isn’t a sufficient reason not to migrate (see&nbsp;[GOV.UK Verify guidance](https://www.gov.uk/service-manual/identity-assurance/index.html)).\n- Investigate ways of avoiding surfacing personal data where possible. For example, when showing the list of clients to a veterinarian consider showing less information. This is not a blocker, rather a suggestion to investigate.\n- The notion of data aggregating to IL3 is no longer valid. It would be good to revisit this. The new security classifications should be used (see&nbsp;[Security as enabler](https://www.gov.uk/service-manual/technology/security-as-enabler.html#new-classification-policy)).\n\n**Summary**\n\nThe assessment panel&nbsp;was really impressed by the agile way the service team is working. This is a great example of a multi-disciplinary, co-located team working together to build a service focused on user needs.\n\nThe panel notes the team's&nbsp;commitment to user research, including field research. The team&nbsp;clearly articulated user needs and the whole team were clear on the most important ones to solve first.\n\nThe team&nbsp;demonstrated a great understanding of the context in which users work. The panel&nbsp;loved the dedication the team&nbsp;demonstrated to embedding research into sprints and making regular, often radical design changes based on findings. The panel&nbsp;looks forward to seeing how the team&nbsp;applies this same dedication and pace during research with potential assisted digital users, and the internal users in laboratories.\n\nThe team had lots of interesting early thoughts about a number&nbsp;of the points raised by the Service Standard. The team's&nbsp;commitment to building a digital service that people prefer to use was clear.\n\nThe team's presentation, knowledge and answers to the panels&nbsp;questions were clear and well-prepared.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/paye-income-tax-estimate-alpha/",
    "title": "PAYE: Check your Income Tax Estimate - Alpha Assessment",
    "summary": "This service will allow users to view their income tax estimate so that they understand how much tax they will pay, how that is calculated and how they will pay it.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n08 January 2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Thornett\n\n**Service Manager:**  \nL. Hawksworth\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment Report\n\nThe PAYE (Check your income tax estimate) has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n### Outcome of service assessment\n\nAfter consideration the assessment panel have concluded the PAYE (Check your income tax estimate) service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n### Reasons\n\nThe service has made good progress through early discovery and alpha stages of development and it was particularly encouraging to see how much user research has been undertaken and the many improvements that have been made to the prototype as a result.\n\nThe team is working well alongside other digital service teams in HMRC and following well understood agile processes which will help ensure that the service continues to iterate and improve through the next stage of development.\n\nConsiderations around security, data privacy and suitable technology standards are well understood by the team and those that support them in the wider HMRC organisation and the development of this service is already benefiting from wider support across HMRC.\n\nThe visual design is a good example of a service built within the GOV.UK style and content design effort is being used to ensure that complex tax language is being made as easy to understand as possible by users of the service.\n\nThe team have a good understanding of the large number of potential users for this service and how digital take-up can be increased using the existing telephone channel and paper-based communication.\n\nThe assessment panel were extremely pleased to see that the team had avoided building a digital service that simply replicated the messaging that is currently sent in a letter from HMRC to a subset of users. Instead, the team have used research and survey data to help them understand what users actually need. During the next phase it is important to keep improving this initial understanding of user need and strive to simplify the service so that any user, whatever their need, is able\n\n### Recommendations\n\nDuring the next stage of development the team will need to:\n\n- Continue their frequent user research and collect analytics data from the private beta service in order to more fully understand the primary needs of users affected by PAYE income tax. In particular, the service needs to evolve to a point where the user journeys are fast and straightforward for users to access and complete, whichever need they are looking to fulfil.\n- Understand the trigger points that cause the users to start their journey so that appropriate start and end points can be constructed from GOV.UK and through the service, before it moves into public beta phase.\n- Make their source code open and reusable. Although work is underway to make code from other components of the PAYE service available via a public GitHub it would be good to see code from this service being made available in the same way, as it is being developed.\n- Continue working with the performance platform to publish dashboards of service performance and to establish reasonable performance benchmarks against the four service KPIs based on evidence from the existing telephony service\n- Increase their understanding of the PAYE user base, giving particular consideration for the amount, and type, of assisted digital support that will be required to support this service when it is public.\n- Test and measure the assisted digital support with users of this service who need it, and iterate it in response to findings. Testing must include users at the lowest end of the digital inclusion scale.\n- Consider support for users currently using friends and family.\n- Confirm that the assisted digital support is sustainably funded (including support not delivered by government) and free to the user.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/office-for-national-statistics-ons-website-voluntary-service-assessment/",
    "title": "Office for National Statistics (ONS) Website  - Voluntary Service Assessment",
    "summary": "The Office for National Statistics (ONS) is the UK’s largest independent producer of official statistics and is the recognised national statistical institute for the UK. It is responsible for collecting and publishing statistics related to the economy, population and society at national, regional and local levels. It also conducts the census in England and Wales every ten years. The website is the primary channel for dissemination of these statistics.",
    "body": "**Department / Agency:**  \nONS\n\n**Date of Assessment:**  \n15/1/2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. Sheldon\n\n**Service Manager:**  \nM. Jukes\n\n**Digital Leader:**  \nR. Patel\n\n* * *\n\n## **Assessment Report**\n\nThe ONS website has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the ONS website is on track to meet the Digital by Default Service Standard at this early stage of development and were impressed with the progress demonstrated at the assessment.\n\n**Reasons**\n\n**User Needs**\n\nThe ONS team have developed the Alpha website considering user needs from the start. During discovery the service team recruited and interviewed users of the existing ONS website. The team talked to expert statisticians, citizens, and are seeking out “critical friends” to challenge their assumptions. This user research has continued throughout using a varied mix of user research techniques. Using good examples, the team showed how they used user feedback to improve the features and offering of the website.The ONS team are planning to continue this user research during development of the Beta. The team are working with an external agency to recruit users to take part in regular research.\n\n**The Team**\n\nONS have put together a co-located, multi-disciplinary team to build the Alpha website and have appointed an empowered service manager to lead that team. Working in an agile way and using appropriate tools and techniques is allowing effective collaboration and communication.Most key roles are currently filled with interim staff, but the service manager is already working to recruit into ONS so that there is a sustainable team, that has the ability and capacity to iterate and improve the website on a frequent basis in future.\n\n**Security, Privacy, Tools and Standards**\n\nThe ONS team are already talking to their Senior Responsible Owner (SRO) and other relevant security staff. They are also using the support of a security consultant. This has helped them address concerns in a risk-averse organisation at an early stage.The approach to technology is based on the principle of “doing less”. The Alpha website runs on minimal technology, using inexpensive cloud hosting. Supported by established open source tools and developing code in the open. This is the right way to allow iteration and improvement early and often during the development of an Alpha.\n\n**Improving the service**\n\nThe technology approach chosen allows the team to deploy to the live website within a 15 minute window. All team members are able to make changes, test them locally and in a staging environment identical to live. The team intend to maintain this agility, with plans to use automated regression testing and empowering other members to take responsibility for accepting deployments to live.\n\n**Design**\n\nThe design of the website has evolved based on the feedback from scenario based user research. It also addresses former criticisms of the current website made in the press. The team showed improvements to search and browse and simplification of complex taxonomies. The website is exempt from GOV.UK, and looks different to it, but is following the same design principles.\n\n**Recommendations**\n\n**User**  **Needs**\n\nThe ONS team must integrate user research into their agile development cycle. Running this regularly, every sprint, so that user feedback can inform improvements during Beta development.\n\nWe recommend the development of personas for the publishing users of the ONS website.\n\nThe service manager should encourage ONS senior stakeholders to attend and observe user research.\n\n**The Team**\n\nThe ONS team should hold regular retrospectives, integrated into the agile development cycle so that the team can also iterate and improve the way it works.\n\n**Summary**\n\nThe ONS Alpha website is on track to meet the Digital by Default Service Standard. The work carried out during the alpha has started with the users' needs of an ONS website. The multi-disciplinary team have embraced an agile culture from the start. Applying agile principles and practices throughout, valuing individuals and interactions over processes and tools. Working in this way has allowed them to begin building a website that is so good users will genuinely enjoy using it.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | N/A |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/mot-testing-service-assessment/",
    "title": "MOT Testing - Service Assessment",
    "summary": "The MOT Testing service will enable users to efficiently and effectively record and report the results of an MOT test in accordance with the MOT scheme rules. For example, it will enable:",
    "body": "- qualified and pre authorised vehicle testers, operating at pre authorised private garages, to electronically record and amend an MOT test result and print a certificate\n- the private garages to pay a transaction (slot) fee to DVSA for the submission of the MOT test\n- DVSA staff to record the outcome of a vehicle re-inspection\n- the results of the MOT test to be shared with DVLA, and in turn support DVLA's on-line electronic vehicle licensing service.\n\n**Department / Agency:**  \nDfT / DVSA\n\n**Date of Assessment:**  \n1/12/2014\n\n**Assessment stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. Sheldon\n\n**Service Manager:**  \nN. Barlow\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## **Assessment Report**\n\nThe MOT Testing service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the MOT Testing service is on track to meet the Digital by Default Service Standard at this stage of development.\n\n**Reasons**\n\nThe service currently meets the requirements of the standard for an Alpha. Areas of good performance against the standard included:\n\n_User needs_\n\nThe assessment panel were pleased to see that the DVSA team have a good understanding of the users and their needs of the service This has been gathered through a range of user research methods, with feedback already being used to iterate and improve the service.\n\n_The team_\n\nThe DVSA service team is led by a skilled and empowered service manager, who owns and is responsible for all online and offline elements of the MOT scheme. All product managers in the scrum teams have experience in the motor industry and have autonomy to lead their multidisciplinary teams and work in an agile way.\n\n_Security, privacy, tools and standards_\n\nEarly and regular engagement with experts, to evaluate the security and privacy risks of the service, have allowed the team to put in place appropriate security with an emphasis on user needs. The assessment panel were pleased to see that the service team have followed a similar approach to idenitity assurance when developing the authentication interfaces and patterns, and are documenting that approach to share with other services not requiring GOV.UK Verify.\n\n_Improving the service_\n\nImprovements to and iteration of the service features are already being made based on feedback from real users and testing several prototypes prior to feature development.\n\n**Recommendations**\n\n_User needs_\n\nThe service team are aware that they lack sufficient user researcher capability and are currently looking to fill that gap in the teams. For beta assessment we expect to see a more regular and methodical approach to formal user research, which is sustainable and incorporated into the continuous improvement process. The current approach, although with real users, appears to be based on general feedback rather than a more structured approach. Whilst we agree that using online surveys is a good way to reach a wider set of users quickly and remote user research software allows testing of specific features, these techniques must only be used to support a robust user research process that the entire team can observe.\n\n_The team_\n\nThe service team are currently supported with a high percentage of interim staff, procured through contracts with external companies. At beta assessment we would expect to see a plan in place to address this balance and build a sustainable multidisciplinary team that can continue to own, operate and improve the service when live. The service team must consider the need for a dedicated analyst on the team who can identify actionable insights from data and analytics. There must also be a named person on the service team who takes ownership of assisted digital.\n\n_Security, privacy, tools and standards_\n\nIt was agreed that the service team will provide further detail on what tools and systems have been procured to support the service. Identifying how those procurements have been made and with what companies or services.\n\n_Open source_\n\nFor beta assessment we expect to see steps taken for this project to be coded in the open, with all code published on github.com in open repositories. Where this is not possible there should be a convincing explanation as to why.\n\n_Improving the service_\n\nTo be able to update and improve the service on a very frequent basis, the service team must continue to shorten the build pipeline with a goal of quicker feedback on builds to the development teams and a reduction in the 5 day lead time of getting production ready code to the live environment.\n\n_Design_\n\nThe GOV.UK style guide and front-end toolkit are currently being applied across the service. There are however a few areas where the patterns vary somewhat from GDS recommendations (e.g GOV.UK header, select-a-failure buttons). If there is a deemed an appropriate user need to build new patterns these must be solidly backed up by evidence from usability testing as opposed to preference from a small number of users.\n\nUse of the Crown icon as well as the GDS Transport font shall be determined based on whether or not the service sits on a service domain of gov.uk and this should be defined before going live.\n\n_Analysis and benchmarking_\n\nThe assessment panel recognise that the new service will be different to the existing service, but the service team should be benchmarking around user satisfaction for comparison. Some of the direct questionnaire feedback highlighted that users are not entirely unhappy with the current service. Measuring and comparing user satisfaction between both services will allow the team to focus on any dissatisfied users, or difficult user journeys and take steps to improve the service and its features.\n\n_Assisted Digital_\n\nInitial steps have been taken to understand the level of assisted digital required to support users who need it. The service team must use non-digital channels to get a full picture of the needs and numbers of assisted digital users, understanding that online surveys only reach users with a level of digital skills and confidence. The service team must carry out user research with users who have low or no digital skills, and use this research to influence design of both the on-screen digital service and any assisted digital support. The service team should plot their service’s users on the digital inclusion scale, to help demonstrate what level of assisted digital support will be required.\n\nThe service team must evidence that user needs will be met by the planned DVLA call centre offering or face-by-face support from users’ colleagues. They must also evidence that support from colleagues is sustainable and meets user needs.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/dwp-change-of-address-service-assessment/",
    "title": "DWP Change of Address - Service Assessment",
    "summary": "The service allows citizens (pensioners) to report a Change of Circumstance (Address) to DWP. The citizen is protected by a security platform (developed by the service team), that uses GOV.UK Verify to assure identity.  \n  \n**Department / Agency:**  \nDWP",
    "body": "**Date of Assessment:**  \n28/11/2014\n\n**Assessment stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nN. Chowdhury\n\n**Service Manager:**  \nS. Kerr\n\n**Digital Leader:**  \nK. Cunnington\n\n* * *\n\n## **Assessment Report**\n\nThe DWP Change of Address service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the DWP Change of Address service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service team have worked hard to understand the needs of their users, and to design a service that meets those needs. They have good evidence of changes and improvements they’ve made to their service based on user research. They have clear plans to continue engaging with users through the beta phase.\n\nThe service team demonstrated strong awareness of the need for assisted digital support for around 400,000 pensioners as non-digital channels are phased out. It is refreshing to see assisted digital user needs being considered so equally alongside those of users who can use the digital service independently. The service team has engaged with numerous assisted digital users, and plans to more strategically and proactively contact many more during the beta phase.\n\n**Recommendations**\n\n_Scope_\n\nThis service is focussed on change of address for users of the pensions service, however the current name “Report a change of address” implies that this is a generic change of address across government and is likely to cause confusion.\n\nAlso, in the future, GOV.UK Verify may support address history and change of address. As the service uses GOV.UK Verify, they should work closely with the team to understand how future development may impact DWP’s Change of Address service.\n\n_User research_\n\n- The service looks very simple, but it was not clear how users would find the service and know it was the right service for them. At their next assessment, the team must provide evidence that appropriate users can find and recognise the service.\n- The service demonstrated can only be used after a user has moved into their new address. The team must do more research around this constraint to ensure the service meets user needs,\n- For security reasons, the service sends users a confirmation letter. The team needs to include the letter in its research.\n\n_Assisted Digital_\n\n- The service team must carry out further research with assisted digital users at the lowest end of the digital inclusion scale to gather their feedback on both the digital service and their assisted digital support needs.\n- The team must user test assisted digital support in every sprint, as per plans for the digital service.\n- The team must find and talk to third parties who would provide assisted digital support for this service, and ensure it is sustainable and meets user needs.\n- The team must ensure the assisted digital support meets the needs of users during the GOV.UK Verify portion of the digital service.\n- The team must ensure support is in place for all users from the full user base who will need it as the service winds down non-digital equivalent services.\n\n_Digital Take-Up_\n\n- The team must contact the GDS Digital Take-Up team to ensure they have an appropriate plan in place.\n- The service team must do more to understand how it will persuade users of non-digital alternatives to switch to the digital service.\n- The service team must gain a fuller understanding of the barriers users face to transitioning to the digital service, and what it can do to remove these barriers for and/or with them.\n\n_Technical_\n\n- The team need to form a closer relationship with their SIRO, and to better understand threats at a process level. In particular, the systemic implications of building a service to change the circumstances associated with a National Insurance number and other systems which may have dependencies on the same information, including GOV.UK Verify.\n- The team demonstrate a mature approach to continuous integration and testing, as well as infrastructure as code. The team should ensure they continue to reduce the risk of lock-in to their current infrastructure provider.\n- The team have yet to make all new source code open and reusable, and publish it under appropriate licences. This needs to happen or the team need to provide a suitable explanation as to why this can’t be done for specific subsets of the source code.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/pension-guidance-service-service-assessment/",
    "title": "Pension Guidance Service - Service Assessment",
    "summary": "The pension guidance service is being set up in order to help those people considering accessing their defined contribution pension savings to:",
    "body": "- Ask themselves the right questions, given their individual circumstances\n- Understand their options (and risks) enough to make an informed next step, given the new defined contribution (DC) flexibilities\n\nFrom April next year, people holding DC pension pots will have increased flexibility in how and when they can access the money in their pension pots. They will be able to withdraw the whole pot as cash, purchase an annuity, or access an income drawdown product which allows them to withdraw some money while leaving the remaining pot invested. All of these options have tax implications and varying levels of risk which may or may not be appropriate for some people.\n\nThe guidance service is being set up so that people wishing to use the new freedoms can better understand what the implications might be for them, so that they are able to ask themselves the right questions about what the best choice is for them, given their circumstances.\n\nThere will be online guidance which will allow some people to self-serve their needs for guidance. However, we anticipate that at least 80% of users will want a guidance session where they can actually talk to someone to help them understand what the options are, and what they mean.\n\nThe service model and guidance content are being developed by HMT, however the actual delivery of appointments with users will be handled by the Pensions Advisory Service (TPAS) on the phone and by Citizens Advice Bureau (CAB) in their face to face offices across the UK.\n\n**Department / Agency:**  \nHMT\n\n**Date of Assessment:**  \n26/11/2014\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nE. Pollard\n\n**Service Manager:**  \nR. Bowen\n\n**Digital Leader:**  \nC. Smewing\n\n* * *\n\n## **Assessment Report**\n\nThe Pensions Guidance service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded the Pensions Guidance service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe assessment panel were very impressed with the clarity of user needs outlined at the assessment, and with the progress that the team has made in delivering an alpha to meet the highest priority user needs. Clearly there is some way to go, especially with regard to the systems which providers will use to record and communicate the outcomes of telephone and in-person guidance sessions, but at this early stage the panel felt very reassured that the team is on track to deliver a high quality service for users when the service goes live.\n\nThe service team clearly articulated their success criteria, which includes the four standard KPIs for all digital services, but also feature the goal that people should actually be better informed once they've used the services (and not just \\*feel\\* better informed). Their user research showed that users have low levels of knowledge around pensions, which makes this success criterion especially appropriate for this service.\n\nThe service team have put in place an excellent multi disciplinary team, who are working in an agile, iterative and user-focused way and clearly have a thorough grasp of what needs to be done and how best to do it, whether in terms of visual design and written content, technology, user research and so on. They have a detailed plan for how to test and iterate the service going forward, including small-sample comprehension testing and extended follow-up to determine what action users took.\n\nThe assessment panel note that web operations is an area where the service currently have a gap that they are working to fill, and that they are recruiting additional people over the next few months as they scale up the operation.\n\nThe service team have clearly taken account of their obligations around privacy and minimisation of data capture, and they are publishing source code, using open standards and following GOV.UK design patterns and style guide.\n\nThe panel confirmed that assisted digital support only needs to be applied to the digital element of the overall service, which in this case is the booking of appointments. The team has made an excellent start and has already started to set up sustainable telephone and face to face support in line with the assisted digital standard.\n\n**Recommendations**\n\nThe assessment panel note that the service team are currently planning to host the information contained in textual guides on the service.gov.uk sub-domain; given recent improvements to the navigation and browse infrastructure of GOV.UK we recommend that you revisit this decision with the Search and Browse team and see whether it's possible to maintain the user journey around pensions guidance and ensure that GOV.UK remains the single information publishing platform for the whole of government.\n\nThe assessment panel note that you are evaluating call-handling systems for your contact centre workers and recommend a chat with the Civil Legal Advice team at MOJ Digital Services about their open sourced call handling system.\n\nDuring beta, the service team must undertake research with assisted digital users to be able to demonstrate that their planned support meets user needs and is appropriate for demand.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/tax-credits-change-of-circumstances-alpha/",
    "title": "Tax Credits Change of Circumstances - Alpha Assessment",
    "summary": "Tax Credits Change of Circumstances allows users to view and update the information used to calculate their tax credits. The aim is to offer an easy to use service that encourages and supports users to advise HMRC of the correct information at the correct time, thereby reducing the levels of error, overpayment and debt.",
    "body": "**Department / Agency:**  \n[HM Revenue & Customs (HMRC)](https://www.gov.uk/government/organisations/hm-revenue-customs)\n\n**Date of Assessment:**  \n11 November 2014\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nJ. Robertshaw\n\n**Digital Leader:**  \n[M. Dearnley](https://www.gov.uk/government/people/mark-dearnley)\n\n* * *\n\n## Assessment Report\n\nThe Tax Credits Digital Change of Circumstances service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\nAfter consideration the assessment panel have concluded the Tax Credit Digital Change of Circumstances service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n### Reasons\n\nThe service manager and the service team spoke knowledgeably about the service and had done a considerable amount of research to understand user needs during discovery and alpha.\n\nThe service team had developed and iterated the prototype quickly during the alpha, based on feedback from users. The assessment team appreciated being able to see the alternate designs that were initially considered, as well as a video walk through.\n\nThe current multidisciplinary team will remain in place throughout the next stage of development.\n\n### Recommendations\n\n#### Assisted Digital\n\nThe service manager showed a good understanding of assisted digital principles but the team did not demonstrate sufficient research with assisted digital users and it was too early in development to meet the service standard for alpha on this point. The team have good plans to undertake research with existing third party providers of support and to join up with related government services. To pass the service standard at beta, the team must undertake research with assisted digital users to be able to demonstrate that their proposed assisted digital support meets user needs and the assisted digital standard (for example, low wait times for calls). The team must also demonstrate that support is sustainable and not rely on third parties such as charities to provide ongoing support to their users.\n\n#### Source Code\n\nThe team weren’t able to talk the assessment panel through their plan for making all new source code open and reusable or, where necessary, the reasons why subsets of the code could not be open. The assessment panel understand that HMRC has an open source policy, and that there are discussions about the security of opening up the code, but it is our opinion that prototypes have very little security impact and therefore should already be open sourced. It feels like the team believe they need to justify the open sourcing of the prototype the same way they would need to justify open sourcing real production code. The assessment panel feel that the source code for the prototype would be a valuable resource for other projects to learn from.\n\n#### Safety and Security\n\nThe assessment panel had some serious concerns about the security implications of the service, in terms of sharing information with users, and whether the team is receiving the appropriate advice to ensure that they carefully balance the security needs and the user needs. The panel feel that at this early stage, this does not preclude advancement from the alpha stage as it can be addressed during the beta phase. Whilst a lot of security considerations have already been made, the panel strongly recommend that the service manager continues to talk to the appropriate specialists.\n\n#### Multidisciplinary Team\n\nA content designer and product analyst (or an appropriate amount of time from these each of these disciplines) should be embedded in service team during the next stage of development.\n\n#### User Research\n\nThe largest volume channel for users to tell HMRC about a change of circumstances affecting their tax credits is currently over the over the phone. Using call centre data and speaking to the people who handle those calls could help inform user needs, engaging with the call centre(s) early should be considered.\n\nThe panel would also suggest at the next stage of development focussing more on what users do and what works for them, rather than asking for them for feedback. For example, the panel noted that the A/B user research the team explained at the assessment involved asking users for a preference, rather than monitoring the effectiveness of the different options.\n\n#### Design\n\nThe team should consider how follow-on actions are presented to users - eg notifications, and make sure that the concepts of ‘pending’ changes are well understood.\n\nThe assessment panel had some concerns that the design that has been worked on in the prototype would not be possible to achieve during the public beta because of technical constraints. The panel did not see evidence that the intermediate state of the service was being carefully designed as well. The panel recommend that the service team work both on the intended end state of the system, and the system that is achievable within the constraints of the service development timeline.\n\nA large percentage of the services users are likely to be on mobile devices, but the prototype is not currently optimised for these users. The service should be designed with this in mind, potentially using a mobile-first strategy.\n\n#### Performance Platform\n\nThe team had an early discussion with the Performance Platform. They should renew these discussions to establish how they are going to track the 4 KPIs and report them on the performance platform.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/agent-online-self-serve-alpha/",
    "title": "Agent Online Self Serve - Alpha Assessment",
    "summary": "This is a new service for tax agents to work with HMRC online. It will let agents register to act on behalf of, and see information about, their clients, and to control a range of transactions on their behalf. These will be built on a new digital tax platform which will eventually replace the current HMRC Portal and be the default platform for new user-facing services.",
    "body": "[https://www.gov.uk/transformation/register-as-tax-agent.html](https://www.gov.uk/transformation/register-as-tax-agent.html)\n\n**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n6/11/2014\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Hughes\n\n**Service Manager:**  \nS. Brodie-Rendon\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## **Assessment Report**\n\nThe Agent Online Self Serve service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Agent Online Self Serve service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe product meets the requirements of the standard for alpha.\n\nParticular areas of strong performance against the standard included:\n\n_User research_  \nThe team has carried out user research and has been prepared to re-examine fundamental assumptions and the scope of the project.\n\n_Empowered service manager and skilled team_  \nThe team is clearly very highly skilled and empowered to make decisions based on evidence.\n\n_Iteration and improvement_  \nThe team has already shown its capacity and appetite for improvement and iteration.\n\n_Assisted digital_  \nThe team has carried out research to gather evidence and develop a good understanding of assisted digital user needs (although the service is exempt from the assisted digital requirement because the users are all paid intermediaries).\n\n_Visual design_  \nThe standard of design is high and consistent with&nbsp;[GOV.UK](http://gov.uk/) patterns.\n\n**Recommendations**\n\n_Reliance on the tax platform_  \nFor the beta assessment the assessment panel would expect to see a comprehensive, clear and detailed explanation of which aspects of the service and its management will be provided by or reliant on the tax platform, and how these will be integrated with the service.\n\n_User research_  \nWhere users have difficulties using the service, the team should try alternative designs rather than adding explanations to support users through the existing design.\n\n_Simplicity_  \nThe team should continue to seek the simplest, most straightforward way for users to achieve their aim in the user journey, and to make it clear within the journey what the user needs to do.\n\n_Analytics_  \nThe team will need a dedicated skilled person to identify actionable data insights during the next phase.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/payrolling-benefits-in-kind-alpha/",
    "title": "Payrolling Benefits in Kind - Alpha Assessment",
    "summary": "The Benefits in Kind Payrolling service will enable a business to inform HMRC that in the future they will be calculating (and deducting) the appropriate amount of Income Tax due on the Benefits in Kind provided to their employees through the company payroll. The service will enable them to specify for which tax year they are going to tax the benefits through the payroll; and which benefit types (Car, Fuel, and Private Medical Insurance etc.) will be included. The service will also enable the business to specify whether any employees will be excluded or not.",
    "body": "**Department / Agency:**  \n[HM Revenue & Customs (HMRC)](https://www.gov.uk/government/organisations/hm-revenue-customs)\n\n**Date of Assessment:**  \n29 October 2014\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. O’Neill\n\n**Service Manager:**  \nC. Brown\n\n**Digital Leader:**  \n[M. Dearnley](https://www.gov.uk/government/people/mark-dearnley)\n\n* * *\n\n## **Assessment Report**\n\nThe Benefits in Kind Payrolling service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n### Outcome of service assessment\n\nAfter consideration the assessment panel have concluded the Benefits in Kind Payrolling service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n### Reasons\n\nThe service team were able to clearly set out the core user need which they were working to meet and how their service will meet that user need. They were clear about the benefits that would accrue to users and HMRC. The team were able to set out how they were engaging with users and how users were responding to testing and engagement.\n\nThe team were aware of the other related programmes underway within HMRC and could set out how they were working with them to unify user experience and tackle risks of “double taxing”\n\nThe team had begun to engage with the Performance Platform team and to identify the metrics required for the service along with the instrumentation for the back end.\n\nThe team had begun to engage with Data Guardians and other key assurance people in HMRC to ensure that the service was robust.\n\n### Recommendations\n\nThe service team should:\n\n- Continue to work closely with the ‘PAYE for Employees’ (company car) exemplar so that they can clearly describe how the joined up user experience will work and be able to demonstrate that it works for users.\n- Be able to evidence through robust user research and usability testing the reasons for top slicing the pyramid of users and how the team will encourage transition to the payrolling service for the rest of the user types.\n- Ensure that user research involves employees from a range of different employer types, both specific to this service and within the context of the wider ‘Your Tax Account’ services.\n- Take ownership of Assisted Digital for the service rather than relying on potential organisation wide support and generic user research. The team has focused on the requirements of larger companies in alpha. They must undertake more user research with small, single and micro companies to understand the specific barriers they might face in using this service and to design appropriate assisted digital support. Proposed support must be put in place to be tested and measured in beta and the team must be able to provide evidence of how this support would meet specific user needs for their service.\n- Ensure that the timetable for delivery is set by the agile programme, the current approach to delivery is too dependent on legacy timescales.\n- Begin work on the exclusions journey as soon as possible and set out their approach to user research and usability testing in advance.\n- Have their cybercrime/threat analysis people review the service as soon as possible.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | No | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | No | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | No | 22 | No |\n| 23 | No | 24 | No |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/land-registry-service-assessment/",
    "title": "Land Registry - Service Assessment",
    "summary": "Home buyers and business intermediaries will be able to search for, gain data on and register property in the UK, without the need for the delays inherent in current paper based systems.",
    "body": "[https://www.gov.uk/transformation/land-registry.html](https://www.gov.uk/transformation/land-registry.html)\n\n**Department / Agency:**  \nBIS / Land Registry\n\n**Date of Assessment:**  \n24/10/2014\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nA.Keene\n\n**Service Manager:**  \nE.Davies\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## Assessment Report\n\nThe Land Registry Alpha has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded the Land Registry Alpha service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe assessment panel recognises the executive level support that has been given by the Land Registry to this Alpha. The panel were impressed by the breadth of the Alpha and the ambition to truly transform Land Registry’s business and the way it supports its many customers. They found that the Land Registry is working on the right lines to meet the panel’s expectations at the next, Beta, assessment. Areas that stood out to the panel include:\n\n- Adoption of modern, open, software practices, tools, environments and standards, preventing long term lock-in to specific vendors.\n- The depth of user research, participated in by the whole team, underpinning the Alpha and using it to guide the proposed betas.\n- The Service Manager’s determination to build an in house team, whilst being mindful of the need to allow outside influence to ensure the way the organisation works is always current.\n- Deep understanding of the data, its constraints and the opportunities to use it wider and in a safe manner.\n- Understanding their requirement to ensure appropriate assisted digital support for users currently choosing to use paid intermediaries, and for all users during the GOV.UK Verify section of the service.\n- Understanding their requirement to help assisted digital users to be more likely to be able to complete this (and other) services independently in future.\n\n**Recommendations**\n\nPoint 1 - Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for digital and assisted digital service design.\n\n- The panel encourage the service to compile a log of assisted digital, digital inclusion and other important population user dimensions during user research and usability testing. This helps in ensuring the service have a rounded understanding of their user strata.\n- The panel recommend the service tests alternative designs to reduce confusion around tenure (i.e. when the same address appears twice).  \nEffort should be made to clear roadblock to providing incentives. This helps to get less biased recruiting for user research and usability testing.\n\nPoint 2 - Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.\n\n- The service should consider how they scale their service delivery teams. To be successful they will need to balance the ambitions of starting quickly, whilst being able to find the right permanent members of staff.\n- The service recognise they have had the benefit of pairing across the team with GDS during Alpha. As the number of people from GDS will be lower in Beta they should consider the softer aspects of service design and build that the GDS people brought to your team. The service should make sure they know how to use the tools GDS brought and also ensure their people are plugged into the right communities of practice.\n- The panel encourage you to embed content designers in each team to ensure the text in each product works as well as possible. Where reasonable, a content designer should attend user testing to gain a better understanding of the sorts of problems users have with the copy, to try new ideas, and to feed back insight about effective content design from the testing sessions to the wider teams.\n\nPoint 9 - Create a service that is simple and intuitive enough that users succeed first time, unaided.\n\n- The panel recommend you take a ‘mobile first’ approach to all of your design. The disciplines required to design a compelling and intuitive service will benefit all of your users, not just those who are using mobile.\n\nPoint 10 - Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it.\n\n- The service should carry out research with assisted digital users of their service (including those with the lowest levels of digital ability) to understand their needs and numbers.\n- The service should talk to users seeking support from places other than their own provision, and across all channels.\n- The service should test and iterate their assisted digital user personas, to ensure they’re accurate.\n\nPoint 11 - Plan (with GDS) for the phasing out of any existing alternative channels, where appropriate.\n\n- The service should contact the Digital Take Up team at GDS to confirm more detailed plans to increase digital take up of their service.\n- The service should ensure their plans include understanding of channel volumes and which organisations/groups are helping users across each of those channels.\n\nPoint 20 - Put a plan in place for ongoing user research and usability testing to continuously seek feedback from users.\n\n- The panel encourage you to create more complete customer journey mapping activity, e.g. an end-to-end visual representation of the user’s journey, starting with awareness of a need for information, through the pages in the service, to having a clear understanding of their answer.\n- Expression of clear user / usability targets / hypotheses / goals and their measurement and iteration, logged and, preferably, made visible for the team.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/universal-credit-service-assessment/",
    "title": "Universal Credit  - Service Assessment",
    "summary": "Universal Credit (UC) Digital provides a simple, personalised digital and non-digital service for claimants and staff. The service encourages individual responsibility, supporting people finding work and finding better paid work. The service fully supports claimants through applying and evidencing the range of benefits supported. UC Digital allows DWP agents to manage the benefit and accurately and timely maintain the claimant information while supporting the operations and delivery of the service.",
    "body": "There are 2 groups of users. The full range of recipients of working-age benefits, including for example, those who would otherwise receive Jobseekers Allowance, Housing Benefits, Employment Support Allowance and Tax credits. And the agents (service centre and work coaches) who will use the system to enable operational delivery of the service.\n\nThere is a substantial set of user needs that the service is being designed to meet ranging from 'as a user I want to be able to log in' to 'as a member of a couple at risk of domestic violence, I want to be protected when I split my couple claim'. The current scope of the service is to support the full range of benefit types and complex circumstances.\n\n**Department / Agency:**  \nDWP\n\n**Date of Assessment:**  \n8/9/2014\n\n**Assessment stage:**  \nAlpha review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nR. Reynolds\n\n**Service Manager:**  \nL. Sampson\n\n**Digital Leader:**  \nK. Cunnington\n\n* * *\n\n## Assessment Report\n\nAfter consideration the assessment panel have concluded the Universal Credit Digital Service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\nAs this was an alpha assessment of the 26 points of the standard, there are 23 points on which the panel are satisfied the service team are already working along the right lines and the remaining 3 points will require further effort in the next phase of work in preparing for a beta assessment.\n\n**Reasons**\n\nThe assessment panel found that the service team is mostly working along the right lines. The team is building the service based on user needs, has made changes to the alpha based on findings from user research, which has been conducted both with end users (claimants) and internal users (agents). The team is working in an agile way, able to adapt and improve processes as you go. A lot of thought has already been given to the security and privacy implications of the forthcoming beta, as well as to the importance of assisted digital provision. Although they haven't yet have a complete end to end hands-on demo, engagement from ministers has obviously already been strong.\n\nThere are some areas that need work. The service is already impressively advanced in many respects, but in the areas of analytics, open source, and building a multidisciplinary team the assessment panel recommends that you still have some more work to do in preparing for a beta phase.\n\n**Recommendations**\n\nThe service is not yet on track to meet the criteria of the service standard on points 13, 15 and 18, and will need to take corrective action in order to pass a future beta assessment:\n\n- Point 13 - There are already plans to strengthen certain aspects of the team. In these early stages of the service, content designers and user researchers should be working closely alongside your developers and designers to solve problems, conducting user research and testing the service with users in order to identify the best ways to that meet users' needs. Good content design will help inform the right approach to your service, e.g. setting an expectation for agents, returning claimants, and claimants coming to the service for the first time. This cannot be tacked on after the fact. The team will definitely need more content designers to ensure knowledge is retained and shared, and so that content can be internally reviewed before it goes into beta.\n\n- Point 15 - Unless there is a reason not to for a specific subset of the source code (for example a verified security risk), the service team should be making all of the source code open and reusable. Despite having identified some reusable components, the lack of a plan to open up any source code at all is disappointing. At this stage the services code should already be opening up (or otherwise be able to explain clearly the specific and compelling reasons why this can not be done for a particular subset of the code). A working assumption that security prohibits the opening up any code isn't reasonable.\n\n- Point 18 - In the proof of concept assessment in December 2013 the panel noted that web analytics should be built in to the alpha as soon as possible. Although the service has now identified a preferred analytics package, it still needs to incorporate analytics capture into the service (e.g. beyond pageviews and dwell time, what data specific to the service will be captured, how to track end-to-end engagement, etc.) and have a process for interpreting and acting on that data. This must have been done before the service considers moving to a public beta.\n\nThe assessment panel also have some other recommendations:\n\n- There must be a description how the journey to the Universal Credit Digital Service starts and ends on [GOV.UK](http://gov.uk/). With an existing Universal Credit Live Service running in parallel, along with several other benefits which will need to direct users towards the right Universal Credit service for them, the risk for users being confused is high, and a clear approach that helps users get to the right service must be agreed in plenty of time before a live beta. With both the Live Service and the Digital Service planning to roll out to increasingly large numbers of postcodes, people will need to know which service to use. We recommend that you come in for a meeting with a proposition manager and product manager from the&nbsp;[GOV.UK](http://gov.uk/) team to agree a plan.\n\n- The service must document the cookie in a service-specific page, as described in the cookies page of the service manual. The relevant pages are&nbsp;[www.gov.uk/service-manual/making-software/cookies](http://www.gov.uk/service-manual/making-software/cookies.html) and&nbsp;[www.gov.uk/service-manual/operations/operating-servicegovuk-subdomains#cookies](http://www.gov.uk/service-manual/operations/operating-servicegovuk-subdomains#cookies)\n\n- The panel have a few small suggestions about the visual design re front end, which will be passed on.\n\n- GDS are happy to review the content of the service too.\n\n- The panel look forward to hearing more about the plans to move away from a self-hosted environment to cloud hosting in the future, and to share the learnings from this with others across government.\n\n- In the beta assessment, the panel would also like to hear more about the plans for iterating the content and design of the beta service on a frequent basis. The expected zero downtime and ability to release as often as needed are both encouraging, but the panel were unclear on your plans for a 2 (or 3) week release cycle.\n\n- For the beta assessment, the panel would expect to be able to access the service ourselves beforehand.\n\n- The panel hopes that, after the pilot in one postcode area, the team will capitalise on the opportunities it affords for even more and better hands-on research with agents, and especially claimants.\n\n- Longer term, despite the regulatory and legislative framework imposing some constraints and complexity for the service, the panel hope you will challenge those moveable constraints, iterating the service to increase simplicity as well as identifying testable reductions in administrative cost and fraud.\n\n- The panel recognise that the service team has already made contact with the performance platform team. The planned conversation with that team will be vital in your decisions around benchmarking and publicly tracking your KPIs. The panel are especially keen, before the next assessment, that as a team you have a chance to consider an approach to benchmarking the performance of this new service against legacy benefits.\n\n- In the beta assessment the panel will ask you to clarify what proportion of the team are involved in the core service delivery / planning for business transformation / integrating with departmental systems / assurance and programme governance overhead, and what proportion of the various roles are contractors. The panel are keen to see the work to embed long-term roles start continue, reducing the risk of losing valuable knowledge when contractors leave.\n\n- For assisted digital, the team will need to show initial thinking about the national roll out of assisted digital support, including more detail on delivery such as the number of expected transactions by channel and costs. Similarly the panel would like to know more about how you will approach digital take-up for the eventual roll out of this digital service.\n\n**Summary**\n\nIn summary, the assessment panel was impressed with what the service team have done since the last assessment and being able to share the progress so clearly and candidly. The panel look forward to seeing the team again soon for a beta assessment.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | No | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | No |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/employment-intermediaries-alpha/",
    "title": "Employment Intermediaries - Alpha Assessment",
    "summary": "In the Government’s autumn statements of 2012 and 2013, it was announced that a number of measures would be introduced to close the tax gap in the temporary labour market.",
    "body": "This service will provide a standardised and digital way for intermediaries in the temporary labour market to report information into HMRC to meet their legislative requirements and help close the tax gap.\n\n**Department / Agency:**  \nHMRC\n\n**Date of Original Assessment:**  \n2 September 2014\n\n**Date of Reassessment:**  \n29 September 2014\n\n**Assessment stage:**  \nAlpha review\n\n**Result of Original Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nL. Scott\n\n**Service Manager:**  \nA. Flynn\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## **Reassessment Report**\n\nThe assessment &nbsp;panel agreed that the Employment Intermediaries Service is now in excellent shape to move into Beta development. The service team put together a professional and considered reassessment with the processes and practice they have put in place being invaluable for other HMRC services to follow. Below is the assessment panel’s response on the steps Employment Intermediaries service have taken to address the 4 criteria not passed at the original assessment.\n\n_3. Evaluate what user data and information the service will be providing or storing, and address the security level, legal responsibilities, and risks associated with the service (consulting with experts where appropriate)._\n\nThe panel were really pleased to see the team consulting with GDS on how to approach the security level of the service. They have addressed concerns about how such a high security rating will impact on the operation of the service.\n\nThey have explained in further detail that while the data will be classed as a higher security rating, the service itself will be classed as a much lower security rating. This means the service can use the tax platform so long as the data is held temporarily. Accreditors and data guardians are happy with this approach.\n\nThe service team explained that they would be using the existing bridge rather than building a new one - they have used data to determine the average file sizes (which are very small) and explained how they will chunk data from larger files.\n\nThis is a good solution and the panel is confident that the service will be able to operate and release frequently given their description of how they will manage the higher security level data.\n\n_2. Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility._\n\n_14. Make sure that you have the capacity and technical flexibility to update and improve the service on a very frequent basis._\n\n_17. Be able to test the end-to-end service in an environment identical to that of the live version on all common browsers and devices. Use dummy accounts and a representative sample of users._\n\nThe service team explained in very useful detail how they will work with colleagues at Dorset House to operate the live service. The assessment panel were impressed with the effort they have gone to in setting up a clear process for their team to follow and for other teams to emulate.\n\nThey explained how they now have a fully functioning development environment with integrated testing. Their process for getting code deployed is clear and they have set up frequent discussions with colleagues in Dorset House to make sure this process is working, allowing opportunities for iteration and prioritisation.\n\nAlthough the service are currently relying on the webops team in Dorset House, they are training up their own team to understand and manage the process. Whilst not being the dedicated support, the team is providing support and capacity for the operation of the service, and are monitoring tests visually so the whole team can see the status of the service and infrastructure.\n\nThe service team articulated a clear line between responsibilities between the service team and the webops team in Dorset House and provided evidence that everyone is aware of their role.\n\nThe assessment panel were very impressed with the high standards and thoughtful quality the service team achieved in this short time to get such an excellent operational model in place.\n\n* * *\n\n## Original Assessment Report\n\nThe Employment Intermediaries service has been reviewed against the 26 points of the Service Standard at the end of Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Employment Intermediaries service is not yet on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe assessment panel was extremely impressed with many aspects of the service.\n\nThe assessment panel’s concerns around passing this service for the next stage of development are primarily around Criteria 3:\n\n_3._ _Evaluate what user data and information the service will be providing or storing, and address the security level, legal responsibilities, and risks associated with the service (consulting with experts where appropriate)._\n\nThe statement that the data is of a significantly high security rating is extremely concerning and has implications for the entirety of the project. The concern of the assessment panel is how this rating impacts the rest of the project, from developer hiring, device management, code deployment and so on.\n\nThe service team need to articulate exactly why the data has a high security rating, and how they view continued development under that regime. For example, can the team open the code? What machines would developers use? Do developers need security clearance? How would developers deploy code? Whilst these questions can be fully addressed in beta the assessment panel expects there will be &nbsp;a number of issues and these would benefit from being identified and addressed at this stage.\n\nThe team need to demonstrate how they will be able to mitigate this risk, either by restating the risk or by ensuring that the nature of the risk doesn't adversely affect delivery of the service.\n\nIn addition, the assessment panel had some concerns around points 2,14 and 17 of the standard:\n\n_2._ _Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility._\n\n_14. Make sure that you have the capacity and technical flexibility to update and improve the service on a very frequent basis._\n\n_17. Be able to test the end-to-end service in an environment identical to that of the live version on all common browsers and devices. Use dummy accounts and a representative sample of users._\n\nThe assessment panel were concerned about the lack of a clear deployment pipeline. Without this setup in place and understood, beta development will be blocked.\n\nThe assessment panel were not yet clear on how development environments and continuous integration will be created and managed for beta development.\n\nThe assessment panel understand that the service team intend to use the HMRC set-up in Dorset House to create development and production environments and live support. We would like to see a clear statement that this is to be the case and how that will be managed.\n\nThe lack of a devops role (we understand recruitment is underway) is a blocker in the move to beta. As it stands there isn't a complete team able to deploy and manage this service.\n\n**Recommendations**\n\n1. Review the high security rating. GDS can assist with this.\n\n2. Provide a statement on how the service team will integrate with the development and production environments in Dorset House, and explain how the service can be frequently deployed and managed via this set-up.\n\n3. Demonstrate how the service will have a complete team who can take full responsibility for devops.\n\n4. Demonstrate the steps that are underway to make source code publicly available (notwithstanding the high security rating comments above). It is much harder to open code after development than to build with this in mind. The service team have shown their intent to do this and are undergoing governance procedures.\n\n**Observations against other criteria**\n\n**User needs and user research**\n\nThe assessment panel noted how the whole service team had a deep understanding of their users, and of the top user needs that the service would address. The team’s user research and data gathering exercise to elicit these user needs was very impressive, particularly their determination (in spite of barriers) to access real users, and their passion in getting the whole team involved in research and analysis.\n\nThe assessment panel were impressed with how the team took findings from user research and used these to inform the service design. The panel noted several great examples of how this user-focused approach has produced an intuitive and well-received digital service.\n\nThe service team have a great plan in place for user research for the next stage of development, and research is embedded in their sprint cycle. The panel were pleased to hear about the team’s plans to reach all types of users, and to re-test with users from the early stages of discovery.\n\n**The team**\n\nThe service team is an excellent example of a multi-disciplinary, co-located team working together in an agile way to design a service to meet user needs. The assessment panel were very impressed with how the team works, communicates and self-organises, along with how they work as a team whilst keeping a clear separation of roles.\n\nThe assessment panel really liked how the team has a clear idea of direction and focus (eg last sprint/next sprint, roadmap) as well as the clear idea they have of the value they are adding to the digital service. (Although the panel had reservations about the lack of a complete team, particularly devops, as discussed earlier).\n\n**Security, privacy and standards**\n\nThe service team have engaged with all the right people and made all the necessary checks for compliance against the standards and codes outlined in the criteria. They are adopting existing HMRC technical approaches using the stack developed by teams working on the exemplars at Dorset House.\n\nThe assessment panel noted how the service are sharing learning and knowledge between teams with regular show and tells, communication and code re-use. The panel loved the example of introductory Scala sessions with new developers, and would urge the service team to share this more widely.\n\nThe assessment panel saw how the team are complying at least in spirit with open documents standards and noted how findings from user research informed the decision not to mandate this.\n\nThe assessment panel were glad to see the team are planning for disaster recovery and business continuity, and that they plan to address this fully during beta. The panel really liked the team’s user-focused approach here, especially their knowledge around peak load times, crucial deadlines, and thinking about the messaging to users.\n\nAs noted earlier, the assessment panel were very concerned about the impact of the proposed high security level on the delivery of the service and the team who will run it. The assessment panel want to learn more about how the service team propose to integrate with the Operations Team in Dorset House.\n\n**Improving the service**\n\nThe service team’s approach to updating the prototype in alpha was a good example of agile development. As discussed earlier, the panel were not clear how the service team plan to manage a full development environment for the beta.\n\n**Design**\n\nThe assessment panel were really impressed with the user-focused design of the service. The service team have used the design patterns and style guides and are contributing back to the community with their findings from research and their design and content solutions.\n\nThe assessment panel really liked the service team’s approach to tackling the offline steps around penalties, and their vision around removing this in the future.\n\nThe assessment panel were struck by the excellent quality of the content design. This is a really good example of designers and content designers working alongside the development team to create a great experience for users.\n\n**Assisted Digital and Channel Shift**\n\nThe service team have carried out considerable user research through known intermediaries and representative bodies. As they have a highly IT literate user base, they have not yet identified a need to provide assisted digital support.\n\nThey should continue to seek out potential assisted digital users throughout the beta phase.\n\n**Analysis**\n\nThe service team have a great grasp of how they will measure success. They are engaging with all the right people and sharing and communicating with teams on similar services. They are recruiting a product analyst and the whole team is learning how to interpret data trends. The assessment panel were really pleased to see how well the whole team knew the data around the service, including projected usage.\n\n**Testing with the Minister**\n\nPreparations for this process are underway.\n\n**Next steps**\n\nThe service should follow any recommendations made in this report and see the&nbsp;[Government Service Design Manual](https://www.gov.uk/service-manual/digital-by-default) for further guidance.\n\nIn order for the service to proceed the service will need to return to GDS for a reassessment of the criteria which were not passed.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | N/A | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/dart-charge-service-assessment-2/",
    "title": "Dart Charge - Service Assessment",
    "summary": "The Dart Charge is the new ‘free-flow’ charging scheme being developed for the Dartford Crossing to ease congestion. Users of the Dartford-Thurrock River Crossing of the Thames on the M25 are required to pay a charge to manage congestion of the bridge and tunnels. Dart Charge is a new remote payment system which will reduce congestion and ease traffic flow at the crossing.",
    "body": "**Department / Agency:**  \nDFT / HA\n\n**Date of Reassessment:**  \n19/8/2014\n\n**Reassessment stage:**  \nAlpha re-review\n\n**Result of Reassessment:**  \nNot passed\n\n**Lead Assessor:**  \nS. Edwards\n\n**Service Manager:**  \nI. Lewis\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## Assessment Report\n\nAfter reassessment of the service the assessment panel have concluded that the Dart Charge service is not yet on track to meet the Digital by Default Service Standard at this stage of development.\n\n**Reasons**\n\nThe service development is not following an agile development cycle through alpha/beta/live stages but nevertheless the service was reassessed at the alpha stage. The project is being delivered for the Highways Agency by a supplier who have experience of several similar road charging schemes in many countries.\n\nUnfortunately the service does not currently meet the Service Standard requirements and will need to make significant changes to the project to be able to satisfy the service standard. The panel were disappointed that few of the recommendations from the previous assessment have been acted upon and would urge the service to review the previous report and recommendations again.\n\nThe assessment panel’s key concerns are that the service:\n\n- does not understand the user needs that the service should meet: which has led to a confusing online experience for users;\n- have undertaken limited user research on 22 participants, without any skilled user researcher being involved. The user research has validated only parts of the user journey in isolation. There is no detailed plan for further user research.\n- has no evidence that the service as a whole is simple and intuitive enough that users succeed first time, unaided. &nbsp;For example, instead of doing the hard work to make things easy for users, the service have front loaded the complexity of the charging scheme into the start of the user journey (account creation). The assessment panel were left confused by the 8 different user account options.\n- is not being delivered by a multidisciplinary team and the service manager is responsible for covering multiple roles including user research, content design and product management. In our previous report we recommended that “It is critical that the current Highways Agency staff are complemented by further staff who can bring the skills necessary to create a multidisciplinary team” but this has yet to be acted upon.\n- has shown some flexibility in changing and adapting their processes, but those processes appear to be ill-defined and may be unsuited to rapidly improving a service; and\n- the service team appear to have insufficient understanding of the Digital by Default assessment process and do not understand the significance of the Alpha and Beta reviews to their overall project milestones.\n\nEach of the 16 points of the service standard that the Dart Charge was re-assessed against is detailed below.\n\n**Point 1** - &nbsp;Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for digital and assisted digital service design.\n\nResult: Not passed.\n\nThe service do not appear to have any defined user needs or user stories and have an action/task based backlog rather than user needs and user story based backlog.\n\nSince the previous alpha review the service team have conducted guerrilla user research on 22 participants. This user research was conducted with passers-by in a shopping centre in the vicinity of the supplier’s call centre in Leeds. The user research tested small parts of the prototype user journey and did not appear to inform or shape the user needs for the service as a whole. The user research provided some insights into user interface design elements but nothing broader and so is insufficient evidence to pass service standard point 9 (see below). &nbsp;There appears to have been no user research with those living locally to the crossing, who appear to be one of the key user groups.\n\nThe assessment panel found the experience of using the service as a whole confusing and there was no evidence that users would not face the same difficulties.\n\n**Point 2** - Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.\n\nResult: Not passed.\n\nSince the first alpha assessment a service manager has been appointed from the existing Highways Agency team. The role does not appear to be empowered to make decisions about the whole service and it was unclear how much influence the service manager can have within the current processes (see point 6 below).\n\nOur comments from the first alpha review remain valid:\n\n“There was limited evidence of a multidisciplinary team either within the supplier or within the Highways Agency. In particular there was no evidence of a user researcher, a designer or user experience specialist, and no evidence of technical skills within the project team, or available from the Highways Agency. The Highways Agency staff we met showed impressive knowledge of their particular areas of specialism but this must be complemented by additional in-house members of the service team who bring additional skills. For example, the Highways Agency are currently relying on an external technical consultant to advise them and provide technical oversight. The technical oversight of a contractor should ideally be provided by Highways Agency staff and not an additional contractor.”\n\nFurthermore, the current project team is unsustainable as it will change in October when the project team hand over to a business as usual team.\n\n**Point 6** - Build the service using the agile, iterative and user-centred methods set out in the manual\n\nResult: Passed.\n\nThe service is being created within the framework of the contract between the Highways Agency and the supplier. The supplier does not appear to have any experience or capability in working in an agile, iterative and user centred method and stated that they follow a civil engineering/waterfall approach to delivery. Nevertheless, we recognise that the service supplier and Highways Agency have made changes to their processes and we would urge them to continue these improvements. We would also urge the team to consider using online collaborative tools in addition to email and telephone communication amongst the team.\n\n**Point 8** - Analyse the prototype service’s success, and translate user feedback into features and tasks for the next phase of development\n\nResult: Not passed.\n\nThere was insufficient evidence of user research informing the features and tasks for the next phase of development. The user research conducted so far has resulted in a number of simple actions to improve user interface elements. The lack of resources for this makes this unsustainable.\n\n**Point 9** - Create a service that is simple and intuitive enough that users succeed first time, unaided\n\nResult: Not passed.\n\nAfter the first alpha review the assessment panel recommended: “User research of the complete service, and not just the web based interface, would ensure that the whole service meets this requirement.”\n\nThe user research undertaken did not provide sufficient evidence that the majority of users were able to succeed at using the service first time. Instead of making things easy for users, the service has front loaded the complexity of the charging scheme into the user journey for creating an account or paying for a journey. There is no clear route for a user to understand which of the accounts is right for them, and each account has an entirely separate journey. &nbsp;For example, a personal account can’t be created if a user does not own a car (although they will not know this until they’ve entered all of their personal details), instead they must choose the Pay As You Go or the SMS PAYG journey. In addition if a payment method fails or a user is unable to pay at that time, an account is not created and the user loses the personal and vehicle data that they have entered into the service.\n\nThis problem is fundamental to the design of the service and can not be mitigated by expecting a user to read guidance content on GOV.UK. before using the service. Instead, the service must be designed to meet user needs with a simple and intuitive service.\n\n**Point 10** - Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it.\n\nResult: Not passed.\n\nThe service team had not researched the service’s assisted digital users’ needs so as to inform the design of appropriate support. There were no plans to test any assisted digital support, and funding for that support was not identified. The service manager could not speak about the service’s assisted digital users’ personas, needs or volumes.\n\nThe service team should carry out research to understand their service’s users assisted digital support needs, their numbers, and from where they are currently receiving assisted digital support (for example charities, friends, family). Research should confirm which channels of support are required to meet their needs (of which telephone support may be just one).\n\nThe service team should identify assisted digital user personas relevant to their service, and plot those personas’ end-to-end user journeys through the service. The service team should be able to explain how the needs and numbers of their assisted digital users will be met by the support they plan to put in place. The service team should consider how their assisted digital support would be user tested during the beta.\n\n**Point 14** - Make sure that you have the capacity and technical flexibility to update and improve the service on a very frequent basis\n\nResult: Passed.\n\nThe service are now making twice weekly deployments and the Service Manager gave some examples of where service changes had been made within 2 or 3 days. However, the Service Manager was a little unclear on the process for making changes and we would urge the team to consider how to clarify and streamline this process.\n\n**Point 15** - Make all new source code open and reuseable, and publish it under appropriate licences (or provide a convincing explanation as to why this cannot be done for specific subsets of the source code)\n\nResult: Not passed.\n\nOur view from the first alpha assessment was:\n\n“We were satisfied that the Highways Agency had given consideration to this requirement as part of the procurement process and had ensured that some IP would owned by the Highways Agency. However, the lack of technical oversight in the Highways Agency means that there is limited scope for the Highways Agency to exercise their rights, for the benefit of Government, to open up parts of the codebase for reuse. For example, the .NET frontend toolkit could be developed and released to the open source community.”\n\nThe assessment panel were disappointed that no progress has been made on this point and that this is dependent upon the priority given to this by the supplier.\n\n**Point 19** - Build a service that can be iterated on a frequent basis and make sure resources are in place to do so\n\nResult: Not passed.\n\nWe saw some examples of how the service had been iterated quickly, but due to the lack of a multidisciplinary team, in particular the absence of a dedicated user researcher, this is unsustainable.\n\n**Point 20** - Put a plan in place for ongoing user research and usability testing to continuously seek feedback from users.\n\nResult: Not passed.\n\nThe service team has undertaken limited guerilla user research without the input of a dedicated or skilled user researcher. There is no fixed plan for continuous user research in future and no plans to recruit a dedicated user researcher for the project. There is an offer from the DVLA to provide some user research resource but it is unclear when this will be available or how much user research this will provide. We would reiterate the recommendation we made in the first alpha review:\n\n“Any user research in the future needs to include a wide range of users such as EU drivers and HGV drivers. The service should not rely on industry groups and representative bodies to represent these user groups in lieu of user research by the service team with actual end users.”\n\n**Points 7, 21, 22, 23, 24** &nbsp;- Establishing KPIs and reporting to the performance platform.\n\nResult: Passed.\n\nThe service manager has met the GDS performance platform team, have established KPIs, and have made preliminary plans for reporting these to the Performance Platform.\n\n**Further recommendations**\n\nThe Highways Agency should review the Government Service Design Manual and consider the Dart Charge service in relation to each point raised above. In addition to the further recommendations made in the first alpha review, the service team should also consider the following points:\n\n1. Deployment requires manually configuring services and we would urge the development team to automate these configurations. The development team should also conduct load testing on the service and not rely on performance based on previous experience and projects.\n2. Further planning should be given to the disaster recovery plan and this should be completed before the service enters the beta phase. There is no provision for DDoS attacks, as we understand DDoS is not part of the contract. The service should consider whether it might be cost effective to put in place appropriate DDoS protection rather than rely on taking down the service.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | No | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | No |\n| 9 | No | 10 | No |\n| 11 | No | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | No | 20 | No |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/annual-tax-summaries-alpha/",
    "title": "Annual Tax Summaries - Alpha Assessment",
    "summary": "Once a user’s Self Assessment return for the previous tax year has been processed their tax summary will become available for access through the newly released Your Tax Account service. It will also be accessible by Agents on behalf of their clients.",
    "body": "The service will provide the user with a summary of the information that they submitted in their original Self Assessment tax return. This will include the following:\n\n- Income\n- Tax and National insurance\n- Tax free amounts and adjustments\n- Capital gains\n- A breakdown of Treasury spend\n\n**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n22/8/2014\n\n**Assessment stage:**  \nAlpha review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nS. Edwards\n\n**Service Manager:**  \nT. Britten\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment Report\n\nThe Tax Summaries service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded that the Tax Summaries service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe assessment panel were impressed by the answers the service team gave and they showed that they had considered all the points of the service standard and are making good progress towards addressing any outstanding issues during the beta. Our detailed reasons for the pass are given below along with a number of recommendations that the service must consider before their beta assessment.\n\nThe service is being delivered by an agile multidisciplinary team who have conducted user research on a range of users. The service is simple and intuitive enough for a user to succeed first time unaided.\n\nThere was a considerable degree of ministerial involvement in the design of the original prototypes and policy teams initially indicated that changes from these designs would not be accepted. The service team used the evidence they collected from user research to make iterative improvements to the service that were accepted by the policy team. It is of particular note that the Financial Secretary to the Treasury has not only used the alpha service but he has seen the results of user research and watched videos of users interacting with the service. The service team must be commended for their work to engage with such senior stakeholders in the iterative development of the product as a result of user research.\n\nThe service team have engaged with their colleagues who are developing other HMRC digital services, in particular Your Tax Account and Digital Self Assessment to ensure that their product is being built in a way that can be fully integrated into those services or accessible through an API, such as accessing the Treasury expenditure information as a microservice.\n\n**Recommendations**\n\nThe following recommendations should be acted upon and must be satisfied before the beta assessment.\n\n**_Service Standard point 1 - Re: User needs_**\n\nThe user needs for Tax Summaries originates from a commitment in the 2012 budget where the Chancellor promised to deliver a personalised summary of Income Tax, National Insurance and a view of associated expenditure by the Treasury.\n\nEven at this early stage of development the service have made progress to understand how those needs can be best met with a digital service. User research has shown that users are not actively seeking the information in the Tax Summary but once they see it they enjoy interacting with the information and are interested in how their taxes are spent. The service should:\n\n- continue user research to identify user needs within the scope of the ministerial initiative, and if necessary change the scope of the policy to ensure it meets user needs\n- iterate the product\n- feedback to the Chancellor and Financial Secretary to the Treasury on how those needs might be met\n\n**_Service standard point 2 - Re: Service Manager empowered to make decisions_**\n\nThe Service Manager is empowered to deliver the digital only product, which is available for Self Assessment users but not the rest of the service. PAYE users will receive a paper based Tax Summary from a service which is managed by a different team. The service manager is making strong progress to influence channel shift by producing a high quality digital product (so that the paper product can be switched off) but the Service Manager is not effectively empowered to make decisions about the whole service. The paper based Tax Summary was produced after limited user research and now looks quite different to the online Tax Summaries. HMRC should avoid producing parallel paper and digital services and instead produce a single service with digital, and if necessary, non-digital offerings.\n\n**_Service standard point 10 - Re:_**  **Assisted digital support**\n\nThe assessors welcomed the plan to procure assisted digital support from the central framework currently being pulled together by GDS in conjunction with CCS and exemplar departments. A central HMRC team is considering assisted digital needs and provision across a range of their services. Existing approaches to supporting users with enquiries are being considered for assisted digital support, and include assisted digital needs assessment.\n\nHowever, the service team needs to proactively seek out and undertake research into the specific assisted digital needs of end users of the service (ie not agents). They should plan to put in place and test tailored support for this service’s users, to ensure that appropriate assisted digital channels are made available that meet their needs and numbers.\n\n**_Service standard point 13 - Re: Content design_**\n\nThe team showed evidence of rapidly iterating the content design in the service based on user research. This work should continue to ensure that complex tax terms are properly explained and links to&nbsp;[GOV.UK](http://gov.uk/) content for further information are added, where user research demonstrates the need.\n\n**_Service standard point 15 - Re: Open source code_**\n\nThe service have not yet made their source code publicly available, although their code base has been carefully managed in a way that is ready for release. We are aware that there is full support at many levels in HMRC for source code to be made open but very little has so far been made public. The impediment appears to be that governance arrangements are not in place and we would urge the HMRC Digital Leader to ensure that the process is streamlined for a Service Manager to obtain the necessary consents from businesses within HMRC to release the source code.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/personalised-registrations-service-assessment/",
    "title": "Personalised Registrations - Service Assessment",
    "summary": "The Personalised Registration service will allow consumer and commercial customers to",
    "body": "- retain a personalised registration from a vehicle;\n- assign a personalised registration to a vehicle\n\nIt will be a real time service to ‘take off’ and ‘put on’ a personalised registration number, simplified to be done instantly online and negating the need to deliver a separate ‘transfer service’ which is currently delivered offline through a paper channel.\n\n[https://www.gov.uk/transformation/personalised-number-plates](https://www.gov.uk/transformation/personalised-number-plates)\n\n**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n30/7/2014\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. O’Neil\n\n**Service Manager:**  \nR. Gye\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## Assessment Report\n\nThe Personalised Registration service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Personalised Registration service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service meets all 26 of the Digital by Default Service Standard at alpha stage.\n\nThe Personalised Registration service team\n\n- explained clearly how they are carrying out user testing and user engagement with user insight being used to drive future iterations of the service. The team were able to set out how their userbase is segmented and how they are working with them to meet user needs and explore opportunities.\n- were able to clearly explain the structure of the team they have in place and how they are working to ensure alignment between the various parts of the team. They recognised the need to tackle gaps and have a programme in place to address this.\n- have a Senior Information Risk Owner (SIRO), an Information Asset Owner (IAO) and a committed Accreditor resource all in place, with a programme to ensure proper assurance processes are followed.\n- recognise and understand their obligations under the Data Protection Act and set out how they will comply.\n- were able to clearly articulate the technical architecture of the project and how they had arrived at the choices they had made around technology and hosting.\n- have a GitHub repository in place and own the Intellectual Property for their service.\n- are engaged with Identity Assurance team in GDS and are looking at how Identity Assurance may align with their future roadmap.\n- have a deployment environment which mirrors live and have a range of browser test options.\n- have a fallback paper channel in place in case of service failure and have monitoring in place to ensure that they know when the service experiences any issues.\n- have a rapid iteration process in place with hotfixes able to be deployed through continuous improvement and business changes in 20 minutes once approved.\n- have a team in place to manage and iterate the service.\n- are able to track user journeys, including dropouts, and have integrated this with the Performance Platform.\n- are working to tackle legislative barriers to becoming a fully digital service.\n- have a Designer in place and they are working with GDS colleagues to ensure alignment with the style guide.\n- are working with GDS on a range of user engagement and testing activities for Assisted Digital. They have identified service complexity and are working with the market to build on existing support channels. They are also considering a move to web based support.\n- have developed a channel shift plan which fits into wider change programmes.\n- have analytics in place to measure the four main KPIs along with browser types, user journey, payments uptime and page response time. And they have defined some initial baselines.\n- testing the service with the new Minister on 2nd September.\n\n**Recommendations**\n\nAs the Personalised Registration service team move from a service aimed at professional users to one which also covers domestic users they should ensure that their Assisted Digital plans are fully tested and iterated through Beta.\n\nWhilst this service quite rightly focuses on one discreet part of the overall user experience, the team should ensure that the need to tackle integration with legacy systems is not lost.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/family-and-friends-alpha/",
    "title": "Family and Friends - Alpha Assessment",
    "summary": "The ‘Family and Friends’ service will allow people to delegate authority to a friend or family member to act on their behalf for digital tax services.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of&nbsp;**** Assessment:**  \n18 July 2014\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nS. Edwards\n\n**Service Manager:**  \nS. Fhima\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment Report\n\nThe HMRC Family and Friends service (the “Service”) has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded that the Service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\nThe panel were impressed by the answers the service team gave, which demonstrated consideration of all points of the service standard. The panel felt that the team are on track to address any outstanding issues during the beta.\n\n**Reasons**\n\nThe Service is being built to meet the user needs around delegating access to HMRC services to a trusted friend or family member who will act as their representative. The Service is an enabling service that will provide functionality for a wide range of services being built on the HMRC tax platform, many of which will be accessible through the Tax Account in development for individuals. The Service is not aimed at users who may be representing a taxpayer in a professional capacity, those needs are expected to be met by the Agents Online Self Service exemplar.\n\nThe Service for online delegation of authorities will grow and will eventually replace eventually replace existing manual HMRC processes for delegation to non-professionals. It is important to highlight that the service team are not merely digitising the existing process but instead they are building a digital by default service to meet the user needs for delegated access to HMRC digital services.\n\nThe service team are a strong multidisciplinary team based in the HMRC Digital Delivery Centre and are led by a Service Manager who is empowered to make changes to the Service. The Service Manager also has a deep knowledge of the IDA programme and provides a vital link into that programme, which is a key dependency and is critical to the success of the Service.\n\nThe service team are supported by a strong governance model which appears to be ensuring that there is a good sharing of information with other HMRC services and also ensures that there is support from senior management to remove any blockers to delivery.\n\nThe service team have conducted user research across a wide range of potential users to help them to develop their user needs and learn from other existing services. User research has ensured that the service has changed rapidly during the alpha and the assessment team saw examples of how the Service has changed significantly as a result of user research.\n\n**Recommendations**\n\n- The team should continue their user research and should supplement their current approach with a high level mapping of the user landscape. This will help ensure that the service team have a clear view of the context in which the Service might be used, where this sits within the customer lifecycle, and to understand the relationships between users of the Service. This will require user research that is not focused on day to day testing but will ensure that the implications of design decisions can be fully tested with users.\n\n- The assessment panel understand that the minimum viable product &nbsp;for the Service is for the delegating user to grant access to all of their HMRC online services and not allow delegation of individual services. The service team must consider carefully, in the light of further user research, whether this is an appropriate minimum viable product for the beta or whether individual delegation should be included.\n\n- The Service requires the user who is delegating access to know the name, date of birth and national insurance number of the person they are delegating access to. The assessment panel accept that the service team must work within the limitations of matching users within the existing HMRC systems, however, the assessment panel would urge the service team to consider carefully whether matching can be achieved without sharing such personal details, in particular the national insurance number, and to test these approaches with a range of users.\n\n- The service team have already tested different names for the Service and the language around the process of delegating accessing to a friend or family member. This work needs to continue as there are already multiple terms in use to describe the users and the action of delegating access. The team should also bear in mind that this is an enabling service for other services, and the language used may need to vary based on the underlying service and the needs of those particular users. It may be that the Service does not need a separate brand from the HMRC service it is supporting as the user may see this as merely a function of the tax service they are accessing.\n\n- It is encouraging that the team are working closely with the assisted digital lead at HMRC and with the GDS assisted digital team, so that support for assisted digital users is being considered in the broader context of other HMRC services and cross government assisted digital provision. Before the beta assessment, the team must fully research assisted digital user needs and put in place and test proposed support through all relevant channels. User research must include assisted digital users who are unable to use or access the online service independently.\n\n- The service team must give early consideration to how they will open the source code for the Service to ensure that any small parts of code that should be kept closed are factored out of the source code from the outset. This will avoid refactoring work later in the project.\n\n- The Service has potential application and user research findings which would be helpful across Government services outside HMRC. The assessment panel would urge the service team to publicly blog about their work on the Service, in particular their user research findings, so that they can share their findings with colleagues across Government. The assessment panel recommend that the service team escalate any blockers to publishing blogs promptly through their internal governance process.\n\n- The service team will need to investigate ways to use their analytics package to measure conversion rates for the full process (i.e. from when the user starts completing the form to request a helper to when they finish accepting the request; or vice versa).\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/share-driving-record-service-assessment/",
    "title": "Share Driving Record - Service Assessment",
    "summary": "Share Driving Record is a new service that will provide access to driver data for Third Party users and will act as an enabler for &nbsp;DVLA to abolish the paper element of the driving licence. The aim of this service is to provide users who currently use the paper part of the driving licence with a new digital version that can be easily accessed. The service will display the information currently available on the paper counterpart and make it available to all those who have a right to see it.",
    "body": "**Department / Agency:**  \nDfT/DVLA\n\n**Date of Assessment:**  \n7 July 2014\n\n**Assessment Stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nA. Newton\n\n**Service Manager:**  \nR. Gye\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## Assessment Report\n\nThe Share Driving Record Service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded that the Share Driving Record Service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nIt was clear from the assessment that the team are using an agile approach to meeting the user needs for Share Driving Record through prototyping and regular user research. Since this service is being built on the IEP platform, on which the View Driving Record Service is soon to be live, the panel were satisfied that appropriate technology and security choices were being made, and the team have the ability to rapidly iterate the service. The team already have a lot of benchmarking data for a service at alpha stage and are talking to the performance platform about measuring this new service.\n\n**Recommendations**\n\nFor the service to succeed at Beta assessment, during the Alpha it will be vital that the team:\n\n- work to publish the service’s code openly as soon as possible\n- take action on GDS’s design recommendations made for both ‘View Driving Record’ and ‘Share Driving Record’ (to be provided as a separate document)\n- develop and test the feature which informs users that someone has looked at their driving record\n- ensure that appropriate levels of assisted digital support are in place for the beta, including:\n  - demonstrating if there is no assisted digital requirement with sound user research\n  - researching the needs of users (including businesses of all sizes and citizens) who cannot use the service independently, to give a full picture of who needs what kind of support\n  - Explicit and adequate assisted digital expertise must be either embedded within or available to the team.\n\ndo further work to discover whether offering an API would be valuable. It was suggested that an API was desired by customers, but there did not appear to have been much exploration of this. One of the [objectives of an alpha](https://www.gov.uk/service-manual/phases/alpha#the-objective-of-an-alpha) should be to validate user needs. An API feels like a new area ripe for discovering whether it is a viable solution for meeting those user needs.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/e-referrals-service-assessment/",
    "title": "e-Referrals - Service Assessment",
    "summary": "The NHS e-Referral Service will replace the current Choose and Book service, which has been in use by NHS in England for 10 years, with over 50 million patient referrals having been completed. The service is designed to support electronic referral in the NHS. The service will make the NHS more efficient, reduce waiting times, make it safer, more convenient, and more secure for patients. e-Referral is looking to support patients booking follow ups, of which there are 60m a year.",
    "body": "Currently there are about 40,000 individual patient referrals completed on Choose and Book each working day with around 45,000 available services published.\n\nUsers are GPs and their Practices, NHS Hospital Providers (consultants and their support teams), Independent Sector providers, NHS Mental Health and Community providers, NHS Commissioners and Allied Health Professionals. Patients can only use the service once a clinical decision to refer has been made.\n\nThe initial build will replicate the Choose and Book functionality to minimise the impact on the NHS and Independent Sector users. This change will enable many more users in future.\n\n**Department / Agency:**  \nHO / NHS England\n\n**Date of Assessment:**  \n2/7/2014\n\n**Assessment stage:**  \nAlpha\n\n**Result of Assessment:**  \nNot passed\n\n**Lead Assessor:**  \nJ. Hughes\n\n**Service Manager:**  \nB. Gildersleve\n\n**Digital Leader:**  \nW. Cavendish\n\n* * *\n\n## Assessment Report\n\nThe e Referrals service was assessed the full 26 points of the Digital by Default service standard criteria for a beta service.\n\nThe purpose of the assessment is to establish whether the service is on track to meet the criteria for a Live Digital by Default service.\n\n**Outcome of service assessment**\n\nThe overall result of the assessment is that the e-Referrals service is not on track to meet the required standards, and has not passed this assessment.\n\n**Reasons and Recommendations**\n\nA more detailed breakdown of the points where the assessment panel did not see sufficient evidence that the service is on track to meet the required standards follows, with recommendations for action to remedy these.\n\n**1. Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for digital and assisted digital service design.**\n\nThe service team has clearly carried out extensive stakeholder consultation to help inform important decisions about the service. This has given the team information about what some users and stakeholders want from the service, and has helped the team to cultivate support for the project in a context of highly complex stakeholder relationships and prevailing resistance to change.\n\nHowever in order to meet the required standard the team should now develop a plan to conduct qualitative and quantitative user research in order to understand more thoroughly the full range of users now and in the future, their needs from the service, and the extent to which the design and build of the service will meet those needs. This should include separate research with patients as distinct from ‘professional’ users, and with a wide range of users within each segment, including people who don’t take part in formal governance mechanisms or organised events. It should include investigating, from the point of view of defined and evidence-based user needs rather than stakeholder opinions, design issues about the choice between optimising for efficiency and optimising for accuracy and completeness in search results.\n\n**2. Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.**\n\nand\n\n**19. Build a service that can be iterated on a frequent basis and make sure resources are in place to do so.**\n\nThere are 2 people who make decisions together about the development of the service, in consultation with various governance groups. The product owner does not have the necessary capacity (being part-time) or authority to make decisions. The product owner is constrained by multiple governance and consultation layers and a lack of ability to change business processes within the service. For example, there are decisions being made about the design of the service on the basis of voting on options by stakeholders, rather than being made by the product owner on the basis of evidence about user needs drawn from user research. This constrains the team’s ability to iterate on a frequent basis.\n\nThe service should establish a single individual who is empowered to make decisions on a day-to-day basis. This should include the ability to make decisions about the relationships between the user interface and the business processes that support the service.\n\nThe service does not yet have a plan to support and maintain the service once it is live. The service should develop a plan for ongoing support once the service is operational.\n\n**9. Create a service that is simple and intuitive enough that users succeed first time, unaided**\n\nThe team is planning to achieve this by replicating an existing system and fixing defects and making minor improvements, so that further training for users will not be required. However the existing system requires training, and this has partly driven the pressure to replicate it rather than building something different and potentially more intuitive. This has the potential to result in a self-fulfilling requirement to continue the existing user interface.\n\nThe team showed some screenshots of alternative designs for the user interface that could be implemented at a later stage, but there are no plans in place to implement them and it was not clear from the information the panel were given how these alternative designs meet specific user needs derived from evidence from user research. The relationship between needs, features / functionality and interaction design was not clearly reflected in the team’s approach to the alternative designs.\n\nTo meet the requirement of this standard the team would need to either:\n\n- stop development of the current solution and revisit the discovery phase for the whole project, elucidate the user needs and develop a new service design and user interface, or\n\n- proceed with the release in November but develop a plan, with appropriate resources and authority, significantly to develop the service beyond its initial release in November.\n\nIn either case the next phase of work needs to be based on a thorough understanding of user needs (as distinct from ‘wants’ expressed in consultation and focus group type exercises), and an approach to designing and building the service in a way that ensures it is capable of developing and iterating to meet those needs. The team should develop a plan to make sure it has the capacity and authority to do this work.\n\n**10. Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it**\n\nThe service team did not demonstrate that they have a full understanding of assisted digital principles and did not provide any evidence of assisted digital user research. Although they were able to give volumes based on the current service and they plan to continue to provide support through an existing contact centre, there were no plans in place to test that support to ensure that it meets user needs and the assisted digital standard (as detailed in the Service Design Manual).\n\nThe service must develop a plan to test their assisted digital support, based on user research and user needs and in line with GDS guidance in the Service Design Manual. GDS will provide a point of contact in the assisted digital team to support this.\n\n**7 and 21-24 - Performance measurement**\n\nTo meet the required standard the service team would need to demonstrate a more fully developed plan to meet the requirements in these 5 points.\n\nThe team does not have a plan in place to measure the performance of the service, seeing this as something that can be put in place after the service goes live in November.\n\nThe team should bring forward its plan to recruit some data analytics expertise, so that it can establish performance benchmarks and ensure the right data is being collected and reported, and take-up of the service properly extrapolated.\n\n**16. Make all new source code open and reuseable, and publish it under appropriate licences (or provide a convincing explanation as to why this cannot be done for specific subsets of the source code)**\n\nThe service team should analyse what opportunities there are to publish some of the software created during the development of the service. This should be assessed on the potential value to the wider public, rather than just benefits to the service itself. The team should develop a plan to release at least some code having carried out this analysis.\n\n**Summary**\n\nThe service is being developed in a highly complex stakeholder environment. The service team has successfully introduced, through its use of external suppliers, some elements of agile working, and is working towards being able to expand this as it introduces an ability to release more frequently and cost-effectively. The team has achieved some positive outcomes so far in respect of stakeholder engagement, using open source platforms, getting away from vendor lock-in, and contributing to open standards.\n\nAs outlined under item 9, there are 2 strategic options available to the team to meet the service standard, given the stage the project is currently at. Our expectation is that the team will want to continue with its planned release in November, in which case the team will need to develop a fully resourced plan for further work beyond November. Beyond November, the team may need to carry out significant additional work to demonstrate compliance with the required standards.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | No | 8 | Yes |\n| 9 | No | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | No |\n| 17 | Yes | 18 | Yes |\n| 19 | No | 20 | Yes |\n| 21 | No | 22 | No |\n| 23 | No | 24 | No |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/passports-service-assessment/",
    "title": "Passports - Service Assessment",
    "summary": "The existing passport service within the UK allows you to complete an online application form to apply for, renew or update a passport. The user then prints a declaration form, signs and dates it and sends it for processing with any documents or photographs that are needed.",
    "body": "Her Majesty’s Passport Services is exploring with GDS the scope for a fully digital passport service and application interface.\n\n[https://www.gov.uk/transformation/passports](https://www.gov.uk/transformation/passports)\n\n**Department / Agency:**  \nHO / HMPO\n\n**Date of Assessment:**  \n26/06/2014\n\n**Moving to:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nS. Edwards\n\n**Service Manager:**  \nH. Berry\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## Assessment Report\n\nThe Passports Service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded that the Passports Service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe assessment panel were extremely impressed by the answers the service team gave to our questions and we are pleased to approve the Passports Service to pass through to beta. The team have considered all points of the service standard and where they have not already addressed an issue there are plans in place to resolve each issue during the beta.\n\nThe service team are delivering the service using agile user centred methods, and have undertaken extensive user research on a wide variety of users with regular sessions to test the alpha service. This research has heavily influenced the design of the service and this shows through in the quality of the alpha and the work the team have done on the innovative image processing functionality. The team showed a good understanding of the needs of many different users. The service has a multidisciplinary team and they are are empowered to make decisions about the digital service. The team demonstrated that they had undertaken some research with assisted digital users and understood the barriers which users might face with this specific service and they have proposals for how assisted digital support will be funded.\n\nThe service is an outstanding example of an alpha service and our recommendations below should help to ensure that the service is in an equally strong position at the beta review.\n\n**Recommendations**\n\nPoint 2 -&nbsp;Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.\n\n- The service manager is empowered to make decisions about the Passports Service but it is unclear whether they have any power to control the non-digital parts of the service. The service is provided across multiple channels and the service manager should be empowered to improve the whole user experience across all channels.\n- The team are heavily dependent on staff from GDS to build the service. It is vital that steps are taken early in beta development to build capability within the Passport Service by recruiting staff to replace GDS staff. This should happen as soon as possible so that those staff are fully involved and responsible for the beta development of the service. The risk of not doing this is that a live service is handed over to new staff who are then not fully informed and empowered to continue iterating the live service.\n- There are plans for the Passports Service to share a content designer with the Home Office. Sharing a key role like this further underlines that the role is limited to the digital service and not to the service as a whole. Such a limited role, shared with another department, will make it more difficult to ensure that the content designer is empowered and can ensure quality on the service.\n\nPoint 3 -&nbsp;Evaluate what user data and information the service will be providing or storing, and address the security level, legal responsibilities, and risks associated with the service (consulting with experts where appropriate).\n\n- The assessment team were satisfied by the work so far on this, but further detailed work on risks and vulnerabilities must be completed during the beta phase. Take special care when using e-mail to exchange information as it is not a secure channel.\n\nPoint 10 -&nbsp;Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it.\n\n- During the early stages of beta, the service must significantly increase the research they undertake with assisted digital users to plan and test appropriate assisted digital support. They must confirm user journeys, including Identity Assurance, and confirm the expected number of transactions by channel (supported by quantitative research), taking into account the specific barriers identified for this service. Plans for assisted digital support must be drawn up early in beta and include an element of digital inclusion and a mechanism to gather user insights to iterate both the assisted digital support and the digital service. A clear funding model will also need to be put in place in the next stage of development.\n\nPoint 12 -&nbsp;Integrate the service with any non-digital sections required for legal reasons.\n\n- The service team are doing some innovative and exciting work on user supplied digital images for the passport and on digital images provided by 3rd party photo services. While the innovations for this component are to be commended it includes risks to the project which should be carefully monitored and managed.\n\nPoint 14 -&nbsp;Make sure that you have the capacity and technical flexibility to update and improve the service on a very frequent basis.\n\n- As noted above, the service manager appears to be empowered to make decisions about the digital Passports Service but it is unclear whether they have any effective power to control the non-digital and backend parts of the service. Furthermore, the scope of the project is currently limited to development of the frontend only and the service must rely on the existing backend. There are currently some plans to reform the backend processing systems but under a separate project outside of the exemplar and any changes are limited to the scope of the existing contract and change control processes. With a separate workstream managing backend changes and no planned reform of the change control processes, the service manager may be limited in their ability to make the service digital by default.\n\nPoint 15 -&nbsp;Make all new source code open and reusable, and publish it under appropriate licences (or give a convincing explanation as to why this can’t be done for specific subsets of the source code)\n\n- The service team should ensure that the approach to source code is open by default, in line with broader government policy, and we expect to see the source code made available under a suitable open source license unless there is a compelling reason to keep it closed. We understand there are concerns about revealing any fraud checks within the code, but any sensitive code should be managed and kept private whilst all other code should, by default, be open source. We would particular urge the team to consider open source code for the photo integration and image processing.\n\nPoint 18 -&nbsp;Use analytics tools that collect performance data.\n\n- Further work is needed at the beginning of the beta stage, prior to increasing numbers of users on the beta, to ensure that the analytics capability for the service will provide the data needed to properly analyse the success of the service.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/cap-information-service-service-assessment/",
    "title": "CAP Information service - Service Assessment",
    "summary": "The Common Agricultural Policy (CAP) delivers EU support to rural areas, and aims to achieve environmental, social and economic benefits.The policy is updated roughly every 7 years, and is currently underway, with the new policy expected to be in place by 1 January 2015.",
    "body": "The CAP delivery programme has been set up by Defra to look at the best way to provide IT systems and processes that support delivery of the Pillar I schemes (for agricultural subsidies to support production) and Pillar II schemes (programmes to promote rural development) and replace the existing internet and paper based application processes, with a user focused digital system where customers will be able to apply and manage their applications online themselves or via an appointed intermediary.\n\nThe system will be a long-term, efficient solution which is capable of delivering not just one cycle of CAP policy.\n\n[https://capreform.blog.gov.uk/](https://capreform.blog.gov.uk/)\n\n[https://www.gov.uk/transformation/rural-support](https://www.gov.uk/transformation/rural-support)\n\n**Department / Agency:**  \nDEFRA / RPA\n\n**Date of Assessment:**  \n25/06/2014\n\n**Moving to:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. O’Neill\n\n**Service Manager:**  \nG. Portman\n\n**Digital Leader:**  \nJ. Pierce\n\n* * *\n\n## Assessment Report\n\nThe CAP information service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the CAP information service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe alpha service passes 24 of the 26 criteria at the level appropriate for an alpha service.\n\nThe service team set out how the alpha had been built around user feedback and how it reflected the ongoing feedback from user testing.\n\nThe current phase of work presented at the assessment is important to the wider programme and in particular how data quality would be a core dependency in the wider programme and to ensure auditable compliance with EU regulation.\n\nThe service team were able to set out their approach to delivery and how it works across teams.\n\nThe service team spoke fluently about assisted digital principles and demonstrated that they have used many methods to understand the barriers faced by their assisted digital users, including engaging directly with farmers, agents, charities and other government agencies. The service team has an appropriate plan to test assisted digital support in beta and has submitted a request for funding which is now with their Finance Board for agreement.\n\nThe assessment panel did have a number of recommendations for the next phase which should be addressed before the beta service standard assessment\n\n**Recommendations**\n\nBefore this service can move beyond beta there are a number of key points that must be addressed.\n\n**The team**\n\n- The programme needs to better articulate how the teams are structured, how responsibilities are set and what the cadence of delivery is.\n- The programme will need to be able to set out how the components of the service fit together, what the licensing models are for each component and how they propose to make the code available.\n\n**Security, privacy, tools and standards**\n\n- The programme needs to set out how the Identity Assurance (IDA) user journey will work given the ability for users to change personal identity data such as their National Insurance number.\n- The programme will need to provide a clear description of their development and operations (devops) model, in particular how incidents are managed, how issues are prioritised and how they maximise uptime.\n\n**Improving the service**\n\n- The programme will need to be able to give clear details of how rapidly the service can be iterated and how the service team will capture user feedback and tackle priority issues.\n\n**Design**\n\n- The programme must urgently address feedback given by GDS on the design and user interface to ensure it complies with the [GOV.UK](https://www.gov.uk/) design patterns and the service manual. A content designer should be working with the designers to make sure the service is easy to understand.\n- The service team should urgently check that the service works on a variety of phones and tablets. There should be a plan for regular browser testing.\n- The service team should start discussions with the [GOV.UK](https://www.gov.uk/) team about the start page required for the service, including the service name.\n- The service team should test with users the impact of the map on the user journey and adapt the service in line with feedback.\n\n**Accessibility**\n\n- The service team should carry out an accessibility audit, checking that the service works for users with a variety of different needs. There is more information on this in the service manual.\n\n**User research**\n\n- The service should give greater clarity on what the user is able to do, and what is required of users. For example, if the purpose of the service is to get users to check their data and to gather good quality information about user's land, there should be some way for users to feed back to Defra that they have checked the information and it is correct.\n\n**Analysis and benchmarking**\n\n- The service should have a performance analyst to continuously assess the service against key indicators, and develop recommendations based on evidence gained via web analytics and user feedback.\n- The programme needs to clearly set out how KPIs such as completion rate and cost per transaction will be captured.\n\n**More broadly assessors had concerns about the wider programme**\n\nThe service team is clearly pursuing an aggressive timescale to get appropriate assisted digital support in place. During the early stage of beta, the service team will need to pin down their assisted digital user journeys by different channels (including Identity Assurance) and demonstrate iteration of the digital service following assisted digital user feedback. Funding must be confirmed for assisted digital and the service team must demonstrate that the support is scalable to cope with high volumes in a tight timescale.\n\nThe reliance on a proprietary package for the core functionality of the wider system poses a number of challenges and it was unclear what the programme's fallback route would be if that package failed to meet their needs or if the supplier withdrew from the market. There are also clear questions to be answered around intellectual property (IP).\n\nThe delivery approach needs to be much better explained in terms of how user needs are addressed rather than in terms of story point velocity.\n\nThe actual scope of the full service needs to be much more clearly explained and related to user needs.\n\nFurther stage assessments will require clear evidence that the recommendations and concerns have been addressed.\n\n**Summary**\n\nThe CAP delivery team have put a huge amount of work into getting the service to this stage and this is reflected in the quality of the product and the clear commitment of the people the assessment panel met..\n\nThe recommendations set out a range of things which the service team will want to consider but this should not take away from the work which has been done so far and the ambition of the wider programme.\n\nThe strong commitment of the team to customer engagement makes this an opportunity to demonstrate the value that comes from putting the user at the heart of the service and the assessment panel look forward to seeing the next stage.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | No | 14 | No |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/civil-legal-advice-service-assessment/",
    "title": "Civil Legal Advice - Service Assessment",
    "summary": "Civil Legal Advice provides state-funded legal help with problems such as repossession, rented home disrepair, court orders to protect against abusive partners etc. This legal help is only available to citizens who pass a means test and whose problems fall within prescribed areas of law. The team are building a public facing application that allows users to log their cases easily. This information is then accessible via an operator interface to allow triage; another interface allows specialist caseworkers to check and take on their allocated cases.",
    "body": "**Department / Agency:**  \nMOJ\n\n**Date of Assessment:**  \n16/06/2014\n\n**Assessment Stage:**  \nAlpha Review\n\n**Result:**  \nPass\n\n**Lead Assessor:**  \nS. Edwards\n\n**Service Manager:**  \nT. Dolan\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## Assessment report\n\nThe Civil Legal Advice service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded that the Civil Legal Advice service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe Civil Legal Advice service provides state funded legal help to those citizens who pass a means test on areas of law within scope. The service we reviewed consisted of three main components: 1) a citizen facing web frontend for users to log their case; 2) an operator interface that allows logging of calls, reviewing digital cases, and the routing of cases to a legal specialist; and 3) an interface for legal specialists to review and accept a case.\n\nThe assessment panel were very impressed by the answers the service team gave to their questions and were happy to approve the Civil Legal Advice service to pass through to beta. The service team have considered all points of the service standard and where they have not already addressed an issue they have plans in place to resolve this during the beta. Particular issues we would like to commend service team on are as follows.\n\nThey have undertaken extensive user research on a wide variety of users in different locations. This research had begun before they had recruited a user researcher and is now continuing with a user researcher organising regular sessions to test existing features in the Alpha product, but also new ideas using paper prototypes. The user researcher has created a portable lab so that user research can be conducted with users in live situations, such as in CABs. All members of the team, except webops, have attended user research sessions. The team showed a deep understanding of the needs of the different user groups (citizens, operators, and legal specialists) and they had already identified and delivered features that had delighted those user groups.\n\nThe team are delivering the service using agile user centred methods. The team have a hard deadline to deliver a working system by November 2014 to coincide with the end of an existing contract and have taken steps to mitigate against a big bang release.\n\nThe team is a multidisciplinary one and the service manager is empowered to make decisions about the service. The assessment panel were also impressed that the Legal Aid Agency Contract Manager attended the service assessment and demonstrated the importance of the close interaction between the service standard and those parts of the service (call operators) that will be outsourced. It was evident that the support from the Legal Aid Agency contract team ensured that a team with suitable skills was recruited and were supported by them to deliver the project in an agile user centred way. The Legal Aid Agency should be commended for their approach to delivering the service.\n\nThe assessment panel were also very impressed with how much progress the team had already made in building a continuous integration environment that includes strong testing facilities such as unit tests, integration tests and tools for browser testing. They also recognise the work the team have completed in performing security testing on their software with tools like Zap to ensure that the software has security built in from the beginning.\n\n**Recommendations**\n\n**Point 1: User needs**\n\nOverall the service is serving user needs well. There is a possibility for confusion in the core aspect of _checking you are eligible_ vs _applying._ Currently a user starts by checking eligibility, the transaction shifts in the final stage to an actual application. The shift from checking eligibility to applying should be well marked.\n\n**Point 10: Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it**\n\nIt was good to see that assisted digital users had been considered to some extent at Alpha. Continued work will be needed around this group; assuming CLA’s assisted digital users will stick to current offline channels could limit a sustained channel shift.\n\nLooking forward, we would expect the Service Manager to be able to speak about the service’s assisted digital users’ personas, needs and volumes. The service would then need to evidence how those needs and volumes will be met by the assisted digital support put in place.\n\nAssisted digital user testing should confirm which channels of support are required to meet their needs (of which a telephone line will likely be just one). Existing telephone call centre service provision does not necessarily equate to quality or value for money assisted digital support. This must be evidenced by quality user research. Other channels also need to be considered for assisted digital provision as per user needs, be that face by face assisted digital support (home visits or high street locations) or web chat.\n\nAssisted digital support should also help build users’ digital skills and confidence, where possible, to help them towards being able to self-serve.\n\n**Point 13: Build a service consistent with the user experience of the rest of** [**GOV.UK**](http://gov.uk/) **by using the design patterns and style guide.**\n\nThe visual look and transaction flow was well considered. Our main recommendations are around certain terms used.\n\nAt this early stage there is potential for confusion between _civil legal advice_ and _legal aid_, both in civil and criminal cases. As the service develops towards Beta, careful consideration should be given to how this service will be found on [GOV.UK](http://gov.uk/) and how it might be differentiated from or integrated with similar services. In any case this should be validated with user research.\n\nThe assessment panel suggest you consider changing the text inside the ‘More info’ link. Currently this serves to explain policy and instead it should help the user answer the immediate question. The team should also consider making improvements to the heading ’Your problem’ to better describe the need you are meeting.\n\n**Point 25: Make a plan for the service going offline.**\n\nThe service team’s plan for disaster recovery needs further development early in the beta phase. In particular, the service should not rely on their hosting provider to mitigate against outages, and the tight binding of the citizen facing interface and case worker/provider facing interface could cause availability conflicts. The assessment panel would like to see a better plan for various forms of disaster and clear evidence that availability of the citizen facing system has minimal effect on the availability of the staff facing systems.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/dart-charge-service-assessment/",
    "title": "Dart Charge - Service Assessment",
    "summary": "Dart Charge is the ‘free-flow’ charging scheme, government is committed as part of a strategic objective to manage congestion in the short, medium and longer term. It is a road scheme for a new operating model at the Dartford Crossing to ease congestion.",
    "body": "Users of the Dartford-Thurrock River Crossing of the Thames on the M25 are required to pay a charge to manage congestion of the bridge and tunnels. Dart Charge is a new remote payment system being introduced from October 2014 to reduce congestion and ease traffic flow at the crossing. Instead of stopping at barriers to pay to cross (as happens now), drivers will pay online, by phone, text, or at one of numerous retail outlets.\n\nThe service will be for all users of the Dartford-Thurrock River Crossing including a broad range of vehicle users from private individuals to large corporate and government accounts, from local residents who use the crossing regularly to individuals.\n\nThe service will provide users with information to understand what they must do to comply with the charging regime and the consequences if they do not. It will help users to pay the charge in a number of different ways to best suit their individual needs.\n\n**Department / Agency:**  \nDfT / HA\n\n**Date of Assessment:**  \n11/06/2014\n\n**Assessment Stage:**  \nAlpha review\n\n**Result of Assessment:**  \nNot passed\n\n**Lead Assessor:**  \nS. Edwards\n\n**Service Manager:**  \nL. Forsyth\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## Assessment report\n\nAfter consideration the assessment panel have concluded the Dart Charge service is not yet on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service was was assessed at the alpha stage, although the service development is not generally following an agile development through alpha/beta/live stages.\n\nThe project is being delivered for the Highways Agency by a supplier who have experience of several similar schemes around the world. The representatives from the Highways Agency gave detailed and considered answers in the assessment and demonstrated considerable knowledge and experience that is of enormous value to the project. The assessment panel are also conscious of the framework within which the Highways Agency must operate and procure this project and we must commend them on their work within these limitations. However, the service does not currently meet the Service Standard requirements and will need to make some changes to the project to be able to satisfy the service standard.\n\nThe assessment panels key concerns are that the service:\n\n- does not meet all validated user needs\n- is not being delivered by a multidisciplinary team, and there is no service manager responsible for the service within the Highways Agency\n- is not using any agile or iterative processes and can not be rapidly improved\n- has had no user research to inform the development\n\nThe Dart Charge service does not meet the Digital by Default service standard on the following criteria points:\n\n- Point 1 - Focus groups were consulted before development started but these focus on testing of the brand rather than the actual product. There was no evidence of any user research in the last 5 months and no users have tried out the alpha service in the test environment. There was no evidence of any research to understand any user needs behind the project. There was no evidence that assisted digital service design had been sufficiently considered.\n- Point 2 - The Highways Agency team the panel met showed impressive knowledge of their particular areas of specialism but this must be complemented by additional in-house members of the service team who bring additional skills. For example, the Highways Agency are currently relying on an external technical consultant to advise them and provide technical oversight. The technical oversight of a contractor should ideally be provided by Highways Agency team and not an additional contractor. Currently there is no service manager currently in place. A service manager is due to join the service but the role does not appear to be empowered to make any decisions about the service and appears to be largely a contract manager role. There was no evidence of a multidisciplinary team either within the supplier or within the Highways Agency. In particular there was no evidence of a user researcher, a designer or user experience specialist, and no evidence of technical skills within the project team, or available from the Highways Agency.\n- Point 6 - The service is being created subject to the requirements of the contractual arrangement between the Highways Agency and the supplier. The supplier does not appear to have any experience or capability in working in agile, iterative and user centred methods. The assessment panel recognise that the supplier has been making changes to their processes to aid remote working and collaboration but this is currently insufficient to meet this point of the service standard.\n- Point 7 - The assessment panel understand that some performance benchmarks are included in the contract with the supplier, although these have not been discussed with the performance platform team at GDS and details were not available at the assessment.\n- Point 8 - There was no evidence of user research informing the features and tasks for the next phase of development. The supplier appears to be reusing, from previous road projects in other countries, a set of user personas and a predefined tree of transaction paths through the system. There was no evidence that these have been analysed with user feedback in order to validate or amend these and inform further development.\n- Point 9 - The assessment panel saw no evidence to prove that the majority of users were able to succeed using the service first time. User research of the complete service, and not just the web based interface, would ensure that the whole service meets this requirement.\n- Point 10 - There was no evidence that research to identify users who will require assisted digital support with the digital service had taken place and estimated assisted digital transaction volumes and costs were not known. Assisted digital user personas (and their user journeys) had not been identified, meaning that there was a lack of knowledge around those users’ needs and barriers to access. There were no plans to test the service’s assisted digital support, and funding for that support was not identified.\n- Point 14 - The assessment panel saw no evidence that the service could be updated and improved on a very frequent basis. The service will be updated on a monthly release schedule and there are no automated deployments. It was also unclear what authority the service manager may have, if any, to make changes to the service.\n- Point 15 - The assessment panel were satisfied that the Highways Agency had given consideration to this requirement as part of the procurement process and had ensured that some IP would owned by the Highways Agency. However, the lack of technical oversight in the Highways Agency means that there is limited scope for the Highways Agency to exercise their rights, for the benefit of Government, to open up parts of the codebase for reuse. For example, the .NET frontend toolkit could be developed and released to the open source community.\n- Point 19 - The assessment panel saw no sign that the service could be iterated on a frequent basis, due to the lack of a multidisciplinary team, no user research to inform the product backlog, no service manager empowered to make changes, and monthly release schedules making changes difficult.\n- Point 20 - User research had been limited to focus groups before the project development started. The service team intend to conduct a phase of user research in the summer rather than continuous user research throughout the life of the service. No user research has taken place in the last 6 months and no users have tried out the alpha service in the test environment. Any user research in the future needs to include a wide range of users such as EU drivers and HGV drivers. The service should not rely on industry groups and representative bodies to represent these user groups in lieu of user research by the service team with actual end users.\n- Points 21, 22, 23, 24 - No work has commenced on this although the assessment panel understand that there are KPIs in the contract with the supplier and that the Highways Agency intend to discuss these with the performance platform.\n\n**Further Recommendations**\n\nThe Highways Agency should review the Government Service Design Manual and consider the Dart Charge service in relation to each point raised above. In addition to this, the service team should consider the following recommendations:\n\n- build the service consistent with the user experience of the rest of GOV.UK by using the design patterns from the Service Standard and the GOV.UK style guide. The service should ensure that there is content design input from Highways Agency content designers to ensure GOV.UK style guide is met\n- The Highways Agency should ensure that they are granted access to any performance monitoring services used, and not rely on performance reporting from the supplier. For example, the Highways Agency should have access to the analytics for the online service.\n- The Highways Agency should consider what open standards might be used or created for this and future projects. Existing standards are not necessarily the most suitable standards to use and creating new open standards may be better for future road charging projects.\n- The absence of a technical specialist in the team that attended the assessment made it difficult to discuss some technical aspects in detail. The Highways Agency should ensure that the service is independently reviewed by a technical specialist. The assessment panel were particularly concerned with the responses to questions regarding planning for managing denial of service attacks.\n- Appropriate assisted digital support should be provided for Dart Charge users who need it, to ensure they are not excluded from the digital service. 21% of the UK adult population lacks ‘Basic Online Skills’ (Source: BBC Digital Capabilities Update, September 2013), although the exact number of Dart Charge users requiring assisted digital support may be very different. Assuming these users will be happy with offline channels is not sufficient.\n- the assessment panel would expect the Service Manager to be able to speak about the service’s assisted digital users’ personas, needs and volumes. The service would then need to evidence how those needs and volumes will be met by the assisted digital support put in place. Assisted digital user testing should confirm which channels of support are required to meet their needs (of which a telephone line will likely be just one).\n- The assessment panel also recommend contacting the Digital and Technology Lead for DfT who may have further advice on providing assisted digital support.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | No |\n| 7 | No | 8 | No |\n| 9 | No | 10 | No |\n| 11 | No | 12 | Yes |\n| 13 | Yes | 14 | No |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | No | 20 | No |\n| 21 | No | 22 | No |\n| 23 | No | 24 | No |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/digital-marketplace-service-assessment/",
    "title": "Digital Marketplace - Service Assessment",
    "summary": "The Digital Marketplace will provide a new single place for the public sector to access and buy from the G-Cloud and Digital Services frameworks.",
    "body": "**Department / Agency:**  \nCO / GDS\n\n**Date of Assessment:**  \n15/5/2014\n\n**Assessment Stage:**  \nAlpha Review\n\n**Result:**  \nPass\n\n**Lead Assessor:**  \nJ. Thornett\n\n**Service Manager:**  \nI. Majic\n\n**Digital Leader:**  \nP. Maltby\n\n* * *\n\n## **Assessment report**\n\nThe Digital Marketplace has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n### **Outcome of service assessment**\n\nAfter consideration we have concluded the Digital Marketplace service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n### **Reasons**\n\nThe Digital Marketplace team have shown that they are:\n\n- focussed on meeting the needs of the users and have a really good understanding of the range of research activity that is needed to maintain this focus throughout service development\n- a multi-disciplinary team working in an iterative, agile way to achieve their goals\n- already considering the impact of data privacy and security implications of the future service\n- building a service with the look and feel of GOV.UK and are looking to re-use existing design patterns and code libraries where possible\n- thinking about a future vision of the service which would enable increased channel shift so that more activity around the buying and selling of cloud services could be undertaken through digital platforms\n\nWe were particularly pleased about the user-centred nature of the development so far and the clear understanding of how the service needs to improve in an iterative way, based on further user research and testing.\n\n### **Recommendations**\n\nAs the service moves into the next phase of development we recommend that:\n\n- the GOV.UK content style guide is used and the content designer works closely with the central content team to ensure all content on the service is consistently written to the highest standards\n- the team review the analytics tools being used on the new service to ensure the configuration is suitable and there is a mechanism in place for collecting and analysing the necessary data through the public alpha phase\n- more analytics data is gathered from the old (currently live) service to better understand existing usage patterns such as distribution of pageviews over time, usage on different devices, and other indications of user need\n- discussions continue with the Performance Platform team to agree suitable benchmarks on existing services and the most useful metrics to measure and publish to assess ongoing performance of the new service\n- the plan to make source code openly available for re-use is kept on the backlog and factored into the next phase of development"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/apprenticeship-applications-service-assessment/",
    "title": "Apprenticeship Applications – Service Assessment",
    "summary": "The exemplar’s vision is to create an easy to use digital service where apprenticeships can be advertised and applied for, with the transaction supported by clear information to inspire and advise users, so that they can self-service, leading to minimal additional support being required.  \n[https://www.gov.uk/transformation/apprenticeships](https://www.gov.uk/transformation/apprenticeships)",
    "body": "**Department / Agency:**  \nBIS / SFA\n\n**Date of Assessment:**  \n17/04/2014\n\n**Assessment Stage:**  \nAlpha review\n\n**Result of Assessment:**  \nPassed\n\n**Lead Assessor:**  \nR. Reynolds\n\n**Service Manager:**  \nV. Chiesa\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## Assessment report\n\nThe Apprenticeships service has been reviewed against the 26 points of the Service Standard at the end of its alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration GDS has concluded that the Apprenticeships service is on track to meet the Digital by Default Service Standard at this early stage of its development.\n\n**Reasons**\n\n- Good evidence of iterating based on user research, including weekly testing sessions and development and validation of personas.\n- The service is challenging of the wider organisation by bringing in agile practices against a backdrop of uncertainty.\n- Strong continuous delivery and the ability to deploy very quickly (for example the &nbsp;demonstration to stakeholders of fast speed of turnaround at a show and tell).\n- Design clarity, and sensible re-use of interaction patterns established in other services.\n\n**Recommendations**\n\n- The user journey for employers will need to be thoroughly tested, including with employers who are not already experienced with Apprenticeships, to ensure employers are able to use it unaided. You should include explanatory text where necessary.\n- Continuous delivery using cloud is going well. It will be important to ensure that good practice is continued through the beta, while exploring any options and avoiding vendor lock-in.\n- Ensure that a content designer is embedded with the team during the beta, as planned.\n- Agree a plan for more thorough accessibility testing for the beta.\n- Some design refinements will be needed, including beta branding (the GDS design pattern library should be useful here). Before launching a public beta, your integration with[&nbsp;GOV.UK](http://gov.uk/)&nbsp;(start and done pages) will need to be considered and agreed with the[&nbsp;GOV.UK](http://gov.uk/)&nbsp;team.\n- Your planned conversations with the performance platform team will prove useful, especially for clarifying how completion can be measured. You will also need to decide how and where user satisfaction will be captured for a public beta.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | N/A |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | N/A | 26 | N/A |\n\n| **Details of criteria that are not applicable to this service** |\n| 18 - assessment panel considered it non-essential to add an analytics package at this stage  \n25 - will need to be explored in the Beta  \n26 - there is a plan to showcase the service before a Beta launch |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/payrolling-benefits-in-kind-beta/",
    "title": "Payrolling Benefits In Kind - Beta Assessment",
    "summary": "The Payrolling Benefits In Kind service allows employers to report to HM Revenue & Customs details of employees' benefits, expenses and tax deducted on these items through payroll.",
    "body": "**Department / Agency:**  \n[HM Revenue & Customs (HMRC)](https://www.gov.uk/government/organisations/hm-revenue-customs)\n\n**Date of Assessment:**  \n17 September 2015\n\n**Assessment Stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nT. Scott\n\n**Service Manager:**  \nA. Davies\n\n**Digital Leader:**  \n[M. Dearnley](https://www.gov.uk/government/people/mark-dearnley)\n\n* * *\n\n## Assessment Report\n\n### Summary\n\nThe Payrolling Benefits In Kind service has shown sufficient progress and evidence of meeting the [Digital Service Standard](https://www.gov.uk/service-manual/digital-by-default) criteria and should proceed to launch as a Beta service on the tax.service.gov.uk domain.\n\n### Detail\n\n#### User Needs\n\nThe core user need to allow payroll managers to quickly register their organisation is at the centre of the team’s work.\n\nThe approach to user testing has changed as the team have adjusted the length of their sprints; testing is in every sprint now. There has been a mix of lab and on-site testing and there is usability testing for each iteration. The focus in user testing has been tasked-based with payroll staff for medium and large organisations (those with more than 100 employees). Offline research was completed with smaller organisations and there was a high level of digital confidence and access from those groups.\n\nFeedback from users highlights the ease of use and ability to update an entire organisation with such a short service and that exemptions can be made easily.\n\nThere are two ways for users to access the service, through GOV.UK directly and from Your Tax Account. There is no research into how this service fits with the Your Tax Account or other services payroll staff use.\n\nThe panel was pleased that usability feedback has helped to improve the design of the service, including putting the most common items at the top of lists of benefits and ensuring exemptions are simple and secure to complete. The public beta will allow the team to look at usage with analytics on a larger scale and adjust designs where groups of users are falling out of the service.\n\nThe team will continue to research potential needs for assisted digital support for the service.\n\n#### The Team\n\nThe team structure is a good mixture of governance and delivery. Most roles are exclusive to the Payrolling Benefits In Kind service but some are shared with a small number of other services. Where roles were missing in the past, for example a user experience designer, they are now part of the service and contributing to its success. Despite the changes across the team, not least the service manager, the team have remained focused on the service and filling the gaps in support.\n\nThe most recent addition to the team has been a performance analyst who is helping to set up user journeys and funnels so that real world usage can feed back into the development of the service in the public beta. As with other HMRC services, WebOps time is shared, which can limit deployment of changes as the team do not have end to end control. However, in a system as complicated as this it is not unusual to have many dependencies and the team understand them and work towards the deployment window each sprint.\n\nThe panel was encouraged to hear that user research is at the centre of development, with the whole team taking time to observe feedback. This has lead to improved designs and a better shared understanding of the needs. Knowledge is shared through a wiki. The team initially wrote bigger stories for the three week sprints but found that velocity of delivery increased by writing more granular stories over a two week sprint period.\n\n#### Technology\n\nThe service team aim to release every sprint. The process is complicated by the infrastructure of the tax platform, meaning that getting code into production can take 48 hours in the normal process, although bug fixes can be completed faster. The team have access to monitoring and logs of the service to improve code and track bugs. There is a reliance on the central WebOps team for out of hours response, however the user research has shown the service will be used mainly during normal business hours. The DSM is the first to be called should the service go down and decides on any response.\n\nFront end designs are sketched quickly and a local development prototype can be created for user research and testing. The service takes advantage of the shared features of the tax platform, using Government Gateway for authentication of users. The front end of the service is quite simple with a RESTful interface, there is no requirement for extended interaction functionality.\n\nThe service has been through security and risk assessments and the Senior Information Risk Officer is satisfied the service is safe.\n\nBusinesses must register before the start of the financial year to payroll for the following year. Any downtime right at the end of the financial year could prevent businesses from registering in time for the new financial year. Although this is an unlikely scenario, a plan is in place to allow businesses a short window at the very start of the new financial year to register for the service.\n\nThe service intend to share the non-configuration code running one aspect of the service on GitHub soon, being one of the first teams to do this at HMRC. The code will be useful to teams in HMRC and also other government services. The team are using tools to check multiple browser compatibility and have access to a library of devices to check how the service works in the real world.\n\n#### Design and Take-up\n\nThe service design is consistent with the look and feel of GOV.UK. Using a national insurance number with the ‘exceptions search’ functionality requires details to match exactly. For other data, fuzzy matching functionality has been implemented to help users. Content terms such as ‘works number’ have been tested with users.\n\nThe team plan to use analytics to monitor usability and completion. The team have a plan for advising the largest businesses using this service but also to promote adoption of the service with a wider business community.\n\nThe team are carrying out accessibility testing and use software to check accessibility as the service is developed.\n\nThe service is only available digitally and support is embedded in the service, which will be tested in public beta. Users of the online iForms P11D service are being directed to this service and the team has a budget and plan for comms which will support their digital take-up.\n\n‘Payrolling Benefits in Kind’ isn't consistent with language on GOV.UK but the team’s research has revealed that 'payrolling' is an industry term that resonates strongly with payroll/finance managers. An alternative title might be ‘Register to pay employee benefits through your payroll’. Though longer, it’s more consistent, active, and descriptive of the service itself. Users aren’t doing any payrolling with the service - they’re registering their payrolling ‘preferences’ with HMRC.\n\nThe team will need to continue to work with GDS to ensure the start page is concise and relevant to what the service can do. The language used in the service should be consistent with GOV.UK. Detailed guidance says employers can ‘pay expenses and benefits through your payroll’ rather than ‘payroll expenses and benefits’. Using ‘payroll’ as a verb is confusing.\n\n#### Analytics and Performance\n\nThe service has analytics embedded throughout, monitoring and measuring users. There are two journeys into the service, directly from GOV.UK or from the Your Tax Account portal. Analytics will be prioritised for feedback once the service moves into public beta.\n\nSome effort has been made to set up the four KPIs for this service. More work is happening on the cost per transaction and digital take-up measures, because of the nature of the service the cost for completion could be as little as £0.10 for the employer but this could represent any number of employees, reducing the cost per transaction as a comparison considerably. The service will be using the GOV.UK done page which will measure user satisfaction.\n\nWork has started to publish data on the Performance platform.\n\n### Recommendations\n\nDuring the public beta phase the service team should:\n\n- Continue testing the service with users, focusing attention on SMEs and micro-companies. Although they are likely to represent the smallest volume of annual returns they will likely represent the broadest scale of capability and understanding, success with this group will translate to success with all users.\n- Ensure they are testing and researching in the context of tax, payroll and PAYE, and Your Tax Account. This service doesn’t exist in isolation yet there is little evidence of research into how the service fits within the wider context.\n- Establish whether there is a need for assisted digital support and, if required, develop and test the provision during the public beta.\n- Check there is consistent use of language between GOV.UK and the service such as ‘works number’.\n- Continue to work with third-party software developers to enable the ‘preferences’ to be set in payroll software.\n- Complete accessibility testing.\n- Develop the plan for phasing out alternative channels.\n- Set better measures for success.\n- Review the release process, in particular the 48h turnaround and dependency on resources external to the team - at live assessment you will need to demonstrate that this has not impeded your ability to iterate at pace.\n\n* * *\n\n## Digital by Default Service Standard Criteria\n\n| Criteria | Result | Criteria | Result |\n| --- | --- | --- | --- |\n| 1 | Pass | 2 | Pass |\n| 3 | Pass | 4 | Pass |\n| 5 | Pass | 6 | Pass |\n| 7 | Pass | 8 | Pass |\n| 9 | Pass | 10 | Pass |\n| 11 | Pass | 12 | Pass |\n| 13 | Pass | 14 | Pass |\n| 15 | Pass | 16 | Pass |\n| 17 | Pass | 18 | Pass |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/check-your-state-pension-beta/",
    "title": "Check Your State Pension - Beta Assessment",
    "summary": "The Check Your State Pension service allows users to obtain an estimate of their state pension and review their National Insurance contribution records.",
    "body": "**Department / Agency:**  \n[HM Revenue & Customs (HMRC)](https://www.gov.uk/government/organisations/hm-revenue-customs)  \n[Department for Work and Pensions (DWP)](https://www.gov.uk/government/organisations/department-for-work-pensions)\n\n**Date of Assessment:**  \n16 December&nbsp;2015\n\n**Assessment Stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. Knight\n\n**Service Manager:**  \nT. Chatterjee (HMRC)  \nJ. Bramfitt-Wanless (DWP)\n\n**Digital Leader:**  \n[M. Dearnley](https://www.gov.uk/government/people/mark-dearnley) (HMRC)  \n[Kevin Cunnington](https://www.gov.uk/government/people/kevin-cunnington) (DWP)\n\n* * *\n\n## Assessment Report\n\n### Summary\n\nThe assessment panel has concluded the Check Your State Pension service has shown sufficient progress and evidence of meeting the Digital Service Standard criteria and should proceed to launch as a public Beta service on a service.gov.uk domain.\n\n### Detail\n\nThe panel were impressed by the work of the Check Your State Pension team. In particular, we were impressed by the breadth and frequency of the user research undertaken and the way in which a multi-disciplinary team had managed to work well across departmental and internal boundaries.\n\nThe team’s research into support has been comprehensive, covering staff and users of their contact centre, relevant charities, IT clubs and paired testing. Research with users with the lowest digital skills indicates a need for face to face support and the team will be testing this through a pilot with Citizens Advice Bureau in beta. Findings have also been used to improve the onscreen service.\n\n### Recommendations\n\n#### Payment\n\nAt the assessment, the team mentioned that there are future plans to include payment functionality in the Check My State Pension service. As this would be a major change to the functionality of this service we would like the team to return for an assessment before launching this functionality. We also recommend that the team engage with the GOV.UK Pay team in advance of work on the payment option.\n\n#### Identity Verification\n\nAs demoed, the service uses GOV.UK Verify to identify users. The service team discussed with the panel that HMRC’s Identity Verification or Gateway Uplift may also be used during the beta as alternatives.\n\nThe panel noted this may reduce a slightly burdensome user journey (especially for users only wanting summary information), but as the service has previously connected to Verify at [LOA2](https://www.gov.uk/guidance/govuk-verify-checks-identity-providers-must-perform), the service team must ensure HMRC’s SIRO and Data Guardians are happy with the reduced level of assurance these alternative identity mechanisms may provide.\n\nThe team may be able to split access to make common uses more straightforward. &nbsp;For example, there may be some information that is less sensitive (such as the summary screen) and some information that is more sensitive (such as the full National Insurance record). The team is already engaged with the Verify team at GDS who can advise on completion rates and assurance levels.\n\n#### Integration with Personal Tax Account\n\nHMRC plans that the service will integrate with the Personal Tax Account (PTA) during the beta. The panel suggests care be taken around how the links to Check My State Pension are integrated with PTA, particularly given the need to shutter the service overnight.\n\n#### User Research\n\nQuestions about comprehension and action should be more important than questions about satisfaction or recommendation. Make comprehension and action your primary metrics, with satisfaction and recommendation as secondary metrics.\n\nDo this by:\n\n- asking your users what action they would take and compare that with what you think would be optimal, or\n- testing your users’ comprehension of the information with questions that ask users to explain back to you what they understand in the information that they are reading. For example:\n  - when will you first get a payment of your state pension?\n  - if you decide to stop work when you are 60, what will you get?\n\nInclude third parties such as financial intermediaries and accountants in your user research. Do not assume that professional bodies who represent financial intermediaries or accountants are themselves representative users. The opinions of professional bodies are useful and worth seeking but they are not a substitute for actual observational research with specific people who are providing financial advice.\n\n#### Design and Content\n\n- Go further to make the language even simpler. For example:\n  - Your state pension will be £140 per week.\n  - Continue paying National Insurance to get the maximum available, or\n  - You won't get the maximum because you've missed some National Insurance payments. You can [make extra National Insurance payments](link) to catch up.\n- Take the user through the service step-by-step – reduce the amount of information shown on each page.\n- Don’t use tabs – they are not appropriate for a service people don’t use regularly.  \nIncorporate ‘View your National Insurance record’ into the main signed-in view. If you have to link to it, this should be a link, not a button – buttons imply action, not just navigation.\n- Don’t put summary information in the right-hand column as some users (e.g. those who use wide screens, those who use screen readers) may fail to notice content that is outside the main column.\n- We are concerned that the disclaimer on the start page might undermine the user's confidence in the service. The easiest way to resolve this is to remove the disclaimer.  \nInstead of linking to generic guidance documents, incorporate the relevant content into the service.\n- For the privacy policy, you can provide service specific information and then just link to the government’s generic policy for the rest: [https://www.gov.uk/government/organisations/hm-revenue-customs/about/personal-information-charter](https://www.gov.uk/government/organisations/hm-revenue-customs/about/personal-information-charter)\n\nAs the service proceeds into public beta, we would expect the team to prototype, test and iterate approaches to the inclusion of this service as part of other services. This should include understanding more about offline steps that could form part of an end-to-end user journey and either removing the need for them or making them part of the digital service. In particular, the panel were concerned about steps that ask the user to obtain information from a previous employer where HMRC already holds it.\n\n#### Design of Support\n\nBefore launching into public beta, the team must include a contact phone number on the service to understand user needs for phone support. This should also be included in promotional material. Phone support is being provided but can only currently be reached through the onscreen service by email contact at the start of the service. Some users may not have an email address or may not have regular access to their email account (eg if they use a library or a family computer for access). The absence of a support phone number may cause people to drop out of the service and may limit the number and type of users seeking support in beta.\n\nThe team should work with the service teams for Personal Tax Account and other similar services to ensure that the end-to-end journey and support for users is consistent.\n\n#### Operational Support\n\nOperational support is currently in place using the HMRC IT system supported by DWP and HMRC staff. &nbsp;Currently, resolving operational issues depends on waking the service manager. &nbsp;The team will need to develop their operational support model before the Live assessment. &nbsp;The panel is aware that HMRC has a strong coordinated approach to operationally supporting the Tax Platform and the service team will no doubt draw on this.\n\n* * *\n\n## Digital by Default Service Standard Criteria\n\n| **Criteria** | **Result** | **Criteria** | **Result** |\n| 1 | Pass | 2 | Pass |\n| 3 | Pass | 4 | Pass |\n| 5 | Pass | 6 | Pass |\n| 7 | Pass | 8 | Pass |\n| 9 | Pass | 10 | Pass |\n| 11 | Pass | 12 | Pass |\n| 13 | Pass | 14 | Pass |\n| 15 | Pass | 16 | Pass |\n| 17 | Pass | 18 | Pass |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/business-properties-rental-information-beta/",
    "title": "Business Properties Rental Information - Beta Assessment",
    "summary": "One of the Valuation Office Agency’s fundamental responsibilities is to produce fair and accurate valuations of non domestic properties. Rental information for all non domestic properties is required in order to achieve this and the method of receiving the required information is currently via an 8 page ‘Form of Return’ (FOR) which is issued to customers in paper format to complete and return to us with the information required.",
    "body": "An online method (eFOR) for completing the form of return (referred to on page 1 of the paper FOR) which feeds the data directly into the database (after a validation process) already exists, but currently only 10% of customers use it – the other 90% of form submissions are by the paper form which is manually inputted in the Agency’s database. The Agency is looking to ultimately replace this paper FOR with a letter advising customers to visit their website and submit online, which will then feed directly into the database.\n\n**Department / Agency:**  \nHMRC / VOA\n\n**Date of Assessment:**  \n18/11/2015\n\n**Assessment Stage:**  \nBeta\n\n**Result of Assessment:**  \nNot pass\n\n**Lead Assessor:**  \nJ. McEvoy\n\n**Product Manager:**  \nH. Christian\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Business Properties Rental Information service should not be given approval to launch on the service.gov.uk domain as a Beta service.\n\n**Reasons**\n\nThe panel wants to make it clear that the development is very much going in the right direction. The team clearly works in agile and collaborative manner, and the handover to the new service manager is being handled very well. It is good to see that the service manager is responsible for the entirety of the service and has the ability to change the paper as well as the digital parts of the service.\n\n_User needs and user research_\n\nThere has been insufficient research with users with low digital skills. Although there is a desire to carry out both prototype-based research on the service and research into support needs with users with low digital skills, this has not yet fully taken place due to issues with recruiting users. This is important because some assumptions have been made about the number of users requiring support, and about how support should be designed. Research will enable the team to test their assumptions and understand those users’ needs for support and start to make decisions during the private beta phase about how, specifically, to meet those needs. It may also help the team to improve the design of the on-screen service.\n\nMore broadly, the team were also unable to make clear statements about the granular user needs across the various audience segments for this service. This seemed to flow from the lack of any clear or systematic segmentation or profiling of the audience. While much useful research has been conducted during the beta so far, it has mainly been with small business users. Other audience sectors e.g. large businesses, and agents, have not featured significantly in recent research. The team mentioned various other audience dimensions - e.g. business size, agent/tenant, tenant experience, single/many returns - but there has been no systematic or broad based research in any of these areas.\n\nRecruitment for the research that is being conducted has generally been through internal channels e.g. people who have contacted the call centre. As a consequence, the sample consists primarily of people who already have some familiarity with VOA and with the process. There is a risk in this approach that important areas of user need will be missed.\n\n_The team_\n\nThe team are working in an agile way, and most disciplines are represented. The GDS design and interaction patterns are being followed, however the panel had concerns around the front-end developer acting as a designer instead of this being a separate role. Given that the team is not observing user research sessions and are shortly to begin sharing their user researcher with another service, this is not sustainable and does not meet the service standard.\n\n_Design_\n\nAlthough the team has enhanced its existing contact centre support and plans to test and measure this in beta, it was not demonstrated why this support was chosen over other providers or channels (e.g. face to face) to meet user needs. This is a requirement for services to move to public beta and was a clear recommendation in the report following the alpha assessment.\n\nThe panel raised two issues with the letter that is sent to users asking them to use the digital service. The logo used on this letter is poor quality and makes the letter look like it could be fake; and the content of the letter is still worded in such a way that it sounds like a user needs to send in a paper form.\n\nThe agency logo is applied to every page of the digital service despite lack of justification in terms of user need. The team should also test removing the logo and tracking the effect on completion rates and takeup.\n\n**Recommendations**\n\n_Point 1 - Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for the design of the service._\n\nMake identification/recruitment of assisted digital users a priority. There has been some work to understand who will have support needs, their barriers to using the digital service independently and what support provision will be effective but more needs to be carried out to ensure the needs are well understood before making decisions around appropriate support. The GDS assisted digital team can help with further guidance on what service teams should have covered by the beta assessment.\n\nDevelop robust and systematic profiles or segmentations of the audience for the service, based on qualitative and quantitative data, which includes attitudinal and demographic dimensions relevant to each.\n\nDevelop a set of user needs statements, based on this research, which reflect the breadth of need across the audiences. A robust user needs statement typically has the following qualities:\n\n- It is something a real user would say\n- It helps you to design and prioritise\n- It does not unnecessarily constrain possible solutions\n- It is based on good evidence\n\nDevelop a research plan which addresses each audience sector identified in the segmentation/profile and which includes a range of research methods - including contextual research and lab research - to clarify user needs that can be further used to iterate the prototype.\n\n_Point 2 - Put a plan in place for ongoing user research and usability testing to continuously seek feedback from users to improve the service._\n\nConsider using a user research lab and an external recruiter. This will allow recruitment of people from the target audience who have no knowledge of the form or process (supporting a more robust understanding of user need) and it will allow the whole team to view research (which will support team buy-in and understanding).\n\nExpand the range of user-types who are recruited for forthcoming research. Include respondents from other parts of the audience, including large businesses and large agents.\n\nUse the findings to identify the key dimensions of user need and user behaviour, and from this develop a profile, model or segmentation of the audience against relevant dimensions, which can be used as a basis for describing user need at a more granular level, and for future research recruitment.\n\n_Point 3 - Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility._\n\nConsider recruiting a designer (ideally the panel would recommend this to be on full-time basis). This will complement the existing skills within the team (front-end developer, user researcher) and ensure that the important interplay between user research and design is fully in place.\n\nAs mentioned above, effort should be made to involve the entire team in user research.\n\n_Point 12 - Create a service that is simple and intuitive enough that users succeed first time._\n\nDesign support to meet user needs, based on user research. All options for support should be explored, including whether a face-to-face route is appropriate. If they are planning to use it, the team should fully understand the support HMRC is proposing and ensure that it meets user needs of the this specific service. All support should be set up and ready to test alongside the onscreen part of the service during public beta.\n\n**Summary**\n\nThe assessment team would like to thank the service team for their well-informed answers to our questions, we look forward to hearing about what the service team learn from their research and seeing how the service develops.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | No |\n| 3 | No | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | No |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmpo-online-appointment-booking-champ-service-assessment/",
    "title": "HMPO Online Appointment Booking (CHAMP) - Service Assessment",
    "summary": "HM Passport Office has developed an online appointment booking service that allows users to book an urgent passport counter appointment. Applicants can be eligible for either a Premium and / or Fast Track appointment and the tool determines their eligibility through a series of straightforward questions. Users typically require this service if they have a need for a new passport urgently (within the next 3 weeks).",
    "body": "**Department / Agency:**  \nHO / HMPO\n\n**Date of Assessment:**  \n3/11/2015\n\n**Assessment Stage:**  \nBeta\n\n**Result of Assessment:**  \nNot pass\n\n**Lead Assessor:**  \nD. Williams\n\n**Service Manager:**  \nJ. Potton\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Online Appointment Booking service should not yet be given approval to launch on the service.gov.uk domain as a Beta service.\n\nThe panel were very impressed with how well the service team had been working across two locations and organisations, and is very obviously working well together. A lot of good progress is being made and the service is on a very positive trajectory. The work to understand both users’ demand for and barriers to using a digital service is good, and the approaches to encourage digital take up are appropriate.\n\nHowever there is still some work to be done to improve the overall service. The panel found that there are some aspects that require further work before the service is ready for public beta.\n\n**Reasons**\n\n_Point 1. Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for the design of the service._\n\nLow-skilled users had been recruited for some of the lab testing of the on-screen prototype, and the team will be expanding this work in public beta. However, the team said they had not carried out research with users of this service to understand their support needs. The team were asking broad questions at the end of lab testing days about how users would access the service, but not about their support needs.\n\n_Point 3. Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility._\n\nThe panel had concerns around the team not having a dedicated interaction designer and user researcher on board, and are sharing that resource across the Passport Exemplar which may not be sustainable.\n\n_Point 12. Create a service that is simple and intuitive enough that users succeed first time._\n\nThe team demonstrated both the appetite and ability to change the design of the service in response to user research. However the current lack of either an interaction designer or researcher in the team will prevent the service from continuing to iterate in this way throughout the public beta stage - which is essential as the service starts being used by real users.\n\nThere is an assumption that the department’s phone support will meet users’ support needs. However, as the team has not researched what support users need, this and any other decisions around support offerings are not well informed. The team said they are working with Timpsons on a pilot to look at face to face support, but before progressing this the team should research to establish whether this will meet a support need.\n\nThere is a requirement for users of the on-screen service to have an email address. The team had observed that users in user testing had all entered an email address and managed to complete the service. However, this does not tell the service team to what extent entering an email address (and then having to access it) is a barrier or pain point for low-skilled users; whether users will struggle to access their email account even if they have one to submit; or whether some users would at this point opt for the phone service.\n\nThe service is able to measure and iterate the telephone support.\n\n**Recommendations**\n\n_Point 1. Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for the design of the service._\n\nThe service should\n\n- do contextual research with users to understand what support they would need for this specific service \n- do user research to fully understand user needs not wants or preferences\n- conduct face to face testing with people using assistive technologies\n- include users with the lowest levels of digital skills, confidence and access\n- include users who would seek support from third parties \n- include users who would get support from friends and family, to understand what alternative support they need (because friends and family support can not be included in the model of support)\n\n_Point 3. Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility._\n\nThe panel commends the team for all the hard work they are doing to further refine and improve the service for end users, especially in the light of resourcing challenges. The good work team is doing around user research should be supported and the panel wants to enable them to take it further. To do this the team needs to be able to secure sufficient user research support, and the service manual generally recommends 3 days/week. A dedicated researcher on the project will enable the team to fulfil their ongoing research activities in a consistent way, as well as help the team to better understand the needs of their broad and diverse audience.\n\n_Point 4. Build the service using the agile, iterative and user-centred methods set out in the manual._\n\nWhile implementation of agile was generally impressive, especially the adaptations made for a team based in multiple locations, the panel was slightly concerned about the overall departmental governance. The discussion of releases needing approval by change boards is not indicative of governance that enables the team to move fast. The team has done everything in their power to minimise the impact that this has on delivery, but the service manager should have the capability to make release decisions.\n\nThe panel recommend that the governance process be defined around “trust but verify” to allow the service manager to make decisions around deployments, but to verify that decisions are being made appropriately.\n\nFurthermore, it was worrying that general oversight was described as a PRINCE2 wrapper around the agile project. This is not an approach that GDS recommends as it tends to result in reduced buy-in and issues with governance. Senior engagement with Show and Tell sessions was impressive; the panel encourage the team to continue to adopt agile governance practices to improve the overall service governance.\n\n_Point 5. Build a service that can be iterated and improved on a frequent basis and make sure that you have the capacity, resources and technical flexibility to do so._\n\nIt is concerning that the team still needs manual deployment steps when deploying to production rather than a fully automated deployment system. Good progress has been made on having an automated build system and automating the creation of installer files, but manual deployment processes are still subject to errors and mistakes. The panel recommends the team move to fully automated deployments, ensuring that the deployments are repeatable, reliable and auditable.\n\nFurthermore, the deployments should be done without any disruption to users. Requiring deployments to be done out of hours or by resetting users’ sessions will actively prevent the team from doing more regular, more common deployments and prevent the team from reducing the cycle time appropriately.\n\nThe service should invest in zero-downtime deployment mechanisms that allow live deployment of the new system without terminating users’ sessions or shutting down the service.\n\n_Point 6. Evaluate what tools and systems will be used to build, host, operate and measure the service, and how to procure them._\n\nThe fact the system is being built upon the ‘Outreach’ platform when options to migrate away from the commercial platform are not available is concerning. It was unclear how much of the IP the service own, especially with regard to ownership of the platform and the custom work. Not owning the full IP would prevent migration to a different supplier.\n\nThe panel recommends that the migration options are fully understood so that the decision on the choice of outreach as a platform can be clearly articulated.\n\n_Point 12. Create a service that is simple and intuitive enough that users succeed first time._\n\nThe service should:\n\n- Work with the Home Office Digital's Head of Profession for User Research and Design to secure a researcher and interaction designer for the public beta stage; the service will be high volume so should be resourced accordingly.\n- Iterate the design of their email notifications to match the GDS design patterns for email.\n- Put together a model of support that is appropriate to users’ support needs and includes:\n\n  - routes provided by third parties (if required);\n  - face to face support (if required);\n  - alternatives for users who would get support from friends and family.\n- Ensure all routes of support are iterable, measurable and sustainable.\n- Be ready to test all support routes (from all providers) during the public beta, to be able to evidence in a live assessment that they are meeting users’ needs, as per the Service Standard.\n- Test for the above on the ‘unhappy’ path such as amending/cancelling appointments.\n\n**Summary**\n\nThe outcome of this reassessment will no doubt be disappointing, however the team should know that the panel were very impressed with the enthusiastic adoption of agile practices and in particular the rapid iterations of the design following user testing sessions.\n\nThe panel were pleased to see that improvements have been made to the service based on the lab and popup testing that has taken place, together with the regular feedback from the Telephony Preference team.\n\nThe panel were also encouraged to hear that most of the team are actively involved with the user testing e.g. observing and analysing the insight collectively.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | Yes |\n| 3 | No | 4 | Yes |\n| 5 | Yes | 6 | No |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | No |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/advocate-defence-payments-service-assessment-2/",
    "title": "Advocate Defence Payments - Service Assessment",
    "summary": "The Legal Aid Agency administers the Legal Aid budget for England and Wales. Advocate Defence Payments looks to replace the existing paper process for barristers and solicitor advocates submitting claims for Crown Court cases.",
    "body": "**Department / Agency:**  \nMoJ / LAA\n\n**Date of Assessment:**  \n12/10/2015\n\n**Assessment Stage:**  \nBeta\n\n**Result of Assessment:**  \nNot pass\n\n**Lead Assessor:**  \nS. Wood\n\n**Product Manager:**  \nS. Hollands\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Advocate Defence Payments service should not be given approval to launch on the service.gov.uk domain as a Beta service.\n\n**Reasons**\n\nThe assessment panel wants to make it clear that team working on the service is very competent and the service is very much going in the right direction.\n\nThere are three issues that resulted in the service not passing at this point.\n\nAdditional design work is needed before this service can go into public beta. [Specific details were attached as an annex to this report.] The panel was impressed with the amount of work that has gone into streamlining the service, and in removing unnecessary forms, such as the AF2. The design assessor has offered to to spend some time pairing with your new designer.\n\nAlthough it is expected that most users of this service will be frequent users and will understand the terminology used, it needs to be designed so that occasional and new users find it as simple as specialists billing clerks would.\n\nThe service should be on the service.gov.uk domain. This may involve designing a start page on the GOV.UK site. The conversation with GOV.UK proposition manafers has not taken place so far and will need to before Advocate Defence Payments can be launched as a beta.\n\nDuring the assessment it was clear that the team is preparing to take the service into private beta. This can happen once a service passes the alpha assessment. The awarding of a beta pass follows, not precedes, a private beta. That the service is yet to go to private beta in itself tells us that there is more testing to do before it can be confidently said that it has reached the minimum viable product (MVP) state and is ready to go onto GOV.UK.\n\n**Recommendations**\n\nAllow firms to submit claims unaided during the private beta phase and monitor results  \nBring a content designer into the team and pair with a GDS designer  \nAlthough it is not mandatory to have a product analyst during the alpha, when the service enters public beta, this role will prove to be invaluable. The service manager is encouraged to bring this role into the team.  \nFrom a technical point of view, while it was very good to hear that an ethical hacker is testing the systems, the panel recommends that a third party conducts a review of the security prior to launching as a public beta.  \nThe API authentication method needs to be defined and confirmed. Failing that, the service should obtain confirmation from the SIRO that she understand the risk and is prepared to accept it.  \nApproach to preventative monitoring needs to be put in place in order to spot any untoward activities, such as login enumeration.  \nContact the GOV.UK proposition team to discuss the domain, start and end pages.\n\n[A number of design recommendations was included in the annexe.]\n\n**Summary**\n\nThe panel would like to emphasise that it was very impressed with the service team. In particular it has been noted that the proportion of civil servants is higher on this service than any other MoJ service. For example the new front-end developer is a civil servant and knowledge transfer is taking place via working with a contractor. It was also good to see that a business analyst is now embedded into the team.\n\nSome really good research into user needs for assisted digital support has been undertaken. The plans for digital take-up are very sound. Although no potential AD users have been identified yet, the proposed support (telephone and face-to-face) is ready to test in beta if required. Digital take-up is vital for this service and the team’s timescale is ambitious and commendable.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | No |\n| 13 | No | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/biometric-residence-permits-service-assessment-2/",
    "title": "Biometric Residence Permits - Service Assessment",
    "summary": "Biometric Residence Permits (BRPs) are issued to non European Economic Area (EEA) nationals as part of their applications to extend their visas or settle in the UK for a period greater than 6 months.",
    "body": "The service offers a structured contact route for individuals who are encountering problems either with enrolling their biometric features as part of an application for permission to remain in the UK, or with the BRP secure token of leave issued to those whose applications are successful. The problems encountered range across delayed/missed delivery or collection of the card, lost or stolen cards to errors on the card itself.\n\n**Department / Agency:**  \nHome Office\n\n**Date of Original Assessment:**  \n14/01/2015\n\n**Date of Reassessment:**  \n17/08/2015\n\n**Assessment Stage:**  \nbeta\n\n**Result of Original Assessment:**  \nNot Pass\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nA. Lister\n\n**Service Manager:**  \nP. Smith\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## Reassessment Report\n\n**17th August 2015**\n\nThe Biometric Residence Permits service has been reviewed against the 14 points of the Service Standard which were not passed at the original assessment.\n\nAfter consideration the assessment panel have concluded the Biometric Residence Permits service has shown sufficient progress and evidence of meeting the Digital Service Standard criteria and should proceed to launch as a beta service on a service.gov.uk domain.\n\n**Reasons**\n\nIt is clear that the service team has made substantial progress since the initial beta assessment. The panel was particularly impressed by the service’s move away from proprietary form building software to in-house development. The benefits of doing this were clear in the quality of the service demonstrated and the ability to make changes to the service quickly and easily.\n\nThe team has responded to recommendations in the previous assessment by increasing user research, including with people who have the most challenging needs and the case workers who support them. They have identified initial user needs for support and proposed support is by telephone through an in-house contact centre and face-to-face through existing Home Office contracts with third parties. The team plans to test both methods of support and explore other potential assisted digital user journeys in public beta. The team are already making changes to the on-screen part of the service in response to feedback from third parties supporting users. Members of the team, including the service manager, have viewed user research and can talk confidently about their users' needs.\n\nThe service is employing standard design patterns and is well engaged with the broader government design community. The service is making good use of the Performance Platform to instrument and monitor the end-to-end service.\n\n**Recommendations**\n\nAlthough the panel appreciate that engaging with a broad range of users and their representatives is difficult, the panel would urge the team to challenge policy on this. The relatively easy wins presented by tech-savvy Tier 2 and Tier 4 applicants should not be considered as indicators of a successful service in isolation. Disadvantaged users, including refugees, those without digital skills and applicants who can legitimately apply without the need for proficiency in English, need to be part of future research plans and appropriate, sustainable support must be provided if there is a need.\n\nThe agile delivery process needs to be more precise with clear definition of tasks in the development backlog, mapping these to user stories, and assessing necessary effort. It should be clear which tasks will be delivered in the current sprint, how user testing will be fed back into the backlog, and what is an estimated delivery time for a user story. If the team practices these methodologies consistently, it will get a necessary level of experience and confidence.\n\nThe team should make sure that a designer, content designer and user researcher are all part of the development team throughout the life of the service. This will support continuous improvement and rapid iteration.\n\nThe designer and front-end developer should participate in the current cross-Government discussions about departmental style guides and toolkits, and determine the best use of toolkits and style guides for the Home Office.\n\nThe team also needs to consider failover scenarios for handling emails when parts of the system not directly under the team’s responsibility are not available. There should be operational procedures in place to notify GOV.UK of planned maintenance and for emergency situations.\n\nFailover is currently monitored using infrastructure capabilities. It would be useful to consider in-application monitoring.\n\n**Summary**\n\nThis is an important service with international exposure. The team has embraced the difficult recommendations set out in the original beta assessment and demonstrated that it’s possible to successfully challenge the status quo to create a high quality digital service that meets user needs. The panel look forward to seeing the service for live assessment.\n\n* * *\n\n## Summary of Original Report\n\n**14th January 2015**\n\nAfter consideration the assessment panel has concluded that the Biometric Residence Permits service should not be given approval to launch on the service.gov.uk domain as a beta service.\n\n**Reasons**\n\nThe service team demonstrated a thorough understanding of the business processes and its potential challenges for service users. However, it was apparent that actual, evidenced user-needs were not currently at the heart of the service’s design. The project’s history was outlined but it remained unclear to the assessment panel when things had been built and how frequent the iterations had been.\n\nThe points against which the service did not pass are explained below:\n\n_User needs (Points 1 and 20)_\n\nUser needs are the foundation of the service standard. Although the Home Office team demonstrated that some research had been completed, the number of users and the frequency with which they were engaged indicates that a great deal of work is required to put users at the heart of the service’s design.\n\nUser needs were expressed as assumptions about potential difficulties users are likely to encounter, based on experience of non-digital provision of the service.\n\nThere was significant disconnect between research, generating actionable insight, integrating and measuring the impact of change. Specifically:\n\n- Performing a discovery phase to understand the needs of people wishing to stay in the country and establish the criteria for success of the service.\n- The number of users engaged and the timing of user research sessions.\n- Beyond face to face sessions and surveys, the research methods used to identify user needs and actionable insights were not clear.\n- User-stories, written in language real users would understand, are the most important tool in an iterative delivery and these were not evidenced at assessment.\n- There was a lack of research into ‘out-of-country’ applicants, who will start to receive BRPs later this year.\n- Learnings from user research obtained before the current researcher joined the team were not apparent.\n\nIt was evident that funding was available to take the service forward but not clear how funds and resource would be allocated to support and sustain continuous iteration.\n\n_The Team (Points 2 and 6)_\n\nThe team has struggled to maintain continuity over the period of development. Meaningful handovers have not happened and the current team relies on documentation stored in Redmine.\n\n_Security, Privacy, Tools and Standards (Points 15, 17 and 25)_\n\nThe service employs proprietary software already in use at the Home Office for reasons of economies of scale across multiple services, despite the fact that it is always difficult, and frequently impossible, to develop a useful and usable service when pre-existing technology is the start-point for a delivery.\n\nProprietary software has been employed because it offers ‘drag-and-drop form design without the need for specialist skills such as coding’. However, developers are also being used to customise the service. This means that the off the shelf solution does not meet the needs of the service and, consequently, the users. The assessment panel felt that the developers would be better employed building the service rather than customising an existing supplier’s product\n\nLive-like end-to-end testing of the service, including any physical hand-in and hand-off points, is vital. The service demonstrated at the assessment had been observed in use by potential users but the research was constrained to the user-behaviour in the digital space. For example, the assessment panel would expect to see a user working from information on physical correspondence they had received during the course of the application and permit issue process. This would include the letter with prompts to the error notification service which was mentioned but not shown.\n\nThe service had been tested using Browserstack but little testing had been done on physical devices other than laptops/desktops. Tablet and mobile devices now dominate as the preferred method for internet access and should be prioritised in research and testing.\n\nAccessibility appears to present challenges because the changes to the proprietary software are prioritised by the vendor rather than the Service Manager. The assessment panel would expect to see any outstanding accessibility issues rectified and supported by appropriate evidence before reassessment.\n\nIn the event of the service being compromised or failing, a number of parties share responsibility. The Service Optimisation Team manage the general running of the service but the service itself is hosted by the software vendor, with the Service Manager ultimately responsible for service availability. This is not necessarily a problem but the assessment panel would like the team to demonstrate a consistent, shared knowledge of who does what and when in the event of service failure.\n\n_Improving the service (Points 14 and 19)_\n\nThe Service Standard requires frequent releases - at least every two weeks - of the service so that improvements identified in user research can move into the public-facing service as quickly as possible. On achieving Beta status, this service moves to the Service Optimisation Team which is also responsible for the Home Office’s other digital services. At the at assessment it was not clear that the working relationship between the Service Manager and the Service Optimisation Team was well defined, because of this it was not possible for the team to commit to the actual frequency of service releases. However, the Home Office has subsequently explained more clearly its service management model and will also make this clear during any follow-up assessment.\n\nSimilarly, some improvements may only be undertaken by the software vendor. Such work requires chargeable evaluation and provision of requirements by the Home Office further extending lead times for releases.\n\n_Design (Points 9 and 13)_\n\nThe assessment panel felt there was insufficient evidence to demonstrate that the service was intuitive and simple to use.\n\nA thorough understanding of the non-digital steps in the process was shared but these steps had not been part of end-to-end service testing.\n\nThe functionality of the service is not inline with either GOV.UK or general web standards, for example, within the service, the browser back button does not work. Recommendations from the GOV.UK design team have been provided.\n\nSimilarly, a number of content design issues of varying severity need to be addressed. Again, observations and recommendations from the GOV.UK content design team have been provided.\n\n_Assisted digital and channel shift (Point 10)_\n\nAs with the core of the digital service, the team proposed assisted digital support based on assumptions, rather than proven user need. The Service Manager showed a good understanding of assisted digital principles but was unable to provide any evidence of research with assisted digital users. Proposed channels and number of transactions are based on a related service and current use of paper, rather than potential assisted digital users of this new digital service.\n\nFor the beta assessment the assessment panel expects to see evidence that the team has undertaken user research to identify user needs and likely demand for each channel for this specific service. The team should also have a clear plan for ongoing user research and testing assisted digital support during public beta.\n\n_Analysis and benchmarking (Points 7, 8, 18, 21, 22, 23 and 24)_\n\nThe Home Office team had undertaken user research and provided videos of the service being tested. However, there was no clear evidence of how actionable insight had been derived from the research, and used to formulate production stories, prioritised, built and released.\n\nSimilarly, low research numbers and constraints around implementing analytics within the proprietary software meant that no meaningful evaluation based on in-service analytical data could be undertaken.\n\nIt was encouraging to see the cost per transaction being clearly understood in terms of the overall operational overhead as well as the cost of operating the digital service. The cost for out of country transactions will need to be evaluated to ensure the data published on the performance platform is accurate. To get this aspect of the service right, early engagement with the GDS performance platform team is advised.\n\nThe take up and completion rates shared by the Home Office team were ambitious and did not appear to have a logical basis given the absence of substantial user research and service testing. The fact that many current users communicate by email does not directly equate to the desire or ability to use a wholly online service. However, once the service achieves Beta status, the real data generated will enable realistic estimates and trajectories to be established.\n\n**Recommendations**\n\nFor reassessment, the team needs to:\n\n- Put the case for using proprietary software which is clearly obstructing development, iteration and control of the service rather than using the currently employed developers to build this relatively simple service in a way wholly aligned with the service standard.\n- Complete end-to-end user research (including non digital elements) with a broader, more representative range of potential users including out-of-country users. This must also include potential in-country users of an Assisted Digital service.\n- Demonstrate how user research is used to generate actionable insight.\n- Show how insight from user research, analytics data, technical and security requirements, etc, is used to create production stories which are developed, tested and integrated into the public facing service.\n- Undertake user research across a range of devices and describe the actionable insight generated.\n- Describe the plan for ongoing user-research and frequent, rapid iteration of the service.\n- Show how in-service analytics will be developed and used to support improvement.\n- Engage with the GDS performance platform team to agree how key metrics will be shared.\n- Explain how the current and future resource models – including the Service Optimisation Team – are managed and led in a way that ensures the service can be iterated frequently and rapidly under the direct control of the Service Manager.\n- Evidence that the known accessibility issues have been resolved – including those in the proprietary software; and  \ncomplete the outstanding corrections and recommendations from the GOV.UK design and content design teams.\n\n**Summary**\n\nThe team shows obvious and genuine commitment to improving users’ experience of their service and, in turn users’ experience of the Home Office as a whole. Many of the elements necessary to achieve this are in place. As it is a relatively simple service, there is scope, with the right commitment, to address the points described above and put the service forward for reassessment in the next eight to ten weeks. To do this, the recommendations need to be fully addressed. The panel looks forward to seeing the service for reassessment.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/mot-testing-service-assessment-2/",
    "title": "MOT Testing - Service Assessment",
    "summary": "The MOT Testing service will enable users to efficiently and effectively record and report the results of an MOT test in accordance with the MOT scheme rules. For example, it will enable:",
    "body": "- qualified and pre authorised vehicle testers, operating at pre authorised private garages, to electronically record and amend an MOT test result and print a certificate\n- the private garages to pay a transaction (slot) fee to DVSA for the submission of the MOT test\n- DVSA staff to record the outcome of a vehicle re-inspection\n- the results of the MOT test to be shared with DVLA, and in turn support DVLA's on-line electronic vehicle licensing service.\n\n**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n14/08/2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Stewart\n\n**Service Manager:**  \nN. Barlow\n\n**Digital Leader:**  \nO. Morley\n\n* * *\n\n## **Assessment Report**\n\nThe MOT testing service is seeking permission to launch on a service.gov.uk domain as a beta service.\n\n**Outcome of Service Assessment**\n\nAfter consideration the assessment panel has concluded the MOT testing service has shown sufficient progress and evidence of meeting the Digital Service Standard criteria and should proceed to launch as a beta service on a service.gov.uk domain.\n\nGiven the particular time pressures regarding the rollout of the new service this pass is conditional on continuing to provide GDS with weekly updates on rollout status and service availability until that information is available via the Performance Platform.\n\n**Reasons**\n\n_User needs_\n\nThe panel were impressed with the detailed understanding the team showed of their primary users (MOT garages) and the wider role of the MOT process in British driving. The team demonstrated a significant level of specialist knowledge and an understanding of how digital approaches could simplify the experience for garages and motorists.  \nThe team had identified and spoken to a range of users who’ll need support to complete the service, and were confident that this range accurately represents all users needing support. The team has a model of support in place for the public beta that is intelligently shaped to meet user needs. The model includes phone and face-to-face support for those who need it, and provides alternative support options for those currently relying on colleagues and trade associations.  \nThe team has ongoing plans in place to continue research with users of all levels of digital skills and confidence.\n\n_The team_\n\nThe team contains a good balance of skills and is working together effectively. While DVSA is heavily dependent on suppliers at present there is a clear focus and plan to ensure sufficient in-house capability to manage the service once it is live. The service manager is responsible for all channels including the existing support team.  \nThe team is distributed across the country but have adapted approaches to working that support this and are using it to their advantage in their ability to visit garages. The assessment panel recommend that all members of the team take part in observing user research, so that the team help keep users in their mind through development.  \nThe panel were pleased to hear how the service manager is empowered well beyond the parts of the service that exist on-screen, with a remit including the assisted digital support elements of the service and responsibility for full digital take up.\n\n_Security, Privacy, Tools and Standards_\n\nThe team appear very familiar with the actions and conversations that need to happen when operating a digital service. They are able to talk clearly about the reasons for technology choices, how they will avoid lock-in and future steps they want to take to further improve the service.  \nThe service is not using GOV.UK Verify but that is as a result of ongoing discussions with the Verify team and with their approval. They are aware of the opportunities for improving how they share the underlying data in the service (via APIs and more regular publication) and looking to develop that element of their offering once the core service is live.\n\nThe renewal of vehicle tax by DVLA is dependent on being able to obtain the MOT status of a vehicle and there is both a batch data exchange and a real-time API in place to support that. The team are clearly aware of that dependency and how it works. They explained that there have been a small number of data quality issues which they have been working to resolve and are including that aspect of the service in their testing.  \nSignificant amounts of performance and capacity have taken place on both new and old infrastructure but there is currently a gap in ongoing functional testing of full user journeys in the production environment. The team are aware of this and the panel was keen that they prioritise adding that testing.  \nThere is an infrastructure migration scheduled within the next fortnight which is clearly planned but high risk. The team is fully aware of that risk, has contingency plans in place and is in regular contact with GDS to review progress.\n\n_Improving the service_\n\nThe team are clearly making regular improvements to the service and were able to talk about their process in detail. There is a plan in place to continue being able to make improvements and the service manager and product managers are in a position to set priorities.\n\n_Design_\n\nThe team have tested the on-screen service with users with lower levels of skill and confidence, and made changes in response to their feedback (e.g. simpler language).  \nThe team acknowledged that the assisted digital support for the service might struggle to cope with capacity if it went live now, so they are increasing capacity while tackling the issues that are leading to the majority of calls in the first place. The team will be using the actual systems, staff and setup, as it would be if live, for testing during the public beta.\n\nThe team have clear plans to test all routes of support during beta, including those currently provided by third parties and the face to face support available through DVSA’s 'Change agents'. It was good to hear how the team have actually pared down other activities to free up face-to-face support staff for when the service moves to public beta, to ensure capacity and that no users fails to get the support they need.\n\nThe team do not feel web chat is required to meet users’ support needs and so have not included it in their support model, although they will be looking into it more during beta.\n\nThe team are in the process of implementing to the front-end toolkit having been previously built around bootstrap due to technical restraints. Where patterns don’t currently exist in the toolkit they have been creating their own. This is fine, however any new patterns must be tested rigorously. They should also check on the design hackpad that similar, appropriate patterns have not already been developed by other design teams.  \nThe service must follow the pattern of all other digital services on service.gov.uk domains and have the GOV.UK logo rather than the MOT logo. The team stated that having the user information positioned prominently in the header tested well with users so that can remain there along side the GOV.UK logo.\n\n_Digital take-up_\n\nThe existing service is 100% digital and as the service team are adding no extra channels, the new service will also be fully digital.\n\n_Analysis and benchmarking_\n\nThe team provided concrete examples of improvements made to the service based on analytics and call centre feedback. Takeup of the new service is being closely tracked and they were able to explain how they would be calculating cost per transaction. Conversations are under way with the Performance Platform team to prepare public dashboards.\n\n**Recommendations**\n\nThe team’s focus over the coming weeks will be on the migration to new infrastructure and switching garages to the new system. Conversations are already taking place between DVSA and GDS to track that and they should continue with regular reporting of rollout progress, service availability, and ongoing test results.\n\nFurther efforts should be made to engage all members of the team in the research process not just those in product and design roles, so that the team help keep users in their mind.\n\nThe team should liaise with GDS on options for exposing further data and APIs from the service, and to discuss taking part in discovery work on notification platforms across government.\n\nFull, routine end-to-end testing for common user journeys (including that resulting data is made available correctly for DVLA’s use) should be put in place to run in the production environment. The panel is satisfied that this testing is taking place in the pre-production environment and is sufficient to test service capacity but making it routine practice in the production environment would significantly increase confidence that changes are working and that issues will be found quickly.\n\nThe team should continue work to confirm that no users are needing to pay for assisted digital support, and have appropriate and free to use options that meet their needs.\n\nThe team should liaise with the GDS design team for more detailed recommendations.\n\n**Summary**\n\nThis is a complicated and high profile service and the timetable for rolling it out to garages is extremely difficult, but the panel were encouraged to see that it is on track and that the team are responding rapidly to issues as they arise.\n\nThe panel was particularly pleased to hear the team’s broad knowledge of their area and that the service manager is genuinely responsible for the overall service.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/company-accounts-and-tax-online-beta/",
    "title": "Company Accounts and Tax Online - Beta Assessment",
    "summary": "Company Accounts and Tax Online will allow the smallest companies with the simplest tax affairs who are unrepresented to file their Company Tax return, accounts and computations. It will be a digital online product which will be a quicker and easier service to use and will allow the user to file to HMRC and Companies House at the same time.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n1 July&nbsp;2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nNot Pass\n\n**Lead Assessor:**  \nL. Reichelt\n\n**Service Manager:**  \nM. Duffield\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## **Assessment Report**\n\nThe Company Accounts and Tax Online service is seeking permission to launch on a service.gov.uk domain as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded the Company Accounts and Tax Online service should not be given approval to launch on the service.gov.uk domain as a Beta service.\n\nThe panel were very impressed with how well the service team had been working across two locations and organisations, and how smoothly they have integrated content designers and designers into their process since the alpha assessment.\n\nThis is a large and challenging service and much of it has improved from the alpha assessment. Where the service differs from established GDS design patterns, the service manager and content designer are clearly comfortable discussing the iterations and user behaviours that have caused them to make those design decisions.\n\nThe team is very obviously working well together, are making a lot of good progress and are on a very positive trajectory, however they acknowledge there is still some work to be done to improve the overall service. The panel found that there are some aspects that require further work before the service is ready for public beta.\n\n**Reasons**\n\n- The service team are overly reliant on the functions and facilities provided by the tax platform without understanding the detail or limits of what is available. The operation of running the service has been devolved to the platform team, but the team showed little understanding of how it’s monitored or what happens in the event of problems. This lack of understanding could lead to gaps in what the team believes is being monitored and managed compared to what the tax platform are actually doing.\n- The service is reliant on integrations with a number of other services but doesn’t appear to have monitoring in place to determine if these integrations are working. Instead, the service team are entirely reliant on monitoring provided by either the tax platform team or the other services, but is unclear on how this monitoring works or what happens in the event of problems.\n- Additional work needs to be done to understand the needs of potential assisted digital users. Based on landscape research, the service team assume that there will be a need for assisted digital support but as no users had been identified, there was no evidence of what the need might be.\n- The existing free filing service is used by a&nbsp;group of users for whom it was not designed nor intended and they will not have access to the future service. Some user research&nbsp;should be done with these users to understand their behaviours and why they choose to use the existing service.&nbsp;These users need to be supported through the transition to an appropriate alternative to the new service.&nbsp;Early and responsive communications with this group of users should be undertaken as soon as possible to remove unnecessary risks and issues from the service.\n- The service is unable to perform end-to-end testing in an environment identical to live due to the numerous integrations with legacy systems. This makes it extremely difficult to gain confidence that the service will work and will continue to work whenever changes are made to the legacy systems.\n- The service has not been tested on multiple browsers or devices.\n- Although the HMRC and Companies House transactions have been integrated on-screen, proposed support for users is not integrated and it wasn’t clear to the panel where a user would go for help when. The end-to-end user journey needs to be worked through to ensure that support is consistent through the whole transaction and that users are aware that support is available.\n- The service team plan to use the HMRC support model to provide telephone talk-through and agents inputting on behalf of users. There was no evidence of a plan to test and measure this support in public beta to ensure that it meets user needs. As the transaction is lengthy and complex, this is essential to know how the support can be improved to meet user needs, for example ensuring that staff are trained on the whole service, that there is sufficient capacity and appropriate availability of support etc.\n\n**Recommendations for beta reassessment**\n\n- Point 1 - The service team must undertake more user research to identify potential assisted digital users and their needs. This will require more creative briefing for user research recruitment, for example seeking users who choose to use agents to file in order to avoid having to file digitally themselves. Also contacting current users who file on paper; speaking to other government agencies or associations which work with small businesses; working with contact centre staff who support people with the current service; starting research with small charities.\n- Point 1 - The team should undertake some user research to&nbsp;understand the needs of the group of users who will not be able to use the new service in the future, manage the impact of withdrawing the service from them and support them through the transition to an appropriate alternative to the new service.\n- Point 3 - The team should consider how they are going to operate the service and understand the limits of the responsibilities of the tax platform team.\n- Point 6 - The team should understand what monitoring is currently in place for systems which the service is reliant on. Where possible, the service should provide it’s own monitoring of the services to ensure that the team is aware of problems when they occur.\n- Point 7 - The team should have a clear understanding of what the threats to the service are and consider how these could be mitigated. The understanding of threats should be shared with the team where possible to ensure they are considered at every stage of development.\n- Point 9 - The service must use agreed open standards where they are available. In particular, the service should ensure that any PDFs generated comply with the PDF/A standard.\n- Point 10 - The service team must consider how they can improve their end-to-end testing to gain confidence that all their integrations with other systems work as expected. Additionally, the service must consider which browsers and devices their users will be using and undertake appropriate testing to ensure the service works on these browsers and devices.\n- Point 12 - The team should continue to simplify the language used in the service and to provide sufficient supporting information so that users can succeed with the service first time, and to support users to ensure they have all the information they need, in the correct format, so they can succeed with the service.\n- Point 12 - The service team should demonstrate that the end to end user journey for assisted digital users has been considered and that there is a plan to test proposed support in beta to ensure that it meets user needs.\n- Point 14&nbsp;– (a)&nbsp;The service team needs a plan for phasing out non-digital channels across the end to end service, including exploring the reduction of paper reminders and paper filing&nbsp;of annual Accounts&nbsp;at Companies House.&nbsp;(b)&nbsp;The service team should also be able to talk about the transition plan for moving end users&nbsp;from the old service onto the new service&nbsp;or an appropriate alternative for those users who won’t be able to use the new service.\n- Point 17 - The team must engage with the Performance Platform team to ensure a dashboard is ready to be published when the service launches its public beta phase.\n\nBefore going live:\n\n- Point 8 - The team must release their code under an appropriate licence before returning for a live assessment.\n- Point 11 - The service team should gain greater understanding of what happens in the event of the service (or part of the service) being unavailable.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | No |\n| 7 | No | 8 | Yes |\n| 9 | No | 10 | No |\n| 11 | Yes | 12 | No |\n| 13 | Yes | 14 | No |\n| 15 | Yes | 16 | Yes |\n| 17 | No | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/company-accounts-and-tax-online-beta/",
    "title": "Company Accounts and Tax Online - Beta Assessment",
    "summary": "Company Accounts and Tax Online will allow the smallest companies with the simplest tax affairs who are unrepresented to file their Company Tax return, accounts and computations. It will be a digital online product which will be a quicker and easier service to use and will allow the user to file to HMRC and Companies House at the same time.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n1 July&nbsp;2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nNot Pass\n\n**Lead Assessor:**  \nL. Reichelt\n\n**Service Manager:**  \nM. Duffield\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## **Assessment Report**\n\nThe Company Accounts and Tax Online service is seeking permission to launch on a service.gov.uk domain as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded the Company Accounts and Tax Online service should not be given approval to launch on the service.gov.uk domain as a Beta service.\n\nThe panel were very impressed with how well the service team had been working across two locations and organisations, and how smoothly they have integrated content designers and designers into their process since the alpha assessment.\n\nThis is a large and challenging service and much of it has improved from the alpha assessment. Where the service differs from established GDS design patterns, the service manager and content designer are clearly comfortable discussing the iterations and user behaviours that have caused them to make those design decisions.\n\nThe team is very obviously working well together, are making a lot of good progress and are on a very positive trajectory, however they acknowledge there is still some work to be done to improve the overall service. The panel found that there are some aspects that require further work before the service is ready for public beta.\n\n**Reasons**\n\n- The service team are overly reliant on the functions and facilities provided by the tax platform without understanding the detail or limits of what is available. The operation of running the service has been devolved to the platform team, but the team showed little understanding of how it’s monitored or what happens in the event of problems. This lack of understanding could lead to gaps in what the team believes is being monitored and managed compared to what the tax platform are actually doing.\n- The service is reliant on integrations with a number of other services but doesn’t appear to have monitoring in place to determine if these integrations are working. Instead, the service team are entirely reliant on monitoring provided by either the tax platform team or the other services, but is unclear on how this monitoring works or what happens in the event of problems.\n- Additional work needs to be done to understand the needs of potential assisted digital users. Based on landscape research, the service team assume that there will be a need for assisted digital support but as no users had been identified, there was no evidence of what the need might be.\n- The existing free filing service is used by a&nbsp;group of users for whom it was not designed nor intended and they will not have access to the future service. Some user research&nbsp;should be done with these users to understand their behaviours and why they choose to use the existing service.&nbsp;These users need to be supported through the transition to an appropriate alternative to the new service.&nbsp;Early and responsive communications with this group of users should be undertaken as soon as possible to remove unnecessary risks and issues from the service.\n- The service is unable to perform end-to-end testing in an environment identical to live due to the numerous integrations with legacy systems. This makes it extremely difficult to gain confidence that the service will work and will continue to work whenever changes are made to the legacy systems.\n- The service has not been tested on multiple browsers or devices.\n- Although the HMRC and Companies House transactions have been integrated on-screen, proposed support for users is not integrated and it wasn’t clear to the panel where a user would go for help when. The end-to-end user journey needs to be worked through to ensure that support is consistent through the whole transaction and that users are aware that support is available.\n- The service team plan to use the HMRC support model to provide telephone talk-through and agents inputting on behalf of users. There was no evidence of a plan to test and measure this support in public beta to ensure that it meets user needs. As the transaction is lengthy and complex, this is essential to know how the support can be improved to meet user needs, for example ensuring that staff are trained on the whole service, that there is sufficient capacity and appropriate availability of support etc.\n\n**Recommendations for beta reassessment**\n\n- Point 1 - The service team must undertake more user research to identify potential assisted digital users and their needs. This will require more creative briefing for user research recruitment, for example seeking users who choose to use agents to file in order to avoid having to file digitally themselves. Also contacting current users who file on paper; speaking to other government agencies or associations which work with small businesses; working with contact centre staff who support people with the current service; starting research with small charities.\n- Point 1 - The team should undertake some user research to&nbsp;understand the needs of the group of users who will not be able to use the new service in the future, manage the impact of withdrawing the service from them and support them through the transition to an appropriate alternative to the new service.\n- Point 3 - The team should consider how they are going to operate the service and understand the limits of the responsibilities of the tax platform team.\n- Point 6 - The team should understand what monitoring is currently in place for systems which the service is reliant on. Where possible, the service should provide it’s own monitoring of the services to ensure that the team is aware of problems when they occur.\n- Point 7 - The team should have a clear understanding of what the threats to the service are and consider how these could be mitigated. The understanding of threats should be shared with the team where possible to ensure they are considered at every stage of development.\n- Point 9 - The service must use agreed open standards where they are available. In particular, the service should ensure that any PDFs generated comply with the PDF/A standard.\n- Point 10 - The service team must consider how they can improve their end-to-end testing to gain confidence that all their integrations with other systems work as expected. Additionally, the service must consider which browsers and devices their users will be using and undertake appropriate testing to ensure the service works on these browsers and devices.\n- Point 12 - The team should continue to simplify the language used in the service and to provide sufficient supporting information so that users can succeed with the service first time, and to support users to ensure they have all the information they need, in the correct format, so they can succeed with the service.\n- Point 12 - The service team should demonstrate that the end to end user journey for assisted digital users has been considered and that there is a plan to test proposed support in beta to ensure that it meets user needs.\n- Point 14&nbsp;– (a)&nbsp;The service team needs a plan for phasing out non-digital channels across the end to end service, including exploring the reduction of paper reminders and paper filing&nbsp;of annual Accounts&nbsp;at Companies House.&nbsp;(b)&nbsp;The service team should also be able to talk about the transition plan for moving end users&nbsp;from the old service onto the new service&nbsp;or an appropriate alternative for those users who won’t be able to use the new service.\n- Point 17 - The team must engage with the Performance Platform team to ensure a dashboard is ready to be published when the service launches its public beta phase.\n\nBefore going live:\n\n- Point 8 - The team must release their code under an appropriate licence before returning for a live assessment.\n- Point 11 - The service team should gain greater understanding of what happens in the event of the service (or part of the service) being unavailable.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | No |\n| 7 | No | 8 | Yes |\n| 9 | No | 10 | No |\n| 11 | Yes | 12 | No |\n| 13 | Yes | 14 | No |\n| 15 | Yes | 16 | Yes |\n| 17 | No | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/tax-credits-change-of-circumstances-beta/",
    "title": "Tax Credits Change of Circumstances - Beta Assessment",
    "summary": "Tax Credits Change of Circumstances allows users to view and update the information used to calculate their [tax credits](https://www.gov.uk/topic/benefits-credits/tax-credits).",
    "body": "**Department / Agency:**  \n[HM Revenue & Customs (HMRC)](https://www.gov.uk/government/organisations/hm-revenue-customs)\n\n**Assessment Date:**  \n24 March 2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nNot pass\n\n**Lead Assessor:**  \nA. Lister\n\n**Service Manager:**  \nJ. Robertshaw\n\n**Digital Leader:**  \n[M. Dearnley](https://www.gov.uk/government/people/mark-dearnley)\n\n* * *\n\n## Assessment Report\n\nThe Tax Credit Change of Circumstances service is seeking permission to launch on a service.gov.uk domain as a Beta service.\n\n### Outcome of service assessment\n\nAfter consideration we have concluded the Tax Credit Change of Circumstances service should not be given approval to launch on the service.gov.uk domain as a Beta service.\n\n### Reasons\n\nWhile the service team have worked successfully in many areas, the service is not yet ready to pass a beta assessment and be made publicly available. It is a key requirement at a beta assessment to be able to show the service, this means that the assessment panel can make observations on the service which will be made public. The team were not able to show the complete end to end service at the assessment.\n\nThe HMRC team demonstrated a thorough understanding of the current service’s business processes and policy. The focus on operational requirements has meant that user needs have not been at the forefront of the service’s design, and the service is therefore not yet meeting user needs.\n\nThe points against which the service did not pass are:\n\n#### User needs (points 1 and 20)\n\nIt’s important to be able to describe user needs in language that users themselves would understand. The service’s design focuses on current process and policy constraints which have not been challenged in order to develop a service which can demonstrably meet user needs.\n\nThe panel were concerned that in the user research there has been a degree of ‘testing for success’. Lab research has been scenario-based with users assuming fictitious identities to complete pre-determined tasks, rather than allow users to engage with the service as if using it ‘for real’. Findings have been captured in terms of user-preference rather than objective analysis. This means that the research is more likely to validate preconceptions, rather than being objective actionable insight which can be used to improve the service.\n\n#### Testing the end to end service (point 17)\n\nThe team could not show the end to end service. This means that no end-to-end testing with a live or live-like service has been completed. At a beta assessment, the panel needs to see the actual service that will be made public on GOV.UK.\n\nLab usability testing was with the prototype, not the real service. Whilst this is appropriate early in development, there are differences between prototypes and production systems, and not testing the real service with users poses a high risk.\n\n#### A simple and intuitive service where users succeed first time (point 9)\n\nThe completion rates in an earlier Beta service were high, however the elements of the service presented at assessment had significant usability issues. Examples of this included:\n\n- content which is awkward or uses jargon, like ‘Does this child have a contract to employment?’;\n- dead end routes from which the user can not return to the service;\n- and poor validation which often requires the user to enter data in a highly specific format, which is unnecessary. For example ‘eg if the total of all amounts shown on your P60 or P45 is £15,453.99, enter 15453’ - the user should be able to enter values as they are written.\n\nThe service currently has questions which are unnecessary for some users. A significant number of fields are optional and have hint text ‘Leave blank if...’ It would benefit from using appropriate techniques such as progressive disclosure to only ask necessary questions and guide the user.\n\nThe service captures information from the user on their change of circumstance. The Beta development has been used to move away from capturing freetext to capture structured data, but this work is not yet complete. There are still a number of areas where the service uses freetext to capture what should be structured data. This means that users are required to deal with complexity the service should be removing.\n\nThe service had been working with their content designer to ensure high accessibility. To validate that the service works for users with varied needs, the team should conduct research with users of varying accessibility needs, including lab usability sessions, and/or commission an external audit.\n\n### Recommendations to meet the criteria not passed\n\nUser needs must be explored objectively and in detail. With evidenced user needs, process and policy can be constructively challenged to create a service that’s right for users whilst being safe and secure.\n\nThe service, exactly as it would be if public, must be tested end-to-end with real users working with their own identities and details. This includes GOV.UK start and end pages. The assessment team needs to see the complete service and understand how it has performed with actual users.\n\nTo ensure that the service is simple and intuitive, the content, design and interactions need to align to GOV.UK standards and patterns, and the user-journey simplified as much as possible. Again, user research should take place to evaluate the effectiveness of the changes made.\n\n#### Additional comments\n\nThere were a number of other points of the standard which the service passed, but on which the panel made observations, these are as follows:\n\n#### The Team\n\nThe service has two fully staffed teams, each with its own product manager. The delivery methods are largely in line with those set out in the service manual.\n\nThe extracts of the service shown suggested that the features and components developed would be ‘tied together’ at a point closer to the date on which the service will be made public. This is a high risk approach which could cause significant problems.\n\nIt was also expressed that the team had been working with a Technical Architect but this was no longer the case. The Technical Architect role needs to be continuous throughout the delivery.\n\n#### Security, Privacy, Tools and Standards\n\nThe team have clearly thought about security and privacy aspects of the service but the assessors had some concern about the approach to handling broken households. We recommend more exploration of how to meet user needs - and user safety - in that context and would look for a more robust approach to be developed during the Beta period.\n\nWe discussed security and privacy elements of the overall process and there is more work to be done as the current service is connected with the backend systems later in the year. In particular the team will need to look more closely at how authority is delegated within households and potential sensitivity there.\n\nThe team indicated that there is a legislative requirement to show people the full set of details on which their case would be determined and that that would be met in the next major iteration. Those requirements will need to be very clearly understood and, if genuine, will require careful design to protect users’ privacy and security.\n\n#### Improving the service\n\nEverything appears to be in place to improve the service and the team clearly has a good understanding of their relationship with the core HMRC Digital operations team and the division of responsibilities.\n\n#### Design\n\nThe service generally looks like a GOV.UK service, however the delivery imperative meant that questions focused more on fitting with the current process’ data requirements than on helping users provide the information they needed to.\n\n#### Assisted digital and channel shift\n\nThe approach to assisted digital is comprehensive and well considered. The team had responded to feedback from alpha and undertaken extensive research to identify user needs. This included speaking to assisted digital representatives across government, the contact centre lead for this service, relevant charities and focus groups. The recruitment company were unable to find assisted digital users with the lowest digital skills and access, so the user researcher took the initiative and went to places where she knew potential users would be. Based on findings from this user research, the team has developed a plan for testing a variety of proposed support in beta.\n\nThe team has a good strategy for digital take-up next year but will need to think beyond that for the Live assessment.\n\n#### Analysis and benchmarking\n\nThe team has a dedicated analytics specialist and a clear understanding of analytics as a tool for measuring the success of the service. They had been measuring completion rate for some time and were aware of factors that affected this important metric on their service. They were also able to explain the value of other metrics such as user satisfaction and cost per transaction.\n\nThe team had a clear plan in place to deliver the 4 KPIs on a dashboard on the Performance Platform, and could comfortably talk through the specific details of delivering each metric.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | No | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/personalised-registration-put-onassign-a-personalised-registration-plate-service-assessment/",
    "title": "Personalised Registration (put on/assign a personalised registration plate) - Service Assessment",
    "summary": "This service will allow users to assign (put on) a personalised number plate to a vehicle.",
    "body": "**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n26/3/2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ.Hughes\n\n**Service Manager:**  \nR.Gye\n\n**Digital Leader:**  \nB.Etheridge\n\n* * *\n\n## **Assessment Report**\n\nThe Personalised Registration (put on/assign a personalised registration plate) service is seeking permission to launch on a service.gov.uk domain as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Personalised Registration (put on/assign a personalised registration plate) service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta service on a service.gov.uk domain.\n\n**Reasons**\n\nThe team provided evidence to demonstrate that the service meets all the points of the service standard for beta.\n\nParticular areas of strength included:\n\n- the Service manager’s thorough understanding of the service and how it is meeting user needs\n- clear evidence that the team is doing the hard work to make it simple\n- the range of types of user research the team is carrying out\n- the Service manager and team’s clear commitment to putting the user first and constantly improving the service\n- the team’s work to recruit a range of participants in research, based on the digital inclusion scale\n- the team’s commitment to test a range of support channels\n- the team’s work with 3rd party providers to develop the assisted digital support model for this service, including approaches to digital inclusion that will help users build digital skills and lessen long term need for further support\n- the team’s efforts to use stakeholder channels and off-screen parts of the existing service to promote digital take up, signposting users to use the digital service\n- embedding policy and security colleagues as part of the team when necessary, which has enabled the team to develop creative ways of meeting user needs\n- the work the team has done to secure changes in legislation so they can make the service straightforward to use (eg removing the requirements for paper and wet signatures)\n\nThe assessment panel noted that the service is not available 24/7 but that there is a clear rationale for this at this point in time and the team will work towards this during the beta. This should be complete before the service’s ‘Live’ assessment.\n\nThe team have worked with the GDS performance platform team to develop a performance platform dashboard, showing all of the KPIs. This will be made public before the service progresses to public beta.\n\n**Recommendations**\n\nThe team is continuing to develop its approach to document-based tasks. The assessment panel recommend the team should share its approach and research findings in the design patterns hackpad for the wider design community to collaborate on.\n\nThe design is consistent with the design principles and design patterns / style guide, and the team has sufficient resources within the design and content design disciplines for a service of this scope and scale. The team has resources within the design and content design disciplines, and described how everyone in the team observes user research and is involved in discussing and acting on the outcomes of research. However the assessment panel did note a few points of detail in the content, and will email the team separately with advice on those to consider.\n\nThe team demonstrated a very thorough and comprehensive approach to user research, however as a point of potential improvement the assessment panel would encourage the team to make sure they allow for observation of spontaneous behaviour rather than prompting users. The assessment panel observed an example, which may have been an isolated case, of a leading question that may have constrained the ability of the team to observe the user’s spontaneous response to the right hand column.\n\n**Next Steps**\n\nThis service has been given approval to launch as a Beta on a service.gov.uk domain.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/vehicle-management-acquire-from-trade-and-sell-vehicle-privately-service-assessment/",
    "title": "Vehicle Management (Acquire from trade and sell vehicle privately) - Service Assessment",
    "summary": "“Acquire from trade” transaction allows motor dealers to tell DVLA when a customer has bought a&nbsp;vehicle from them.",
    "body": "“Sell vehicle privately” transaction allows motorists to tell DVLA when they sell a vehicle to another&nbsp;motorist. The current keeper (the seller) has the responsibility to notify DVLA that they have sold their&nbsp;vehicle. They will provide details of the new keeper (the buyer) and this will update DVLA's records.\n\n**Department / Agency:**  \nDfT / DVLA\n\n**Date of Original Assessment:**  \n19/3/2015\n\n**Date of Reassessment:**  \n5/6/2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Original Assessment:**  \nNot pass\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nM. Sheldon\n\n**Service Manager:**  \nR. Gye\n\n**Digital Leader:**  \nO. Morley\n\n* * *\n\n## Original Assessment Report\n\nThe Vehicle Management (“Acquire from trade” and “Sell vehicle privately”) service is seeking&nbsp;permission to launch on a service.gov.uk domain as a public beta service.\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded the Vehicle Management (“Acquire from trade” and “Sell&nbsp;vehicle privately”) service should not be given approval to launch on the service.gov.uk domain as a&nbsp;public beta service.\n\nAlthough the service team are able to clearly articulate the user needs of the specific transactions&nbsp;being assessed, the panel agreed users could perceive these as separate services on GOV.UK. As&nbsp;more transactions are added this will only increase the complexity of the service and its content.\n\n**Reasons**\n\n**The team (service standard point 2)**  \nThe team lacks a designer, content designer and data analyst. In its current form the team appears&nbsp;consistent with business as usual service support. It does not have the core disciplines required to&nbsp;build and iterate a new service.\n\n**Frequent service iteration (service standard point 19)**  \nThe team have only made relatively minor changes to user journeys whilst adding the “Acquire from&nbsp;trade” and “Sell a vehicle privately” transactions. During private beta the team should be investigating&nbsp;and prototyping many potential solutions to the service’s diverse user needs and expectations.\n\n**A simple, usable service (service standard point 9)**  \nIt is not clear if the 3 vehicle management user journeys make sense as separate transactions. To the&nbsp;user they will appear as 3 separate services on GOV.UK and only complicate a single vehicle&nbsp;management service. Services should not rely on the GOV.UK start pages to remove any uncertainty&nbsp;users may have. This was highlighted when reviewing the relatively complex content of those start&nbsp;pages.\n\n**Service consistency with GOV.UK (service standard point 13)**  \nThe service content does not currently meet GOV.UK style for content design. Some pages are&nbsp;verbose whilst others are unclear on where the user is in the transaction and what they need to do&nbsp;next.\n\nThe service notification emails need to look and feel as though they are from GOV.UK and have&nbsp;consistency with the service. Care needs to taken in the wording of the email, its subject and sender.\n\nThe service uses a non-standard right hand column for display information during the transaction.&nbsp;This may be useful but the team should research variations, checking that users need and see this&nbsp;information.\n\n**Analysing the prototype service’s success (service standard point 8)**  \nThe team have not completed enough contextual research to show that a diverse group of users can&nbsp;succeed unaided, first time. The private dealership users of the current public beta are familiar with&nbsp;the service and have seen the trade user journeys before. The private individual users have mainly&nbsp;been friends and family of DVLA employees. For example, will 'selling' make sense to users if no&nbsp;money is being exchanged in the transfer of ownership?\n\n**Recommendations**\n\n**The Team**  \nTo meet point 2 of the Service Standard the team should:\n\n- have content designers, designers and data analysts as part of the vehicle management team\n- have frontend developers and designers that can create quick prototypes for user research\n- ensure there are enough developers to allow changes to the service based on that research\n\n**Frequent service iteration**  \nTo meet point 19 of the Service Standard the team should:\n\n- continue in private beta allowing enough iterations for more contextual user research\n- prototype as many possible solutions to the needs identified in user research\n- include the entire team, including developers, when viewing user research. GDS recommends&nbsp;a minimum of 2 hours every 6 weeks for every member of the team.\n\n**A simple, usable service**  \nTo meet point 9 of the Service Standard the team should:\n\n- scale up their private beta to include more dealers and private individuals of different types\n- include participants that are not familiar with the service and users that have not used any&nbsp;DVLA digital services\n- conduct a full code review for accessibility&nbsp;Service consistency with GOV.UK\n\n**To meet point 13 of the Service Standard the team should:**\n\n- get content designers trained in GOV.UK style to conduct a detailed review of the service’s&nbsp;content\n- a designer should review the service against the service manual and make changes to the&nbsp;service as necessary\n- review and ensure that the emails sent out by the service are consistent with GOV.UK and&nbsp;carry out research to see how the emails could be improved\n- share and discuss any new design patterns with colleagues across government\n\n**Analysing the prototype service’s success**  \nTo meet point 8 of the Service Standard the team should:\n\n- have someone on the team responsible for data analysis\n- &nbsp;scale up the level of participation in the private beta so that there is enough data from all&nbsp;types of user. This will allow changes to the service to be made, and their outcome tracked,&nbsp;based on data.\n\n**Next Steps**\n\nIn order for the service to proceed we require a reassessment of the criteria not passed.\n\n**Summary**\n\nFor a private beta the vehicle management team are in a good position and already meeting many&nbsp;points of the service standard. The assessment panel were encouraged by the knowledge and&nbsp;commitment of the service team to understand and articulate the user needs of each transaction. With&nbsp;a plan already in place for continued user research, the team have an opportunity to iterate, prototype &nbsp;and test to deliver a service that is simple and intuitive enough that users succeed first time, unaided.&nbsp;The assessment panel look forward to running a reassessment so that Vehicle Management service&nbsp;can be confidently launched as a public beta on the service.gov.uk domain.\n\n* * *\n\n## Reassessment Report\n\nThe Vehicle Management (Acquire from trade and sell vehicle privately) service is seeking permission&nbsp;to launch on a service.gov.uk domain as a Beta service.\n\n**Outcome of service reassessment**\n\nAfter consideration we have concluded the Vehicle Management (Acquire from trade and sell vehicle&nbsp;privately) service has shown sufficient progress and evidence of meeting the Digital by Default&nbsp;Service Standard criteria and should proceed to launch as a Beta service on a service.gov.uk domain.\n\n**Reasons**\n\nSince the previous assessment the service team have shown improvements in the following areas:\n\n**The team (service standard point 2)**  \nThe service team now has the core skills needed to build and iterate the service. Content designers,&nbsp;data analysts and designers are co-located with the team and pairing with GDS where needed.\n\n**Frequent service iteration (service standard point 19)**  \nUser insight and user research sessions are now held weekly at the DVLA. All team members are&nbsp;attending research, with user feedback informing regular iteration and improvement to service&nbsp;transactions.\n\n**A simple, useable service (service stand point 9)**  \nHaving broadened the research to include more members of the public, the team now have a better&nbsp;understanding of the needs of private sellers. The team have made specific user experience&nbsp;simplifications based on their feedback. They have also carried out a full accessibility review.\n\n**Service consistency with GOV.UK (service standard point 13)**  \nThe DVLA and the GDS have reviewed and improved the content and design of the service following&nbsp;service standard styles. The service team are also going to share any non-standard design patterns&nbsp;with colleagues across government.\n\n**Recommendations**\n\nDuring public beta we recommend that the service team focus on:\n\n- Continuing content and design reviews to simplify the language and user experience of the&nbsp;service transactions. More specific recommendations will be provided in a separate&nbsp;document.\n- Prototyping single service solutions without relying on a GOV.UK Smart Answer as a user&nbsp;journey navigational guide. This will become more important as other parts of vehicle&nbsp;management (such as change of address) are included.\n- Trialling remote research sessions with real users of the service who have been identified&nbsp;through the contact centre, to observe their experience first hand, rather than relying on&nbsp;retrospective feedback.\n- Running user research outside of the lab situation using mobile phones and tablets to&nbsp;replicate how private sellers have said they would use the service.\n\n**Summary**\n\nThe service team have demonstrated that they can adapt the way they work, including the skills and&nbsp;experience needed to focus on improvements to meet user needs. This is encouraging to see in such&nbsp;a short period of time. However, we would have liked to have seen more prototyped solutions to&nbsp;address the service as a whole.&nbsp;Moving to public beta will allow testing of the assumption that users can understand the individual&nbsp;transactions of vehicle management, as opposed to single cohesive service for vehicles. The&nbsp;challenge for the service team now will be to iterate based on much more qualitative and quantitative&nbsp;feedback from real users.\n\n&nbsp;\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | Yes | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | No |\n| 9 | No | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | No | 14 | No |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | No | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/share-driving-record-service-assessment-2/",
    "title": "Share Driving Record - Service Assessment",
    "summary": "Share Driving Record is a new service that will allow driving licence holders to share their entitlement and endorsement information to Third Party users and will act as an enabler for DVLA to abolish the paper element of the driving licence. The aim of this service is to provide users who currently use the paper part of the driving licence with a new digital version that can be easily accessed. The service will display the information currently available on the paper counterpart and make it available to share to those who have a requirement to see it.",
    "body": "**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n15/4/2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Hughes\n\n**Service Manager:**  \nD. Ashford\n\n**Digital Leader:**  \nO. Morley\n\n* * *\n\n## **Assessment Report**\n\nThe Share Driving Record service is seeking permission to launch on a service.gov.uk domain as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Share Driving Record service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta service on a service.gov.uk domain.\n\n**Reasons**\n\nThe service meets all the required elements of the digital by default service standard for a beta service. In particular, the panel noted the following points of strength against the standard:\n\n- The service has been built in response to a clear demand from users in response to the existing View Driving Record service, as evidenced by the quantity of feedback asking for this service to be provided.\n- The team has researched needs and tested the product with a range of users, and made changes based on the results of the research.\n- The team has now implemented an approach of observing task-based research rather than leading people through the journey.\n- The team is reducing its reliance on external contractors in a managed way.\n- The team has changed and developed its ways of working based on learning as they go along.\n- There is evidence of improvement over time in the design and quality of the user experience.\n\n**Recommendations**\n\nThe panel makes the following recommendations, which the team should act upon before a live assessment.\n\n- The paper counterpart is due to be abolished in June 2015. It is likely that users will start to rely on this service once that happens. The team should therefore work to bring the service for a live assessment as soon as possible.\n\n- The team should continue to develop its approach to research, as it has already started to do, to identify and test improvements through the observation of task-based research\n\n- There is work required during public beta to make sure the team takes ownership and fully understands decisions about design in respect of security features (so that the security features are appropriate and not excessive for the service, given the risks that pertain to it). For example the team should continue to investigate the usability of the check code and related parts of the process for giving and activating permission to view a driving record, to make sure there is an appropriate and usable level of protection in place given the specific risks relating to the service.\n\n- The team described an API approach based on trusted third parties gaining access to data without use of user generated check codes, with the third parties agreeing to strict compliance policies, and using an API separate from the service. This creates a significant barrier to entry for what is a very simple check, which could be provided as an open API, without any required compliance policies. The team should consider providing an open API as part of this service in line with guidance in the service manual.\n\n- Review their infrastructure requirements in the light of the changes in rules about security since the contract was last let, and ensure the results of this review are reflected in the next procurement of infrastructure\n\n- The team has made a commitment to publish more of its source code - this should be completed before the live assessment.\n\n- There are opportunities to improve further the design and UX during the public beta, particularly in respect of security features and how users respond to those features (including in the telephone and other assisted digital channels). In particular, the team should continue to research questions to establish what security features are needed and how they can best be designed so make them as straightforward for the user as possible.\n\n- The team should carry out more specific research and analysis of assisted digital needs during the public beta, including the need for support outside the current working hours of the call centre and through channels other than the phone.\n\n- The team plans to schedule any releases that require downtime during times when there are no users of the beta service (in the ‘early hours’ of the day), and to keep the timing of releases under review so as to minimise the impact on users of releases. This would mitigate the impact of downtime on users, but it risks acting as a disincentive to doing frequent releases to iterate and improve the service (because of the cost and inconvenience of overnight releases). For the live assessment, the team will need to demonstrate that it has continued to iterate and improve the service, and that its measures to prevent downtime affecting users have been effective.\n\n- As users come to rely on the share driving licence service, particularly once the paper counterpart is removed, it will be important to make sure that planned releases don’t disrupt people’s use of the service. The team should be planning towards implementing zero downtime deployment for this service before it moves from beta to live. The service manager stated that, according to DVLA’s principles for the digital services platform, there should be zero downtime deployment in place. We would agree and expect to see this in place in time for the live assessment.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/employment-intermediaries-beta/",
    "title": "Employment Intermediaries - Beta Assessment",
    "summary": "This is a new digital service that will enable intermediaries (or Agents acting on their behalf) to comply with legislation by uploading a report to HMRC providing details of the workers they supply, and the payments they have made to those workers, where they did not operate Pay As You Earn. The intermediary will have to upload and send HMRC a report that contains the information once every 3 months using this service.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n24 March 2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nA. Keene\n\n**Service Manager:**  \nA. Flynn\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**  \nAfter consideration, the assessment panel have concluded that the Employment Intermediaries service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta service on a service.gov.uk domain.\n\n**Reasons**  \nThe panel felt that the service team demonstrated a commitment to place continual user research at the heart of the service development. The team had evolved their methods of research from emailed on-line questionnaires, through Skype interviews, to attending trade expos, to face-to-face user testing. The service team had also shown an understanding of the advantages and disadvantages of the different methods of interaction with their users. They had conducted extensive and, in in the panel’s opinion, sensible research to uncover users with assisted digital (AD) needs. The panel agreed with the team that, currently, there is no identified need for AD support for this service.\n\nThroughout the assessment, the panel found that the service team showed a depth of understanding of their users needs, based on their research.\n\nThe panel also found the Employment Intermediaries team to be a strong multi-disciplinary team, headed up by an empowered Service Manager. The panel was impressed to see that the team coped well with the loss of their User Researcher, with the role taken on by their User Experience Designer. However, the panel do expect the team to have a replacement User Researcher before they return for a Live assessment.\n\nThe service team is well supported by the tax platform - they showed an understanding of how they use and interact with the platform and have also given something back, in the form of PDF rendering.\n\nThe team have shown the panel how they have deployed frequently, at least weekly, since launching private Beta. They demonstrated the evolution of the service in the assessment from the initial Alpha sketches, through the private Beta minimum viable product, through to the current service.\n\nThe team presented a credible plan for the evolution of the service through public Beta through to Live.\n\nAdditionally, the panel also found that the team demonstrated a sensible approach to the management of the service data, management of their key stakeholders and the attendant risks, in line with government practice. The panel were glad to see that improvements had been made since Alpha.\n\nThe team have immediate plans to open up validation engine code, to support the external software providers, who will in turn support your service users, with plans to open up further.\n\nThe team also demonstrated the use of open source tools and open standards to avoid vendor lock in and forcing software choices on their users.\n\n**Recommendations**  \nThe assessment panel believe that the service team need to be planning for what happens next for Government Gateway.\n\nThe service team need to ensure they have a User Researcher embedded, before they return for the Live assessment.\n\nThe assessment panel also advise that the team start releasing code into open public repositories for re-use, ideally starting with the validation engine code.\n\nThe panel believe that the service team should investigate if there are alternative ways to satisfy the legislation. The current user journey places a non-trivial reporting burden on organisations. Are there alternative sources of this data, or could the data could be collected and collated from several existing sources? If not, could this data be collected through another existing reporting system?\n\nThe team need to be able to provide a cost per transaction for the service. To do this, the service team need to work with, and encourage, colleagues in HMRC finance to develop a method of apportioning costs from shared services (e.g. the tax platform).\n\nThe assessment panel recommend HMRC move their pre-live service away from the internal VPN, to behind a password. This would save the trouble the service team had in the assessment with the demo, and should also make testing with users in the field easier.\n\n**Summary**  \nThe panel want to take this opportunity to thank the service team for their hard work in developing the service and for attending the service assessment. It is clear that there is a passion for user research and continual improvement within the team, and the team are striving to learn more about their users and to develop their continually acquired skills in service development.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | N/A | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/nhs-e-referral-service-assessment/",
    "title": "NHS e-Referral - Service Assessment",
    "summary": "The NHS e-Referral Service will succeed the current Choose and Book (CAB) service. CAB has been live in the NHS in England for 10 years, with over 60 million patient referrals being processed since then.",
    "body": "**Department / Agency:**  \nDH / HSCIC\n\n**Date of Assessment:**  \n12/05/2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Hughes\n\n**Service Manager:**  \nB. Gildersleve\n\n**Digital Leader:**  \nA. Bye\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**  \nAfter consideration, the assessment panel have concluded that the NHS e-Referral service should be given approval to launch as a Beta service. This means that the service is ready to be made available to the public on a beta basis, whilst continuing to be developed and improved for live.\n\nThe panel have, as requested, assessed the service against the beta criteria, but are concerned that, in reality, there is no planned beta phase for the service (see further detail on this below). According to the definition of a ‘live’ service, the plan to launch the service will mean it will effectively be live from 15 June 2015, since the existing system will be turned off at that point and all users will be using the new system instead.\n\nMoving straight from alpha to live in this way without a period of beta testing is not recommended by the panel. The panel note that in this particular circumstance it would be very difficult (though not impossible) to do a phased beta launch given the complexity and scale of the system, and they recognise that the team has done a lot of work in advance to minimise the risk of things going wrong - this work is recognised as being valuable. However, the risk and impact of failure given the complexity and scale of the system are the precise reasons why a beta phase is recommended for new digital services, rather than a big bang launch.\n\nThis successful beta assessment should not be interpreted as a de-facto approval of this approach. To approve the move into ‘live’, the service needs to undergo a live service standard assessment. At this stage, the panel think it is unlikely the service would pass such an assessment, because there is work still to be done during the beta phase to fully meet the criteria for a live service. The panel have made recommendations in this report to help the team take action to meet the required standards.\n\nThe assessment panel recommend that the service be submitted for a live assessment at the earliest opportunity, and definitely within 3 months of the service going into production.\n\n**Reasons**  \nAt the last beta assessment, the assessment panel proposed two possible ways forward for the service. The team has chosen the option that involved prioritising replacing the legacy technology whilst maintaining the user experience broadly as it is under the old system (although the team has made improvements to the user interface based on feedback and research), providing a basis for further iteration and improvement.\n\nThe assessment panel think it would have been preferable, possible, and more consistent with the approach laid out in the Digital by Default Service Standard and the Service Manual, to transform the service more fully end to end from the outset. But the panel accept that the option the team has chosen represents a significant step forward, replacing legacy technology with a service that can be iterated and improved over time. The team is clearly committed to improving and iterating the service once it is in beta.\n\nObviously it is important that the team now fulfils its clear commitment to improve the service over time - the risk is that once the first phase (technology replacement) is achieved, investment for and commitment to ongoing improvement starts to wane. The panel were convinced in the beta assessment that the team is committed and is putting resources in place to do this and, on this basis, were satisfied that the relevant beta criteria are met through this option.\n\nSince the previous beta assessment of the service, the team has made a lot of progress and the service is now much more clearly on track to meet the required criteria. In particular:\n\n- The team has carried out some user research using a prototype and has developed a backlog of prioritised needs which it plans to work on after the service goes into production, and it has plans in place to carry out ongoing user research.\n- The team has developed a prototype for a new patient-facing service, using agile, user-centred methods - it is currently at prototype / alpha stage but if the team continues to test and develop that element of the service using these methods, the panel are confident it will represent a big improvement in the quality of the service for patients.\n- The service is already on[gov.uk/performance](http://gov.uk/performance), and the team has plans to expand the range of measures included on the dashboard during the beta.\n- The team has made significant progress in its understanding of assisted digital user needs and how support might be delivered, and has plans to test and develop support during the beta.\n\n**Recommendations**  \nThe assessment panel have seen sufficient evidence that the team is on track to meet the service standard requirements to pass a beta assessment, but to meet the requirements for live, the panel believe that the team will need to complete some of the work still underway in relation to some aspects of the service standard. These elements are as follows.\n\n- iteration and improvement - the team is planning to monitor analytics and carry out ongoing user research to inform the future development of the service. It’s not possible for the team to do this until the service goes into production, because the legacy system doesn’t allow for analytics or frequent iteration. For a live assessment, the team would need to demonstrate evidence that it has iterated and improved the beta service on the basis of analytics and research.\n\n- research and analytics - The team recognises the importance of analytics and has a broad understanding of how they can use them to improve the service. During the beta they will rapidly need to further develop their plans and capability to match their aspirations to use analytics to improve the service. This includes having a clear point of responsibility and capacity to carry out the required analysis.\n\n- The team is placing a lot of emphasis on the value of analytics in the new service, but has not yet put in place the capability that will be required monitor and interpret the analytics, and is still recruiting for 3 research posts within the team. This capability will need to be fully in place and working, with evidence of frequent user research and analysis taking place and feeding into ongoing improvements, in order for the service to meet the requirements for a live assessment.\n\n- design capability - the team does not include any designers - to fulfil the team’s commitment to ongoing iteration and improvement, it will be essential to fill this gap. The plan is to do this through new contractual arrangements with the development partner. For a live assessment the panel would need to see evidence that the design capability is fully embedded in the team and its ongoing development processes.\n\n- assisted digital - the team has assisted digital support in place for beta that will effectively complete the transaction on behalf of people, either in person or on the phone. The team plans to extend and develop the assisted digital offering to provide support for people to complete the transaction themselves. Research should be undertaken with assisted digital users at each point of the user journey to demonstrate how assisted digital support meets user needs.\n\n- publishing code - the team has not yet established its policy for opening its code (this is partly contingent on corporate decisions within the organisation), or published any components of it, although it is sharing code within the organisation and is using and contributing to open source tools. The team has identified some components that can be published during the beta, and for its new patient-facing service will start publishing code as that part of the service moves into beta. The panel were satisfied that there was sufficient potential to meet the requirement for a live service, providing the team makes significant progress during the beta phase in developing its formal policy and releasing its code.\n\n**Use of design patterns and style guide -**  \nThe service going into beta does not use the[GOV.UK](http://gov.uk/) design patterns and style guide, because of the phased approach the team has taken (tech first, UX iteration on that basis), a decision that the panel have accepted based partly on the lack of ability to measure and improve the legacy system’s user interface. The panel have accepted that this approach is sufficient for starting the beta phase, assuming that the team is going to iterate and improve the service, with significant design input, from the start of the beta onwards. To meet the requirements for Live the service will need to have gone through some significant iteration and design improvement to meet this criterion, based on user research and design work in the context of[GOV.UK](http://gov.uk/) and[NHS.UK](http://nhs.uk/).\n\n**Summary**  \nThe panel would like to recognise and congratulate the team for the progress it has made in a complex technical, operational and stakeholder environment.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/redundancy-payments-claim-for-redundancy-claims-and-monies-owed-service-assessment/",
    "title": "Redundancy Payments: Claim for Redundancy Claims and Monies Owed - Service Assessment",
    "summary": "This assessment covers the “Claim for Redundancy Claims and Monies Owed” (RP1) component of the Redundancy Payments service. RP1 is the primary Redundancy Payments service, allowing users to claim their initial entitlements of redundancy, arrears of and holiday pay owed.",
    "body": "**Department / Agency:**  \nBIS / IS\n\n**Date of Assessment:**  \n5/3/2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nN. Williams\n\n**Service Manager:**  \nG. Ecart\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## **Assessment Report**\n\nThe Claim for Redundancy Claims and Monies Owed (the first stage of the two-stage Redundancy Payments service) is seeking permission to launch on a service.gov.uk domain as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Claim for Redundancy Claims and Monies Owed service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta service on a service.gov.uk domain.\n\n**Reasons**\n\n_User needs, research and design_\n\nThe service is meeting well-understood needs, and being developed iteratively in accordance with the service manual by a high-functioning, multidisciplinary team.\n\nThe assessment panel were particularly impressed by the degree to which the team has done the hard work to replace a long, complex form with a much simpler digital service. The team has challenged every question and are only asking for information which is needed. The team has iterated the service well, incorporating learnings from user research, to make each step of the form intuitive. The panel were pleased to see the extent to which user research has been embedded into normal working processes, covering the full range of the service’s users, and that plans are in place to continue on this basis. The paper checklist that has been created to help users gather the information they need beforehand is also well thought through.\n\n_Assisted Digital_\n\nOn Assisted Digital (AD), the team has done a thorough job of speaking to users of the service with all levels of digital ability, building a good understanding of their support needs. Testing plans are in place for all channels during the Public Beta, including with non-government agencies delivering face-to-face support.\n\nThe service's&nbsp;AD support includes signposting to other government services related to the user’s situation, in line with the on-screen service - the panel were pleased&nbsp;to see AD users getting the same consideration as users who complete the digital service independently. The AD support also includes digital inclusion approaches through scripting and signposting. Needs assessment is in place within the phone support, for the issuing of face-to-face support.\n\nThe service team knew the cost of phone support, and are budgeting a comfortable contingency for provision of face by face support, the final cost of which will be confirmed during the Public Beta.\n\n_Technical design and security_\n\nThe team has had sensible conversations, and the service manager understands, the security and fraud risks relating to running the service. The team will be increasing the length of time sensitive data is stored for Beta (save and return) and the panel believed&nbsp;the team are executing this in a sensible manner.\n\nIt is good that the team&nbsp;has pulled out ‘form-monkey’, a library for creating forms, from the&nbsp;core code base with plans to open source it. The panel hopes to see this gain further documentation so that it could be shared with the wider government.\n\nThe&nbsp;team appeared empowered to make and own technical decisions, and it was impressive to see how content changes and&nbsp;code deploys had been decoupled, enabling&nbsp;the team's&nbsp;content editors to be more responsive to change.\n\n**Recommendations**\n\nAt the next assessment, the panel will need to see convincing evidence that the service manager and product manager will have access to permanently-funded, dedicated developers with the skills and knowledge to operate and improve the service. The service will not pass live assessment&nbsp;without this dedicated resource in place and a clearly defined support model.\n\nThe team&nbsp;showed that you have volumetrics data, but this is&nbsp;yet to be submitted to the performance platform. It is important to get this to the performance platform team as soon as possible to help the service&nbsp;track and share improvements.\n\nThe team must also confirm that face-to-face AD&nbsp;support has the capacity to cope with varying demand, both geographically and over time.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/rural-payments-service-assessment/",
    "title": "Rural Payments - Service Assessment",
    "summary": "The Rural Payments digital service is the new way to register for the Basic Payment Scheme (BPS) and other rural payment schemes.",
    "body": "You can also use it to keep your personal and business details up to date, and to give someone permission to do your application for you.\n\n**Department / Agency:**  \nDEFRA / RPA\n\n**Date of Assessment:**  \n29/1/2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nNot Passed\n\n**Lead Assessor:**  \nJ. Thornett\n\n**Service Manager:**  \nG. Portman\n\n**Digital Leader:**  \nJ. Pierce\n\n* * *\n\n## **Assessment Report**\n\nRural Payments service is seeking permission to launch on service.gov.uk as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded that although the Rural Payments service has made significant progress since November’s mock beta assessment, the service does not yet meet the beta standard requirements of the Digital by Default Service Standard. Nevertheless, this is a complex service that has made tremendous progress in recent months, for which the service team deserve considerable credit. The panel believes that it is an achievable goal to pass the three outstanding points before the service is due to enter the next phase.\n\n**Reasons**\n\nThe team has made substantial progress building the service, and it was particularly encouraging to see improvements to the delivery structure so that responsibility for decision making lies with the service manager, and product teams are able to make frequent changes to the front-end application.\n\nThere is a good understanding of the users that will be required to use the service, and the team’s approach to assisted digital (AD) support in particular is exemplary. The team has developed telephone and face-to-face support based on well-researched user needs and delivered this through appropriate government agencies and the third sector. The team proactively contacted potential AD users to make them aware that support is available and is testing a triage process. The team demonstrated that they are working closely with the support providers and are reacting quickly to feedback to improve the digital service, reducing the need for offline contact. Support has been designed to be scalable to cope with a likely peak in demand close to the claim deadline.\n\nThe service should now work to provide evidence of the following, that:\n\n- The service is simple and intuitive enough that users succeed first time, unaided.\n- The service is consistent with the GOV.UK design patterns and style guide.\n- All new source code is open, re-useable and published under an appropriate licence wherever possible.\n\n**Recommendations**\n\n_Service design & GOV.UK style_\n\nThe team needs to address front-end development style; services on GOV.UK must work across a variety of browsers including on mobile and tablet (over 10% of page views of the service's start page are on mobile or tablet). Where pages are not responsive, clear warnings should be given to users on unsupported devices.\n\nThe recommendations from the accessibility report should be implemented. The team should check that all concerns at Web Accessibility Initiative (WAI) levels A & AA have been mitigated.\n\nIf AngularJS is used throughout the service. Care needs to be taken that users can use the service with limited bandwidth and that page changes are clear to the user. A fallback version of functionality that works without JavaScript should be considered throughout the service.\n\nAll pages should be checked to make sure that interactions conform to the current GOV.UK style guide. New interactions that have been developed, such as mapping, should be fed back into the design patterns Hackpad to see if they can be reused across other government services.\n\n_Focus on users succeeding first time_\n\nHard deadlines stretching into 2016 appear to be putting considerable pressure on the team to deliver new functionality. Consequently, functionality does not appear to be being routinely developed iteratively based on user research and analytics. The service needs to ensure there is enough capacity in the teams to make the service better whilst continuing to add functionality.\n\nThere should be a designer, content designer, user researcher and front-end developer in each scrum/product team to improve the speed of delivery, and to allow more iterative improvements to user journeys through the service.\n\nDesigns should be prototyped and put into user research before complete implementation, and new functionality should ideally be trialled first with a subset of users to ensure it meets user needs. Live analytics should supplement in person user research, and functionality iterated until users can complete the prototype unaided and understand the process.\n\n_Make source code open_\n\nDefra owned source code being developed in-house by the service team should be published in the open and made available for others to reuse.\n\n**Summary**\n\nThe team have been making great strides in building the Rural Payments service in recent months, and have demonstrated the ability to make significant changes to the service and the way it is being delivered since their alpha assessment. The service is on course to meet the Service Standard and it is expected that, at the current rate of progress, the service will meet the beta standard in the imminent future.\n\nEssential feedback from the first users who have registered with the service is being gathered, and by adding this information to continued user testing and iterative improvement, the team is heading in a good direction for the future development of the service.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | No | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | No | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/immigration-health-surcharge-service-assessment-2/",
    "title": "Immigration Health Surcharge - Service Assessment",
    "summary": "The Immigration Health Surcharge is a key measure in the Immigration Act 2014. Temporary, non-EEA migrants coming to the UK for more than six months will be required to pay this fee in order to access the NHS before they are granted leave to enter/further leave to remain in the UK.",
    "body": "**Department / Agency:**\n\nHome Office\n\n**Date of Assessment:**\n\n9/3/2015\n\n**Assessment stage:**\n\nBeta\n\n**Result of Assessment:**\n\nNot passed\n\n**Lead Assessor:**\n\nM. Harrington\n\n**Service Manager:**\n\nS. Cooper\n\n**Digital Leader:**\n\nM. Parsons\n\n## **Assessment Report**\n\nAfter consideration, the assessment panel have concluded the Immigration Health Surcharge service should not be given approval to launch on the service.gov.uk domain as a Beta service.\n\nThe service team have clearly made significant progress since the alpha assessment, however, the panel were concerned that there were still many things to do in the short time left before the planned beta release date.\n\n**Reasons**\n\n**User needs**\n\nThe latest iteration of the registration journey had only been tested in one round of research. The panel feels that this should be tested with more users so the team are confident that the majority of users are succeeding first time.\n\n**The Team**\n\nThe team would benefit from greater familiarity with the [operations guidance](https://www.gov.uk/service-manual/operations/web-operations-stories) in the service design manual. Some of the operations responsibility is being outsourced, but there wasn’t a clear sense of ownership about who was responsible for the service being available.\n\n**Security, Privacy, Tools, and Standards**\n\nRelated to the issue with team knowledge about operations, the service team did not seem to be familiar with the [conversations](https://www.gov.uk/service-manual/operations/web-operations-stories) that should have happened when running a digital service. The panel observed no appreciation for what a modern monitoring and alerting solution should look like. The panel also found there was no convincing answer about who owned what part of the service, when tested with some sample scenarios.\n\nThe Home Office had apparently issued guidance on the day of the assessment about how code can be published by Home Office projects. The panel welcomed this news, and eagerly awaited a link from the service team to code on the internet. The panel would also like to see that code being the live repository, rather than a periodic dump of the code.\n\nThe service is designed as an API (but hasn’t been exposed as that). The assessment panel hope that publishing the source code will lead to other services learning how to expose similar functionality in that manner. It should also provide working code for ideas that could potentially be taken to the Standards Hub; for example, JSON Web Tokens and a delegated authorisation model.\n\n**Improving the Service**\n\nA digital service designed for users around the globe should not require any downtime for deployments. The proposed mechanism did not appear well-tested (custom scripts per environment) and no configuration management appears to be used. Consequently, deployments would not be regular, automated, low-risk activities, but would require manual intervention and babysitting. Blue-Green deployments are a standard, proven way of doing this across the industry.\n\n**Assisted Digital and Channel Shift**\n\nThe panel found that there has been a good amount of progress on Assisted Digital (AD) since the alpha assessment and the team presented a much better understanding of this at the beta assessment. However, the panel had some concerns that the support is based around existing structures rather than meeting user needs.\n\n**Analysis and Benchmarking**\n\nThe team have a lead in place for analytics however the service has not yet been instrumented and more time needs to be spent on understanding what good looks like and how this will be measured.\n\n**Recommendations**\n\n**User needs**\n\nThere has been a considerable amount of user research done since the alpha assessment, and user needs are becoming more well understood. The team should continue to test and iterate, especially the latest journey for the stand alone service. While not a requirement to reach beta, the service may benefit from having another user researcher to help support the team.\n\n**The Team**\n\nTo meet point 2 of the Service Standard:\n\n- The service manager and team should ensure they are familiar with the [operations section of the service manual](https://www.gov.uk/service-manual/operations), and should not underestimate the amount of work that is required.\n- The team should have a clear understanding of the monitoring requirements taking the monitoring stories as a starting point and be able to clearly articulate who is responsible for what and what actions would be taken if there is an issue with any part of the service.\n\n**Security, Privacy, Tools, and Standards**\n\nTo meet point 5 of the Service Standard:\n\n- This point is closely linked to point 2. The team should have suitable tools in place to monitor the service to understand when there is an issue and what it is. Google Analytics is not a suitable tool for monitoring the complete performance of the service.\n\n**Improving the Service**\n\nTo meet point 14 of the Service Standard:\n\n- Be able to evidence that taking down a worldwide service for up to two hours to make a database change does not impact on users.\n\nOnce in beta the team should:\n\n- Continue to evaluate whether having a single database is the right solution for a service such as this.\n- Take the time to automate their deployment.\n\n**Assisted Digital and Channel Shift**\n\nTo meet point 10 of the Service Standard the team should:\n\n- Carry out more research to understand the AD support that users receive from providers other than the department’s own customer support services. The service has an understanding of friends and family support but should focus on support groups, including those mentioned in the assessment who haven’t yet been tested with.\n- Design a model of support based on user needs rather than around existing channels.\n\nOnce in beta the team should:\n\n- Confirm that the AD support could be scaled to meet demand for live. This should be reviewed throughout beta to include an understanding of costs and whether all channels of support (via all providers) are sustainable.\n\n**Analysis and Benchmarking**\n\nTo meet points 7,18, 21, 22, 23, 24 of the Service Standard the team should:\n\n- Install and configure analytics. This is on the backlog but not yet done.\n- The team should consider other KPIs which will give them insight in to how the service is performing in addition to those mandated by the Service Standard.\n- For the beta, which is a stand alone solution, a done page should be in place to collect user satisfaction.\n- Have a performance platform dashboard.\n\n**Design**\n\nA list of design recommendations has been provided separately. The assessment panel recommend further testing on mobile devices, especially those popular in countries with high volumes of applications.\n\n**Summary**\n\nThough the service did not pass the assessment, there were many positives to take and the recommendations in this report are within the capability of the team to complete. The panel were pleased to see the focus on user needs and how this has continued to evolve since the alpha assessment. There has been a significant amount of research and it is clear to see the benefit this is having on the service and the team.\n\nThe team structure and the agile way of working has been iterated and the panel were pleased to hear the three key learnings from the alpha were: co-location, user research standups and better sharing of stories, ideas, walls, etc. The panel were also pleased to hear how the team have challenged the accepted way of doing things, especially with regards to copy and terminology to provide a better service for the user. With regards to AD, the panel were pleased that scripts had been prepared for the call centres, that plans were in place to measure volumes and gain insights about the support provided and that the service were investigating how international call centres may be able to offer AD support. Ultimately, the panel felt the service came in for assessment a little too early but expect it to be able to meet the points of beta soon.\n\n_Note: subsequent to this assessment the Home Office Digital Leader has confirmed that he, and the programme SIRO and SRO have approved the service and that the Home Office takes full responsibility for launch._\n\n_The Home Office Digital Leader has also confirmed that the Immigration Health Surcharge project will:_\n\n- _&nbsp;pass a service standard reassessment (including integrating the customer journey) by the end of July_\n- _&nbsp;continue to iterate the service based on user research_\n- _&nbsp;provide a formal monthly progress update, starting with a fully resourced plan and timeline to address all service assessment recommendations_\n- _&nbsp;have alpha branding on the service until a reassessment is passed (at which point it will be branded a beta service)_\n\n_The service has been allowed to be made public, as an alpha service._\n\n## **Digital by Default Service Standard criteria**\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | Yes | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | No | 6 | Yes |\n| 7 | No | 8 | Yes |\n| 9 | Yes | 10 | No |\n| 11 | N/A | 12 | Yes |\n| 13 | Yes | 14 | No |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | No |\n| 19 | Yes | 20 | Yes |\n| 21 | No | 22 | No |\n| 23 | No | 24 | No |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/pay-hmrc-beta/",
    "title": "Pay HMRC – Beta Assessment",
    "summary": "This service will allow users to make payments to HMRC online via credit and/or debit card.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Original Assessment:**  \n2 December 2014\n\n**Date of Reassessment:**  \n12 February 2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Original Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nA. Lister\n\n**Service Manager:**  \nO. McGuire\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## **Reassessment Report**\n\nThe HMRC Payment Service has been reviewed against the points of the Service Standard not passed at the original beta assessment (points 1, 8, 9, 13, 17 and 18).\n\n**Outcome of reassessment**\n\nAfter consideration the assessment panel have concluded the HMRC Payment Service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard to pass their beta assessment.\n\n**Reasons**\n\n**User needs (Point 1 of the service standard)**  \nThe service team demonstrated a comprehensive and in-depth knowledge of the service’s users. This understanding was gained from frequent and substantial lab and pop-up user research sessions. In addition around 600,000 users have used the beta service with 385,000 users providing feedback.It was encouraging to see that the team is testing and iterating the service in response to a range of research inputs. Improvements and enhancements based on these inputs was well demonstrated at the assessment.\n\nForward planning for user research and iteration is both comprehensive and robust.\n\n**Use of analytics (Points 8 and 18 of the service standard)**  \nOverall, the approach to analytics and generating actionable insight was well understood. However, there are two routes to the service and a reliable method of measuring the service as a whole needs to be defined. Similarly, the cost per transaction needs to be calculated accurately.\n\n**Create a service thats is simple and intuitive (Point 9 of the service standard)**  \nOver the peak self-assessment period in January 2015, over 600,000 people successfully used the service. This clearly demonstrates that the service is both useful and usable. The continuing research and analytics input will ensure the service continues to be simple and intuitive.\n\n**Consistency with GOV.UK (Point 13 of the service standard)**  \nResearch showed that the transition to pages that did not contain the familiar GOV.UK or HMRC branding caused users to question the legitimacy of the service. These pages have been reworked to reflect core GOV.UK branding. The team has dedicated content design resource and a front end developer. There are minor design issues on some pages, but these are easily rectified with support from the GOV.UK team.\n\n**End to end testing (Point 17 of the service standard)**  \nThe service team demonstrated the service processing real payments during the assessment. Large volumes of users have left feedback on the services and end to end testing is undertaken frequently.\n\n**Recommendations**\n\nHigh volumes of feedback will prove difficult to analyse, the service team needs to define an approach, possibly through segmentation, that allows manageable amounts of feedback from reliably identified groups of users.\n\nThe service team should continue to work closely with the GOV.UK teams to ensure that minor design and content inconsistencies are addressed as soon as possible.\n\n**Summary**\n\nThe service team presented a robust, coherent and comprehensive view of their service which demonstrated a thorough understanding of iterative delivery based on user needs.\n\n* * *\n\n## **Original Assessment Report**\n\nThe HMRC Payment service is seeking permission to launch on a service.gov.uk domain as a Beta service.\n\n**Outcome of original service assessment**\n\nAfter consideration the assessment panel have concluded the HMRC Payment service should not be given approval to launch on the service.gov.uk domain as a Beta service.\n\n**Reasons**\n\nAlthough the assessment panel considers that the service isn’t ready for Beta status we’d like to stress that all of the components for success are in place. The HMRC team showed capability and commitment and for reassessment, the panel would like the team to ensure the elements explained below are demonstrated as a coherent approach to the service’s development. The panel fully understand the complexity and constraints the team is working within and would highlight the outstanding work the Service Manager is doing to progress this delivery.\n\n**User needs (Point 1 of the service standard)**  \nUser needs are the foundation of the service standard. Although the HMRC team demonstrated that research was being undertaken frequently there were noticeable gaps between the research activity, identifying actionable improvements, integration into production and measurement. Specifically:\n\n- the sample recruitment brief is extremely niche, describing users most likely to succeed with the service\n- the methods used during research to identify user needs and actionable insights were not clear\n- user stories were presented in business requirement language, not as service users would naturally express themselves\n- convenient payment was highlighted as a key requirement for people choosing to pay by card, yet providing the correct payment amount as a default value has not been prioritised due to the complexity of some back end work. Doing the hard work to make it simple is a key design principle which this service is not currently demonstrating.\n\n**Testing the end-to-end service (Point 17 of the service standard)**  \nA significant part of the service is operated by a third party. With a hybrid digital service such as this, end to end testing is of paramount importance. The assessment panel saw limited evidence of this. Specifically:\n\n- the beta service standard requires that the service can be demonstrated end-to-end with all components in place. This wasn’t possible without skipping between environments and simulations.\n- it was understood that an ‘available at the point of need’ service is required - paying by card is about user-convenience and current data shows that this means tablets and smartphones. However, the service’s design is not currently responsive and retrofitting this will be a significant challenge.\n\n**Design (Points 9 and 13 of the service standard)**  \nThe visual design was largely compliant with the GDS toolkit. However the challenges around comprehensive testing, described above, continue to hamper meaningful end-to-end testing of visual design, content and interactions with a broad spectrum of users and a range of devices. Specifically:\n\n- evidencing that the service is ‘simple and intuitive’ requires objective research with users of many different abilities using many different devices. Beyond the lab research sessions, the service was tested with ‘ten tame users’ in Dorset House. This wouldn’t be considered sufficiently objective to gain meaningful, actionable insight\n- although content and user experience expertise is available in the team, the components of the service shown evidenced disconnect in terms of close collaboration and having ‘the right people in the same room’\n\n**Analysis and benchmarking (points 8 and 18 of the service standard)**  \nIt’s accepted that the current service cannot be benchmarked as analytics are not installed. It’s also essential that the new service meets user needs. The assessment panel was concerned that the inability to test a complete service hinders this objective. Specifically:\n\n- as referenced previously, there’s no end-to-end ‘live-like’ test environment\n- the team had plans to integrate their analytics into the service’s dashboard but was unclear as to the analytics account in use\n- HMRC’s decision not to bespoke the commercial product has limited the amount of web analytics available.This is a concern as much of the complexity of the service happens within those components. The team should be able to demonstrate that their analytics tool allows them to gather actionable insight.\n\n**Recommendations**\n\nThe assessment panel recognised that the HMRC team had done significant work to implement the recommendations of the Alpha assessment and this indicates a clear commitment to building a high quality service. To be ready to pass a beta assessment the team should address the concerns above and the recommendations below.\n\n**User needs and Design (Points 1, 9 and 13 of the service standard)**  \nAlthough the panel understand that this service is being driven by commercial and technical imperatives, the focus on meeting user needs must remain at the forefront of the team’s thinking. The majority of the service standard points which were not passed concern:\n\n- how user needs are identified\n- how actionable insight is derived from that research\n- the methods for progressing features into production and measuring against the service’s key performance indicators\n\nWe would therefore re-iterate the recommendations from the alpha assessment. Specifically:\n\n- stronger user stories are developed and expressed in natural language\n- a ‘real’ fully coded end-to-end service is used for user research\n- a broader, more representative user research sample is recruited\n- user research is wholly objective rather than focussed on proving a predetermined outcome\n- all paths through the service are evaluated using live or ‘live-like’ journeys - including the commercial components and journeys which include, or conclude with, error messages/pages\n\n**Analysis and benchmarking (points 8 and 18 of the service standard)**  \nA thorough grasp of the service’s approach to analytics is required to ensure that the correct measurements are baked into the service throughout development rather than considering them later in the process.\n\n**Testing the end-to-end service (Point 17 of the service standard)**\n\n- For the reassessment be able to demonstrate the end-to-end service with all components in place.\n- Be able to demonstrate that the design is responsive and can be used on common browsers and devices.\n\n**Support and Operations (points 5 and 25 of the service standard)**  \nWhile it’s understood that much of the operational support for the service will be provided by a separate team, it’s critical that there are strong plans in place to deal with failure scenarios. Plans should be developed so that the team operating the service have the capability to act to resolve issues without relying on development staff who are not formally supporting the service. e.g. steps required to increase the number of instances of the application.\n\nIn addition to the recommendations above which should be addressed before reassessment, the below should also be considered.\n\n**The Team (point 2 of the service standard)**  \nAdditionally, the value of getting the team together in the same physical location shouldn’t be underestimated. The team should take every opportunity to work ‘in the same room’ across the lifecycle of user research through story-prioritisation to analytics and evaluation.\n\n**Assisted Digital (point 10 of the service standard)**  \nHMRC provides many different online and offline ways for users to pay tax liabilities and each of the individual HMRC services which use this payment service are developing appropriate assisted digital support for their specific users. Therefore specific assisted digital support does not need to be provided for this service in line with GDS policy but this should be reviewed if the range of HMRC payment options is reduced.\n\n**Testing with the Minister (point 26 of the service standard)**  \nFor services processing or likely to process more than 100,000 transactions per year, the Minister should test the service before it goes live.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/waste-carrier-registration-service-assessment-2/",
    "title": "Waste Carrier Registration - Service Assessment",
    "summary": "Waste Carrier Registration service&nbsp;allows businesses who carry, broker or deal waste to fulfil their regulatory requirement to register with the Environment Agency. &nbsp;Some users, including those that only carry waste from their own business, pay no fee (lower tier). Other&nbsp;users, who carry wastes for others, pay a fee for registration (upper tier). For upper tier users, registrants are checked against a list of relevant convictions. &nbsp;The service also publishes the list of registered carriers.",
    "body": "**Department / Agency:**  \nDEFRA / EA\n\n**Date of Original Assessment:**  \n5/8/2014\n\n**Date of Reassessment:**  \n10/3/2015\n\n**Assessment Stage:**  \nBeta\n\n**Result of Original Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nC. Mitchell\n\n**Service Manager:**  \nP. Moore\n\n**Digital Leader:**  \nJ. Pierce\n\n* * *\n\n## Reassessment Report\n\n**10th March&nbsp;2015**\n\nThe Waste Carriers Registration service&nbsp;has been reassessed against points 2, 4, 9, 10, 13, 14, 15 & 26 of the Digital by Default Service Standard.\n\n**Outcome of service reassessment**\n\nAfter consideration the assessment panel have concluded that the Waste Carriers Registration service should be given approval to launch on the&nbsp;[service.gov.uk](http://service.gov.uk/) domain as a Beta service.\n\n**Reasons**\n\nThe service has made considerable progress in achieving the standard criteria under&nbsp;reassessment, and has responded well to the recommendations made at the last assessment.\n\nThe quality of the digital product itself has shown substantial improvement. Whilst there are still some outstanding bugs including a significant issue relating to email confirmation, the team have demonstrated the&nbsp;ability to rapidly fix, iterate and improve the service to address these issues.\n\nAs well as building capability within the team,&nbsp;reliance on external suppliers has been reduced, and the team are moving towards a much more agile and user-focused way of working.\n\nTechnical operation of the service has also improved, with clear responsibilities, effective monitoring and tried and tested processes to ensure user data is protected, and the impact of outages minimised.\n\nThe service team have demonstrated an understanding of their assisted digital (AD) users and their needs, as well as making sensible decisions to to try and meet those needs. Plans are in place to test the AD service, and while there is still work to do to ensure scalability and continuity of service, the team is on track for this stage of development.\n\n**Recommendations**\n\nOpportunities were identified for further improvement towards the “live” standard, with recommendations listed below.\n\n**Point 2** – Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.\n\n- The Team have progressed well here, though there remains a reliance on a single person to perform design, content design and front-end development.\n- **Recommendation** : continue with plans to build extra capacity in this area and create a separation of roles.\n\n**Point 9** – Create a service that is simple and intuitive enough that users succeed first time, unaided.\n\nThe digital service has improved considerably since the last assessment, though some bugs remain, particularly around management of sessions and content.\n\n- A significant issue relating to email confirmation and the user flow that were previously identified in prior assessments had not been addressed. [Guidance](https://designpatterns.hackpad.com/Email-confirmation-loops-rJlwfm9N3QA) (previously provided) is available.\n- **Recommendation** : It is strongly recommended that email confirmation be reconsidered for removal. If the service does continue to use email confirmation, the user interface (UI) must be improved as a matter of priority.&nbsp;The other bugs should be added to the product backlog to be prioritised and fixed as part of the normal development cycle.\n\n**Point 10** – Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it.\n\n- Good progress has been made here, though work is required to move towards a fully tested and sustainable service able to meet the Service Standard for live.\n- The service team will need to confirm that the AD support channels across all providers has capacity to support users currently getting AD from friends and family (because this is not a sustainable source of AD). The team will also need to carry out fuller research to confirm suggestions that there is no AD being provided beyond the department’s own contact centres and users’ friends and family. The team should revisit their AD persona (“Nathan”), to ensure it is appropriate for modelling AD support against, and not more relevant to digital take-up and accessibility approaches.\n\n**Point 15** – Make all new source code open and reusable, and publish it under appropriate licences (or give a convincing explanation as to why this can’t be done for specific subsets of the source code).\n\n- The service team have demonstrated a good understanding of the concepts around coding in the open and have made significant steps toward this achieving this.\n- The service must now focus on making extensive amounts of their service code publicly available with immediate effect.\n\n**Point 26** - Test the service from beginning to end with the minister responsible for it.\n\n- **Recommendation** : The service team should deliver on their commitment to test the service with their minister shortly after the launch of the public beta.\n\n**Summary**\n\nOverall, the service team has shown dramatic improvement in terms of product quality, team capability and service management. In addition, the team has tackled a number of external business constraints and driven improved ways of working with other parts of the Environment Agency that will support more rapid iteration and improvement of the service. The team has also demonstrated a strong sense of ownership and desire to improve the service to meet user needs.\n\nThe resulting pass of this assessment and release of the service to the public will deliver significant benefits to the user and Environment Agency alike as well as stimulating user feedback that will drive further improvement.\n\n* * *\n\n## Summary of Original Report\n\n**5th August&nbsp;2014**\n\nThe Waste Carrier Registration service is seeking permission to launch on service.gov.uk as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Waste Carriers Registration service should not be given approval to launch on the&nbsp;[service.gov.uk](http://service.gov.uk/) domain as a Beta service.\n\n**Reasons**\n\nThe service team has a good understanding of their digital users and their needs. There is strong service management with suitable empowerment. The current phase 1 service is working well, with a good response from users and improvements have been made based on feedback. The team has also shown an understanding of agile and has been improving the way it works as part of the development.\n\nHowever, as recognised by the service team, the phase 2 version of the product is not as far down the development life-cycle and not yet ready for a general Beta release. The team was unable to fully articulate how it is structured along with some of the processes it uses, highlighting potential capability gaps that will need to be reviewed / resolved prior to Beta launch.\n\n**Recommendations**\n\n**Point 2** - Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.\n\n- The team were unable to fully articulate the capability within the team and some of their processes, pointing to capability gaps within the team that cover development, content design, testing, and analytics.\n- **Recommendation** : review and clarify capability within the team, with a view to filling any gaps\n\n**Point&nbsp;4** - Evaluate the privacy risks to make sure that personal data collection requirements are appropriate.\n\n- The service uses a generic Environment Agency website privacy policy and cookie statement which is 3 years old. The experience for reviewing the privacy policy can be jarring for users.\n- **Recommendation** : review and update the user journey for people wishing to view the privacy policy and provide details specific to this service\n\n**Point&nbsp;9** - Create a service that is simple and intuitive enough that users succeed first time, unaided.\n\n- The current application is unfinished and still contains some serious defects. There are also some areas of the user flow which can lead to dead ends.\n- **Recommendation** : Reconsider approach to development and testing in order to reduce the number of bugs. Complete functionality, resolve outstanding defects, and ensure effective testing is carried out.\n\n**Point&nbsp;10** - Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it.\n\n- Assisted digital users are able to access a service that will complete the registration for them, however there is insufficient evidence to support decisions made around this provision. The assisted digital support does not incorporate digital inclusion approaches.\n- **Recommendation**** :** Carry out specific research with assisted digital users (of all abilities) and design support to meet their needs and volumes, using any required channels.\n\n**Point&nbsp;13** - Build a service consistent with the user experience of the rest of&nbsp;[GOV.UK](http://gov.uk/) by using the design patterns and style guide.\n\n- The content of the service does not fully meet the&nbsp;[GOV.UK style guide](https://www.gov.uk/design-principles/style-guide), and requires better signposting and copy throughout.\n- **Recommendation** : Have a&nbsp;[content designer](https://www.gov.uk/service-manual/the-team/content-designer.html) work on the service to ensure it is understandable and meets the standard found elsewhere on&nbsp;[GOV.UK](http://gov.uk/).\n\n**Point&nbsp;14** - Make sure that you have the capacity and technical flexibility to update and improve the service on a very frequent basis.\n\n- The team were unable to fully articulate their testing processes.\n- **Recommendation:** Review/update testing approach to ensure:\n  - Outstanding defects are identified, prioritised and the remaining effort is understood.\n  - Automation where possible.\n  - Suitable testing to support target browsers/devices.\n  - There is a clear and efficient approach to defect resolution.\n\n**Point&nbsp;15** - Make all new source code open and reusable, and publish it under appropriate licences (or give a convincing explanation as to why this can’t be done for specific subsets of the source code).\n\n- Code from the service has been published and is currently being reused by another government organisation. However the process for publishing code should be improved, in order to improve its reusability and value to government.\n- **Recommendation** : Formalise a policy around releasing open source software that takes into account the risks and benefits of doing so. CIAN 2013/01 from CESG has some relevant guidance in this area.\n\n**Point&nbsp;26** - Test the service from beginning to end with the minister responsible for it.\n\n- The existing phase 1 service has been shown to the relevant minister, though there is not yet a plan in place to demonstrate the “phase 2” part of the service.\n- **Recommendation** : set up a meeting to demonstrate the new service to the relevant minister before the service moves into the live stage.\n\n**Summary**\n\nThe Service team has made good progress bearing in mind some of the constraints they face and showed a high level of maturity in a number of areas. There are also areas, such as building internal DevOps capability, where work being carried out now will make things significantly easier in the future.\n\nIt can be tricky to time the assessment so that the service is fully ready, without holding up delivery. we are confident that many of the issues identified by the assessment would have been resolved had the assessment been made at later date. The team’s willingness to take on and respond to feedback stands them in good stead for future assessments.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/contracts-finder-service-assessment-2/",
    "title": "Contracts Finder - Service Assessment",
    "summary": "Contracts Finder will be the central repository for government contract information referring to future opportunities, current opportunities, awarded contracts and pre-procurement engagement with the market. The terminology for these states is currently being tested. The website will provide enough relevant business opportunity information for buyers and suppliers to able to manage and act on this and interact directly with each other using a number of channels. Contracts Finder will also present contract information to other interested parties and will provide features that will facilitate the publication of government contracts and their associated expenditure.",
    "body": "**Department / Agency:**  \nCO / CCS\n\n**Date of Assessment:**  \n17/2/2015\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nD. Vaughan\n\n**Service Manager:**  \nP. Sinclair\n\n**Digital Leader:**  \nP. Maltby\n\n* * *\n\n## **Assessment Report**\n\nThe Contracts Finder service is seeking permission to launch on a service.gov.uk domain as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Contracts Finder service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta service on a service.gov.uk domain.\n\n**Reasons**\n\nThe team have shown that they have a good understanding of who their users are including buyers within government, organisations supplying to government, and those interested in how/what government are buying. They’ve made good progress over the last few months building a digital service to meet the needs of those disparate groups.\n\nThe Service Manager is empowered to make decisions and has worked closely with the multidisciplinary team to develop the beta service. Although reliant on an external supplier and spread across multiple locations, the team has shown that they work well together in an agile manner and can make changes to the service quickly.\n\nThe design of the service has been iterated based on feedback from users and lab based sessions over the last few months and now follows the GOV.UK look and feel. The team have shown that they have plans in place to continue this iteration during the public beta.\n\nThe team has worked hard to resolve some of the flaws in the original Contracts Finder service including improving the quality of the data about contracts and helping to define appropriate standards.\n\nThe team is in contact with the Performance Platform to ensure it’s collecting the required metrics and to identify how best to publish this data.\n\n**Recommendations**\n\n- The service team should continue with its intention to test the service with users using lab-based sessions throughout future phases of development. This should include usability testing with people with disabilities.\n- The service team needs to commission an accessibility review to ensure development of the service is informed by advice that considers the full range of use-cases.\n- The team should start to forecast their traffic levels with a view to making sure they have the budget available for a paid for digital analytics solution if required\n- The team should ensure that IP anonymisation has been enabled for their analytics solution and that they have opted out of sharing data with 3rd parties.\n- The service team should ensure that the code for the service has been released prior to launch\n- The service team should engage with the cross-government design community to gain advice and contribute learnings from the development of the beta.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | N/A |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/dart-charge-service-assessment-3/",
    "title": "Dart Charge - Service Assessment",
    "summary": "The Dart Charge is the new ‘free-flow’ charging scheme being developed for the Dartford Crossing to ease congestion. Users of the Dartford-Thurrock River Crossing of the Thames on the M25 are required to pay a charge to manage congestion of the bridge and tunnels. Dart Charge is a new remote payment system which will reduce congestion and ease traffic flow at the crossing.",
    "body": "**Department / Agency:**  \nDfT / HA\n\n**Date of Assessment:**  \n18/11/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nNot Passed\n\n**Lead Assessor:**  \nS. Wood\n\n**Service Manager:**  \nI. Lewis\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## **Assessment Report**\n\nThe Dart Charge service is seeking permission to launch on service.gov.uk as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel concluded that the Dart Charge service should not be given approval to launch on the service.gov.uk domain as a Beta service. The service standard is grouped into themes, and stated below are the assessment panel’s views on where the Dart Charge service currently stands against these.\n\n**Reasons**\n\n_Assisted digital and&nbsp;digital take-up_\n\nThe service team had not undertaken sufficient research into assisted digital (AD) users to understand their barriers, so could not show how proposed support meets user needs. The service&nbsp;was too early in development to meet the service standard for beta, but the service manager understands AD principles and has plans in place to undertake research with AD users over the next few weeks. The team has tested the digital service with people who are lower on the digital inclusion scale and made improvements based on findings.\n\nIt was recognised that there are plans in place to test SMS messaging and automated telephone transactions. The panel would like to see the results of these tests, and actions based on these results, when the service returns for reassessment.\n\nIt was noted that the team had put in place telephone and face-to-face assistance. However, the team needs to put into place proper AD testing in order to demonstrate that the channels and providers meet the needs of the AD community. The panel would be looking for, amongst other things, evidence that users of these channels are aware of how to make payments, and for these channels to have low waiting times. This is particularly important because the payment window is short.\n\nFinally, the panel had concerns about the call centre’s initial ability to handle volumes. The issue here is that AD users should not be penalised.\n\n_Technology and security_\n\nThe assessment team’s confidence on the security assessment is based on the service team’s confidence in the thoroughness of its formal accreditation process, including PCI accreditation and end-to-end security architecture assessment by specialists in the team and the Highways Agency.\n\nThe service does not conform to the GDS policy on open standards and common government platforms. Commercial considerations may be hindering the process of making APIs open source. The panel would like more information on this when the service returns for reassessment.\n\nThe panel questions&nbsp;how the service would function if a user had JavaScript disabled. Furthermore, accessibility standards have not been implemented or tested with users. The cookie policy is not currently written and should also be published in accordance with the EU legislation on cookies.\n\nIt is noted that the test environment was very nearly identical to the proposed beta service. However, the panel was not convinced that the testing regime is sound enough, nor that the expected loads are well enough understood. A service that is not available or has load issues would generate more work for the call centre.\n\n_User needs_\n\nThe assessment team recognised the huge amount of work that the service team has carried out in research and identifying user needs. Testing was carried out in the Dartford area, meaning that representative or ‘real’ users were taking part. Social media activity was analysed and where research did not produce meaningful results (a pop-up session in a Dartford library did not identify&nbsp;enough drivers) an agency was used to improved the quality of user research.\n\nThe service manager explained the way stories are prioritised, adequately summarised a top-level user need in one sentence, and was clear that they owned the backlog.\n\nThe panel did have some concerns around decisions made in the early stages of the service's development. One being that the use of the Congestion Charge ‘C’ sign could confuse some users into thinking that the London Congestion Charge also covered the Dartford Charge and vice versa. The panel recommends that testing is carried out in this respect to ensure users are confident that this is not the case. Also, the service has not yet been tested with fleet car administrators. Again, it is recommended that this be carried out. A plan for addressing these concerns is in place, and provided that the team has the user research capacity going forward, then the panel is reasonably confident these points will be addressed.\n\n_The team_\n\nThe service team is split over multiple sites, which goes against the principles set out in the Government Service Design Manual. The assessment team is concerned that the development team (in New York) is too cut-off from users of the service, despite efforts to share research with the New York team. The planned Google Analytics function is also to be based in New York (further comment on this below). Furthermore, the team is currently heavily reliant on GDS and DVLA for resource.\n\nThe service manager described a useful \"steady state\" model, albeit this is subject to a successful recruitment campaign and effective training. Funding appears to be in place, and the panel noted that the service manager is both highly competent and empowered to make decisions.\n\n_Improving the service_\n\nThe service team is committed to updating the service and the fact that the product is superior to what was presented in the Alpha review is evidence of this. The resources are not wholly under the control of the service team at present, relying as they do on a supplier (based in New York), with closed code, and GDS researchers. Also, it was noted with approval that the service team aims to split the architecture so that it at least owns the web layer.\n\n_Design_\n\nThe design of the web service appears sufficiently effective. Drop-offs take place at sign-up when users realise they have to pay a minimum of £10. The assessment panel realises that this is due to policy issues, however, the panel recommends the service team research this matter further in order to discover whether there is a figure that does not deter users. This evidence should then be used to push back on policy decisions which do not support user needs.\n\nThere are style issues within the service, with examples where wording could be improved e.g. “A return journey counts as two crossings”. The name field could be a single input rather than split into first and second names. The PIN question could be confusing and the confirmation screen requires improvement.\n\n_Analysis and benchmarking_\n\nIt was good to see that goals have been set up, and an initial conversation has been held with the GDS Performance Platform team. The service team should follow up on this initial conversation and engage with the Performance Platform team to build a dashboard for the service. Doubts exist as to whether the Senior Information Risk Office (SIRO) has authorised the use of Google Analytics, with the Standard version of Google Analytics currently in use. There may be a capacity limit imposed by the Standard version once the service goes live.\n\nThe service's supplier will take on the analyst role. Given that this is likely to be in New York there is a risk that Management Information (MI) will be provided rather than analysis.\n\nThe assessment panel recommends that the analyst should work with the researchers and contribute to the creation of user stories in order to be properly effective. On-page events and funnels should be instrumented to provide better forward-looking analysis insight. Satisfactory plans are in place to provide benchmarking data, although several of the metrics will be gathered in a manual way, when automation could be used.\n\n_Testing with the minister_\n\nThere is a plan in place to test with the minister this week.\n\n**Recommendations**\n\nThe concerns raised above should be addressed before returning for beta re-assessment. In addition, the panel has further recommendations that should be considered before re-assessment. These include:\n\n- Testing&nbsp;on how users relate to the 'C' Congestion Zone signage. This is to ensure users are confident that any London Congestion Charge they have paid does not cover the Dart Charge (and vice versa: that the Dart Charge does not cover the London Congestion Charge).\n- Testing the service with fleet car administrators.\n- Carrying out research to understand why 20% of users are dropping out of the sign-up option when they discover that the minimum charge is £10. Would a lower figure meet with a higher take-up rate? If so, what is that figure? Any evidence for this should then be used to push back on policy.\n- Working to ensure that users who have JavaScript disabled, especially if used in conjunction with assistive devices, can still use the service.\n- Ensuring that the digital analyst is not confined to producing MI reports. Instead, to be properly effective, the analyst should work with the researchers and contribute to the creation of user stories, discovering issues, and providing evidence.\n- Publishing the list of cookies that are used by the service and why they are needed.\n\nThe above should not be seen as a checklist. When the service returns for reassessment the assessment panel will be looking for changes in teams&nbsp;and&nbsp;process that will drive deeper understanding of issues such as these.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | No | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | No | 14 | Yes |\n| 15 | No | 16 | No |\n| 17 | No | 18 | No |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | No | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/personalised-registration-service-assessment/",
    "title": "Personalised Registration - Service Assessment",
    "summary": "The Personalised Registration service will allow consumer and commercial customers to",
    "body": "- retain a personalised registration from a vehicle;\n- assign a personalised registration to a vehicle\n\nIt will be a real time service to ‘take off’ and ‘put on’ a personalised registration number, simplified to be done instantly online. The service is currently delivered offline through a paper channel.\n\n[https://www.gov.uk/transformation/personalised-number-plates.html](https://www.gov.uk/transformation/personalised-number-plates.html)  \n  \n**Department / Agency:**  \nDFT / DVLA\n\n**Date of Assessment:**  \n08/12/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. O'Neil\n\n**Service Manager:**  \nR. Gye\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## **Assessment Report**\n\nThe Personalised Registration service is seeking permission to launch on a service.gov.uk domain as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded the Personalised Registration service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta service on a service.gov.uk domain.\n\n**Reasons**\n\nThe team were able to clearly set out how the service was built in response to user need and were able to evidence how the service was iterated in response to feedback.The assessment team was persuaded that the service was built in response to user need. The volume of user engagement was sufficient to ensure that the product satisfactorily met the broad needs of its audience.\n\nThe team were proactive in engaging with their user community and could bring to life the high level needs and challenges of their user communities.The Service Manager set out how the team was structured and was able to provide clear evidence of their ability to iterate and improve the service.The service does not hold any data at rest and the team were able to explain the role of the SIRO in the sign off of the service.The technology stack is the same as that for Vehicle Management and the team were able to explain their build and deployment process with clear examples and evidence.The team were very experienced and able to contextualise their service with respect to the range of other DVLA services.\n\nThe design is in keeping with the style-guide, uses the correct header and footer and has consistency with other services on GOV.UK. There have been noticeable improvements since the alpha with design changes coming directly as a result of user research.The team have carried out good research to understand users’ assisted digital support needs. They included users at the lowest end of the digital inclusion scale, and have used learnings both to design and test the digital service, and to consider what assisted digital support will need to be put in place.\n\n**Recommendations**\n\n**Assisted digital:**\n\n- User testing: The service team must test all assisted digital support channels with assisted digital users of this specific service during the beta, and be able to then evidence that users’ needs of assisted digital support are being met. User testing must include the full end-to-end support (from when the user realises they want to use the service, through to transaction completion) and must include users at the lowest end of the digital inclusion scale. The team must carry out testing to understand what users will need in the absence of unsustainable assisted digital support from family and friends.\n- _Awareness:_ The service should note that the live assessment requires evidence that users are aware the assisted digital support they need. The team should look to properly signpost users to assisted digital support, rather than to non-digital services.\n- _Volumes:_ The team must revisit the estimate that 17% of their users will require assisted digital support, as this was based in part on online surveys (users inherently far less likely to need AD support). The team must ensure that judgments of assisted digital user needs and decisions about assisted digital support are taken from talking directly to assisted digital users of this service.\n- _Costs:_ The team must specify the cost per minute of all channels of assisted digital support for their service, including face to face.\n- Assisted digital ownership must be clearly stated in the team’s organogram, as an area in its own right.\n\n**User Needs and User Research**\n\n- The service team should ensure that the user needs that exist in the audience and the user needs that are being met by the product are both capable of being clearly articulated (based on user research data). There should be clarity about the relationship (if any) between sets of personas that have been developed and the behaviour and features of the product.\n- If research supports the position that the disparate set of user types represented by the team’s personas only have one simple user need that the product must meet (i.e. replacement of the old paper process with the new online process) it is recommended that the personas are adapted to reflect this.\n- If the different personas have more nuanced needs from the product, it is recommended that appropriate product behaviour and features are considered for each persona and that this decision-making is capable of being clearly communicated.\n- The personas suggest that the respondents from the motor industry with whom the research was conducted may not in all instances be the end users of the product.\n- It is recommended that the needs of these admin and helper end-users are assessed through research, that the features and behaviour of the product are considered in the light of this work, and that this information is capable of being clearly communicated to stakeholders.\n\n**User research**\n\n- The service team should ensure that information about the usability issues that are uncovered during iterative development, and the solutions that are developed to resolve these issues, are clearly understood and documented for internal and external consumption, and can be communicated to stakeholders.\n- The user research documents that were shared indicate some needs that were uncovered in user testing of early prototypes that the current beta product does not meet. For example: &nbsp;dealerships would prefer to pay via a pre-funded account rather than by credit/debit card; contact details and a live chat feature present in early prototypes (and welcomed by respondents) were missing from the beta design. It is recommended that the status of these user needs/requirements is available in a form that can be clearly communicated to stakeholders.\n- Remote A/B preference testing was conducted, and decisions about the product were made, on the basis of the preferences that were expressed in the exercise for different versions of certain pages. It is recommended that this kind of evidence is in the future supplemented by observational user research where users’ ability to successfully use different versions of the page to achieve their objectives is also assessed alongside stated preference (if understanding stated preference remains of interest).\n\n**Design**\n\n- The design is in keeping with the style-guide, uses the correct header and footer and has consistency with other services on GOV.UK. There have been noticeable improvements since the alpha with design changes coming directly as a result of user research.\n- Support for web clients (browsers and the devices they operate on) has been well planned, based on the surveyed user-base, but now needs to be supported by data from analytics. This should be possible during the public beta and the team should monitor this, making the relevant changes to their support strategy.\n\n**Team**\n\n- Emphasis placed on ensuring operations roles are being filled within DVLA for time of live assessment. The team should ensure there is a plan in place to address any possible skills shortage should suppliers change / leave.\n\n**Privacy & Infrastructure**\n\n- Concern about single leased line. For live we would probably want to see some durability here - either leased line into both data centres or reduced dependency on leased lines.\n\n**Open Source**\n\n- Only a small proportion of code has been open-sourced. One reason for this was the presence of elements of configuration, which are deemed private. Steps should be taken to minimise the impact of these files and other such resources. Either by extracting these elements to private repositories and opening the main functional code or by open sourcing these configuration files if possible. Files describing interactions between services should not be deemed closed by default.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/civil-legal-advice-service-assessment-2/",
    "title": "Civil Legal Advice - Service Assessment",
    "summary": "Civil Legal Advice provides state-funded legal help with problems such as repossession, rented home disrepair, court orders to protect against abusive partners etc. This legal help is only available to citizens who pass a means test and whose problems fall within prescribed areas of law. The team are building a public facing application that allows users to log their cases easily.",
    "body": "**Department / Agency:**  \nMOJ\n\n**Date of Assessment:**  \n16/12/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. Harrington\n\n**Service Manager:**  \nL. Citron\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## **Assessment Report**\n\nThe Civil Legal Advice service is seeking permission to launch on a&nbsp;[service.gov.uk](http://service.gov.uk/) domain as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Civil Legal Advice service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta service on a&nbsp;[service.gov.uk](http://service.gov.uk/) domain.\n\n**Reasons**\n\n_User needs:_  \nThe service team were able to clearly articulate the user needs of this service and gave good examples of where user research had fed directly into the design of the service.\n\n_The team:_  \nThey have put in place an excellent multi-disciplinary team, with representation from the Legal Aid Agency. The service manager is new to post – this was an iteration on the original process to stop issues with people not being available. The Governance meetings the team have set up to communicate progress were a good example of the team working agile alongside more traditional processes.\n\n_Security, Privacy, Tools and Standards:_  \nThe service team have clearly used a variety of appropriate tools to build, host and deploy the system. &nbsp;The assessment panel found it encouraging that the service team had clearly thought about user security heavily, and that they had taken all of the appropriate steps to balance user needs with the security requirements for their answers.\n\n_Improving the service:_  \nThe service team have iterated the service on a very frequent basis and are in a position to continue this in public beta. It was also positive that there was a good deal of trust in the team if urgent changes/tweaks were needed.\n\n_Design:_  \nThe service looks and works like it belongs on&nbsp;[GOV.UK](http://gov.uk/). The service team have used&nbsp;[GOV.UK](http://gov.uk/) design patterns effectively.\n\n_Assisted digital and digital take up:_  \nThe team has a good understanding of their assisted digital users’ barriers and needs and has plans to test their proposed support in beta. The proposed telephone support is comprehensive, offering call-back, a free translation service and covering a variety of communication needs. The team has started work on digital take up, including raising awareness with relevant 3rd parties and segmenting user groups.\n\n_Analysis and benchmarking:_  \nBasic analytics tagging has been put in place and the team is recruiting for a data analyst. The team have held discussions with the Performance Platform team and have provided access to their analytics for when the service is in public beta. The service mapping work will also enable the team to identify components of the user journey for display on the Performance Platform.\n\n**Recommendations**\n\n_User needs:_  \nThe assessment panel were concerned that the main objective of the service is to reduce call volumes. This is primarily a government need. The panel recommend the service team take time to detail the long term vision for this service with a focus on the benefits to users.\n\nThe panel recommend the service team map out the entire user journey for getting Civil Legal Advice, and work with the teams responsible for the call handling system and other aspects of the service.\n\nIs it clear to users with difficult lives that _Civil Legal Advice_ can help them? And is it clear that this is where you actually get Civil Legal Advice, not just where you check eligibility? The panel recommend the service team use user-generated tasks in research to understand what users expect to do with the service.\n\nThe panel also recommend the service team investigate whether users are sufficiently clear on what is covered under civil as opposed to criminal legal advice. It may be worthwhile to investigate including areas of criminal legal advice in stage 1 (/problem) in order to test this hypothesis and direct users effectively.\n\nThe panel recommend the service team investigate the possibility of allowing users to select more than one problem area in stage 1 (/problem). The service team’s research has highlighted that users typically have multiple interrelated problems. The panel appreciate that this adds complexity and has been out of scope for the product thus far, however as the service moves toward live, the service team should be _doing the hard work to make it simple_.\n\nAt the assessment the panel discussed that it might be possible to offer simpler user journeys if users begin the transaction with certain information already captured (eg housing problems) from different start pages. It would be good to explore the possibility of this with the&nbsp;[GOV.UK](http://gov.uk/) team..\n\n_Team:_  \nThe panel recommend that the service team continue in their efforts to recruit a product/data analyst.\n\n_Security, Privacy, Tools and Standards:_  \nThe cookies page needs to be updated and accurate for the cookies that are actually set, their lifetime and their scope.\n\nThe panel thought that some of the service team’s technology decisions have been interesting and pioneering in government and would like to see some evidence of the service blogging and talking about their use of container technologies, continuous integration and testing.\n\n_Improving the service:_  \nIn Beta the team should consider the benefits of being able to deploy with no downtime and assess whether this would be worthwhile work as backend deploys cannot be done in call centre hours.\n\nDesign recommendations covered under _user needs_.\n\n_Assisted digital and digital take up_:  \nThe team must increase qualitative research with assisted digital users and current 3rd party providers (including charities) as planned in public beta and must fully test the proposed support to ensure it meets user needs and the assisted digital standard. User research and testing must confirm which channels of support are required to meet their needs, including telephone, face by face support (home visits or high street locations) and web chat. The team must also consider how they will incorporate digital inclusion into their support.\n\nThe team had plans for digital take up but as this may be particularly challenging for this service, the panel recommend that the service team develop their plan with the GDS digital take up team. This should be tied in to the long term vision for this service, mentioned above.\n\n_Analysis and benchmarking:_  \nBasic tagging will only yield basic data. In Beta the team need to consider the goals (at both macro and micro level) of the service and instrument these in the analytics to understand how many users are achieving them and where in the process they are dropping out. Analysing the existing Legal aid checker data will reveal some insights that can help with the development of the Civil Legal Advice service and possibly some benchmarks.\n\nNote that in the next assessment the assessment panel will be asking for access to the stats and clear evidence how they have been used to develop the service.\n\n_Testing with the Minister:_  \nThe team have a plan in place to test with the minister before the Live assessment.\n\n**Summary**\n\nThe panel thought that the team answered the questions very well at the assessment. There has been a clear focus on user research and it was good to see how the service has been iterated based on this. Similarly, the good working relationship between the Legal Aid Agency and MOJ Digital Services was an example of how committed both are to delivering a great product.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/redundancy-payments-claim-for-loss-of-notice-service-assessment/",
    "title": "Redundancy Payments: Claim for Loss of Notice - Service Assessment",
    "summary": "This assessment covers the \"Claim for Loss of Notice\" component of the Redundancy Payments service. All employees, by law, are entitled to receive advanced notice of their redundancy, with the period of notice based on their length of service. Where this has not been given and their employer cannot or refuses to pay, then a compensation claim for loss of notice can be made by ex-employees using the online Redundancy Payments service.",
    "body": "**Department / Agency:**  \nBIS / IS\n\n**Date of Assessment:**  \n12/12/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nN. Williams\n\n**Service Manager:**  \nG. Ecart\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## **Assessment Report**\n\nThe Claim for Loss of Notice service (the second stage of the two-stage Redundancy Payments service) is seeking permission to launch on a service.gov.uk domain as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Claim for Loss of Notice service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta service on a service.gov.uk domain.\n\n**Reasons**\n\nThe team presented strong evidence that the service has been developed to meet well understood user needs, has been iterated to meet those needs better as more has been learnt about the needs of users, and that the service team has the skills and is empowered to support and continually improve the service.\n\nThe panel agrees with the team’s assertion that making this second part of the Redundancy Payments service available in Beta on the service.gov.uk domain alongside the existing paper form will immediately benefit users. It was also clear that the service team now needs to see this part of the service being used in anger in order to learn more about demand for Assisted Digital support both for this and for the first stage of the service, and to get validated learnings about further improvements to the second stage.\n\n**Recommendations**\n\nAs early as possible during the Beta, and prior to coming to a Live assessment, the service must address&nbsp;all of the following points.\n\n_Cookie policy_\n\nThe service must include a cookie policy, clearly linked to in the footer.\n\n_Team size_\n\nThe assessment panel had concerns that the service team may struggle to support and iterate this second part of the service in response to user feedback during the Beta, while also continuing to develop the first part of the service. The team's plan to allocate 25% of the team for iterating the Claim for Loss of Notice service is a very good approach, but 25% of the current team strength is likely to be too little. The panel will expect to see iteration between now and the Live assessment, and recommend that the team considers growing by 1-2 developers from now until both parts of the service are fully live.\n\n_Assisted Digital_\n\nThe service team must ensure appropriate Assisted Digital (AD) support is in place as the parallel paper service is wound down, and the service moves towards its target of 90% digital take up. In particular the panel asks that, before the next service assessment, the team:\n\n- Revisits its conclusions around support plans and volume estimates where they have been drawn from data that includes online surveys. (Online survey respondents are much more likely to not require AD support and therefore do not represent the needs of more vulnerable users).\n- Ensures that AD support is in place for users currently relying on friends and family.\n- Gathers evidence that the full end-to-end user journey (from when the user starts to seek information about the service through to when they complete it) has been considered and tested.\n- Ensure&nbsp;there is&nbsp;sufficient quantitative data alongside anecdotal information to back up decisions made around AD support. The team should also develop a full range of AD user personas from their work with actual users, and use these for ongoing research and planning.\n- Gathers evidence that third party support meets users’ needs, has sufficient capacity to deal regionally with peak demand, and is sustainable. The service team should consider a wider range of support providers, if required.\n- Gathers evidence how digital inclusion will be delivered during phone support.\n- Specifies how many transactions are expected across each channel, and their cost per minute.\n\n_Digital take-up_\n\nThe service team must work with the digital take-up team at GDS to ensure the ambitious plans to achieve 90% digital take up within months of the service going live are achievable.\n\n_Start page_\n\nAs part of moving to a service domain, the service team will need to remove all the guidance information from the first page of the service and work with GDS to include it on a GOV.UK start page. The service must start and end on GOV.UK. It was suggested in the assessment&nbsp;that had the service not passed, it could be launched regardless on a .org.uk domain. The team should be aware that this approach would be in conflict with the Cabinet Office spend controls process.\n\n_Open source_\n\nThe panel were pleased to hear about plans to open source the form builder component (named Dumbledore). The service team&nbsp;expects this will be completed&nbsp;by the time&nbsp;of the&nbsp;Live assessment. The panel&nbsp;encourages the team&nbsp;to continue to explore the potential to publish as much of the service’s code in the open as possible.\n\n_Design_\n\nIt was noted that the date entry field pattern used had caused issues with some users on other projects. It was recommended that the team look at the latest pattern on&nbsp;GOV.UK&nbsp;elements using the work that led to it (see [https://github.com/alphagov/govuk\\_elements/pull/47](https://github.com/alphagov/govuk_elements/pull/47 \"https://github.com/alphagov/govuk\\_elements/pull/47\")) as reference for any changes.\n\nThe team explained the service produces PDFs to fulfil a requirement for paper-based documents. It was suggested that the team investigate publishing these in a HTML format, similar to those on GOV.UK&nbsp;(see [https://insidegovuk.blog.gov.uk/2013/03/28/html-publications/](https://insidegovuk.blog.gov.uk/2013/03/28/html-publications/ \"https://insidegovuk.blog.gov.uk/2013/03/28/html-publications/\")). This would ensure they were usable by default for users of assistive technology.\n\n_Analytics_\n\nThe service team has made a good start by getting analytics installed and goals configured, and has some good ideas for future analytics iterations; however, there has not been the volume of traffic to enable the team&nbsp;to use data to make improvements to the service. By the time of the&nbsp;Live assessment, the panel&nbsp;would expect the team&nbsp;to be able to demonstrate how analytics is embedded in the service planning.\n\n_The service overall_\n\nThe assessment panel&nbsp;felt it important to mention that the long term roadmap for the Redundancy Payments service overall needs to include plans for joining it up with other government services. The service currently requires users to supply information which government already holds, such as receipt of, or refusal of benefits.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |\n\n&nbsp;"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/companies-house-service-service-assessment/",
    "title": "Companies House Service - Service Assessment",
    "summary": "The Companies House Service is a new, unified web service that brings together the company search and filing functionality that was previously split across disparate, legacy web services. This free to use service allows users to find company information and for companies to update their own company information.",
    "body": "**Department / Agency:**  \nBIS / CH\n\n**Date of Assessment:**  \n3/12/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Barlow\n\n**Service Manager:**  \nR. McNeil\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## **Assessment Report**\n\nThe Companies House Service is seeking permission to launch on service.gov.uk as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel&nbsp;has concluded that Companies House Service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria, and should proceed to launch as a Beta service and move to a service.gov.uk domain.\n\n**Reasons**\n\nThe assessment panel were impressed by the extensive user research that had been completed by the service. The service had a very good overall understanding of user needs and showed clear examples and evidence of how this had and will continue to be used to improve the service.\n\nThere was also evidence to show how initial design decisions had been challenged and changed in line with user feedback. For example, the search functionality was simplified following feedback from users.\n\nThere were also a number of examples of where policy and legislation had been challenged to make sure the service meets user needs.\n\nThe service has been designed so that a number of existing Companies House services are consolidated into a single, simpler service. This included looking at both online and offline elements as part of the same user journey.\n\nThere was evidence of effective digital take-up activity, making users aware of and encouraging them to use the online service.\n\nThere was a commitment to making Companies House data open and free of charge. This included Companies House using the same RESTful API as third parties.\n\nThe service has been designed so that there can be an individual URL for every UK company, allowing each to be easily indexed by search engines. Search is one of Companies House core functions, so it makes sense to make data open to search engines in this way.\n\n**Recommendations**\n\nThe assessment panel recommends that the service continues to work with GDS to integrate the service more fully into GOV.UK. This work will need to be completed before the service returns&nbsp;for live assessment. Be aware that the operation of a service on the service.gov.uk subdomain does not permit the indexing of information from search engines. To allow for this, an alternative would need to be agreed with GDS.\n\nUser research should be primarily task-based. It’s more important that users can complete the tasks they need to, than opinions on wording and layout. Rather than always setting a scenario that fits what the service currently offers, user-generated tasks should be used to understand what users expect to do with the service. This will more accurately reflect the experience of users who are less familiar with what Companies House offer. Use a mix of recruitment methods to test with a wide range of people - too heavy a reliance on volunteers in the user panel will&nbsp;bias results to people who are familiar with Companies House, and those more likely to understand what they can do with the beta service.\n\nThe service team should determine the optimal company authentication user journey for company officers and 3rd parties, and&nbsp;work towards this&nbsp;with the policy team. The team should consider contacting the teams working on Your Tax Account at HMRC, and Rural Payments at the RPA as these services are working on the same problem.\n\nIt was mentioned during the assessment that there are several users who simply consume the whole API. If so, it may make sense to offer timestamped, gzipped database dumps and a latest changes feed.\n\nThe service team should increase qualitative research with assisted digital users as planned, and fully test the proposed support to ensure it meets user needs and the assisted digital standard.\n\nThe assessment panel would expect most of the service's source code to be made publicly available. Rather than making a judgement on what source code will be useful and reusable, the default approach should be to publish (sensitive information such as passwords, configuration information etc. should remain private). The panel would particularly like to see Perl code using the front end toolkit be made available to other government agencies, in case other services are considering a similar approach.\n\n**Summary**\n\nThe panel were impressed by the overall breadth and depth of research that had been completed. It was clear throughout the assessment that the team has a strong commitment to delivering a service that meets user needs and continues to improve.\n\nThe team also gave a number of examples where they had challenged and pushed back where research showed that user needs were not being met.\n\nThe service had a clear plan and vision on how they plan to deliver improvements in the future, again prioritised by user need.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/lost-and-stolen-reporting-service-assessment/",
    "title": "Lost and Stolen Reporting - Service Assessment",
    "summary": "Lost and Stolen Reporting allows British passport holders to notify HM Passport Office of the loss or theft of their passport. This allows passports to be promptly cancelled, minimising the risk of their use in identity based crime or foreign travel.",
    "body": "**Department / Agency:**  \nHO / HMPO\n\n**Date of Assessment:**  \n9/12/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. O'Neill\n\n**Service Manager:**  \nH. Berry\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## **Assessment Report**\n\nThe Lost and Stolen Reporting service is seeking permission to launch on a service.gov.uk domain as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded that the Lost and Stolen Reporting service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria, and should proceed to launch as a Beta service on a service.gov.uk domain.\n\n**Reasons**\n\nThe Service Manager and the service team were able to give a clear description of how the service was built and the user needs supported, backed by clear evidence.\n\nThe team had a clear structure and defined roles. It was clear how the team works with external groups to build and deliver systems and services.\n\nThe team are using an agile delivery process and sprint process. The service is iterated based on feedback and user input.\n\nThe role of the Senior Information Risk Officer (SIRO) was clearly explained though the move to the Home Office has complicated sign off.\n\nThe team had carried out a Privacy Impact Assessment.\n\nThe team were able to clearly set out the tech stack and how they built and deployed the service. The work of the team was open source by default.\n\nThe team had analytics in place and are waiting for the new SIRO to sign off on the Google Analytics package.\n\nThe service team have worked to understand user needs around assisted digital support, and put in place a considered plan to test all channels including with third parties during the beta. The team had carried out research using their own assisted digital user personas modelled on users across the digital inclusion scale. It was really useful to have the team’s user researcher in the room, with plenty of useful examples of user stories around the digital and assisted digital areas.\n\n**Recommendations**\n\n_Assisted digital_\n\nThe team must fully test all assisted digital support channels during the beta so as to be able to clearly evidence before going live that all support is meeting user needs. The team must also specify the cost per minute of all channels of assisted digital support for their service, including face to face.\n\n_Digital take-up_\n\nThe service team must contact the GDS Digital Take-Up team and ensure that appropriate digital take-up plans are in place. These plans must include clearly stated targets that are ambitious and achievable.\n\n_Technology and tools_\n\nWhile the drop-down of suggested locations is a neat approach that enhances both usability and correctness, the team might consider changing from a blacklist of misspellings to using a Double Metaphone algorithm (sample implementations are in the public domain), which is used to detect spelling mistakes in word processors.\n\n_Digital analytics_\n\nThe team should make contact with GDS Product&nbsp;Analytics team to implement further Google Analytics tagging. The team should build on the work already undertaken with the GDS Performance Platform team to make their dashboard live.\n\n_Design and content_\n\nThe panel has provided feedback on the service’s design and content. In particular, the following should be prioritised:\n\n- accessibility testing\n- improving the experience for users with JavaScript disabled\n\nThe team should also explore opportunities to simplify the text and user interface, and look at whether it’s possible to join up the service with GOV.UK in a more seamless way.\n\nThe team should ensure the new SIRO signs off on the Risk Management and Accreditation Document Set (RMADS) and Google Analytics case.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/vehicle-management-service-assessment-2/",
    "title": "Vehicle Management - Service Assessment",
    "summary": "Vehicle Management will provide an online facility for motorists to notify changes to their vehicle registration details. This will include notifying a change of keeper and change of name and address, which will allow tens of millions of motorists each year to transact via digital channels rather than the existing paper based channels.",
    "body": "The first service to be developed within Vehicle Management and the one being assessed for Public Beta is notifying DVLA that you sold a vehicle to the motor trade. This is a real-time service enabling the vehicle keeper to notify the sale of their vehicles into trade, speeding up any refund due for vehicle tax. This service will be provided via Motor Dealers, Fleets and Auction Houses. A service for individual users will be delivered later next year.\n\n[https://www.gov.uk/transformation/manage-vehicle.html](https://www.gov.uk/transformation/manage-vehicle.html)\n\n**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n27/11/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. O’Neill\n\n**Service Manager:**  \nR. Gye\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## **Assessment Report**\n\nThe Vehicle Management service is seeking permission to launch on a service.gov.uk domain as a Beta service.\n\n**&nbsp;**** Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the Vehicle Management service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta service on a service.gov.uk domain.\n\n**&nbsp;**** Reasons**\n\n**&nbsp;** The service team were clearly able to set out how the service is based on a clear user need and evidenced how it is meeting that user need.\n\n**&nbsp;** The panel were impressed by the work the team have done to build an effective devops deployment process. The use of RPMs and a YUM repository was an interesting idea which would be of interest to others deploying services.\n\n**&nbsp;** The team have an effective continual deployment process in place with clear ownership of key elements and an understood security model.\n\n**&nbsp;** The team have a well maintained private Github repository in place and are making the bulk of their code available as open source. One recommendation for the future is to continue to clearly separate out secure code and patterns from the wider code base to allow more code to be open sourced and shared publicly.\n\n**&nbsp;** The team were also able to clearly set out how they worked with legacy systems to minimise any threat or impact to core services.\n\n**&nbsp;** The team were able to set out how resources across the delivery team are structured but it would be useful to more clearly define how non-core resources are actually brought into the team as needed.\n\n**&nbsp;** The team were able to set out how they planned to tackle any remaining non-digital legacy aspects of the process, such as the follow up letter.\n\n**&nbsp;** Though the work on analytics was at an early stage, the team had obviously given thought to the process and the approach.\n\n**&nbsp;** The team have considered assisted digital users and their needs, including using assisted digital personas to inform their thinking. The service team has worked with the DVLA call centre to design and put in place assisted digital phone support specifically for this service’s users. The team expects 80% of trade users to be trying to use this digital service within 3 years.\n\n**&nbsp;**** Recommendations**\n\n**&nbsp;Narrative**\n\n- The service should better articulate the statistics around user population, the slide used in the presentation confused the assessment panel by quoting absolute percentages of time-based slices of the user population without providing the context.\n- Demonstrate through evidence that the working hours availability meets user needs.\n\n**&nbsp;Service name and start page**\n\n- The team should work with content designers on GOV.UK to agree a name for the service that makes sense to the service’s users (ie dealers and people in the motor trade). The service should be written from their perspective to help differentiate between this service and future potential services, including individual-to-individual sales.\n- The start page is currently far too long to be included on GOV.UK, and the team should work with GOV.UK content designers to decide what needs to be included on this page, and what should be included in the service.\n\n**&nbsp;Service design**\n\n- The team should make sure that they are taking the latest set of GOV.UK component designs from the service manual. Where possible they should be using the latest front-end toolkit supplied by GDS. A list of design suggestions will be supplied separately to this assessment.\n- Some pages are currently quite wordy and do not meet GDS content design principles.\n\n**&nbsp;Team structure**\n\n- The team must contain a named designer, content designer, user researcher and data analyst that sits with the team (even if not full time on the project).\n\n**&nbsp;Technical**\n\n- The team’s use of continuous integration, package based deployment, and automation of infrastructure as code is impressive. The team should continue to improve their deployment process, reducing the deployment window between preview and live environments, and ensure they are not locked into their current hosting provider.\n- The team demonstrated good reactive approach to security and monitoring. They should continue their good relationship with their SIRO, and technical security team, and consider further ways of identifying any process based attacks possibly introduced by digitising an existing paper-based service with limited hours of availability.\n- The team are periodically publishing the front-end code as open source code, and should continue to identify other parts of the service which may be of use in other services, and look into collaborating on code from other organisations, audit code from HMRC and the address lookup service used by IER, for example.\n\n**&nbsp;Assisted digital**\n\n- The service team must ensure that research and user testing is being carried out with users who have low or no digital skills, as much of their work to date has been through digital channels and thus with users who are already online with some digital skills.\n- The team must contact and conduct research with users who responded to their 2014 survey saying they will need assisted digital support, to better understand their needs.\n- The team must revisit the 10% estimate for the number of users who will require assisted digital support, as this has largely been arrived at through online research, meaning respondents will likely have good digital skills and internet connectivity.\n- The team must use offline channels to find all assisted digital users of their service.\n- The team must monitor support across all channels (phone, face to face, or web chat), iterating in response to both user feedback and performance measurement.\n- The team must revisit the figure of 99% digital connectivity for users.\n- The team should plot users on the digital inclusion scale, rather than basing decision on whether users workplaces have an internet connection.\n- The team must build digital inclusion strategies into their assisted digital support, even though users of this service have indicated that they will likely only need support once or twice.\n- The team must specifically allocate ownership for assisted digital within their team structure.\n\n**&nbsp;Digital take up**\n\n- The team must continue to work with the Digital Take Up team in GDS, to ensure an appropriate plan is in place for this service.\n\n- The team must explore non-digital channels to discover and engage with users at the lower end of the digital inclusion scale and understand if and how they can be encouraged to switch to the digital service.\n- The team must test digital take up messaging during beta and iterate it in response to user feedback.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/apprenticeship-applications-service-assessment-2/",
    "title": "Apprenticeship Applications - Service Assessment",
    "summary": "The exemplar’s vision is to create an easy to use digital service where apprenticeships can be advertised and applied for, with the transaction supported by clear information to inspire and advise users, so that they can self-serve, leading to minimal additional support being required.",
    "body": "**Department / Agency:**  \nBIS / SFA\n\n**Date of Assessment:**  \n12/11/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nR. Reynolds\n\n**Service Manager:**  \nG. Tucker\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## **Assessment Report**\n\nThe Apprenticeship Applications service is seeking permission to launch on service.gov.uk as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the service is mostly on track to meet the 26 points of the Digital by Default Service Standard at this stage of development, subject to some issues being addressed before the service can proceed to launch as a Beta service on a service.gov.uk domain.\n\n**Reasons**\n\nThe service team are building the service based on user needs and iterating the service based on user research, which they have conducted with end users including assisted digital users. The team is working in an agile way, and are able to adapt and improve the processes as they go. The assessment panel are confident that the service team will continue to iterate and improve the service as they move into the next stage of development and that they have a plan in place to deploy frequently.\n\nThe service team has undertaken extensive research to find assisted digital users for their service through third parties, including charities, colleges and other government agencies. They have demonstrated a good understanding of barriers to using the service and have incorporated these into their personas, as well as plotting users on the digital inclusion scale. The proposed assisted digital user journey was clear and joined up with other government agencies. The team has iterated the digital service based on feedback from assisted digital users, which will support digital take-up. There are good plans for digital inclusion, to encourage users to complete the service independently in future. The team has plans to test their assisted digital support and estimated figures during the beta.\n\nThere are, however, some areas that need more work before the service can move to public beta, these are&nbsp;listed below.\n\n**Recommendations**\n\nThe service team&nbsp;must address the points below before moving onto a service.gov.uk domain:\n\n- Ensure the&nbsp;cookie & privacy page accurately documents all cookies, including third party cookies, and that it is updated whenever the cookies set by the page change. The&nbsp;service currently sets some third party cookies (several from [google.com](http://google.com/) when maps are displayed and one from [stats.matraxis.net](http://stats.matraxis.net/)) which are not clearly documented on the&nbsp;cookies page.\n- Consider whether allowing third parties to set cookies (i.e. from [stats.matraxis.net](http://stats.matraxis.net/) and [google.com](http://google.com/)) is good for users. Third party cookies are intrusive, and can be used to track a user from one site to another. Use and inclusion of third party tools within your service e.g. mapping and analytics raise a number of security and privacy concerns. The service team&nbsp;must have a robust approach for evaluating these risks and for making subsequent decisions. The service manager should be involved in and understand these decisions.\n- Ensure that visitor IP collected by the&nbsp;analytics package is anonymised at the time of collection. (The assessment panel believes that currently, although visitor IP addresses are masked in service reports, SFA, Matraxis and Matraxis’ hosting company all have access to the full IP address of each visitor in the raw logs.) See [https://www.gov.uk/service-manual/making-software/analytics-tools.html#privacy](https://www.gov.uk/service-manual/making-software/analytics-tools.html#privacy) \"anonymise IP addresses that your analytics provider collects\" for the guidance and [http://kb.webtrends.com/articles/How\\_To/Excluding-visitor-IP-addresses-from-data-collection-1365447689565](http://kb.webtrends.com/articles/How_To/Excluding-visitor-IP-addresses-from-data-collection-1365447689565) for details of how IP addresses can be excluded from collection using when WebTrends.\n- Ensure there are&nbsp;clear plans for publishing open source code in the next stage of development. The service team&nbsp;should also arrange for source code to be moved from [https://github.com/Valtech-NAS](https://github.com/Valtech-NAS) to an organisation that doesn't include the name of the service supplier in order to avoid confusion over ownership of the source code.\n- The service team&nbsp;must agree an approach with the GOV.UK team regarding start and done pages for the service, and request any necessary content changes before public beta. (The assessment panel&nbsp;notes that the service team&nbsp;already has a planned meeting with the GOV.UK team regarding start pages and done pages to agree what happens to [www.gov.uk/apply-apprenticeship](http://www.gov.uk/apply-apprenticeship) and whether a done page is needed, etc.)\n\nAdditionally:\n\n- The assessment panel has&nbsp;some suggestions about some design considerations of the front end, which the design assessor&nbsp;will pass on.\n- Consider KPIs carefully, bearing in mind that the overall success of the service isn't defined by the proportion of users who complete their application. Consider whether overall successful completion, overall cost per apprenticeship filled, or a similar metric would be a useful additional key performance indicator for the service.\n- The&nbsp;service is in two parts (finding apprenticeships and applying for them) and the service team has&nbsp;already had to seek exemption from the normal [https://www.gov.uk/service-manual/operations/operating-servicegovuk-subdomains](https://www.gov.uk/service-manual/operations/operating-servicegovuk-subdomains) guidance on allowing search engines to index the service. The service team&nbsp;will need to discuss the long term architecture of the&nbsp;service with the GOV.UK team during public beta, especially whether apprenticeship listings should eventually be information pages on [www.gov.uk](http://www.gov.uk/) with only the registration and application part of the service being the [service.gov.uk](http://service.gov.uk/) transaction.\n- In order to pass a live assessment the team must be able to demonstrate that they are sufficiently able to continue to iterate and improve the service without being dependent on one particular supplier.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/digital-marketplace-service-assessment-2/",
    "title": "Digital Marketplace - Service Assessment",
    "summary": "Digital marketplace is a browse and search tool for civil servants to find products and services available on the G-Cloud framework.",
    "body": "It allows buyers of services to do both keyword searching and filtered searches based on attributes of the services. Additionally it provides the ability for buyers create accounts, which enables saving of searches.\n\nSuppliers who have products on the G-Cloud framework have additional functionality around managing their supplier and service details. Functionality is this area is limited for this release to enabling new suppliers to create an instance and also for existing suppliers to manage the users that are associated with their company. Future functionality will allow further management of supplier and product data.\n\n**Department / Agency:**  \nCO / GDS\n\n**Date of Original Assessment:**  \n29/9/2014\n\n**Date of Reassessment:**  \n5/11/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Original Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nL. Scott\n\n**Service Manager:**  \nI. Majic\n\n**Digital Leader:**  \nP. Maltby\n\n* * *\n\n## **Reassessment Report**\n\nThe assessment panel have agreed that the Digital Marketplace is now in great shape to move into Beta development.\n\nBelow is the assessment panel’s response to the steps Digital Marketplace have taken to address the 4 criteria not passed at the original beta assessment. The panel were really encouraged to see how the service had acted on all the recommendations the panel had made in a very short time.\n\n2.&nbsp;_Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility._\n\n- The backlog of web operations tasks is now almost complete, and a user support and web operations model has been discussed and agreed, set up and tested.\n- There is an agreement with the&nbsp;[GOV.UK](http://gov.uk/) 2nd Line Tech Support team to provide 3rd line support, and this support model has been tested operationally.\n- The service team reiterated that there are 1200 users/day, with no out-of-hours expected use, hence pager duty is unlikely.\n- At the time of assessment, the Ops Manual was ¾ complete, and is expected to be finished imminently.\n\n5.&nbsp;_Evaluate what tools and systems will be used to build, host, operate and measure a service, and how to procure them_\n\n- The panel discussed monitoring, log collection and aggregation with the service team. Graphite is in place, and other measures, eg key application metrics, should be finished imminently (planned for the current sprint). Standard system metrics will be used.\n- The service team explained why they will not be doing log aggregation. The panel agree that it is not worth doing these infrastructure changes since the plan is to move to more of a PAAS (platform as as service) in 2 to 3 months time.\n\n18.&nbsp;_Use analytics tools that collect performance data_\n\n- The panel were struck by how the service team have really turned around the service with respect to this area of the Standard.\n- The team confirmed they have upgraded their analytics provider.\n- They have set customised KPIs which better reflect the service, along with more granular service improvement measures.\n- There is a product analyst full-time on the team, and the service manager was rich in her praise of the individual in this role. It was clear how an embedded data analyst is benefitting the service and its users by inspiring the team, sharing knowledge and making great use of data insights to inform service development and design. The team has already made changes based on analytics.\n- The dashboards are now far more optimal, the team now has multiple views of their data including a raw profile. They have started segmenting visits and have set up real-time search terms which help keep the team in touch with their users.\n- The service manager explained how they are concentrating on analytics that will inform the team to make user-focussed improvements.\n- The panel and the service team had a good discussion about benchmarking the service and measuring performance. The service manager was convincing in the description of the service’s success thus far, including a successful transition from the CloudStore, unsolicited positive feedback, no vehement negative feedback, and peer organisations recommending the Digital Marketplace.\n\nRecommendation: There was mention made of exploring the use of Google Tag Manager, this will need to go through the Assurance Process if pursued.\n\n25.&nbsp;_Make a plan for the event of the service being taken temporarily offline._\n\n- The team explained how there is a CDN (Content Delivery Network) in place, and downtime measures in place (via the operational support model discussed earlier). The[GOV.UK](http://gov.uk/) Infrastructure team have done an evaluation and are happy with this approach.\n- The service team reiterated that there is high tolerance for small outages from users, although no outages are anticipated. The team explained how they can contact all active users quickly with any communications in the unlikely event of prolonged downtime.\n\nRecommendation - a bespoke failover page should be developed during the beta, to replace the standard ‘This application is unavailable’ page.\n\n* * *\n\n## **Original Assessment Report**\n\nThe Digital Marketplace is seeking permission to launch as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded the Digital Marketplace should not be given approval to launch as a Beta service.\n\n**Reasons**\n\nThe panel concluded that the assessment was too early and that the Digital Marketplace was not yet at the standard GDS expects for services going into Beta. The specific criteria which were not passed are explained below.\n\n_2. Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility._\n\n- The panel’s main concern is the lack of permanent web operations roles in place. The service currently has a single person on loan from&nbsp;[GOV.UK](http://gov.uk/). There is a large backlog of web operation tasks outstanding, and we expect these to be more complete before a Beta assessment can be passed. The provision of web operations once the loan period is over was unclear.\n\n_5. Evaluate what tools and systems will be used to build, host, operate and measure a service, and how to procure them_\n\n- The panel had concerns about the lack of web operations roles in place to operate the service, and the lack of monitoring, log collection and aggregation. The panel understand that this work is planned, but to pass the Beta assessment, this work must be complete.\n\n_18. Use analytics tools that collect performance data_\n\n- Previous recommendations from the alpha assessment indicated that the team should look at analytics from the existing cloudstore service. These analytics could be used to baseline existing success measures, and track how well the replacement digital marketplace service performed. That work does not appear to have happened. There is a plan in place to do this and an analyst is being seconded to the team for a reasonable term, but we would expect this work to happen before the product can pass into Beta.\n- It is acknowledged that the 4 KPIs in the service standard don’t map as well to a service that fundamentally isn’t a transactional service. We would like to see the team work with the Performance Platform to put in the work to define what KPIs are relevant and define success measures accordingly.\n\n_25. Make a plan for the event of the service being taken temporarily offline._\n\n- There was no evidence of a clear plan to follow in the case of an unexpected outage or malicious attack. The business requirements have indicated the sufficiency of a 9am to 5pm, Monday to Friday support model. However alerts, a planned response, and a responsible team to deal with an unexpected outage must be in place for a product to pass into Beta.\n\n**Recommendations**\n\n1.&nbsp;The service team needs to contain people with the capabilities to be able to operate the service, either as full-time members of the service team, or as a demonstrable support model from another team with the capabilities and capacity.\n\n2. Monitoring, log collection and aggregation needs to be in place.\n\n3. An operations manual should be written and available.\n\n4.&nbsp;A plan must be in place for actions for the operations team to take in event of an emergency and this plan must have been tested.\n\n5.&nbsp;A plan must be in place for scheduled or unplanned downtime, including communications to users.\n\n6.&nbsp;Benchmark the performance of the old service (CloudStore) to provide a baseline to measure the performance of the Digital Marketplace.\n\n7. Define how you will measure success and set your own KPIs.\n\n8. Upgrade to the Premium version of your current analytics package.\n\n**Observations against other criteria**\n\n_User needs_\n\n- The excellent work to determine the user needs for this service was evident. The Digital Marketplace is a revolutionary product and the service manager, product manager and user researcher displayed a deep knowledge and understanding of users and their needs, which was shared by the whole team.\n- The service design has been truly informed by user research and analysis of user needs. The team gave excellent examples of this during the assessment by describing the research-prompted features of saved searches, and/or searches, the need for repeatability, and service descriptions.\n- The team has used a variety of research methods and gathered valuable data and insights. The panel was impressed to hear of the team-wide attendance at weekly research sessions and the resultant knowledge and understanding of their users that the team demonstrates. There are 2 user researchers on the team.\n\n_The team_\n\n- There is a multidisciplinary team in place, with the exception of a web operations role, as discussed above. A product analyst was about to join the team.\n- Some great examples of agile product delivery were discussed, including how the team turned around problems raised in retrospectives, putting more effort into planning, using a feature wall to give developers more autonomy. The team has seen an increase in productivity as a result.\n- The content designer on the team is working in isolation - we discussed that they should collaborate with the GDS content design community to ensure the Digital Marketplace product follows latest content design patterns.\n\n_Security, privacy, tools and standards_\n\n- We had a good discussion around these criteria and the service team displayed a thorough understanding of the needs and how they would solve them. They have undergone assurance processes and are working out potential areas of concern identified.\n- The Panel had some concerns about aspects of these criteria, outlined above.\n- The information on cookies is out-of-date, although we heard this work was planned.\n\n_Improving the service_\n\n- The panel was impressed to hear how the service team can respond quickly to iterate the product, and do so frequently, following findings from research.\n- The team gave a good example of a feature they introduced within a couple of weeks following insights from research, through to design and testing, through to deploy.\n- The panel also noted how the team have removed unnecessary or incomplete features that were not contributing positively to the user experience.\n\n_Design_\n\n- The team showed thorough evidence that users can successfully use the product unaided and have a positive experience. User research informed all design decisions. The team have been tracking technical ability of their users and making decisions accordingly.\n- The team have solved problems for users, such as having 2 start pages for the service for different audiences.\n- The service team have not specifically tackled the offline steps in this service, although they have a vision for how this could work and plenty of research to aid development in that area.\n- The panel noted how the service team is using an adapt and adopt approach to GDS style guides and design patterns. Some of the content in the service isn’t in&nbsp;[GOV.UK](http://gov.uk/) style. The Content Designer should work with&nbsp;[GOV.UK](http://gov.uk/) Content Designers to get the content into&nbsp;[GOV.UK](http://gov.uk/) style before the next assessment.\n- The service has not been designed to be responsive. Data has informed this decision. The team explained they are monitoring data in case they need to review this decision.\n\n_Assisted Digital and Channel Shift_\n\n- The team demonstrated that their users were highly IT literate due to the nature of their roles and the need to have completed other more complex services before accessing the digital marketplace. They provided evidence of this by plotting the users they tested onto the digital inclusion scale. The panel was particularly struck by this excellent approach.\n- They have not yet identified a need to provide assisted digital support for this service, but will continue to conduct research with suppliers and to seek out potential assisted digital users.\n\n_Analysis and Benchmarking_\n\n- The service team have got tracking but not interpretation of analytics in place. A new role due to start will take responsibility for this area. The panel had concerns about the stage the service is at with this criteria, outlined above.\n- The analytics profiles will benefit from a more optimal set-up. The panel made several suggestions for how the performance of the service could be measured, including aligning with business goals, measuring the performance of search rankings, segmentation possibilities such as measuring results by procurement framework.\n- The standard KPIs for services are not relevant for this product.\n- The panel agreed the team needs more defined performance measures in place to evaluate success, as outlined in the recommendations above.\n\n_Testing with the Minister_\n\n- The team has made plans for this.\n\n**Next Steps**\n\nYou should follow the recommendations made in this report and see the&nbsp;[Government Service Design Manual](https://www.gov.uk/service-manual/digital-by-default) for further guidance. In order for the service to proceed we require a review of the not passed criteria.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | N/A | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | N/A | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | N/A | 22 | N/A |\n| 23 | N/A | 24 | N/A |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/my-business-support-service-assessment/",
    "title": "My Business Support - Service Assessment",
    "summary": "A diagnostic tool that through a short set of questions provides people in business, or those wishing to start a business, with clear advice and information that meets their needs. This includes signposting to sources of information, government schemes that could help their business, private sector support; and, for those businesses that have a specific need, where to get that support. The tool helps tease out the support and information that a business should consider based on a series of well tested and structured questions – particularly important for those businesses not entirely certain what they need to do to grow, start up, or solve a problem.",
    "body": "[http://www.greatbusiness.gov.uk/](http://www.greatbusiness.gov.uk/)\n\n**Department / Agency:**  \nBIS\n\n**Date of Original Assessment:**  \n2/9/2014\n\n**Date of Reassessment:**  \n31/10/2014\n\n**Assessment Stage:**  \nBeta\n\n**Result of Original Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nN. Chowdhury (Original) / M. Harrington (Reassessment)\n\n**Service Manager:**  \nD. Adams\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## Reassessment Report\n\n**31st October&nbsp;2014**\n\nThe My Business Support service is seeking permission to launch as a Beta service.\n\n**Outcome of service reassessment**\n\nAfter consideration the assessment panel has concluded that the My Business Support service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria to pass a Beta assessment. Due to the similar nature of this service to the existing Business Finance Support Finder, discussions should continue with GOV.UK on next steps for both of these tools.\n\n**Reasons**\n\n_User needs_\n\nIt is clear that the team have made significant progress since their first assessment and it was really positive to hear examples of how user feedback had directly influenced the design of the product. Similarly, the use of call centre information to iterate the questions and terminology was particularly good. The possible emergence of different user groups for the the two tools, My Business Support and Business Finance Support Finder, was interesting and it will be good to see how this hypothesis develops with the planned further A/B testing. There is however a slight concern that the service could be being used to test users rather than the other way round, but with care this can be mitigated.\n\n_The team_\n\nThe service manager was able to talk through the team on the product and describe the working relationships with the agency building the product. The usual agile artifacts are being used and the service manager has suitable input and prioritisation over stories. There is now a user researcher embedded in the team for 60% of their time, and while development is not co-located, the integration of design and research appears to be working well.\n\n_Security, Privacy, Tools and Standards_\n\nThere is no personal data stored and no accounts. Testing is run in a staging environment. An external agency have been engaged to do the pen testing. A very similar product is live on the Great Business site which passed pen testing. The product is tested on desktop, mobile and tablets across a range of browsers.\n\n_Improving the service_\n\nThe team can respond to bugs/issues and iterate quickly. It is easy for the development team to release but there is some downtime necessary (albeit measurable in minutes). These abilities are expected to remain in place for public beta with the service looking to move towards two-week sprints from one-week sprints.\n\n_Design_\n\nThere has been no designer involved in this project but the team have done well to give the service the look and feel of a GOV.UK service. There are no non-digital steps to integrate with the service.\n\n_Analysis and Benchmarking_\n\nThe team gave good examples of how they have analysed and iterated on the service. The example of changing the layout of the report based on user feedback and then testing the new design right away was one of these. &nbsp;The service is using analytics and data from the contact centre to iterate. It is particularly good to see this offline data being used to iterate the service.\n\n**Summary**\n\nThe panel thought that the team answered the questions well at the assessment and there has been significant progress since the first assessment on 2nd September. It is good to see the team have acted on the recommendations of the previous report and have focused on user research.\n\nThe service has passed the beta assessment and the recommendations listed above are within the capability of the team to help further iterate the service through public beta.\n\n* * *\n\n## Summary of Original Report\n\n**2nd&nbsp;September 2014**\n\nMy Business Support is seeking permission to go to public beta on the service.gov.uk domain.\n\n**Outcome of service assessment**\n\nThe assessment panel concluded My Business Support should not be given approval to launch on a service.gov.uk domain as a beta service.\n\nWhile it is clear there has been significant effort from the team to develop the tool in alpha, there is considerable concern that this tool is too similar in scope to the Business and Finance Support finder on GOV.UK which is also currently under iteration.\n\nIt does not simplify the process for the user, and is not cost-effective to continue to develop two information tools in parallel when they intend to serve the same or very similar purposes. The panel strongly recommends that My Business Support should stop development and work with GOV.UK to determine user needs and let this inform which single tool to iterate.\n\nIn order for My Business Support Finder tool to continue development the outcome of discussions with the GOV.UK team should be reported to the DbD Service Standards team, along with an agreed plan and timeline for the phasing out of either service. The service which continues development will need to demonstrate a clear understanding of user needs and have on-going financial commitment to continue.\n\n**Recommendations**\n\nAs part of the on-going development of the single tool, the panel suggests the team focuses on the following areas.\n\n_User needs_\n\nWhen asked to name user needs, the evidence used by the team was grounded in an annual report from the Star Chamber, not in a methodology in line with the Service Standard. In the on-going the development of the single tool there must be continuous user research to understand user needs. This can be achieved by undertaking the following actions.\n\n- Conduct in-depth research into user needs and develop a shared understanding across the team by talking directly to a robust sample of users\n- Put a clear plan in place for research in the next phase\n- Use search term data on GOV.UK to find out what user needs there are for this sort of service\n- Embed a user researcher within the team and make sure the team is concentrating on real user needs\n- Make sure that the backlog is prioritised in response to user feedback\n- Make time for more than one iteration based on user feedback\n- Test the questions that the service contains\n  - Are they the right sort of questions?\n  - Are users task-focused rather than exploratory?\n  - Do users expect government to provide this sort of information?\n  - Do users just google this sort of information?\n- Test the report that is generated at the end of the service to ensure it is meeting user needs\n\n_Assisted digital and digital take-up_\n\n[Following discussion with the GDS Assisted Digital team it was agreed that because this website is non-transactional, assisted digital support and digital take-up would not be required. This area was therefore not considered at reassessment.]\n\nThe team demonstrated comprehensive national support for people who are unable or prefer not to use the digital tool, including web chat, telephone (talk through and on behalf of) and face to face support. However, there was no evidence of user research into assisted digital user needs specific to this service so it was unclear whether this support would meet those needs. There were also no clear plans to test and iterate the support based on feedback in beta. It is essential to do this to meet the standard. The service should also develop a digital take-up plan to phase out existing alternative channels, where appropriate.\n\n_Technology, Architecture, and Openness_\n\nThe team explained the choice of technologies, the planned architecture, and the plans for opening up the code they have developed. The use of widely adopted open source tools limit locking, and allow for future reuse/repurposing. The plans, agreed by the relevant BIS staff to release the code under the MIT licence should be followed through on without waiting for release of a public beta. This will make it easier for the BIS and GOV.UK teams to determine if there is a way to combine components from the two tools.\n\n_User Format_\n\nThe tool is currently applying a GOV.UK style format which is out-of-date. The team should follow the guidance in the service manual.  \n[https://www.gov.uk/service-manual/user-centred-design/resources/patterns/index.html](https://www.gov.uk/service-manual/user-centred-design/resources/patterns/index.html \"https://www.gov.uk/service-manual/user-centred-design/resources/patterns/index.html\")  \n[https://www.gov.uk/service-manual/user-centred-design/resources/sass-repositories.html](https://www.gov.uk/service-manual/user-centred-design/resources/sass-repositories.html \"https://www.gov.uk/service-manual/user-centred-design/resources/sass-repositories.html\")  \nThey should also implement the templates in [https://github.com/alphagov/govuk\\_template](https://github.com/alphagov/govuk_template \"https://github.com/alphagov/govuk\\_template\")\n\n_Content_\n\nThe smart answer format was changed from the original Business and Finance Support Finder to the current finder tool. This structure seems to be replicating a previous iteration of the Business and Finance Support Finder tool. The questions on the smart answer part of the tool were generally fine with a clear effort to be plain English. There are problems in the output which should be addressed:\n\n- The first section under My Business doesn’t follow the style guide (it should be a table or text, not split, for accessibility reasons)\n- Generally a profusion of bold text which should be limited\n- The formatting of the contact details and links are not in style\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | N/A | 4 | N/A |\n| 5 | N/A | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | N/A |\n| 11 | N/A | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | N/A | 16 | N/A |\n| 17 | Yes | 18 | N/A |\n| 19 | Yes | 20 | Yes |\n| 21 | N/A | 22 | N/A |\n| 23 | N/A | 24 | N/A |\n| 25 | N/A | 26 | N/A |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/annual-tax-summaries-beta/",
    "title": "Annual Tax Summaries - Beta Assessment",
    "summary": "Once a user’s Self Assessment return for the previous tax year has been processed their tax summary will become available for access through the newly released Your Tax Account service as well as HMRC’s existing Online Services. It will also very soon be accessible by Agents on behalf of their clients.",
    "body": "The service will provide the user with a summary of the information that they submitted in their original Self Assessment tax return. This will include the following:\n\n- Income\n- Tax and National insurance\n- Tax free amounts and adjustments\n- Capital gains\n- A breakdown of Treasury spend\n\n**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n22/10/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nN. Chowdhury\n\n**Service Manager:**  \nT. Britten\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## **Assessment Report**\n\nAnnual Tax Summaries is seeking permission to launch as a Beta service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded Annual Tax Summaries has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta.\n\n**Reasons**\n\nFrom the assessment, it is clear that Annual Tax Summaries are an experienced multidisciplinary team who have made good progress incorporating user research as a routine part of the development cycle. This has led to significant change in the design of the summaries since the original prototypes that were informed by policy and ministerial contributions.\n\nThe panel were also impressed with the attention and knowledge the Service Manager expressed on the operational running of the feature, liaising with Web Operations, Policy, Comms and related HMRC product teams in order to anticipate support issues.\n\n**Recommendations**\n\nThe assessment panel has a few observations which the Annual Tax Summaries team should seek to address as part of its future development.\n\n**Integrate with Your Tax Account and Digital Self-Assessment. &nbsp;&nbsp;**\n\nAnnual Tax Summaries is not a transactional service, but a feature which is to be available as part of Digital Self-Assessment and housed within Your Tax Account. Therefore the panel suggests that for live, the feature is reviewed as part of the assessment for one of these services.\n\n**Develop Assisted Digital support based on user need**\n\nThe team proposes using HMRC’s in-house assisted digital support to support users but this is not yet in place. As an interim measure in beta, the team has arranged to provide assisted digital support by email and through an existing tax telephone helpline, with the phone number communicated to users on the equivalent self-assessment paper forms.\n\nTo meet the live assessment criteria, it is not acceptable for services to rely on existing or generic departmental support; teams must evidence how this support meets specific user needs for their service. The team demonstrated some understanding of potential users of self-assessment related digital services but significantly more work needs to be done in public beta. The team’s dedicated user researcher will work on this and the team have a plan to test and measure their assisted digital support through analytics and feedback. The team must test both the interim support and any other proposed assisted digital support to provide evidence that the support they are putting in place meets their specific users’ needs.\n\n**Service Manager empowered beyond the digital product**\n\nAs detailed in the&nbsp;[Alpha assessment report](https://gdsdata.blog.gov.uk/annual-tax-summaries-service-assessment/), the service manager is responsible for the development of the digital tax summary available within self-assessment, but not the paper tax summary which is part of PAYE. The user does not benefit from the paper and digital products being developed separately, therefore the panel recommends the service manager is empowered to lead a single service, combining the two products until the paper edition can be phased out.\n\n**Dedicated support from a Product analyst**\n\nThe panel recommends that the existing multidisciplinary team is extended to include a Product Analyst in order to analyse the digital analytics gathered during the beta stage. This may not necessarily be a full time resource but someone they can call on to give them actionable data to inform improvements and sprints\n\nFor example: The analyst will be able to provide a tagging strategy for the 'service' i.e. event tracking to track the usage of help links etc.\n\n**Open Source Code**\n\nThe panel were encouraged to hear HMRC are making progress in this area, but we are still yet to see any service code published. Publishing source code must be in place for live assessment.  \n[https://www.gov.uk/service-manual/making-software/choosing-technology#when-to-make-new-software-versus-using-existing-software](https://www.gov.uk/service-manual/making-software/choosing-technology#when-to-make-new-software-versus-using-existing-software)[.](https://www.gov.uk/service-manual/making-software/choosing-technology#when-to-make-new-software-versus-using-existing-software.)\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/digital-forms-beta/",
    "title": "Digital Forms - Beta Assessment",
    "summary": "The Digital Forms Service (DFS) will provide a digital replacement for all appropriate HMRC print and post forms. They can be submitted online from the Multichannel Digital Tax Platform. The first form to use the service will be for claiming tax relief for expense (P87 form).",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n2 October 2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nNot passed\n\n**Lead Assessor:**  \nJ. Barlow\n\n**Service Manager:**  \nG. Brown\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nThe tax relief for expenses form is one of 600 forms which the HMRC plan to develop using the DFS (know as iForms) service. This one form has over 150,000 submissions every year. This has the potential to be a very high volume service which could be used by all other appropriate HMRC forms to replace the current print and post forms.\n\nAfter consideration the assessment panel have concluded the iForms service should not be given approval to launch on the service.gov.uk domain as a public Beta service.\n\n**Reasons**\n\n**1. Understanding user needs**\n\nThe service does not have a broad or deep enough understanding of their service users to adequately inform the design of the service.\n\nThe forms are used by a large and diverse population of users. User research to date has been much too narrow and infrequent. The service needs to do research every sprint, and with a much broader range of users - including those who have low digital skills, low literacy, no experience with tax, motor, cognitive, visual & auditory impairments. etc. There is also greater scope for the use of digital analytics to monitor how people are interacting with the form and if there are areas where people are dropping out.\n\n**2. The Team**\n\nThe design capability on the team are form designers, not interaction designers. They sit outside of the main delivery team and are only focussed on a subset of the service. Likewise the content designers are not part of the delivery team.\n\n**3. End-to-end user journey**\n\nThe service has been very focussed on the digital version of a paper form. The service does not have an adequate understanding of how the service relates to a user’s end to end journey, which includes the acknowledgement or refusal of the claim via post.\n\nThere was also not enough evidence to show how a form fits into the wider service. Such as:  \nWhat aspect of a wider service tells a user they need to fill in a form?  \nHow do they navigate from there to the form?  \nOnce a user has submitted a form how is that visible in the wider service?  \nAs they need to identify themselves, why do users have to repeat so much information?\n\nWith further user research there is the potential to make more fundamental changes and improvements to the end-to-end user experience - particularly as the form it is not constrained by legislation.\n\n**4. Design**\n\nThe form was not styled using the design patterns or style guide. There is a possibility that after a software upgrade this will allow more control over the HTML output in the future, however the team could not demonstrate this and at current the design doesn’t meet the criteria.\n\nAs the team do not have full control over the HTML output, it is unclear whether the code is accessible. It was not clear from the presentation that the form components and fragments align with the design patterns set out in the service manual.\n\n**5. Tools & systems**\n\nThe team was unable to explain clearly how the platform was selected and that alternative options were explored prior to it’s selection. As the software is responsible for the auto-generation of the digital forms, it’s unclear how the team would be able to fix any usability or accessibility issues introduced by the software. It’s also unclear how useful analytics could be collected from the forms produced by the software.\n\nThe panel have concerns that the output from the software platform requires JavaScript to work and does not work at all in Internet Explorer 6 or 7. This has the potential to exclude a proportion of potential users from accessing the service. Additionally, if JavaScript is unavailable it does not display an error or any information to the user to inform them how to proceed. This does not follow the practise of progressive enhancement as set out in the service manual. JavaScript availability can affect a range of users for reasons out of their control, and therefore the service should provide a rudimental experience to all users.\n\nWe are also concerned that reliance on the chosen platform to auto-generate the digital forms would make it difficult to replace the product in the future.\n\n**6. Assisted digital**\n\nThere was no evidence that assisted digital support meets the specific needs of AD users, nor that the channels available are adequate in nature or availability.\n\nCentral HMRC support would be available to assisted digital users of this service (HMRC call centre and in-person support from third parties as part of HMRC Network of Enquiry Centres). The telephone support channel would include a triage function. A central HMRC team is looking at assisted digital support for this service, but the pilot is not looking specifically at this service’s users. The service team were therefore unable to demonstrate learnings or support design iterations from research with their specific users.\n\nThe service team did not have an estimate of how many support enquiries would be received nor at what cost. The service team are talking to HMRC call centre staff about what assisted digital users are requiring help with, but are not incorporating digital inclusion methods into any assisted digital support.\n\n**7. Digital Take-up**\n\nThe service team have a broad view on potential long term HMRC-wide plans to wind down non-digital channels, but have no specific digital take-up plan in place for this service.\n\nThe service team said they wanted to prove the benefits of the digital service before undertaking digital take-up communications to users. As such, the team could not explain plans to increase take-up, nor demonstrate how they had improved messaging.\n\n**Recommendations**\n\n- Test the service with a larger and more diverse user group - making sure user needs are continuously used to improve the service.\n- Test and improve the end to end user experience - including offline elements of the service.\n- Put in place digital analytics to monitor how people are using the form and to highlight if there are any parts of the form where users are dropping out.\n- Conduct an accessibility audit with an external agency to ensure the output from the software product is demonstrably usable, alongside meeting the WCAG 2.0 AA standards.\n- Liaise with the senior designer at the Digital Delivery Centre in Newcastle around design and design patterns. Ensure the form components are in line with the design patterns as set out in the service manual.\n- The service the panel was shown in the assessment was not styled accordingly. In order to pass a beta assessment the team need to demonstrate the service they wish to put into beta.\n- Ensure the team has control over the HTML output. A lack of ability to change or update HTML is a risk as there is no control over the accessibility or usability of the service.\n- Conduct user research with assisted digital users of this specific service, to understand their needs and from where they are currently seeking assisted digital support (including non-departmental, third sector, friends and family).\n- Use learnings from this research to design specific assisted digital support that is appropriate for the users of this service. This should include plans for testing; expected number of transactions and costs, by channel (during the beta and after live); joined up and consistent support across other central government transactions, and; incorporation of digital inclusion.\n- Plan for testing the assisted digital support for this service during the beta, including how user insights will be gathered and used to iterate the support during the beta.\n- Bring full control of the assisted digital support for this service into the service team.\n- Contact GDS's Digital Take-up team to put together a plan for the phasing out of any existing alternative channels, where appropriate. This should include evidence-based plans to increase digital take up during the beta; regular analytics/metrics for usage volumes across channels and; evidence that users’ perceived risks have been addressed.\n- Test the service with the minister responsible for it.\n\n**Summary**\n\nWhile the service is not currently at a standard to move into public beta, there is a longer term vision, sustainable team and infrastructure in place to be able to quickly build on the work done to date.\n\nIn particular, increasing the amount of user research undertaken will enable HMRC to further improve the end-to-end experience for it’s very large and diverse group of users.\n\nThis is the first form to be developed using iForm, so the recommendations above provide an opportunity to put the service on a good footing ahead of being rolled out across all 600 HMRC forms.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | No | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | No | 6 | No |\n| 7 | Yes | 8 | No |\n| 9 | No | 10 | No |\n| 11 | No | 12 | No |\n| 13 | No | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | No |\n| 19 | Yes | 20 | No |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | No |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/trusted-helper-beta/",
    "title": "Trusted Helper - Beta Assessment",
    "summary": "The Trusted Helper service allows users to delegate authority to a friend or family member to act on their behalf for digital tax services.",
    "body": "**Department / Agency:**  \n[HM Revenue & Customs (HMRC)](https://www.gov.uk/government/organisations/hm-revenue-customs)\n\n**Date of Assessment:**  \n1 October 2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nR. Grove\n\n**Service Manager:**  \nS. Fhima\n\n**Digital Leader:**  \n[M. Dearnley](https://www.gov.uk/government/people/mark-dearnley)\n\n* * *\n\n## **Assessment Report**\n\nThe HMRC Trusted Helper service is seeking permission to launch on a[service.gov.uk](http://service.gov.uk/) domain as a Beta service.\n\n### Outcome of service assessment\n\nAfter consideration we have concluded the Trusted Helper service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta service on a service.gov.uk domain.\n\n### Reasons\n\nThe service sufficiently demonstrated adherence to the Digital by Default Service Standard. &nbsp;Key areas of success are:\n\n- the rationale for choosing the product and roadmap were clearly articulated by the Service Manager with a user focus, for example enabling reduction in future call volumes for other digital services\n- the Service Manager had an excellent understanding of the service and HMRC, which allowed him to make significant decisions in a timely manner, for example challenging the need for signatures which are prominent on the existing paper form, yet have little functional use\n- the team were highly proficient in their use of agile and demonstrated the ability to implement the right technique at the right time, for example two word retrospectives\n- design iteration was evident throughout which had benefited the user experience, for example decisions to completely remove terms & conditions\n- a dedication to capability building, especially in technical skills, for example cross training Java developers to use Scala\n- use of a variety of user research techniques, for example guerrilla testing, lab testing, 3rd party research\n- involving the entire team in user research sessions, showing testing as a ‘team sport’, for example the technical team had observed live research sessions\n- allowing development to happen in unrestricted environments which allow maximum productivity for the development team, with a view to deploying in more secure environments. We would encourage HMRC to blog about this approach (either on their own or as a guest post on the GDS technology &nbsp;or architecture blogs). It is a good story demonstrating a sensible approach to risk management which could help across government.\n- the team demonstrated a good understanding of their assisted digital user demographics and needs based on service-specific qualitative research and broader HMRC studies. The service is an enabler for other HMRC services and the team have been proactively working with GDS to define how assisted digital support and digital take-up should be handled in this case. The service is joined up with HMRC’s approach to assisted digital support which will give consistency for the user and the team are planning a pilot alongside an HMRC service to test this support.\n\n### Recommendations\n\nThere are still some areas which the service should focus on throughout the beta phase and must be addressed before coming for a live assessment.\n\n- Publishing source code must be in place for the live assessment.  \nSee [Sharing Software in the Service Manual](https://www.gov.uk/service-manual/making-software/choosing-technology.html#sharing-software).\n- The team should continue to refine the process for how the service is operated, ensuring that the process between the delivery team and web ops is rapid and enables continuous deployment. See [The Team in the Service Manual](https://www.gov.uk/service-manual/the-team/index.html).\n- Feedback forms are critical to the beta process; the feedback paths should be user tested to ensure the feedback is relevant to the concern which the users has.\n- Control and design of the feedback forms were outside of the team. &nbsp;This should be moved to give the team full access to customer feedback which will inform future changes. See [Survey Design in the Service Manual](https://www.gov.uk/service-manual/user-centred-design/user-research/survey-design).\n- There was no [Information Asset Owner](https://www.gov.uk/service-manual/making-software/information-security#information-asset-owner), to own the data that a relationship between helper and people being helped, this should be reviewed and ownership assigned.\n- The current analytics package is using the free license, which means data sampling will not be truly representative of usage. &nbsp;This should be an upgraded to eliminate sampling issues to aid data driven decision making. See [Analytics Tools in the Service Manual](https://www.gov.uk/service-manual/making-software/analytics-tools).\n- While the service is simple and intuitive, it is important the service conducts user research into users understanding of the importance of the change being made, rather than just how easy the form is to complete.\n- GDS strongly recommend that the team prioritise notifications to users who have requested or accepted authority by using the service - this will help completion rates and users understanding of the importance of their decision.\n- [Progressive Enhancement](https://www.gov.uk/service-manual/making-software/progressive-enhancement) is critical, as the service should work for everyone. &nbsp;Testing should be re-run to ensure this is the case, and change the build where it is not.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/registered-traveller-service-assessment-2/",
    "title": "Registered Traveller - Service Assessment",
    "summary": "The Registered Traveller service enables pre-approved regular travellers from a selected group of countries, to pass through the UK border faster.",
    "body": "Users are business travellers or frequent flyers to the UK that meet the current eligibility criteria and have passed the detailed background checks conducted during the application process. &nbsp;Once approved, members are able to use the ePassport gates (if they have a biometric passport) at Gatwick or Heathrow airports.\n\nhttps://www.gov.uk/transformation/apply-registered-traveller.html\n\n**Department / Agency:**  \nHO / BF\n\n**Date of Assessment:**  \n22/9/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Hughes\n\n**Service Manager:**  \nJ. Dos Remedios\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## Assessment Report\n\nThe overall result of this assessment is that the service has passed - congratulations to the team.\n\n**Reasons and Recommendations**\n\nThe panel were particularly impressed by:\n\n- the progress the team has made in building up its user research capability and plans - clearly a lot of progress has been made since the alpha assessment\n- the work the team has done to develop the caseworking system to meet the needs of back office users\n- the transparent integration of user research into the backlog\n- the team’s success in putting user needs first and working in an agile, iterative way in a complex stakeholder, policy and security environment\n- the effort the team has put into making sure the service meets accessibility requirements\n- the way the team is using a range of methods and applying them in ways that make sense in the context of the organisation and the service\n- the team’s work to obtain a change in the Border Force’s legacy system so that there are only 5 seconds added to the user’s passage through border controls at the enrolment stage (instead of requiring a much longer interview) and that there is no longer a reliance on email\n\nWe recommend that in the next phase of development the team:\n\n- make further progress towards publishing more of its code, particularly for elements that would be useful for other services like the casework management system\n- expose the service name and branding to more research and testing to make sure it makes sense as part of the whole user journey, for example by researching language that is commonly used by users when navigating airports and passport control\n- build up the team’s internal content design capacity through either a dedicated person and / or training for existing team members\n- replace the drop-downs on the eligibility questions with the GDS checkbox design pattern (see https://designpatterns.hackpad.com/Radio-buttons-and-checkboxes-8eBuLm9eRaz)\n\nThe service team has demonstrated that additional assisted digital support does not need to be provided at this time. If the scope of the service changes the user base, the team may need to undertake research with assisted digital users and design, test and provide appropriate assisted digital support which meets user needs.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | N/A |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/gov-uk-verify-service-assessment/",
    "title": "GOV.UK Verify - Service Assessment",
    "summary": "The GOV.UK Verify service allows users to prove their identity when accessing digital services, without having to send items in the post or attend a counter service in person. This means people can safely access their data and perform transactions when using digital public services, and government services can be confident to a defined level of assurance that a user is who they say they are. It helps government digital service providers reduce the risk of user’s data and services being exposed to the wrong people.",
    "body": "The users are users of the digital government services that require verification of identity. The user need is to be able to securely access their personal data and services online, be confident that others can’t pretend to be them in order to access their personal data and services, and know their privacy will be protected.\n\nhttps://identityassurance.blog.gov.uk/\n\n**Department / Agency:**  \nCO\n\n**Date of Assessment:**  \n16/9/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nN. Williams\n\n**Service Manager:**  \nS. Dunn\n\n**Digital Leader:**  \nP. Maltby\n\n* * *\n\n## Assessment Report\n\nAfter consideration the assessment panel have concluded&nbsp;[GOV.UK](http://gov.uk/) Verify (the new name for the identity verification service from the Identity Assurance Programme) has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch in Beta.\n\n**Reasons**\n\nThe assessment panel were impressed in particular by the team’s iterative research and design process and commitment to finding more challenging groups of users with which to test the service. This work has paid dividends in making this very complex service appear simple and clear, not least by adopting its new name. The presentation of research outputs was excellent.\n\nIt was also very good to see that there are security analysts and operations specialists in-team, ensuring the service is secure and putting the right governance in place to ensure identity providers (IDPs) comply with data security.\n\n**Recommendations**\n\nThe assessment panel have a few observations which, though not serious enough to prevent the service moving into Beta, will be important to address as soon as possible during the beta (and before the service comes to Live assessment).\n\n1. **Demographic coverage.** The service team said that the twoIDPs currently available cover around 75% of the UK population in terms of the evidence users are required to provide (users need to have a UK credit history or a passport/driving licence to verify their identity through&nbsp;[GOV.UK](http://gov.uk/) Verify). While the panel agree this is a great place to start (from a base of 0%) the 25% of people it preclude is significant. The service therefore needs to:\n  - actively work with the market to grow this coverage to as close to 100% as can be achieved, as early as possible during the Beta\n  - ensure that relying party services assess how this demographic coverage maps to their own users as part of their onboarding, and ensure that they have a clear plan to meet the demand for alternative ways to verify users’ identity for those who can’t provide the required evidence\n  - until 100% coverage is possible, provide a clear journey for users who need to take an alternative route to verify their identity\n2. **Assisted digital support.** Related to the above, to ensure users needing assisted digital support are aware of their options, the panel recommend that&nbsp;[GOV.UK](http://gov.uk/) Verify should include service-specific signposting to the assisted digital support available for each relying party service. The service team should test for successful ways of signposting service-specific AD support on the IDPs’ pages and take steps to require IDPs to include such signposting in their pages.\n3. **Prioritise testing disaster recovery and continuous deployment.** The assessment panel recommend that the planned work on testing the data-centre failover system, and improving the ability to deploy seamlessly without risk of interrupting the service, both be given very high priority.\n4. **Look harder at the user experience of choosing an ID provider.** The panel were uncertain about:\n\n- how well users will understand the choice they are being asked to make between different ID providers (both now when there is little choice, and in future when there is a risk of too many choices for the user to understand)\n- how well users will remember their choice when they return to re-use the service\n- the limited control the&nbsp;[GOV.UK](http://gov.uk/) Verify team has over the quality of the user experience for the IDP part of the journey\n\nat the Live assessment, the panel would like to see evidence of these things not being a problem for users, or changes to the service or governance arrangements which address them.\n\nThe assessment panel are also keen to see the service integrate with the performance platform as soon as possible (the service team is already working with performance platform on this).\n\nThe service has clearly come a long way since the assessment at the end of the alpha and is a glowing example of “doing the hard work to make it simple”.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/paye-company-car-tax-beta/",
    "title": "PAYE: Check or Update your Company Car Tax - Beta Assessment",
    "summary": "PAYE for Employees will eventually allow all 41m PAYE employees, those who work for an employer and pay income tax through Pay As You Earn (PAYE), to see what tax they pay and why, with the ability to change/update their particular circumstances/information which govern the amount of tax they pay. Initially the service will allow PAYE employees to view and change their company car tax benefit which will ensure that they pay the right amount of tax based on the company car they have.",
    "body": "[https://www.gov.uk/transformation/paye](https://www.gov.uk/transformation/paye)\n\n**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n4 September 2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Thornett\n\n**Service Manager:**  \nL. Hawksworth\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment Report\n\nPAYE for Employees (My Company Car Tax) service is seeking permission to launch as a&nbsp;[GOV.UK](http://gov.uk/) Beta service.\n\n### Outcome of service assessment\n\nAfter consideration the assessment panel have concluded the PAYE for Employees (My Company Car Tax) service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a&nbsp;[GOV.UK](http://gov.uk/) Beta service.\n\n### Reasons\n\nThe service was assessed against all 26 points of the Digital by Default Service Standard and the assessment panel were particularly impressed with how the team are:\n\n- iterating and improving the service based on data and evidence gathered from regular user research\n- working with the right people within the HMRC PAYE organisation to ensure that the service is able to support transformation within the business as well as providing a better experience for users\n- taking a sensible approach to privacy, data security and risk\n- using appropriate tools and technologies to develop and operate the service\n- using multiple environments to allow full end-to-end testing and working towards a continuous integration model of deployment\n- working in an agile way using appropriate methodologies, tools, techniques and processes to deliver working software early and often.\n- benchmarking and comparing the performance data to the existing telephony based service and have a plan, including the necessary legislative changes, to increase take-up of the new digital service\n\nThe team have developed a very detailed understanding of the users and their needs within this service and have demonstrated that additional assisted digital support does not need to be provided at this time. &nbsp;If the scope of the service changes in any way (for example, new transactions are added which changes the user base), the team must undertake research with assisted digital users and design, test and provide appropriate assisted digital support which meets user needs.\n\n### Recommendations\n\nIn advance of the public beta release the team must:\n\n- make their source code open and reusable. The team explained that the code was written to be shared and reusable but it was not clear why it was therefore not already being published in the open and what was needed to make this happen\n- convert their free analytics solution to a paid-for service which will provide a better assurance on the use of data collected from users and how this is stored and managed by the external provider\n- update their cookie page to reflect the actual analytics solution that is being used by the service. The existing information on the cookie page is incorrect.\n- define success criteria for the public beta phase in order to know when the service is ready to be assessed for a live release\n- continue working with the performance platform to publish dashboards of service performance\n- continue working with the&nbsp;[GOV.UK](http://gov.uk/) team to define the user journey into the start of the service and the suitable end-points when the user returns to&nbsp;[www.gov.uk](http://www.gov.uk/)\n- take note of the content style recommendations that have been shared separately in order to improve some of the use of style within the service\n\n### Next Steps\n\nThis service has been given approval to launch as a&nbsp;[GOV.UK](http://gov.uk/) Beta service.\n\n### Summary\n\nIn summary the assessment panel are pleased to report that the service is ready to progress to a public beta stage. The work carried out during alpha and private beta to iterate and improve the service based on the needs of users was very encouraging and we are looking forward to seeing how the service further improves now that a larger number of users will be able to access it.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/performance-platform-service-assessment/",
    "title": "Performance Platform - Service Assessment",
    "summary": "The performance platform is an enabling service to help departments, and specifically service managers within the department, monitor the performance of the service they are responsible for. The platform provides dashboards to present data stored within the departments - Legacy IT systems, &nbsp;manual data from non-digital channels and online analytics. These dashboards contain important information about a service so it can can be viewed and assessed.",
    "body": "The platform provides details on the performance of a service, both digital and assisted digital. It breaks down details of how citizens use a transaction service to enable problems to be spotted, improvements to be tracked, for example, did the changes I make result in an improvement in the performance of the service\n\n**Department / Agency:**  \nCO / GDS\n\n**Date of Assessment:**  \n27/8/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Hughes\n\n**Service Manager:**  \nW. Drummond\n\n**Digital Leader:**  \nP. Maltby\n\n* * *\n\n## Assessment Report\n\nThe Performance Platform is seeking permission to enter into its public beta phase on&nbsp;[GOV.UK](http://gov.uk/).\n\n**Outcome of service assessment**\n\nAfter consideration we have concluded the Performance Platform has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta service.\n\n**Reasons**\n\nThe product meets the requirements of the standard for public beta.\n\nParticular areas of strong performance against the standard included:\n\n- The service has a programme of user research which is being used to inform decisions about new and developed features\n- The platform is consistent with the&nbsp;[GOV.UK](http://gov.uk/) design patterns\n- The product has been developed and tested for accessibility\n- The product works in different browsers and on different devices\n- The team can demonstrate some examples where service managers have used data from the platform to inform decisions about the development of their services\n\n**Recommendations**\n\nWe recommend the following priority areas for development over the next 3 months as the service scales from a providing a small number of bespoke dashboards to rolling out the platform across many services.\n\n- The team should revisit its analysis of the user needs the platform is seeking to meet, based on the evidence it has gathered during the alpha and further user research if necessary, so it can validate and prioritise the range of user needs the team has identified.\n- The team should develop a clear and compelling product vision. This should go beyond rolling out existing products to many services and be based on a clear articulation of the most important user needs the team is aiming to meet.\n- The team should develop a clear, structured and transparent approach to prioritising user needs and resolving potential conflicts between the needs of the different users of the platform the team has identified.\n- The team should prioritise and develop a clear roadmap for its work to allow services to self-serve where they are using standard dashboard products. This will free up the team to work towards delivering its wider product vision.\n- The team should extend its research more fully to include the users in the ‘secondary’ list of users.\n- The team should further develop its approach to measuring the extent to which the product is demonstrably meeting real user needs. This should include more use of the available data about user engagement with the platform (eg analytics such as the percentage of users who drill down to the tabular content, or who download data, etc).\n- The assessment panel would encourage the team to share more of its thinking about priorities, user needs and design decisions as part of their new comms strategy\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/waste-carrier-registration-service-assessment/",
    "title": "Waste Carrier Registration - Service Assessment",
    "summary": "The Service allows businesses who carry, broker or deal waste to fulfil their regulatory requirement to register with the Environment Agency. &nbsp;Some users, including those that only carry waste from their own business, pay no fee (lower tier). Some users, who carry wastes for others, pay a fee for registration (upper tier). For upper tier customers registrants are checked against a list of relevant convictions. &nbsp;The service also publishes the list of registered carriers to allow other business and the public to check if people are registered. &nbsp;An assisted digital route is provided as a telephone service through our national customer contact centre.",
    "body": "https://www.gov.uk/transformation/apply-to-carry-waste\n\n**Department / Agency:**  \nDEFRA / EA\n\n**Date of Assessment:**  \n5/8/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nNot passed\n\n**Lead Assessor:**  \nC. Mitchell\n\n**Service Manager:**  \nP. Wright\n\n**Digital Leader:**  \nJ. Pierce\n\n* * *\n\n## **Assessment Report**\n\nAfter consideration the assessment panel have concluded the Waste Carriers service should not be given approval to launch on the&nbsp;[service.gov.uk](http://service.gov.uk/) domain as a Beta service.\n\n**Reasons**\n\nThe service team has a good understanding of their digital users and their needs. There is strong service management with suitable empowerment. The current phase 1 service is working well, with a good response from users and improvements have been made based on feedback. The team has also shown an understanding of agile and has been improving the way it works as part of the development.\n\nHowever, as recognised by the service team, the phase 2 version of the product is not as far down the development life-cycle and not yet ready for a general Beta release. The team was unable to fully articulate how it is structured along with some of the processes it uses, highlighting potential capability gaps that will need to be reviewed / resolved prior to Beta launch.\n\n**Recommendations**\n\n**Criteria 2** - Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.\n\n- The team were unable to fully articulate the capability within the team and some of their processes, pointing to capability gaps within the team that cover development, content design, testing, and analytics.\n- **Recommendation** : review and clarify capability within the team, with a view to filling any gaps\n\n**Criteria 4** - Evaluate the privacy risks to make sure that personal data collection requirements are appropriate.\n\n- The service uses a generic Environment Agency website privacy policy and cookie statement which is 3 years old. The experience for reviewing the privacy policy can be jarring for users.\n- **Recommendation** : review and update the user journey for people wishing to view the privacy policy and provide details specific to this service\n\n**Criteria 9** - Create a service that is simple and intuitive enough that users succeed first time, unaided.\n\n- The current application is unfinished and still contains some serious defects. There are also some areas of the user flow which can lead to dead ends.\n- **Recommendation** : Reconsider approach to development and testing in order to reduce the number of bugs. Complete functionality, resolve outstanding defects, and ensure effective testing is carried out.\n\n**Criteria 10** - Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it.\n\n- Assisted digital users are able to access a service that will complete the registration for them, however there is insufficient evidence to support decisions made around this provision. The assisted digital support does not incorporate digital inclusion approaches.\n- **Recommendation**** :** Carry out specific research with assisted digital users (of all abilities) and design support to meet their needs and volumes, using any required channels.\n\n**Criteria 13** - Build a service consistent with the user experience of the rest of&nbsp;[GOV.UK](http://gov.uk/) by using the design patterns and style guide.\n\n- The content of the service does not fully meet the&nbsp;[GOV.UK style guide](https://www.gov.uk/design-principles/style-guide), and requires better signposting and copy throughout.\n- **Recommendation** : Have a&nbsp;[content designer](https://www.gov.uk/service-manual/the-team/content-designer.html) work on the service to ensure it is understandable and meets the standard found elsewhere on&nbsp;[GOV.UK](http://gov.uk/).\n\n**Criteria 14** - Make sure that you have the capacity and technical flexibility to update and improve the service on a very frequent basis.\n\n- The team were unable to fully articulate their testing processes.\n- **Recommendation:** Review/update testing approach to ensure:\n  - outstanding defects are identified, prioritised and the remaining effort is understood\n  - automation where possible\n  - suitable testing to support target browsers/devices\n  - there is a clear and efficient approach to defect resolution\n\n**Criteria 15** - Make all new source code open and reusable, and publish it under appropriate licences (or give a convincing explanation as to why this can’t be done for specific subsets of the source code).\n\n- Code from the service has been published and is currently being reused by another government organisation. However the process for publishing code should be improved, in order to improve its reusability and value to government.\n- **Recommendation** : Formalise a policy around releasing open source software that takes into account the risks and benefits of doing so. CIAN 2013/01 from CESG has some relevant guidance in this area.\n\n**Criteria 26** - Test the service from beginning to end with the minister responsible for it.\n\n- The existing phase 1 service has been shown to the relevant minister, though there is not yet a plan in place to demonstrate the “phase 2” part of the service.\n- **Recommendation** : set up a meeting to demonstrate the new service to the relevant minister before the service moves into the live stage.\n\n**Summary**\n\nThe Service team has made good progress bearing in mind some of the constraints they face and showed a high level of maturity in a number of areas. There are also areas, such as building internal DevOps capability, where work being carried out now will make things significantly easier in the future.\n\nIt can be tricky to time the assessment so that the service is fully ready, without holding up delivery. we are confident that many of the issues identified by the assessment would have been resolved had the assessment been made at later date. The team’s willingness to take on and respond to feedback stands them in good stead for future assessments.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | Yes | 2 | No |\n| 3 | Yes | 4 | No |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | No | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | No | 14 | No |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | No |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/schools-academy-conversion-form-service-assessment/",
    "title": "Schools Academy Conversion Form - Service Assessment",
    "summary": "This service is to allow schools who wish to convert to academy status to submit applications online, quickly and correctly. The form can be saved at any time and does not need to be completed in a single sitting. The primary audience is schools. The online service will replace the offline application.",
    "body": "**Department / Agency:**  \nDepartment for Education\n\n**Date of Assessment:**  \n30/7/2014\n\n**Assessment stage:**  \nBeta Review\n\n**Result of Assessment:**  \nNot passed\n\n**Lead Assessor:**  \nM. Harrington\n\n**Service Manager:**  \nL. Rugg\n\n**Digital Leader:**  \nS. Bruce\n\n* * *\n\n## Assessment Report\n\nAfter consideration the assessment panel have concluded the Schools Academy Conversion Form does not yet meet the service standard at Beta and should not be given formal Beta status and a&nbsp;[GOV.UK](http://gov.uk/) start page at this time.\n\n**Reasons**\n\nThe panel would like to highlight that while this assessment was not passed by following the recommendations below a pass could be achieved.\n\nThe Schools Academy Conversion form did not pass for the following reasons:\n\n- User needs: Good work was done to understand user needs at discovery and a positive example was given of how the login process was redesigned to meet the needs of the user. However, this user research hasn’t been continued and there is no regular testing in place.\n\n- The team: While the service team is small they have clearly worked hard to deliver the service so far. The lack of design, content, user research and testing support means that the team have to support many different roles. The lack of access to specific expertise impacts the ability for the team to meet some key points of the standard.\n\n- Software, Privacy, Tools and Standards: The service team do not currently share non-sensitive source code, design artefacts or tests as open source, doing so would mean these could be re-used by other organisations. It should also be noted, that while using an online forms service might be suitable for the front end replacement of paper and phone it is likely to introduce design and process constraints which are hard to overcome when looking at end to end service re-design.\n\n- Improving the service: The software allows for quick changes and edits by the service team but the lack of a user researcher or research plan mean iterative improvements are not being driven by real users.\n\n- Design: Although there has been no designer for the service the team have worked to build the form with the look of&nbsp;[GOV.UK](http://gov.uk/). However, advice on design patterns from the service manual has not been closely followed and there is still work to do to improve the design to meet the&nbsp;[GOV.UK](http://gov.uk/) standard that would be expected of a public Beta. Specifically the team should look at the following areas:\n\n- JavaScript / progressive enhancement **-** The site relies on JavaScript to display. If JavaScript is turned off the site fails to display anything, despite there being HTML served to the browser. Teams should be creating services that work for everybody, regardless of browser capabilities. A lack of JavaScript should not impede the use of the service and JavaScript and other additional technologies should only be used to enhance the experience. The use of JavaScript also affects the accessibility of the service. All pages are shown at a single URL, the back button does not behave as most users expect. Each page should have its own URL, a unique page title which explains the purpose of the page and the respective headings alongside this. If JavaScript is used to navigate or load pages (on a service this simple, it is not technically necessary) then functionality should be put in place to update the browser history and page title.\n- Modal popups - It is strongly recommended that modal popups are not used at all as these present significant usability and accessibility issues. A separate sign in and registration flow could straightforwardly be incorporated into the process.\n- Navigation, Form Design and Headers, Footers and Typography - A number of specific concerns and recommendations were made by the panel in these areas.\n\nThe team will need full control over the front end to address these issues. &nbsp;The panel were advised a non-JavaScript enabled version will be included in the next release from the developer. The panel will expect to see evidence of this either having taken place or of an agreed timeline when the service returns.\n\n- Analysis and Benchmarking: Google Analytics has been instrumented but little has been done to implement goals/conversion funnels. These are important to better understanding the service and meeting the requirement to publish the KPIs on the Performance Platform.\n\n- Digital take-up: The team has no plan in place for digital take-up and have requested advice from GDS.\n\n**Recommendations**\n\n- User needs: The team should put together a plan for user research and &nbsp;ideally should have access to a dedicated user researcher. &nbsp;This is a relatively small service (20-30 applications per week) and the research should be scaled to this but without research it is unclear where the iterative improvements will come from.\n\n- The team and Improving the service: Support a multidisciplinary team to deliver the best possible product. The team should have access to specialist skills in the department to provide expertise in the areas of user research, design, content design and digital analytics. These skills will be of benefit not just to this service, but will enable all digital services the department are developing to meet the standard.\n\n- Software, Privacy, Tools and Standards: The service needs to own their URLs, not the underlying technology so they could more easily switch suppliers if the needs arose. The panel also recommends automated testing (especially as the number of forms increases), service monitoring and a plan for how to operate a service which could go down or be abused (DDoS). The team need to understand and be able to explain how long they will hold the data provided and the purpose of this.\n\n- Design: The team would benefit from a designer on the team to help with improving the user experience and form design. The team will need full control of the front end for this. The form should also work without JavaScript and must be tested for accessibility.\n\n- Analysis and Benchmarking: If keeping Google Analytics this should be upgraded to Google Analytics Universal. IP anonymisation should be implemented and data sharing with third parties turned off if not done already. The team should start discussions with the Performance Platform team regarding a dashboard for the service.\n\n- Assisted Digital: The team clearly understood assisted digital principles and had good plans in place to provide support through Project Leads. They should do more research to understand the number of schools which will need this support and the channels they will use. They need to develop their plan to measure the assisted digital support and gather feedback from users in beta, to ensure that the support will fully meet the assisted digital standard in live.\n\n**Summary**\n\nThe panel thought that the team presented answers openly and succinctly at assessment and have made good progress in implementing a new digital approach in their department. The form is close to meeting the standard for Beta. In particular the panel were very impressed by the work of such a small team and how they are using agile in spite of challenges. The recommendations for a multidisciplinary team are there as the panel believe additions to the team would provide significant support and expertise which will be necessary to help the existing team improve the product. In particular the panel thought the points on assisted digital were very well answered and it is good to see that support is already in place and well on the way to meeting the standard.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | No | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | No | 8 | Yes |\n| 9 | No | 10 | Yes |\n| 11 | No | 12 | Yes |\n| 13 | No | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | No |\n| 19 | No | 20 | No |\n| 21 | No | 22 | No |\n| 23 | No | 24 | No |\n| 25 | No | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/visas-service-assessment/",
    "title": "Visas - Service Assessment",
    "summary": "If you need a visa to visit the UK you’ll be able to apply using a simple online service.",
    "body": "[https://www.gov.uk/transformation/apply-visa](https://www.gov.uk/transformation/apply-visa)\n\n**Department / Agency:**  \nHO / UKVI\n\n**Date of Original Assessment:**  \n03/06/2014\n\n**Date of Reassessment:**  \n20/06/2014\n\n**Moving to:**  \nBeta\n\n**Result of Original Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nM. Sheldon\n\n**Service Manager:**  \nT. Bruck\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## Reassessment Report\n\n**20th June 2014**\n\nThe Visit Visa service, for mainland China, is seeking permission to launch on service.gov.uk as a Beta service.\n\n**Outcome of service reassessment**\n\nWe have concluded that the service has shown sufficient progress and additional evidence to launch as a Beta on the service.gov.uk domain. We have made this decision based on the evidence the service provided for criteria 1, 2 and 9 of the Digital by Default Service Standard, which were the sections the service did not pass at its original assessment.\n\nThe further information submitted by the team and explored at reassessment provided sufficient evidence of user research with a range of potential users of the service. This complimented the evidence provided at assessment which showed a thorough approach to user research, with a focus on quality.\n\nFurther evidence on the team’s data analysis capability was reassuring and sufficient to assure the assessment panel. With their emphasis on building capability within the team and working with GDS on recruitment of core digital roles across the Home Office, the assessors are happy to pass the service on criteria 2.\n\nAt reassessment the service team demonstrated significant engagement with content designers since the assessment, and the service under discussion at reassessment showed very significant improvement from the original assessment. The service team evidenced a clear commitment to continuing to iterate and improve content in response to user feedback, and the changes they had succeeded in making to content, in conjunction with policy and legal colleagues were very welcome.\n\n**Summary**\n\nWe were pleased to see the immediate improvements made to the content of the service and the approach to prioritise further improvements. We were also grateful to the team for the additional evidence provided on the scope and scale of user research. We are therefore pleased to see the service proceed to Beta. We look forward to the team sharing feedback from the user research trip to China when they return for Live assessment.\n\n* * *\n\n## Summary of Original Report\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded that the Visit Visa General Visitor service should not launch on the&nbsp;service.gov.uk domain as a Beta service, for the reasons given below.\n\nIn line with current plans, the service should continue to test with real users, in a controlled way, so that the team can monitor and iterate the service. Over this time, through this process, the service team will be able to address the points made below. &nbsp;The assessment panel will then be able to reassess the service so that it can move to Beta on the&nbsp;service.gov.uk domain.\n\n**Reasons**\n\nThe assessors were pleased to see that the Visas service team were meeting most of the 26 criteria of the Digital by Default Service Standard, using the same multidisciplinary team, platform and product catalogue built for the Tier 2 Visit Visa service. However, the assessors agreed that service did not fully meet the following criteria:\n\n**1. Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for digital and assisted digital service design.**\n\nAlthough the service team have carried out regular user research whilst developing the service, the assessment panel felt that this was not completed with enough real users. The current planned user research trip to China should be completed. This will provide the team with a deeper understanding of the population demographics and user proficiency profiles of China.\n\n**2. Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.**\n\nThe service team realise there is a skills gap around content design and are grateful for the support GDS has provided. There was some concern over how frequently the GDS Content Designer has been able to iterate and improve the content based on user feedback during the service development (see Criteria 9).\n\nThe service team also need to find a suitably skilled member to focus on service analytics and analysis. With the future planned rollout to other countries it will become an increasing challenge for the team to analyse service analytics and translate findings into service improvements. This was a recommendation from the Tier 2 Visit Visa assessment and there was insufficient evidence of a plan to act on this recommendation.\n\n**9. Create a service that is simple and intuitive enough that users succeed first time, unaided.**\n\nDuring the assessment some verbose and confusing content was spotted, with noticeable errors. The assessment team felt that given the length and complexity of the form its content needs significant improvement. This is especially important for a service intending to launch in a country where the users’ primary language is not English. The assessment panel understand the service has immediate plans to do this but suggest the testing with real users also informs content improvement before reassessment.\n\n**Recommendations**\n\nFor the service to pass and proceed to Beta on&nbsp;service.gov.uk the assessment panel recommend that the service team:\n\n- continues to work closely with a GDS Content Designer and complete a thorough review of the service’s content, which must include fixing errors and improving the language used. It should be as simple and easy to follow as possible, incorporating improvements based on user feedback and these changes must be reflected in the Chinese translations.\n- put in place a plan to find a dedicated Content Designer and transfer the knowledge and skills of the GDS Content Designer.\n- put in place a plan to find a dedicated Product Analyst to focus on service analytics and analysis.\n- continues with the planned trip to China and test the service with real users. Use their feedback to inform improvements to the service features and content.\n- continues to work with the&nbsp;[GOV.UK](http://gov.uk/) User Formats team to plan how to recruit a growing number of users via the&nbsp;[GOV.UK](http://gov.uk/) start page once the service passes a Beta assessment.\n\n**Next Steps**\n\nThe service team should follow the recommendations made in this report and see the&nbsp;[Government Service Design Manual](https://www.gov.uk/service-manual/digital-by-default) for further guidance. In order for the service to proceed GDS will require a review of the failed criteria; 1, 2 and 9.\n\n**Summary**\n\nThe assessment panel were encouraged by the knowledge and commitment of the service team to ensure that the best service is delivered to its users. We were pleased to see continued improvements to the agile ways in which the team are working, the visas platform and the product catalogue. With the planned user research trip to China the team have an ideal opportunity to test with real users, gather their feedback and use this to improve the service. We look forward to running a reassessment so that the Visit Visa service can be confidently launched as a public Beta in China.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/prison-visit-booking-service-assessment/",
    "title": "Prison Visit Booking - Service Assessment",
    "summary": "If you're visiting a prison you’ll be able to book using a single service, offering a simpler, faster experience for families, friends and professionals.  \n[https://www.gov.uk/transformation/book-prison-visit](https://www.gov.uk/transformation/book-prison-visit)",
    "body": "**Department / Agency:**  \nMOJ\n\n**Date of Assessment:**  \n9/5/2014\n\n**Moving to:**  \nBeta\n\n**Result:**  \nPass\n\n**Lead Assessor:**  \nN. Williams\n\n**Service Manager:**  \nT. Duarte\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n**Assessment report**\n\nThe Prison Visit Booking service is seeking permission to formally launch as a Beta service covering the majority of state-operated prisons, with a start page on&nbsp;[GOV.UK](http://gov.uk/).\n\n**Outcome of service assessment**\n\nGDS are pleased to conclude that the Prison Visit Booking service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a Beta service on&nbsp;[GOV.UK](http://gov.uk/).\n\n**Reasons**\n\nIt was clear from the assessment that the service has been built around a deep understanding of user needs, that it is meeting those needs successfully and is providing a much improved experience for prisoners, visitors and prison staff alike. GDS were satisfied that the Prison Visit Booking service have given due thought to the safety of the service and involved technical and security experts accordingly, and that they are working in an agile method and are proactively improving the service on an ongoing basis in response to user needs.\n\n**Recommendations**\n\nFor the service to succeed at Live assessment, during the Beta it will be vital that Prison Visit Booking:\n\n- publish the remainder of the service’s code openly, and ensure that you are using an appropriate licence both for the newly published code and the component of the service you have already open sourced\n- put in place plans to ensure that there will be a permanent team available to iterate and improve the service post go-live, and that this team includes time from a dedicated person with the expertise to gather and gain insight from analytics data\n- evaluate the assisted digital support pilot during beta and ensure that the appropriate levels of support are in place for the live service. This should include:\n  - ensuring assisted digital support is made available to all users who need it\n  - measuring volumes and cost per minute of assisted digital per channel, and showing they are in line with estimates\n  - showing that assisted digital users are aware of support and can access it easily\n  - showing positive feedback from users and experts\n  - verifying that there is sufficient capacity to deliver phone and face-by-face support, including that external organisations are sufficiently funded to meet demand\n  - including messages within the service itself to signpost the available support\n- publish information about the cookies used by the service including their purpose and how long they are stored for (see&nbsp;[https://www.gov.uk/service-manual/making-software/cookies](https://www.gov.uk/service-manual/making-software/cookies)&nbsp;for more)\n\n**Next steps**\n\nThis service has been given approval to launch as a beta with a start page on&nbsp;[GOV.UK](http://gov.uk/). (The service is already on a&nbsp;[service.gov.uk](http://service.gov.uk/)&nbsp;domain)."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/civil-claims-service-assessment/",
    "title": "Civil Claims - Service Assessment",
    "summary": "Civil Claims is a service area that allows the public to solve a wide range civil legal disputes. Civil Claims can be applied to numerous scenarios - from disputes with your neighbour to personal injury - but are predominantly used when trying to obtain money or property owed.  \n[https://www.gov.uk/transformation/court-claims](https://www.gov.uk/transformation/court-claims)",
    "body": "**Department / Agency:**  \nMOJ\n\n**Date of Reassessment:**  \n6/5/2014\n\n**Moving to:**  \nBeta\n\n**Result:**  \nPass\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nE. Fineberg\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## **Reassessment report**\n\nThe Civil Claims service is seeking permission to launch the Accelerated Possession Claim on a&nbsp;[service.gov.uk](http://service.gov.uk/)&nbsp;domain as a Beta service.\n\n### **Outcome of service assessment**\n\nAfter consideration GDS have concluded the Civil Claims service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria andshould proceed to launch as a Beta service on a&nbsp;[service.gov.uk](http://service.gov.uk/)&nbsp;domain.\n\n### **Reasons**\n\nThe team spoke knowledgeably about their users, demonstrating strong evidence of the user research that had been done so far and its plans to continue to iterate the service based on research, data and user feedback.\n\nThe strong multidisciplinary team will remain in place throughout the next phase of development.\n\nThe team is able to iterate the service quickly and has a continuous deployment process set up, with zero-downtime deployments already in place.\n\nThe service has the appropriate safety, security and privacy measures in place.\n\n### **Recommendations**\n\nWork with GDS to ensure the relationship between&nbsp;[GOV.UK](http://gov.uk/)&nbsp;and the Civil Claims service provides a good user journey by sharing data/hypotheses to feed into the start page content and design.\n\nEvaluate the assisted digital support pilot during beta to ensure that the appropriate levels of support are in place for the live service. This should include ensuring assisted digital support is made available to all users who need it, even those choosing at this time to use professional intermediaries. This makes sure the service is sustainable and that no one is excluded from using it on the basis of cost.\n\nUse data (to supplement the research) during the beta phase to continue to iterate and evaluate the service. Plans, already in the backlog, to create funnels to see where users are dropping out and to mark PDF forms to evaluate how many users are coming through the digital service should address this.\n\nTest the service from beginning to end with the minister responsible for it.\n\n### **Next steps**\n\nThis service has been given approval to launch as a Beta on a&nbsp;[service.gov.uk](http://service.gov.uk/)&nbsp;domain."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/office-for-national-statistics-ons-website-voluntary-service-assessment-2/",
    "title": "Office for National Statistics (ONS) Website - Voluntary Service Assessment",
    "summary": "The Office for National Statistics (ONS) is the UK’s largest independent producer of official statistics and is the recognised national statistical institute for the UK. It is responsible for collecting and publishing statistics related to the economy, population and society at national, regional and local levels. It also conducts the census in England and Wales every ten years. The website is the primary channel for dissemination of these statistics.",
    "body": "**Department / Agency:**  \nONS\n\n**Date of Assessment:**  \n16/12/2015\n\n**Assessment Stage:**  \nlive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nM. Jukes\n\n**Digital Leader:**  \nT. Makewell\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel can confirm the ONS Website has shown sufficient evidence of meeting the Digital Service Standard at this stage of development. The service should now remove any beta branding.\n\n**Reasons**\n\nThe website was assessed against all 18 points of the Digital Service Standard.\n\nThe assessment panel were really impressed with the service team’s detailed and knowledgeable answers during the assessment. Their enthusiasm and commitment to creating a website based on user needs that could be iterated at pace was clear.\n\n_Research and design_\n\nThe ONS website is exempt from using the frontend toolkit and GOV.UK look and feel (Transport font, the crown icon etc), however the team demonstrated that the website is built in the spirit of the design principles, and the principles of the design patterns.\n\nThe team gave several examples of how they iterated the design of the website during the beta phase of development. These iterations were informed by regular user research using appropriate methods, and the research was based on what the team needed to learn. Examples of research techniques used included one-to-one, face-to-face research, lab sessions, online task-based sessions, A/B tests, and click testing. The team completed 27 rounds of research, talking to users of the website and users of the publishing tools.\n\nThe team also benchmarked the beta website against the existing site by testing tasks that users had struggled to complete on the existing site. The team have plans for ongoing research once the website is live, including diary studies and further A/B tests.\n\nThe team completed an accessibility audit which identified three main areas of work for improving accessibility. The team have plans to complete this work before launching the website, including improving the search and listing pages, reorganising the layout of the pages to make them more readable by screen readers, making the CSV downloads more prominent and ensuring that the CSVs can be accessed without the use of JavaScript. In the longer term the team also plan do more work to improve the accessibility of the interactive charts.\n\n_The team_\n\nThere is an empowered multi-disciplinary team in place and there are clear and sensible plans for transferring knowledge from members of the team who’ve been building the beta to the permanent team members recruited during the beta phase.\n\nThe team are working in an agile way using themed sprints, and quickly bringing findings from research into the next phase of work.\n\nRecruitment had been a challenge during the beta phase. The panel were really impressed with how the service manager had approached the problem, including how they put job descriptions on a hackpad to be peer reviewed, and tailoring them to explain what it meant to work for the ONS, rather than using generic job descriptions.\n\n_Technology decisions_\n\nThe technology decisions the team have made were clearly articulated during the assessment and based on user needs. There are some huge improvements from the legacy site, including a simple deployment process which means that the website can be iterated quickly; code changes to the current site are made only once once or twice a year. They have a well-thought-out set of environments that allow continuous feedback through functional, performance and load testing. All the source code has been made available.\n\nThe service manager explained that they had implemented monitoring for downtime and the health of all their applications. Full application support is provided from 8am - 6pm with some further support provided by their supplier, however the ONS have accepted the risk, signed off by their SIRO (Senior Information Risk Owner), that some issues could remain unresolved outside of the full support hours of 8am - 6pm.\n\n**Summary**\n\nThe GDS assessment panel would like to thank the ONS service team for a really positive assessment, their enthusiasm and well-articulated answers to our questions. We look forward to seeing the ONS website launch and continue to develop and iterate based on user needs.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/share-driving-record-service-assessment-3/",
    "title": "Share Driving Record - Service Assessment",
    "summary": "Share Driving Record is a new service that will provide access to driver data for Third Party users and will act as an enabler for DVLA to abolish the paper element of the driving licence. The aim of this service is to provide users who currently use the paper part of the driving licence with a new digital version that can be easily accessed. The service will display the information currently available on the paper counterpart and make it available to all those who have a right to see it.",
    "body": "**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n09/12/2015\n\n**Assessment Stage:**  \nLive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Hughes\n\n**Service Manager:**  \nD. Ashford\n\n**Digital Leader:**  \nO. Morley\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter completing the assessment, the panel can confirm the Share Driving Record service has shown sufficient evidence of meeting the Digital Service Standard and should go live on GOV.UK. The service can now remove any beta branding.\n\n**Reasons**\n\nThe service was assessed against and has met all 18 points of the Digital Service Standard\n\nParticular strengths noted by the panel included:\n\n- there is a multi-disciplinary, co-located team which is well-informed about its product and actively constantly working to improve the service\n- there is clear evidence of iteration of the service based on evidence & feedback\n- the team is working to enhance its knowledge and understanding, and is contributing to the development of expertise in the rest of the organisation for example by training new developers\n- the team is actively opening up its code\n- there is evidence of benefits realisation across the agency, not just within the service, eg data quality improvements and channel shift\n- the team has demonstrated clear evidence of learning from all the experiences during its beta, including early problems with the performance of the service - the team has put in place measures to ensure that these problems are not repeated in future with this or other services\n\nThe team credibly explained commercial sensitivities that mean they are not currently publishing cost per transaction data, whereas they are monitoring it internally.\n\nThere are exciting future opportunities, including the development of an API that could simplify the user journey if it is widely adopted, because it would allow integration of driver entitlement checking with car hire websites.\n\nSupport for users will be provided through DVLA’s contact centre and a large number of agents have been trained to talk users through the digital service. Scripts and training materials have also been shared with 3rd party organisations, to enable them to support users when appropriate. The service team demonstrated how all elements of support (routes, providers, availability, awareness etc) meet user needs, identified through testing, analytics and user research.\n\nDigital take up is already high and the team has appropriate plans to increase it further.\n\n**Recommendations**\n\nThe team should continue actively to seek out opportunities for improvement.\n\nThe team should continue looking at how to make the user journey as simple as possible, with particular attention to:\n\n- the expiry time for the check code - the team should consider defaulting to the same time for all users eg 23:59 on the day of expiry\n- the format of the check code to make it as straightforward and easy as possible for people to use. The code-entry error rate has been reduced from 11% to 7%, which is good progress, but it may be possible to reduce it further by making the user journey simpler. We recommend the team should look at using caps only and displaying the code in 4 blocks of 2 characters to make it easier to read.\n- the way that entry errors are shown to users, to make it straightforward to complete the forms correctly\n\nMore detailed suggestions are provided in the design feedback, attached at annex A.\n\nOutside the formal assessment process, the GDS content team has reviewed the content in detail and provided feedback and recommendations for the team's consideration as they continue to iterate and improve the service.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/make-a-plea-service-assessment-2/",
    "title": "Make a Plea - Service Assessment",
    "summary": "The Make a Plea service is a service through which people charged with summary motoring offences can respond to the charges against them. The service reduces case time and costs for the courts and the police, and began as a pilot in the Greater Manchester area.",
    "body": "**Department / Agency:**  \nMoJ\n\n**Date of Original Assessment:**  \n22/06/2015\n\n**Date of Reassessment:**  \n24/09/2015\n\n**Assessment Stage:**  \nLive\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nC. Mitchell\n\n**Service Manager:**  \nN. Gallon\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## **Reassessment Report**\n\n**Outcome of service reassessment**\n\nThe assessment panel can confirm the Make a Plea service has shown sufficient evidence of meeting the Digital Service Standard and should go live on GOV.UK. The service can now remove any beta branding.\n\n**Reasons**\n\nThe service was re-assessed against criteria 1,2,12,13,15 & 16 of the Digital Service Standard and has passed all criteria.\n\nOverall the service team has responded very well to recommendations made at the previous assessment. The team showed a strong understanding of their users and their needs. Extensive work has been done to research assisted digital users and an effective plan for ongoing user research is in place.\n\nThe service requires users to provide their National Insurance number, though this is not strictly required to make a plea. For some users, providing their National Insurance number will be useful later and the team showed that the need to provide this was not causing significant numbers of users to abandon the service. There is also an apparent benefit to the taxpayer through reduced costs in collection of fines, though this benefit was unquantified and messaging around collection of National Insurance number was unclear.\n\nThe team has designed, implemented, thoroughly tested and iterated an effective new telephone talk-through service.\n\nLegislation currently prevents the service from being completed on users’ behalf but the team is working to remove the legal constraint. The team explored establishing face-to-face support but their user research strongly indicated that users would prefer to seek help from family and friends or, if that was not an option, to go to court, rather than choose this type of support. The team are also working to improve the paper channel, which will improve the service for users who do not have digital skills or access in the interim, while the legislation is challenged.\n\nThe team have addressed a number of design and content changes recommended at the last assessment, to bring the service in line with GOV.UK. The panel was impressed that the changes had also been tested and final decisions on improvements were “led by the user”.\n\nThe team have implemented improved analytics tools and use of data to explore user segments, especially for assisted digital channels. The team showed sufficient performance analysis capability and were making good use of analytics data. However, it was recognised that there was not a dedicated product analyst within the team and the capability within the team was due to the skills of individuals, rather than those associated with the role.\n\nThe team face a number of constraints around the provision of key performance indicators (KPIs), resulting in delays to publication. However, there was clear evidence of benchmarking, monitoring, targets and plans for improving each of the four KPIs. Cost per transaction data has been provided and will be published on the Performance Platform soon.\n\n**Recommendations**\n\n_Point 1_  \nThe collection of National Insurance numbers should be further researched. It is recommended that the cost-benefit is better understood so that the requirement to collect this data for all users can be reviewed.\n\n_Point 12_  \nAlthough the provision of a face to face route for assisted digital users has been explored and no user need for this was established, it is strongly recommended that user research continues in this area after the service goes Live, to ensure that AD users’ needs are fully met in the absence of an on-behalf-of telephone service. If a need for face to face support is found at any point, however small in volume, this route must be provided by the service. The Digital Training and Support Framework (currently being developed) might provide a suitable option for procuring this support.\n\n_Point 15_  \nIn order to ensure continuity it is strongly recommended that a dedicated performance analyst be identified to work with the team. The requirement is not full-time, so the resource could be shared across multiple teams within the MoJ.\n\n**Summary**\n\nThe team has been working in a challenging and complex environment, with multiple stakeholders, and numerous legal constraints. Despite all of this they have established a high performing team that are committed to continuously improving the Make a Plea service. The quality of the digital service is reflected in high rates of user satisfaction and uptake, and delivery of significant benefits to government and the taxpayer. The team has also shown a holistic view of the service and a commitment to break down obstacles that get in the way of efficient and effective service delivery.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/civil-legal-advice-service-assessment-4/",
    "title": "Civil Legal Advice - Service Assessment",
    "summary": "Civil Legal Advice provides state-funded legal help with problems such as repossession, abusing partners, house disrepair etc. This legal help is expensive, and is only available to citizens who pass a means test and whose problems fall within key areas of law.",
    "body": "**Department / Agency:**  \nMoJ\n\n**Date of Original Assessment:**  \n22/7/2015\n\n**Date of Ressessment:**  \n23/9/2015\n\n**Assessment stage:**  \nLive\n\n**Result of Original Assessment:**  \nNot Pass\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nS. Wood\n\n**Service Manager:**  \nL. Citron\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## **Reassessment Report**\n\nThe Civil Legal Advice service is seeking permission to be branded a live service on the service.gov.uk domain. The service has been reassessed on points 3 and 15 of the service standard.\n\n**Outcome of Service Assessment**\n\nThe assessment panel can confirm the Civil Legal Advice service has shown sufficient evidence of meeting the Digital Service Standard and should go live on GOV.UK. The service can now remove any beta branding.\n\n**Reasons**\n\nThe service had been assessed against all 18 points of the Digital Service Standard on 22nd July and passed on all but two: Point 3: Put in place a sustainable multidisciplinary team… and Point 15: Use tools for analysis that collect performance data. The service team subsequently returned to GDS and were successfully re-assessed against those two points.\n\n- Point 3: The assessment panel was pleased to see that a product analyst has been recruited into the team. The product analyst is working well with the user researcher and product owner and has already started to contribute to the service. The panel was particularly pleased to hear of plans to continue improving the service post-live\n- Point 5: The team uses Google Analytics, along with data from the contact centre. The team seems to have a stronger understanding of how customers use the service. Also, it is good to see that the analyst is working closely with the user researcher. The team is exploring how and why users drop out of the service. \n\n**Recommendations**\n\nThe panel was pleased that there is now a performance analyst in post who is taking ownership of measurement. It is clear already that data is being used to validate and pose new questions, and that user behaviour data is used along with user research insights.\n\nThe performance analyst was clearly at the start of their work in the team, so it's difficult to get a firm handle on what her approach to product analysis will be in the longer term. However, the panel does have concerns that the performance analyst is not being exploited to the fullest, i.e. being given the opportunity to ensure that there's solid loop between the hypotheses that emerges from user research and any subsequent data analysis, which in turn would inform future research. That said, with the space to work to develop a measurement plan that aligns with the product backlog/roadmap, the service as a whole will benefit.\n\n**Summary**\n\nThere is a good team in place, and it has been made all the stronger for having a product analyst embedded in it. The panel is confident that the service will continue to improve and deliver value for the users.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/civil-legal-advice-service-assessment-3/",
    "title": "Civil Legal Advice - Service Assessment",
    "summary": "Civil Legal Advice provides state-funded legal help with problems such as repossession, abusing partners, house disrepair etc. This legal help is expensive, and is only available to citizens who pass a means test and whose problems fall within key areas of law.",
    "body": "**Department / Agency:**  \nMoJ\n\n**Date of Assessment:**  \n22/7/2015\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nNot Pass\n\n**Lead Assessor:**  \nS. Wood\n\n**Service Manager:**  \nL. Citron\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## **Assessment Report**\n\nThe Civil Legal Advice service is seeking permission to be branded a live service on the service.gov.uk domain.\n\n**Outcome of Service Assessment**\n\nThe assessment panel has concluded the Civil Legal Advice service should not be given approval to remove beta branding and launch on a service.gov.uk domain as a live service.\n\n**Reasons**\n\nAlthough the Civil Legal Advice Service has not passed the live assessment, the service team demonstrated many positives across the 18 points of the service standard and the panel was impressed by the quality of the product.\n\nParticularly strong areas of performance include:\n\n_User Research_  \nThe team clearly understands the needs of their users. Research has covered an impressive 239 people including call centre staff and those who need assistance to use the digital service. The team has made use of a variety of resources including Citizens Advice Bureau and disability groups. Pop-up research has also been effectively used. Where there has been difficulty finding the right people the team has put out adverts and used agencies. And when it was discovered that some deaf people had difficulties in using the service, British Sign Language was introduced. All this demonstrates that the researcher in the team is in full command of their brief and the team acts on research findings. It was good to see that all members of the team have attended user research sessions and that user research will continue throughout the life of the service.\n\n_Technical_  \nThe panel were satisfied that the service is robust and stable. The panel noted that developers swap in and out with other services through a central MoJ “hub”, thereby increasing the skill base and adding to knowledge share. The technical architect in the team explained that migration to Amazon services is about to take place and this appears to be being managed very well. Two CLAS consultants have been involved, and there is close liaison with the Office of the Government Senior Information Risk Owner (OGSIRO) and accreditors on issues like backups. The team has a sound understanding of the datasets being used, and is aware where any issues lie. The technical architect also described what measures are in place (sanitisation, workflows, role access) to ensure that data is handled appropriately. Call centre code has been looked at and design patterns reused. The service owns the call centre code so can “lift and shift” the call centre if required.\n\nThe panel were slightly concerned about the live support model that is in place and the demands it may place on what is a relatively small team. A recommendation would be to ensure that the service has robust documentation and alerts and that the bulk of support issues can be triaged by the central support function.\n\n_Design_  \nThe team demonstrated that they had worked with the content teams of both GOV.UK and MoJ digital services, and are in regular contact with other GDS teams. The product owner and user researcher demonstrated how changes to the pages were evidenced based on user research. The service team showed video footage from testing sessions, and were able to explain what they had learnt and how this had resulted in changes to the service.\n\nThe designer and content designer are involved in each sprint, resulting in changes being made iteratively. The text is shown to lawyers, which does run the risk of content not being written for the user, and has the potential to slow things down. However, the team explained how they had developed good working relationships with the legal teams and how this mitigates the risk of the content losing user focus.\n\nSupport for users is primarily through a contact centre, although face to face support is available if needed. Close working with the Legal Aid Agency Business Owner, and a good partnership with the outsourced call centre provider, means that the team is able to gather a wealth of information about user needs and can quickly respond to feedback. The team have changed processes to make the on-screen service simpler for users and keep them online (for example, removing the need to scan documents) and to improve the end-to-end user journey for assisted digital users (by making changes to how delegation to another person is handled). They identified peak times in demand for support, and resolved this by amending bookable appointment times to ensure that waiting time is low. The team is measuring the four mandatory KPIs among other metrics.\n\nDigital take-up has increased since Beta and the team is reviewing messaging and drop out points to try to keep users in the online service. Digital take-up will be a key focus for the team post-live.\n\nDespite these positives, the service did not pass the live assessment. This was on two points of the service standard and the reasons for not passing are closely related. They are:\n\n- Point 3 (Put in place a sustainable multidisciplinary team…) and\n- Point 15 (Use tools for analysis that collect performance data. Use this data to analyse the success of the service and to translate this into features and tasks for the next phase of development.)\n\n_Point 3_  \nThere is no performance analyst dedicated to the team that is responsible for identifying actionable data insights from the service. The assessment panel for the beta assessment recommended that  \n‘the service team continue in their efforts to recruit a product/data analyst.’ and this has not being addressed by the service team yet. The team is an agile multi-disciplinary one who are working well together and the panel had no other concerns in this area.\n\n_Point 15_  \nThe team has collectively adopted responsibility for managing analytics (for instance, by setting up funnels on Google Analytics where required). This seemed merely to add to the amount of management information that is generated, rather than provide the actionable data insights needed to help the team focus their efforts on improving the service. The lack of an embedded performance analyst meant the service team were not able to adequately demonstrate how they are analysing the success of the service through data, and using this to improve the service. For example, there was not enough evidence to show how user research linked to actual on-site activity. Also, it was unclear how data feeds into the product development process. And the team has yet to implement virtual pageviews as goals, which would be an effective way to identify leaks within user journeys.\n\nThe product manager suggested that there are a number of data related items on the backlog. However, it was not clear how or when these would be prioritised. Consequently, there is a gap that in-depth, iterative analytics would provide in supporting user research. By this the panel understands that comments from users are not being validated using accompanying analytical data.\n\nFurthermore, ownership (and therefore prioritisation) of data and analytics is split between a number of individuals within the team. This reduces the opportunity for ad hoc reporting and analysis, which can often lead to the greatest insights.\n\n**Recommendations**\n\nIn order to pass the reassessment:\n\n- the service team should recruit a performance analyst\n- the performance analyst should be able to demonstrate analysis that has led to actionable data insights the team has used to improve the service. The panel can put the team in touch with a performance analyst at GDS for additional information about the role and how it can help the service team.\n\nBeyond the live assessment, the service team should consider:\n\n- continuing to work with Citizens Advice Bureau and other relevant third parties to understand user needs for support, particularly around needs for face to face support and signposting users to develop their digital skills  \ninvolving content designers from other MoJ digital services to carry out the content and design “second eyes” review\n\n**Summary**\n\nTo conclude, a lot of excellent work has been done by the team and the panel hopes they are not too downhearted by the findings. The panel is confident that the team is generally on track to build a service that meets user needs and is looking forward to seeing the service again for a reassessment against the not passed points.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | No | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/pay-hmrc-live/",
    "title": "Pay HMRC - Live Assessment",
    "summary": "This service will allow users to make payments to HMRC online via credit and/or debit card.",
    "body": "**Department / Agency:**  \nHM Revenue & Customs\n\n**Date of Assessment:**  \n18 June 2015\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nPassed\n\n**Lead Assessor:**  \nJ. Gould\n\n**Service Manager:**  \nO. McGuire\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment Report\n\nAfter completing our assessment we can confirm the HMRC Payment Service has shown sufficient evidence of meeting the Digital Service Standard and should go live on GOV.UK. The service can now remove any Beta branding.\n\n**Reasons**\n\nThe service was assessed against and has met all 18 points of the Digital by Default Service Standard. The assessment panel was impressed with the progress made by the digital service manager and team since the beta assessment and were satisfied by plans to maintain, support and improve the service in the future.\n\nThe use of regular user research (to iterate the service, improve the user experience and drive down a reduction in query phone calls), strong use of analytics, and having a well planned roadmap for the team’s resourcing were particularly impressive. The panel especially liked the fact that your research resulted in confusing reference numbers being removed from letters which demonstrates excellent wider service engagement.\n\nAt the same time, a good understanding of how this channel fits into the wider payments strategy for HMRC demonstrated a strong, pragmatic approach to creating a positive user experience. The platform has been designed with user privacy in mind and as such stores no personal details.\n\n**Recommendations**\n\n_Point 3_\n\nThe service manager should develop plans to build long term permanent staff capability in the team and reduce reliance on contractor staff.\n\n_Point 10_\n\nIt was indicated that performance testing in anticipation of the January peak is on the roadmap for later this summer. The panel recommends that this work is prioritised as soon as practicable and should begin no later than September 2015.\n\n_Point 13_\n\nThe service manager should continue to monitor requirements for dedicated content designer resource once the service is live, particularly when the team merges with the Your Tax Account team. We also recommend that the team works closely with the GDS content team to improve GOV.UK guidance for users, making the transition from website to service as seamless as possible.\n\n_Point 15_\n\nThe service team expects to engage with the the digital services for business analytics team in the next four to six weeks with a view to deciding whether or not it will be necessaryto recruit dedicated analytics resource into the service team. The earlier this assessment of service team needs can be made the better.\n\n_Point 16_\n\nIt is important that the team work to identify a cost per transactions measure as soon as possible. The panel would expect all future HMRC services coming to GDS for assessment to be able to demonstrate cost per transactions measures.\n\n_Point 17_\n\nThe panel noted that the performance platform dashboard has been published since the service assessment and appreciate the speed at which this has been addressed.\n\n_Assisted Digital_\n\nAs discussed at the beta assessment, HMRC provides many different online and offline ways for users to pay tax liabilities and each of the individual HMRC services which use this payment service are developing appropriate assisted digital support for their specific users. Therefore specific assisted digital support does not need to be provided for this service in line with GDS policy but this should be reviewed if the range of HMRC payment options is reduced.\n\n&nbsp;\n\n&nbsp;\n\n**Summary**\n\nThe panel were impressed by the professionalism, knowledge and sense of ownership demonstrated by the service manager and team. It was particularly pleasing to to see evidence of a commitment to open sourcing from the team.\n\n&nbsp;\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n\n&nbsp;"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/make-a-plea-service-assessment/",
    "title": "Make a Plea - Service Assessment",
    "summary": "The Make a Plea digital service allows people charged with summary motoring offences to respond to the charges against them. The service allows defendants to make their plea online from any internet-enabled device, for example, mobile phone, tablet, computer or laptop. A plea can be made 24 hours a day. The Make a Plea digital service is an alternative to a postal plea or attending court.",
    "body": "**Department / Agency:**  \nMinistry of Justice\n\n**Date of Assessment:**  \n22/06/15\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nNot pass\n\n**Lead Assessor:**  \nC. Mitchell\n\n**Service Manager:**  \nN. Gallon\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n### **Assessment Report**\n\nThe Make a Plea service is seeking permission to be branded a Live Digital by Default service on the service.gov.uk domain.\n\n**Outcome of service assessment**  \nAfter completing our assessment the panel have concluded the Make a Plea service should not be given approval to remove Beta branding and launch on a service.gov.uk domain as a Live Digital by Default service.\n\n**Reasons**  \nThe Service team is well established and operating in an effective, and agile way. The team’s use of technology, tools and techniques have set them up well to continuously improve the on-screen elements of the service, which they have been doing throughout the beta phase. The majority of users are well understood and their needs are being met.\n\nHowever, understanding of users that require assistance was less well developed. The team recognised that this was an area that required more work, though they did not clearly articulate a detailed plan for ongoing user research for assisted digital users. Performance data and tracking for assisted digital users was also limited and the team were unable to demonstrate these users were either able to complete the service or satisfied with the support they received.\n\nSince the Digital Service Standard was revised, assessment of assisted digital elements has been spread across a number of different criteria. As a result, shortcomings in the area of assisted digital now result in not pass results across more criteria, reflected in the table below.\n\nFor the on-screen elements the standard of the user experience design was good, though the service was not entirely consistent with GOV.UK standards. Whilst thought had been put into improving the 4 KPIs, plans lacked targets, clarity on next steps and ownership. These last 2 points were not currently a serious concern, rather they had fallen short of the standard expected of a fully live digital service and should be addressed before a reassessment.\n\nIn addition, the assessment panel were concerned by the inclusion of the non-mandatory fields to collect Driving Licence and National Insurance details, as well as the mandatory nature of providing an email address. It was positive to hear that the service manager has ownership of the on-screen service; the team should be sure that the service is based on user needs rather than business needs. At reassessment the panel would like to hear more about the testing of these elements and how they impact the user journey.\n\nThe panel would also advise that the service is used as a beta in more locations before it moves into live. The locations in which it has been used so far indicate that there are likely to be differences in the way the service is used in different geographical locations and it would be helpful for the team to gain assurance, while in beta, that the service will work equally well for these users.\n\n**Recommendations**\n\n**Criteria 1**\n\n- Develop personas for assisted digital users and fully research their needs, so the team can make informed decisions around the provision of assisted digital support. Research should include recruiting appropriate AD users, including those with the lowest levels of digital skills. Research should also include potential users of the digital service (eg those currently choosing to use paper channels) and users requiring support from third party organisations.\n- Review the need to ask users to optionally supply NINO and Driver Number as these are not required to deliver the Make a Plea service\n\n**Criteria 2**\n\n- Develop a more detailed ongoing user research plan for assisted digital users to enable iteration of AD support\n\n**Criteria 3**\n\n- Identify a more dedicated source of analytics support and identify someone within the team to lead work on assisted digital\n\n**Criteria 7**\n\n- Management and responsibility for updates to software, systems and tools should be clarified and formalised, especially during the transition to centralised 2nd line support\n- The cookie policy currently links to the GOV.UK page, which does not reflect the current use of cookies for the service. Cookie policy should be reviewed and a dedicated page should be created\n\n**Criteria 11**\n\n- While current support provision is appropriate for the service, the team should review out of hours support as the service scales, to ensure that peak weekend volumes aren’t unduly affected by outages\n- Support processes and responsibilities between the service and central support team should be fully tested\n\n**Criteria 12**\n\n- The team was unable to demonstrate that users who need assisted digital support were able to complete the service. It’s also not clear if it’s even possible to do so via the current phone support (the only support route being offered), due to the need for an email address and declaration. The team should review the AD routes provided and fully test all AD routes from all providers. The team should note that relying on support from friends and family is not appropriate.\n\n**Criteria 13**\n\n- To address inconsistencies and opportunities in the user experience, the team should review the service against GOV.UK design patterns and styles, then implement changes as required\n\n**Criteria 14**\n\n- The ability to track and shift users to the digital channel is constrained by policy and the various police forces that own the paper channels. The team should build on their engagement with policy teams and police forces, to remove some of these constraints\n\n**Criteria 15**\n\n- Key metrics around the performance of the AD support (such as satisfaction) are not being captured. The Team should collect performance data for AD users and implement changes to bring the standard of reporting in line with purely digital users\n- As the service rolls out, the team should invest resource so it can use digital analytics and other data sources to investigate user segments and service performance as outlined in the team's roadmap\n\n**Criteria 16**\n\n- Although there are constraints around collecting and publishing key performance indicators, the team should formalise plans to improve these metrics by establishing benchmarks, clear responsibility, action plans and targets for each of the 4 KPIs.\n\n**Criteria 17**\n\n- Publishing of the cost per transaction metric on the Performance Platform should be prioritised.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | No |\n| 13 | No | 14 | Yes |\n| 15 | No | 16 | No |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/your-tax-account-service-assessment-2/",
    "title": "Your Tax Account - Service Assessment",
    "summary": "Your Tax Account is the service through which small and medium businesses will interact with HMRC for all their needs. It provides a personalised homepage allowing users to view the information most important to them, do the things they need to do in one place, and link them to other services and opportunities pertinent to their individual circumstances.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n23/3/2015\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nE.Stace\n\n**Service Manager:**  \nO.McGuire\n\n**Digital Leader:**  \nM.Dearnley\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter completing the assessment, the assessment panel can confirm that the Your Tax Account service has shown sufficient evidence of meeting the Digital by Default Service Standard and should go Live as a Digital by Default service on[GOV.UK](http://gov.uk/). The service can remove Beta branding once the performance platform dashboard (which is currently under development) is published showing data for the KPIs.\n\n**Reasons**\n\nThe service was assessed against and has met all 26 points of the Digital by Default Service Standard\n\nThe assessment panel believe that the service has made good progress since the early stages of Beta development and found it particularly reassuring to see how much user research had been undertaken and improvements made to the service as a result.\n\nThe panel found that the service team were working well alongside other digital service teams in HMRC and were also following well understood agile processes which will help ensure that the service continues to iterate and improve once it is Live.\n\nConsiderations around security, data privacy and suitable technology standards were found by the panel to be well understood by the team, as well as by those that support them in the wider HMRC organisation. The development of this service is already benefiting from wider support across HMRC.\n\nThe panel found the visual design to be a good example of a service built within the[GOV.UK](http://gov.uk/) style and were pleased to see that content design effort was being used to ensure that complex tax language was being made as easy to understand as possible by users of the service.\n\nIndividual services available through Your Tax Account are responsible for developing their own assisted digital support and digital take-up plans for their specific services. The panel found that the Your Tax Account service team had undertaken significant research into potential assisted digital users of this specific service and had not identified a need for assisted digital support. The team had spoken to representative bodies, enterprise networks and relevant charities, worked with HMRC’s contact centre and had run focus groups with a variety of users across different industries. The service team’s research showed that businesses use agents to complete their digital services for other reasons than lack of digital skills and access.\n\nThere is no existing offline equivalent of this service. The service team have a plan to migrate user groups of relevant digital services to Your Tax Account over the next year.\n\nThe service had Google Analytics Premium implemented and have set up suitable goals to track task completion rates as it pertains to Your Tax Account. The team demonstrated the ability to iterate service design based on digital analytics and user research data.\n\n**Recommendations**\n\nThe panel believe that the service should ensure that their performance platform dashboard is published as soon as possible, and before beta branding is removed. The dashboard should include data on all KPIs, including data on completion rates derived from the goals set up in Google Analytics.\n\nThe panel also believe that the service team should consider the following as part of the on-going development of the service:\n\nThis service was described in the service assessment as “hub” service, meaning that users land on this information page before advancing to other transactional services within the wider HMRC service landscape. These are services for which the service manager of Your Tax Account is not responsible for. This provides a significant challenge to the principal role of the[service manager](https://www.gov.uk/service-manual/the-team/service-manager.html), who should have full responsibility and accountability for digital service, including all related processes. This, together with the difficulty of collecting meaningful analytics across the full user journey, make it difficult to quantify and track the success metrics of this service.\n\nThe service manager should work with other service teams to more clearly articulate the shared responsibilities for improving this service and invest in a digital analyst who should be co-located with the service team with responsibility to improve analytical data and insights across the entire customer journey. This individual would be responsible for managing the Google Analytics configuration, optimising the digital analytics implementation and identifying actionable data insights to provide candidates for further service design iteration. The cookie statement should properly reflect the current version of Google Analytics (i.e Universal Analytics).\n\nSpecific design recommendations were sent to the service team under separate cover.\n\nThe panel advise that the service team continue to monitor potential need for assisted digital support as more user groups are migrated to the service. As new digital services are added to the portal, the team should ensure that there is a consistent assisted digital user journey across those services.\n\n**Summary**\n\nIn summary, the assessment panel were pleased to report that the service, once the performance dashboard is delivered, is ready to progress to live.\n\nThe panel would like to take this opportunity to thank the team who attended the assessment at Aviation House for providing clear, evidence-based answers to their questions, and the panel enjoyed seeing the results of their hard work.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/digital-self-assessment-live/",
    "title": "Digital Self Assessment (Opt-In Messaging) - Live Assessment",
    "summary": "Digital Self Assessment (SA) is one of HMRC’s flagship online services: over 85 percent of SA customers chose to file online during 2014-15. Despite this, HMRC still send large volumes of paper to SA customers. HMRC want to improve this by giving them the option to receive electronic rather than paper communications. Digital SA allows customers to say \"yes\" to paperless and choose to receive digital alerts instead of paper.",
    "body": "[https://www.gov.uk/log-in-file-self-assessment-tax-return](https://www.gov.uk/log-in-file-self-assessment-tax-return)\n\n**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n18/3/2015\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nT. Scott\n\n**Service Manager:**  \nS. Sankriwala\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment Report\n\nAfter completing the assessment, the panel can confirm the Digital Self Assessment Opt-in and messaging service has shown sufficient evidence of meeting the Digital by Default Service Standard and should go Live as a Digital by Default service on [GOV.UK](http://gov.uk/). The service can now remove any Beta branding.\n\n**Reasons**  \nThe service was assessed against and has met all 26 points of the Digital by Default Service Standard.\n\n**User needs and research**  \nThe stated user need for the service was \"as a Self Assessment online user I want to sign-up for digital alerts so that I can receive Self Assessment communication electronically\".\n\nSprint based research into the usability of the service has led to frequent improvements during the beta period. Once improvements are identified they are fed into the backlog and prioritised. During the private beta the opt-in was offered to 100 users, with 75 choosing to take up this service, however some of those thought they were signing up to a digital self-assessment service, rather than to receive their messages digitally. This was quickly identified and the language and the layout of pages have been iterated regularly to make it clear what the service is offering. When the service moved to public beta there was initially a 53% take up. This improved further when the user journey changed so that new users signing into the My Tax Account service were offered the opt-in as part of the process at the very beginning. Currently there are over 1.2 million users signed up, with a very low contact rate of 0.3% (most of which relate to the process of tax returns rather than the service itself).\n\nThe use of A/B testing allowed the testing of graphical icons like checks/ticks to the opt in process, showing an increased uptake of the service by drawing users in to the content, increasing the comprehension of the service. So far only a tiny fraction of people have chosen to opt-out after signing up to the service. Most of the research has been carried out in testing labs with a task based approach. It was good to see that user research is available to the team to observe, the live user research demonstration was a first in a Digital by Default service assessment.\n\n**The team**  \nThe team have most of the expected roles in place, either directly part of the co-located team or as part of a shared resource through HMRC’s common technology resources. There has yet to be a Digital Analyst recruited and much of this work has been carried out by the Deputy Service Manager. The Service Manager is empowered and responsible for the service, an example where the business wanted to push marketing material to users through the service was resisted to protect the interests of the users.\n\nThere is an identified reliance on contractors, but a plan is in place to reduce those numbers and share knowledge. As an exemplar service there has been support from the GDS Transformation team during early beta but that resource has decreased as the service team have taken over. Roles are clearly defined with clear demarcation which is especially important with the reliance on the shared services offered by HMRC.\n\nThe service team use showcases and ceremonies, and have stand ups led by scrum master. Non-functioning components are prioritised in the sprint and the team use a variety of agile tools to help manage the work from a backlog. Originally the team ran with 2 week sprints but are now running weekly. An example of the agile process working was the changes to the verification email step resulting in a reduction in contacts asking what the verification link was, the time scale from identification to production was about a month including user research and testing. While introducing agile into the organisation was initially tricky there are now expectations for very quick delivery of products and services built this way. The team average 2 releases a week, but demonstrated the ability to make changes as frequently as they needed. Some dependencies are across the common platform and take some more time to deploy, however most changes now are around the content and can be quickly released, an example of a bug that was identified and removed within 2 hours down to the regular deployment process having no downtime.\n\nThe assessment panel were encouraged to see the service is sharing the knowledge and learnings from this service to other teams in HMRC, particularly around the content of paperwork being able to be reduced and made clearer.\n\n**Development and security**  \nThe service team have engaged with all the right people across HMRC from the outset and continued to engage at each important change, for example a CLAS consultant was in the same building and the team frequently involved them. There is a good understanding of the risks posed by the service and the design has taken appropriate measures to defend against them, for example of the risk of phishing attacks.\n\nThe [GOV.UK](http://gov.uk/) Verify service is not currently being used because it does not yet provide all the features needed, the service will be looking to switch over as soon as appropriate. A large proportion of the code is open source and being developed in the open. Some libraries are not yet open source but the team has a roadmap for how these will also become open source in due course.\n\n**Design and content**  \nThe service has Google Analytics and the team have set up some funnel visualisations to identify dropout points, although there was not a clear explanation of the funnel. User research informs the look of the service (based on [GOV.UK](http://gov.uk/) design patterns), an example the team gave around design included removing a blue banner that had messaging directed at the user, this had a direct impact in increasing users engagement (most users were ignoring it). Content changes to the opt-in service can be made quickly.\n\nThe service is yet to fully meet all the AA standards, an outside independent body is to test th the service in April, changes are needed are HTML tweaks to help with screen readability and ordering. Any changes should be prioritised.\n\n**Assisted Digital and digital take up**  \nPersonas were created dependent on different circumstances, those who struggle tend to go through charities rather than directly to the HMRC. The team demonstrated that assisted digital support does not need to be provided at this time. If the scope of the service changes (eg new transactional services are added or the user base changes), the team may need to undertake research with assisted digital users and design, test and provide appropriate assisted digital support which meets user needs. As this service is part of Your Tax Account service that service has responsibility for providing Assisted Digital (the use of Digital Self Assessment is optional and user will need an email address before signing up).\n\nAt the time of the assessment there were no plans to mandate paperless services (the assessment took place before the 2015 Budget), however the take up for this service has been higher than initially expected. Contact centre staff have been asked to encourage users to opt in, followed up with IVR messaging.\n\n**Analytics and performance**  \nGoogle Analytics Premium has been instrumented on the service and goals set up to provide completion rates for the Performance Platform. SPLUNK has also been used to provide the data for the A/B testing with support from the Behavioural Trials Programme at HMRC.\n\n**Testing with the Minister**  \nThe service was tested with the responsible minister.\n\n**Recommendations**  \nThe service has met all points of the Service Standard but the assessment panel have highlighted the following recommendations to support the service’s continued development.\n\n**User needs**  \nWhile the service has met the user need for many of its users there is some scope for further thought about the options for notifications, it may be that important call to actions in messages could be backed up with additional notifications via other digital channels (such as SMS messaging), more research into this would help understand this better.\n\n**Digital analytics**  \nIt is recommended that when recruited the digital analyst should be co-located with the service management team and be responsible for managing the improvement of the Google Analytics configuration (i.e. views, filters, goals and funnels), further optimisation of the implementation and the provision of actionable data insights for consideration for further design iteration or AB testing. This responsibility should not sit with the Service Manager or the Deputy Service Manager.\n\n**Content**  \nThe team should share the research into the use of visual prompts (ticks/checks) that led to increased take up, this is potentially useful for other services. The reduced word count in the messages to users leads to a clearer message, it’s now important to ensure users understand the content and can easily act on any calls to action, more research should be conducted on the style of the language used.\n\n**Digital take up**  \nThe service team will need to continue to encourage users to opt-in to digital communications, the option to print out communications will help some users to transition across. More research should be carried out to find out why some users do not sign up and others choose to revert to paper based communications. It will be useful to look at benchmarking the digital take up against other financial services.\n\n**Summary**  \nThis messaging service, one of many parts of My Tax Account, has been given approval to go Live as a Digital by Default service. We look forward to seeing what the team will deliver in the future for Self Assessment.\n\nThe success of the service so far in public beta and the reassurance of this pass result should encourage all users to make the choice to switch to digital messaging with HMRC and the Self Assessment service. 2.2 million pieces of post have been saved so far saving £600k.\n\nThe assessment panel thanks to the whole team for their time and clear answers during the assessment, this service demonstrates the kind of change of approach for all communications needed across government, it exemplifies the Digital by Default approach.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/paye-company-car-tax-live/",
    "title": "PAYE: Check or Update your Company Car Tax - Live Assessment",
    "summary": "PAYE for Employees will eventually allow all 41m PAYE employees, those who work for an employer and pay Pay As You Earn (PAYE) income tax, to see what tax they pay and why, with the ability to change/update their particular circumstances/information which govern the amount of tax they pay. Initially the service will allow PAYE employees to view and change their company car tax benefit which will ensure that they pay the right amount of tax based on the company car they have.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n23 March 2015\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nN. Chowdhury\n\n**Service Manager:**  \nL. Hawksworth\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment Report\n\nThe PAYE check or update your company car tax service is seeking permission to be branded a Live Digital by Default service on the service.gov.uk domain.\n\n### Outcome of service assessment\n\nAfter completing our assessment we can confirm the PAYE check or update your company car tax service has shown sufficient evidence of meeting the Digital by Default Service Standard and should go Live as a Digital by Default service on [GOV.UK](http://gov.uk). The service can remove any Beta branding once the immediate actions detailed below are complete.\n\n### Immediate actions\n\nThe team need to complete the following actions before removing the beta labelling from the service.\n\n- Update the service cookie page to reflect changes in analytics provision\n- Add cost per transaction data to the service performance dashboard.\n\n#### Meeting the service standard criteria\n\nThe panel were particularly impressed with how the team have:\n\n- established and maintained a well-skilled multidisciplinary team. Agile practices are a natural part of their way of working and there is clearly a good relationship and communication between Service and Product Manager.\n\n- a deep understanding of their users. They have combined research findings and operational data as evidence to drive improvements to the service through beta. And as user volumes have grown, they are making effective use of analytics data and user feedback from their end of transaction questionnaire.\n- partnered well with other parts of HMRC to remove blockers to service development\n- made progress in making source code open since the beta assessment. It was particularly encouraging to hear from the team that they have already had conversations with outside parties over reuse of the published car tax calculator source code ([https://github.com/hmrc/car-tax-calculator](https://github.com/hmrc/car-tax-calculator)).\n- created a service that is easy for users to complete in a short amount of time, using the patterns consistent with those in the service manual.\n- procured and moved to a paid-for analytics provision, providing assurance on the use of data collected from users and how this is stored and managed by the external provider.\n- Published a comprehensive [service performance dashboard](https://www.gov.uk/performance/paye-for-employees-company-car).\n\n#### Assisted Digital\n\nThe team demonstrated that assisted digital support does not need to be provided at this time. If the scope of the service changes (eg new transactional services are added or the user base changes), the team may need to undertake research with assisted digital users and design, test and provide appropriate assisted digital support which meets user needs.\n\n### Recommendations\n\nThe team should consider the following as part of the on-going development of the service\n\n- Working with DVLA to implement the vehicle details lookup API as a priority, or look for alternative means, as the team acknowledged this would greatly enhance the overall experience and speed at which the service can be completed.\n- Create a clearer plan for continuing user research for the live service. This should include more rigorous accessibility testing with a wider range of potential users. For example, users with mobility and dexterity problems, those who use assistive technologies other than screen readers, deaf people who sign as their first language, etc.\n- Test significant new features (eg registration number lookup) with participants’ real data rather than dummy data. The team should also ask participants to bring their company car documentation and use it in testing. Using real data makes testing more rigorous and effective.\n- Continue to evolve plans for channel shift, working closely with the appropriate internal teams to establish realistic targets and plans to achieve them.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/apprenticeship-applications-service-assessment-3/",
    "title": "Apprenticeship Applications - Service Assessment",
    "summary": "The exemplar’s vision is to create an easy to use digital service where apprenticeships can be advertised and applied for, with the transaction supported by clear information to inspire and advise users, so that they can self-serve, leading to minimal additional support being required.",
    "body": "**Department / Agency:**  \nBIS / SFA\n\n**Date of Assessment:**  \n19/3/2015\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nR. Reynolds\n\n**Service Manager:**  \nG. Tucker\n\n**Digital Leader:**  \nT.&nbsp;Knighton\n\n* * *\n\n## **Assessment Report**\n\nThe Apprenticeship Applications service is seeking permission to be branded a Live Digital by Default service on the service.gov.uk domain.\n\n**Outcome of service assessment**\n\nAfter completing the assessment, the panel can confirm the Apprenticeship Applications service has shown sufficient evidence of meeting the Digital by Default Service Standard and should go Live as a Digital by Default service on GOV.UK. The service can now remove any Beta branding.\n\n**Reasons**\n\nThe assessment panel were pleased that such strong progress has been made in the relatively short amount of time since the service's beta assessment. The team is clearly led by an empowered and committed service manager.\n\nThe panel were pleased to see a service built around user needs and tested with users, replacing a service that did not have the same focus on its users.\n\nThe panel were satisfied that plans are in place to continue to make improvements to the service, and that the service will continue to iterate in line with user needs during the service's Live phase.\n\nThe service's approach to assisted digital was exemplary, showing:\n\n- A clear understanding of specific user needs.\n- Developing relationships with related government agencies and charities.\n- Tailoring of the digital service to support less digitally able users.\n- Relevant assisted digital support in place throughout the user journey.\n\nThe approximately 150 hours of user research that has been conducted shows through in the way the service has been iterated and presented. This is exemplified in the maps and travel times, and attention to detail with features such as the support for frequent misspellings in search terms.\n\n**Recommendations**\n\nThe panel were pleased to see a strong use of user research, and were confident that future development will continue to be based on user needs, even when this challenges long-held assumptions, habits, and practices of the organisation.\n\nThe panel were pleased with the high rate of user satisfaction and more importantly, with the significant improvements introduced through iteration of the Public Beta. A plan for understanding the cause of dissatisfaction amongst the remaining users will be valuable for improving the service as a whole.\n\nGiven that the overall success of the service is not defined by the proportion of users who complete their application, the service team will need to consider whether overall successful completion of an apprenticeship, total cost per apprenticeship filled, or a similar metric would be a useful additional key performance indicator for the service.\n\nThe panel welcomed the service's long-term roadmap, including:\n\n- The plan to migrate users from the old system to the new system.\n- A focus on improving user satisfaction with careers advisors.\n- Improving the overall journey of how users get to the digital service.\n- Defining metrics that ensure the success of the service as a whole (rather than the digital presentation of the service) is measured and improved.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |\n\n&nbsp;"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/slc-full-time-application-service-assessment/",
    "title": "SLC Full Time Application - Service Assessment",
    "summary": "Student Loans Company (SLC) Full Time Application service provides financial support for people studying at universities and colleges throughout the United Kingdom. The service pays loans and non-repayable grants for living costs and studying expenses and provides loans to meet the costs of tuition fees, which are paid directly to universities and colleges on behalf of students.",
    "body": "**Department / Agency:**  \nBIS / Student Loans Company\n\n**Date of Original Assessment:**  \n19/2/2015\n\n**Date of Reassessment:**  \n8/5/2015\n\n**Assessment stage:**  \nLive\n\n**Result of Original Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nM. Sheldon\n\n**Service Manager:**  \nD. Thomson\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## Reassessment Report\n\n**8th May&nbsp;2015**\n\nThe SLC Full Time Application service has been reviewed against point 10 of the Service Standard at the end of beta development.\n\n**Outcome of service reassessment**\n\nAfter consideration the assessment panel has concluded that the SLC Full Time Application service has shown sufficient evidence of meeting the Digital by Default Service Standard and should go Live as a Digital by Default service on GOV.UK. The service can now remove any Beta branding.\n\n**Reasons**\n\nThe service team demonstrated that they had undertaken thorough research into their assisted digital users, contacting a significant number of people who had used offline methods to complete the application in the past, and by working very closely with their contact centre agents. The team demonstrated an understanding of user needs and had designed appropriate assisted digital support based on this research.\n\nThe telephone support has been iterated to include needs assessment, dedicated assisted digital agents, and telephone talk-through by appointment or at the time of the call. There are legal barriers to SLC completing the form on behalf of users by telephone. The team are seeking to resolve this, either through policy or by the use of a third party. Although there was no demand during beta, the team identified a potential need for face by face support through user research and are offering this if required, through outreach.\n\nAvailability of the current service is good and the team have imminent plans to improve user awareness of support and to reduce the availability of the paper form.\n\nThe service team have a good plan for improving support post-Live, including exploring web chat, co-browsing and the ability for someone else to complete the transaction on a user's behalf. They plan ongoing engagement with Higher Education Institutions around support that is offered to students. Assisted digital support will be monitored through analytics and feedback, and the service team have developed a strong pool of users who are willing to contribute to further user research as the support is developed. The requirements related to face by face support will continue to be tested, and senior managers at SLC have committed to supporting the assisted digital procurement framework.\n\n**Recommendations**\n\nAfter going Live, the team commit to:\n\n- Continuing to iterate assisted digital support based on analytics and user research.\n- Continuing to work with GDS assisted digital team on procurement of third party support.\n- Improving digital take-up by encouraging use of assisted digital support.\n- Testing GDS draft guidance for measuring assisted digital transactions through their assisted digital support.\n\n**Summary**\n\nThe service has now fully met the Digital by Default Service Standard, with the service team responding quickly and positively to the feedback from the original assessment. The team have shown a high level of commitment to meeting the needs of assisted digital users, and have clear plans for ongoing improvements to the service post-Live.\n\n* * *\n\n## Summary of Original Report\n\n**19th&nbsp;February 2015**\n\n## Assessment Report\n\nThe SLC Full Time Application service is seeking permission to be branded a Live Digital by Default service on the service.gov.uk domain.\n\n**Outcome of service assessment**\n\nAfter completing the assessment, the assessment panel has concluded that the service does not quite meet the live requirements of the Digital by Default Service Standard. However, the panel believes that achieving that goal is well within reach of the SLC service team.\n\nSince beta assessment, the team have made very positive progress and received encouraging user feedback from live use of the service during 2014. With significant improvements to user satisfaction, digital take-up and completion rates, and an increased focus on understanding service users, the team are transforming the service to meet user needs.\n\n**Reasons**\n\nThe SLC Full Time Application service is making good progress to meet all 26 points of the Digital by Default Service Standard.\n\nThe team demonstrated they:\n\n- Have a very good understanding of user needs, and are conducting regular and appropriate research.\n- Have a sustainable team, recently re-organised to focus on continual improvement and new projects.\n- Are engaged with the right people inside and outside of the SLC to address the security and privacy needs of the service.\n- Have used appropriate tools to build, host and operate the service and also put code in the open.\n- Have capacity and flexibility to update and improve the service.\n- Are analysing the service against all four&nbsp;Digital by Default KPIs, and are tracking the entire online user journey. (The team deserve considerable credit for raising these KPIs during the 2014/15 application season).\n- Have tested the service end-to-end with the ministers responsible for it.\n\nThe team must now focus on the following areas:\n\n**Assisted Digital**\n\nThe team have started identifying the potential number of users who will need assisted digital (AD) support, the types of support and the projected costs. The&nbsp;service will&nbsp;now offer talk-through telephone support and provide face-to-face support at the office in Darlington. By working in this way, the&nbsp;team is&nbsp;making good progress and are on track for what would be expected for a Beta service.\n\nThere was however, not enough evidence to show that the&nbsp;team&nbsp;fully understood the needs of&nbsp;AD&nbsp;users, and the face-to-face support offered is minimal and may not scale. At a live assessment the panel&nbsp;would have expected to see the support thoroughly tested and iterated based on feedback.\n\nTo pass a live assessment the team must:\n\n- Use a more robust survey method for assessing assisted digital needs for users without online access or skills.\n- Thoroughly test the telephone and face-to-face support with users to ensure that proposed support meets user needs.&nbsp;\n- Have a plan to iterate and measure the support based on ongoing user research.\n\n**Design**\n\nSince the beta assessment, the team have continued to iterate the design of the service, making improvements based on user feedback to ensure it is simple to use. This work has been carried out whilst engaging with the GDS design patterns and Hackpad, as well as with the wider government design community. However, the service contains inconsistencies throughout, from its design and interactions to its typography and content.\n\nAlthough the service is responsive, many design elements such as the progress bar are not optimised for smaller screens. 30% of users are already accessing the service on mobiles or tablets, and this will only increase as smaller screens become users’ primary digital devices.\n\nThe panel&nbsp;understands that the team have prioritised focusing on features such as change of circumstances and graduate medical entry, which was the right approach to take. Having done so, the team now have the opportunity to make the user experience of the service as consistent as possible, focusing on tried and tested design patterns and following content style guides.\n\nThe panel&nbsp;recommends that the SLC team:\n\n- Assign ownership and responsibility of the service’s user experience to an appropriate team member.\n- Aim for user experience consistency across the service by following the GDS design patterns and guidelines.\n- Focus on improving the user experience on smaller screens; especially for mobile and tablet devices.\n- Conduct a review of the service’s content.\n\n**Summary**\n\nThe SLC team are building a service so good that users will prefer to use it. Doing this in an organisation undergoing transformation has been challenging. A&nbsp;sustainable multidisciplinary team is being built; able to operate and improve the service based on user feedback from regular research.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |\n\n&nbsp;"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/employment-tribunal-fees-service-assessment/",
    "title": "Employment Tribunal Fees - Service Assessment",
    "summary": "Employment tribunals determine disputes between employers and employees over employment rights. An application to an Employment Tribunal Fees is known as a claim, and it is submitted by a claimant.",
    "body": "Before submitting a claim, all claimants must contact ACAS to attempt early conciliation with the respondent. If no resolution is found, the claimant is issued with a certificate which enables them to make a claim to an employment tribunal.\n\nTribunals review each claim and assess whether it falls under their jurisdiction and consequently whether it can be heard by a judge. Respondents are notified of the claim and have an opportunity to respond. Once all information is gathered and accepted, the claim (or claims if a group) becomes a case which is reviewed by a judge who makes the final decision on the outcome during a hearing.\n\n[https://www.gov.uk/transformation/pay-tribunal-fees.html](https://www.gov.uk/transformation/pay-tribunal-fees.html)\n\n**Department / Agency:**\n\nMOJ\n\n**Date of Assessment:**\n\n24/2/2015\n\n**Assessment stage:**\n\nLive\n\n**Result of Assessment:**\n\nPass\n\n**Lead Assessor:**\n\nT. Scott\n\n**Service Manager:**\n\nT. Wynne-Morgan\n\n**Digital Leader:**\n\nM. Coats\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter completing the assessment, the panel can confirm the Employment Tribunal Fees service has shown sufficient evidence of meeting the Digital by Default Service Standard and should go Live as a Digital by Default service on [GOV.UK](http://gov.uk). The service can now remove any Beta branding. **&nbsp;**\n\n**Reasons**\n\nThe service was assessed against and has met all 26 points of the Digital by Default Service Standard.\n\n**User needs**\n\nThe service team displayed a deep understanding of their users and their needs to the assessment panel. The panel thought the team were an excellent example of how starting with user needs, embedding research into sprint cycles, and focussing the whole service team on meeting the most important user needs first, helps create a digital service that users can complete successfully, unaided. **&nbsp;**\n\nThe panel saw plenty of evidence that the service team had gathered to inform the service design. The team had recruited real users for research and carried out research with all types of users using appropriate methodologies. Almost half of users (individual claimants) will encounter the service during a stressful and unpleasant time. The service team displayed empathy with this user group. The other main user group are professionals (solicitors, advisers and other representatives) claiming on behalf of someone else. The team have put equal effort into both sets of users, and showed evidence for how some of the professional group will also be infrequent users of the service. **&nbsp;**\n\nUser researchers will continue to be embedded in the service team. Feedback from all sources is captured by the team and analysed, informing stories for the backlog.\n\nThe service team has made an exemplary effort to ensure users with assisted digital needs are catered for. The team sought out users with assisted digital or digital inclusion needs and has set up a sustainable service for them.\n\n**The team**\n\nThe assessment panel thought the service team were an excellent example of a co-located, multi-disciplinary team working together, focussed on meeting user needs. There were no gaps in the team and the recommended roles are filled. The service manager is empowered and responsible for the entire end-to-end service (the digital service referred to here is solely about making a claim, and is managed by an empowered product manager).\n\nThe team is using agile principles, including a variety of tools and techniques that allow the team to collaborate and share responsibilities for meeting needs and supporting the service. The team participate in user research.\n\n**Security, privacy, tools and standards**\n\nThe team have adopted a collaborative approach with the relevant experts to make sure that security doesn’t get in the way of meeting user needs. The assessment panel saw compelling evidence of the effectiveness of this approach. Security colleagues are involved from the start, meaning that they can work with the service team and gain from context and understanding of users when talking about potentially contentious security issues. Hence, the team was able to justify downgrading the security classification. The team has secured all necessary data accreditation and has a cookie policy in place.\n\nThe service team have rebuilt the front-end of the service during beta. They have opened up the source code (they have reused code from other services and anticipate some features of this one will be useful too) and have adopted an approach that moves away from vendor lock-in. MOJ owns the data. Capacity planning is in place and has been tested with x5 the expected load. The service has processes in place for dealing with an unexpected or malicious incident - a failover page will be available that will direct users to the paper application form. Backups are in place, and pager duty will be activated. An impact assessment of service downtime shows that users will still be able to make and follow up claims using readily available alternative channels. This process has been tested with a real incident by the service team, and the results were positive.\n\nThe team use a staging environment for testing, including user research. They have a scaled testing approach, depending on the size and impact of each feature. Pen testing is used for larger features. More comprehensive testing and user research on different designs and functionality is carried out in a demo environment. The service team have access to a professional hacker who attacks the service regularly. Any issues found are resolved within 2 days.\n\nThe service is responsive, although data and research suggests that desktops are most likely to be used.\n\nThere is a disaster recovery plan in place - once the underlying issue is resolved the service will be back within 10-12 minutes, or 2-3 hours if a different system is needed.\n\n**Improving the service**\n\nThe team demonstrated the ability to be very flexible and to iterate rapidly.This ability will continue through to live operation. The team iterated features continuously during beta in response to user research. They are committed to further improving the user experience and have a prioritised backlog of features to research and iterate next. The service has set up automated testing and they deploy as soon as something is ready. There is enough structure in place to ensure the right levels of product review are adhered to, without making the release process overly cumbersome. The service team plan to encourage content designers to make pull requests for small copy changes, rather than incorporating these into sprint work.\n\nThe team have ensured they are gathering all sources of data and evidence to be confident they are getting a full picture of how the service is performing and what users are saying. They are linked up with other parts of the end-to-end service, such as the Public Enquiry Line team, and any insights are incorporated back into the service design.\n\n**Design**\n\nThe team have evidence to show that users are able to complete the service unaided. Their knowledge of their users and the context in which they’re operating reveals that many will return to the service to complete it later. They are seeking to add tracking to ensure that the journey for re-accessing the service is successful. Currently users will access their saved claim via their case reference number (via email) and their memorable word. The team investigated GOV.UK Verify and explained that a full identity check wasn’t appropriate nor needed. Users tend to collaborate on a claim with their representative. The team have an assumption, which they’re testing, that the memorable word step is not useful nor required for assurance purposes. They are collaborating with MOJ security experts on this and their SIRO is aware of it. The team are still in discussions with these experts about this feature.\n\nThe service team displayed a thorough and impressive understanding and engagement with the end-to-end service. This is a complex legal process involving several parts of government and third parties, such as Acas. The team have led the way in collaborating with all parties to improve the user experience and encourage a digital by default approach. At present, the service becomes mostly paper-based once a claim has been submitted. The team have made several improvements, eg paper applications are now entered into the digital service by tribunal staff. The team are working with BIS and HMCTS to redesign the paper application form and to ensure the language matches the digital service.\n\nThe team has collaborated closely with Acas (who provides the mandatory mediation service) and the CAB, who are providing a trial of facebyface assisted digital and who also have the remit to advise claimants.\n\nThe service uses the GOV.UK design patterns and style guide. The team showed how they have contributed to the above toolkits when there is no standard pattern, and when user research has recommended a different approach. The designer and content designer on the service team work closely with the wider government community. The service includes inline guidance, which the team justified with evidence from user research. The service panel would encourage the team to work with the GOV.UK content team to ensure that any overlapping content on GOV.UK is consistent. The panel also spotted some style guide inconsistencies.\n\n**Assisted digital and digital take-up &nbsp;&nbsp;**\n\nThe service used research with assisted digital users to forecast the demand for assisted digital support, although in testing there has been lower demand than expected. They have tested their telephone support for 4 months and iterated the support to meet user needs, incorporating appropriate needs assessment processes and making improvements to the digital service. They have tested the face-by-face support in a pilot with a 3rd party in a few locations. There are challenges to delivering this (splitting out supporting the transaction from providing legal advice) but this has been resolved by the team. They are running a pilot on payment for this support to ensure that it is sustainable. Awareness that support is available could be clearer on the digital service’s ‘contact us’ page but otherwise is good, including signposting through 3rd parties where appropriate.\n\nThis service is one part of a wider process which is largely paper-based, most applications are by intermediaries who find paper a more convenient way to engage with their clients and users can pay by cheque in the post. This makes digital take-up for this service more challenging but the team demonstrated that they are working with related services, agencies and intermediaries to move users online. They are also in the early stages of working with BIS to improve the paper form, in line with their findings for the digital service.\n\n**Analysis and benchmarking**\n\nThe service is using Google Analytics and has several team members with the skills to interpret data. As well as a fully optimised Google Analytics dashboard, the team uses a geckoboard to display real time data. They have a dashboard on the performance platform currently tracking 3 KPIs, with a plan to add the 4th KPI very soon and to switch the dashboard over to the new digital service. The team have identified 2 further KPIs that they will use to track success: percentage of users who use the ‘save and return’ feature and percentage of professional users who use the service interface to record a claim, versus uploading an attachment.\n\nThe team are proficient in using performance metrics to track the service against the benchmarks they have set. They will be able to see how the redesigned service performs against the current beta to establish whether they have improved the experience for users. Data captured during the private beta suggests that performance against the KPIs will show improvement.\n\nThe team have carefully considered and consulted around identifying the cost per transaction figure - they have ensured this represents the entire end-to-end service. Similarly with the user satisfaction metric - the team explained how the positioning of the data capture survey can skew results away from measuring the actual digital part of the service.\n\n**Testing with the Minister**\n\nThe service team showed a video of the minister making a claim via the service, as if they were a user. They were able to complete unaided, and gave good feedback.\n\n**Recommendations**\n\n1. Adopt the same approach as the excellent collaboration shown within government by working closer with GOV.UK content teams. The service team has developed an in depth understanding of the wider needs surrounding employment tribunals and could impart some of that expertise to the GOV.UK team, both in GDS and in other government departments and agencies.\n\n1. Specifically, work directly with the content team at GOV.UK to ensure that the content in the inline guidance reflects content design standards and GDS house style. Encourage collaboration and learning from each other.\n\n1. The team should continue to develop their plans for digital take-up as part of the wider employment tribunals process. Processes should be improved so that users that can use the digital service choose it over paper.\n\n1. The work on deploying the application into Amazon Web Services (AWS) and achieving authority to operate is great. The team are working towards accreditation. The panel believes it would be fantastic if the service team could share their experiences more widely within government if they are successful.\n\n**Summary**\n\nMaking a claim to an employment tribunal is a difficult challenge to address digitally. The team has shown an exemplary service design approach and has demonstrated impressive results. They have turned around the service during beta and have produced a user focussed service with evidence to show that users prefer it. Their “putting users first” approach, including users with assisted digital and digital inclusion needs, is demonstrable from their research methods and ways of team working, through to their attitude towards security considerations and offline elements of the wider service.\n\nThe panel was extremely impressed and had no doubt in passing all 26 criteria. The service team was incredibly well prepared and were able to answer questions clearly and concisely. The level of knowledge of users, service design and technical stack was high in all members of the service team. All disciplines represented in the assessment showed a commitment and passion to building and improving a user focussed service, and their empathy and understanding towards these users was evident.\n\n## **Digital by Default Service Standard criteria**\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/visit-visa-china-service-assessment/",
    "title": "Visit Visa (China) - Service Assessment",
    "summary": "An online service for people in China applying for a Child, Business or General Visit Visa to come to the UK. It replaces an existing service that is no longer suitable.",
    "body": "[https://www.gov.uk/transformation/apply-visa.html](https://www.gov.uk/transformation/apply-visa.html)\n\n**Department / Agency:**  \nHO\n\n**Date of Assessment:**  \n25/2/2015\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nM. Bogunovic\n\n**Digital Leader:**  \nM. Parsons\n\n## Assessment Report\n\n**Outcome of service assessment**  \nAfter completing the assessment the panel can confirm the Visit Visa (China) service has shown sufficient evidence of meeting the Digital by Default Service Standard and should go Live as a Digital by Default service on GOV.UK. The service can remove any Beta branding when it has completed the move to the service.gov.uk domain.\n\n**Reasons**  \nThe service was assessed against and has met all 26 points of the Digital by Default Service Standard for the scope of the current service, Visit Visa (China).\n\nThe service team have built a service based on user needs, that has been (and can continue to be) iteratively improved and has the appropriate safety and security measures in place.\n\nThe team explained how they have improved the service based on research and feedback, completing 7 days of research in China, two further rounds of remote research and analysis of 800 pieces of feedback.  \nClear examples of iterative improvements made based on research were given, examples include removing a confusing mandatory free text section that repeated the previous question and cutting a large amount of content from the declaration down to 70 words, which demonstrated how the service team worked with policy colleagues to make sure they included only absolutely necessary content.\n\nThe survey feedback received during beta also indicated that users were finding that the emailed invoice was not accepted as proof of purchase, the team made changes to the content of the email to resolve the issue.\n\nSince beta, the team have continued to iterate the design making sure it is simple to use. The team have engaged in the GDS design patterns and hackpad. The assessment panel think it would be great to see more evidence based design through doing more user research and the team have a clear research plan in place to allow them to continue to iterate the service in this way.\n\nThe panel are pleased to see the team go above and beyond in tackling the technical challenges of this project. They not only produced a digital service that is safe and secure, but added integrations with legacy case management tools to provide a better service to users despite wider organisational concerns about the technical feasibility of such integration. The panel was pleased to see the team proving out these integrations early in minimal style and demonstrating their ability to iterate upon difficult to change systems.\n\nThe assessment panel were very pleased to note that security specialists have been involved throughout the project, closely working with the team to ensure security throughout rather than being final gatekeepers or merely assuring the security of the product. The team seemed to have a good understanding of the risks of their service and had taken the appropriate risk based decisions for the platform. The assessment panel look forward to hearing more about this and encourage the team to blog about their experiences building a complex system in such a manner.\n\n**Recommendations**  \n**Scope**  \nIt should be clear that the scope of the service that has been assessed and passed the standard is the Visit Visa (China) service. The service team should talk to the GDS assessments team about how it continues to be assessed as the scope of the service expands either to include other countries, or other visa types.\n\n**Make all new source code open and&nbsp;**** reusable**  \nWhile it is fantastic that part of the codebase has already been reused by the Registered Traveller service and the team have open sourced the payments part of the codebase, the remaining components are not yet open source. The panel were glad to hear that the Home Office Digital policy is to take open source commitments seriously and that the intention is to work at reversing the original closed source policy. GDS welcomes the team’s plan to continue to open source the remaining components over the next 6 months according to the supplied timeline:\n\nAdmin and Catalogue - April 2015  \nCopy Editor - May 2015  \nCustomer - July 2015  \nPSN Boundary Controls - August 2015  \nSubmission Service - August 2015\n\n**The team**  \nThere is a strong multidisciplinary team in place, but there have been gaps in the team during beta which have now been addressed. The team have had difficulties in recruiting a digital analyst, they now have an analyst joining the team, who will be working with all the Home Office exemplars (spending a third of their time with the Visas service). The service manager should assess the team’s ongoing need for analysis, particularly when the scope of the service widens.\n\n**Deployments**  \nThe team can release code changes as often as needed, but deployments currently require downtime. Deployments are timed to happen at the least busy times and plans are in place to enable zero-downtime deploys. As the service expands worldwide, users will access the service increasingly out of UK office hours, and the panel also believe that the team cannot fully predict when the least busy times will be. The panel would therefore encourage the team to move to zero-downtime deployments as soon as possible.\n\n**Hosting on the** [**service.gov.uk**](http://service.gov.uk/) **domain**  \nThe assessment panel were disappointed to hear that although work was underway to migrate the domain over to[service.gov.uk](http://service.gov.uk/), the service could reach the point of live assessment without being on the[service.gov.uk](http://service.gov.uk/) domain. To be ‘live’ the service must be hosted on the correct[service.gov.uk](http://service.gov.uk/) domain, and the current domain is not given permission to remove the beta banner as part of this assessment.\n\nThe team should contact the GDS content team to amend the[GOV.UK](http://gov.uk/) start page once the[service.gov.uk](http://service.gov.uk/) domain is live.\n\n**Design**  \nThe team should aim for user experience consistency across the service by following the GDS design patterns and guidelines, a design snag list will be sent separately to this report.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/vehicle-tax-sorn-and-vehicle-enquiry-service-assessment/",
    "title": "Vehicle Tax, SORN and Vehicle Enquiry - Service Assessment",
    "summary": "This service is designed to make re-taxing more convenient for customers, as they are able to tax from home, work or even aboard, 24 hours a day, and 7 days a week. &nbsp;The service is compatible for use across different browsers and devices.",
    "body": "**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n26/9/2014\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nNot passed\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nC. Williams\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## **Assessment Report**\n\nThe Vehicle Tax, SORN and Vehicle Enquiry services are seeking permission to be branded a Live Digital by Default service on the&nbsp;[service.gov.uk](http://service.gov.uk/) domain.\n\n**Outcome of service assessment**\n\nAfter completing our assessment we have concluded the vehicle tax, SORN and vehicle enquiry services should not be given approval to remove beta branding and launch on a&nbsp;[service.gov.uk](http://service.gov.uk/) domain as a Live Digital by Default service. The service should retain beta branding until it has passed a reassessment.\n\nThe service will not need to complete a full reassessment, but the service should be reviewed against the criteria which it has not fully passed in order to remove beta branding and launch as as a Live Digital by Default service.\n\n**Reasons**\n\nThe GDS assessment team were very impressed with the scale and pace of delivery since the vehicle tax service launched as a beta service on a&nbsp;[service.gov.uk](http://service.gov.uk/) domain in January 2014.\n\nThe team have dealt with three large changes to the scope of the service within that time, the abolition of the tax disc, adding direct debit payment options and expanding online vehicle licensing to include Northern Ireland.\n\nThe core team are working in an agile way which meant they were able to rapidly adapt and deliver these changes to the service as the scope changed.\n\nThe appropriate safety and security provisions are in place and the team have a good understanding of user needs for the services and have taken on feedback from research to iterate the beta service.\n\nHowever, the assessment team felt that the service didn’t meet two points of the standard to a degree that would mean moving to Live status. The Live assessment is deliberately stretching, and is designed to ensure that a service meets all points of the standard now, and will be in a strong position to continue to do so in the future.\n\n**Point 2: Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.**\n\nSpecifically the following aspects of point 2:\n\nS_how there are no gaps in the team or explain how they will address any gaps:_\n\n- The team clearly explained the benefits of being co-located and how this had worked well. However, there are areas where this has not been the case and the assessment team felt that this was visible in the product. Specifically, content design, interaction design and product analyst skills aren’t currently sufficiently integrated or represented within the team. These disciplines should be fully involved in the research and development of the service, in order to iterate the service to meet user needs.\n\nS_how that the team will be sustained to continuously improve the service after it goes live:_\n\n- It wasn’t sufficiently clear how the service will continue to be iterated and developed once it is live and the team that will be in place to deliver further iteration. The developers within the team will be shared across other projects.\n- The service team will need to be able to respond to feedback quickly. It is vital that there is a team in place to analyse large volumes of data from various sources (call centre data, analytics and email feedback) and then iterate the service, based on this, to better meet user needs.\n- If there isn’t the capacity to iterate once the service is live, it will quickly degrade.\n\n_Show that there is a separation of key roles (ie the same person is not performing multiple roles within the service):_\n\n- There isn’t a clear separation of key roles in some areas, the lead developer is also covering front-end development, design and analytics. While it is good that real-time analytics are available to the whole team, it’s important that there is an individual with sufficient dedicated time to turn the analytics data into actionable insight.\n\n_There is at least one user researcher working regularly and frequently on the service:_\n\n- There are no user researchers co-located or embedded within the service team. There are plans in place to meet with the customer insights team to discuss future research, but it wasn’t clear who would lead experimental design and research to iteratively improve the service.\n\n**Point 10 - Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it**\n\nAlthough the service provides offline support for users through several channels, the team did not provide evidence of sufficient research into assisted digital users for this specific service so it was unclear whether the proposed support would meet the needs of those users.\n\nThe service must undertake research into the full range of their assisted digital users to understand their needs, including people who are unable to use or access the online service independently. They must then ensure the proposed assisted digital support meets those needs and is in line with the service standard.\n\n**Other issues and recommendations**\n\nThere are design and content issues that the service team should address at the next opportunity, the assessment team will send over the specific information separately to this report.\n\nTerms and conditions content should be present (where relevant).\n\nThe service(s) subdomain URL shouldn’t be indexed by external search engines (the start page on&nbsp;[GOV.UK](http://gov.uk/) should be the start of the service).\n\n**Next Steps**  \nThe service team should follow the recommendations made in this report and see the&nbsp;[Government Service Design Manual](https://www.gov.uk/service-manual/digital-by-default) for further guidance. In order for the service to proceed to live and remove beta branding it will need to be reassessed against the criteria, which were not passed.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/registered-traveller-service-assessment-3/",
    "title": "Registered Traveller - Service Assessment",
    "summary": "The Registered Traveller service enables pre-approved regular travellers from a selected group of countries, to pass through the UK border faster.",
    "body": "Users are business travellers or frequent flyers to the UK that meet the current eligibility criteria and have passed the detailed background checks conducted during the application process. &nbsp;Once approved, members are able to use the ePassport gates (if they have a biometric passport) at Gatwick or Heathrow airports.\n\n[https://www.gov.uk/registered-traveller](https://www.gov.uk/registered-traveller \"https://www.gov.uk/registered-traveller\")\n\n**Department / Agency:**  \nHO\n\n**Date of Assessment:**  \n15/12/2014\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Hughes\n\n**Service Manager:**  \nJ. Dos Remedios\n\n**Digital Leader:**  \nM.&nbsp;Parsons\n\n* * *\n\n## **Assessment Report**\n\nRegistered Traveller&nbsp;service is seeking permission to be branded a Live Digital by Default service on the service.gov.uk domain.\n\n**Outcome of service assessment**\n\nAfter completing the assessment, the panel can confirm Registered Traveller service has shown sufficient evidence to pass the Digital by Default Service Standard for a Live service.&nbsp;This service has been given approval to go Live as a Digital by Default service. Beta branding can now be removed and replaced with Live branding.\n\n**Reasons**\n\nThe service has met all 26 of the points of the service standard. Particular areas of strong performance included:\n\n- User research - a wide range of methods are being used and clear evidence was shown of how research has translated into improvements to the service.\n- Progress on content design - the service looks better at each assessment and there is clear evidence of improvement over time.\n- The service team is taking an active approach to making agile process work for them.\n- The team has delivered rapid iteration in response to feedback.\n- The team&nbsp;described the planned move to a shared service model and demand for the expertise from this team to be applied elsewhere in the Home Office.\n- The team&nbsp;explained how the risk of a loss of adequate support for this service will be mitigated.\n- The [performance dashboard](https://www.gov.uk/performance/registered-traveller) for the service, showing real time information, is publicly available on the performance platform.\n\nNote: the service team has demonstrated that additional assisted digital support does not need to be provided at this time. If the scope of the service changes the user base, the team may need to undertake research with assisted digital users and design, test and provide appropriate assisted digital support that&nbsp;meets user needs.\n\n**Recommendations**\n\nThe service has not yet published all of its source code. However, the panel&nbsp;have assessed the service as meeting point 15 of the standard because there is clear evidence of some work already having been done, as well as reasons for the service not having published the code yet, and plans in place to publish code over the coming months.\n\nThe service manager explained that some code has already been published, and some components are already being shared within the Home Office. The reasons for not publishing the code previously are that it is not yet ready for publication and is about to be replaced using a different technology stack - the team will publish that code in accordance with the timescales listed below.\n\nThe panel recommend that the team now proceeds to fulfil the commitments given in the service standard assessment. These are outlined below under ‘next steps’.\n\n**Next Steps**\n\nThe service should proceed to implement the plan for publishing its code as provided during the assessment. The timetable provided by the team is:\n\n- December - &nbsp;open source the node-worldpay component under appropriate licences to a Home Office public GitHub account.\n- December / January - push the node-worldpay module up to the NPM.\n- February - publish the rest of the Updates front-end code.\n- March - publish Renewals front-end code.\n- May - publish a reworked new application form. Any appropriate new components that can be extracted will be open sourced.\n- June - open source a new Play plugin for authentication and authorisation, initially using Mongo and memcached as datastore, and&nbsp;open source a new Play plugin for persisting emails from templates and send these out asynchronously.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |\n\n&nbsp;"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/carers-allowance-service-assessment/",
    "title": "Carer's Allowance - Service Assessment",
    "summary": "Carer’s Allowance is a benefit for people looking after someone with substantial caring needs. Users can currently make a claim through the post or online. The exemplar project replaced the previous online claim process which had low take-up and did not meet the standards set out in the department’s digital strategy.",
    "body": "[https://www.gov.uk/carers-allowance](https://www.gov.uk/carers-allowance)\n\n**Department / Agency:**  \nDWP\n\n**Date of Assessment:**  \n13/11/2014\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nL. Reichelt\n\n**Service Manager:**  \nP. Desmond\n\n**Digital Leader:**  \nK. Cunnington\n\n* * *\n\n## **Assessment Report**\n\nThe Carer’s Allowance service is seeking permission to be branded a Live Digital by Default service on the service.gov.uk domain.\n\n**Outcome of service assessment**\n\nAfter completing the assessment, the panel can confirm the Carer’s Allowance service has shown sufficient evidence of meeting the Digital by Default Service Standard and should go Live as a Digital by Default service on GOV.UK. The service can now remove any Beta branding.\n\n**Reasons**\n\nThe service was assessed against and has met all 26 points of the Digital by Default Service Standard.\n\nThe assessment panel congratulates the team on the progress that has been made on this service and within the team since the beta assessment. This service is a real exemplar of what comes from putting users at the heart of the service, using research and usage data to identify opportunities for improvement and prioritising work to help the service better meet user needs. The panel&nbsp;hopes that other teams in DWP will look to the way the service team was created,&nbsp;and the processes and methods that have been used, as they work on other DWP digital services.\n\nAreas that stood out to the panel include:\n\n- A deep understanding of the user needs through extensive and iterative user research. The team really understand and can clearly state the needs that people have when they encounter this service and work hard to make sure that the work they do on the service directly impacts the user experience in a meaningful and measurable way.\n- The development of the in-house team, and the work done to help DWP staff develop the skills to be able to work in a user-centric, iterative and agile way.\n- Working with the wider team, including policy, to make difficult but important changes to the service design including removing 172 questions from the application form (49% of the questions) and removing the need for wet signatures.\n- Excellent use of data and analytics to guide the prioritisation of work on the service.\n- Ability and extensive experience with rapidly and frequently updating the service and great ability to iterate.\n- Early and iterative research to understand the assisted digital needs of the users and working to develop ways of supporting these needs.\n- Collaboration with the design and user research communities across government to share knowledge and experience and contribution to shared repositories so that many other teams can benefit from the good work done in this service.\n- The commitment to continue with this agile and user centred way of working beyond achieving ‘live’ status and having the team and necessary infrastructure (for example, procurements for the user research lab for continued ongoing research) in place with appropriate budgets, for the next 12 months.\n\n**Recommendations**\n\nThe panel commends the team for the work they have done to run pilots and to work closely with their call centre to make sure that people who need assistance with the digital service are well supported. We encourage the team to continue to explore ways of seeking out people who need additional support using digital services and to continue to iteratively improve both the telephone and in person services through testing, as you would the digital service.\n\nThe service must continue to work with the assisted digital team at GDS to ensure appropriate support is in place as the digital service rolls out to users currently using non-digital alternatives. This work should include further user research specifically with assisted digital users who are currently using the non-digital alternatives to the digital service. It should also include developing specific testing of the assisted digital support within the broader phone support. The work should also include continuing to design and test assisted digital support with those same users, ensuring it meets their needs and volume.\n\nThe service’s ongoing research and testing must continue to ensure that assisted digital from third party organisations is high quality and sustainable. The service must also ensure that users receiving assisted digital support from friends and family continue to have a sustainable and tested alternative available, and that an alternative paper-based service is not included as part of any assisted digital support.\n\nThe panel encourages the team to ensure prompt migration to DWP's analytics platform once this is available.\n\nThe&nbsp;panel also encourages the team to have a content designer run through the service again to ensure that it follows the GOV.UK style guide.\n\nThe content would also benefit from a full ‘second pair of eyes’ check before launch.\n\n**Summary**\n\nThe work that the team has done on the Carer's Allowance service is a real exemplar of how a user-centred and agile approach to delivery leads to a better outcome for users, especially those who need our help the most. As the team said in the assessment, ‘with everything else that is going on in their lives, claiming Carer’s Allowance should be the least of their worries’. The team has done a great service to these users and the team's great work has taken a lot of stress away from people who most deserve our support.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |\n\n&nbsp;"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/vat-mini-one-stop-shop-live/",
    "title": "VAT Mini One Stop Shop - Live Assessment",
    "summary": "VAT Mini One Stop Shop (MOSS) allows users to register, report and pay VAT due on sales of digital services to consumers in the EU.  \nThe [VAT Mini One Stop Shop guidance](https://www.gov.uk/guidance/register-and-use-the-vat-mini-one-stop-shop) provides further information.",
    "body": "**Department / Agency:**  \n[HM Revenue & Customs (HMRC)](https://www.gov.uk/government/organisations/hm-revenue-customs)\n\n**Date of Assessment:**  \n3 October 2014\n\n**Assessment Stage:**  \nLive\n\n**Result of Assessment:**  \nNot Passed\n\n**Lead Assessor:**  \nM. Harrington\n\n**Service Manager:**  \nA. Collins\n\n**Digital Leader:**  \n[M. Dearnley](https://www.gov.uk/government/people/mark-dearnley)\n\n* * *\n\n## Assessment Report\n\nThe VAT Mini One Stop Shop service is seeking permission to be branded as a Live Digital by Default service within the HMRC portal.\n\n### Outcome of service assessment\n\nAfter completing our assessment we have concluded the VAT Mini One Stop Shop service should not be given approval to be a live service on the HMRC portal.\n\n### Reasons\n\n#### User Needs\n\nThe team have not tested the service with a broad enough sample of users to truly develop a good understanding of their needs, particularly SMEs. While the team have demonstrated elements of the service to groups in-depth testing has only been done with 4 people. This is not enough to try out different design directions. Although the assessment panel understand that the full service has only recently been available elements of the service could and should have been tested through development. The design is based on the assumption that because a user is familiar with VAT sign up they should be fine with this service, there is no strong evidence to back this up. Similarly, there was little evidence of a plan to continue user research once the service went live, making iterative improvements very difficult. There had been no testing of the assisted digital support.\n\n#### The Team\n\nIt was good to hear the team worked in an agile way during the build, with a product owner in charge of the backlog. The Senior Responsible Owner also has a close relationship with the team which is positive. However, the lack of a dedicated user researcher or designer (for example) in the team full time has impacted the teams ability to meet all the points of the standard.\n\n#### Security, Privacy, Tools and Standards\n\nThe Mini One Stop Shop application is predicated on an existing infrastructure and is essentially an extension rather than new software. Security and Privacy have been taken into account by the team. The application has proprietary applications, for the database tier and the application servers. This is the common platform upon which all the portal applications are built. The assessment panel would prefer an open source solution to these common service tiers of which there are several options. Though it is appreciated that this common approach had program benefits with regards to the operational aspects of the service.\n\nFrequent deployments of the Mini One Stop Shop service are hindered by existing HMRC structures. With regards to disaster recovery, the team had put little work into this area and were utilising existing HMRC infrastructure to handle concerns. Links are established to existing support teams to handle queries and issues.\n\n#### Improving the service\n\nThe service is exempt from this part of the assessment as agreed at the GDS Ops Board on 21 July 2014. Yet, it was positive to hear that the team could quickly respond to copy issues if they became aware of them and that deployments are happening more regularly.\n\n#### Design\n\nThe service is exempt from having the look and feel of[GOV.UK](http://gov.uk/) and there are no offline sections which require integration. It is very difficult to judge whether the service is simple and intuitive for users to succeed first time as user research has been limited to only 4 people and a great deal of reliance is placed on the user having experience of the VAT transaction in the same portal.\n\n#### Assisted Digital and Channel Shift\n\nThe service team have not done specific research to discover assisted digital users of this service and have made a broad assumption that their users have the skills to use the service independently. Working with a user researcher it would be good to validate this assumption.\n\nAssisted digital users are supported by a central HMRC team who have been given scripts/guidance to help them offer support. This has not been tested at all. The lack of testing and research here meant that the team was unable to talk about many aspects of the assisted digital channel, such as awareness, wait times, completion rates and trust.\n\nDigital take-up is also covered in this section of the assessment. This service is only available online so anyone using this service will do so via the digital channel. The comms plan preparing users for when the service goes live, this hasn't involved GDS.\n\n#### Analysis and Benchmarking\n\nThere are tools in place to collect data on the service. These includes Webtrends for analytics and access log data to better understand journeys and user behaviour. There was no evidence at the assessment that this data was being used to learn about the service and improve it.\n\nThe service team have recently approached the Performance Platform team to discuss displaying the four KPIs as outlined in the service manual but are not currently in a position to do so. It was clear from the assessment that the team do not have access to all the data of the service without needing to involve a third party which might impact their ability to report on the four KPIs.\n\n### Recommendations\n\n#### User Needs\n\nPut into action a plan for regular user testing with a user researcher. Many of the not passed points of this assessment are due to the lack of user research. A better understanding of user needs and validation of the team's assumptions would put them in a much stronger position for re-assessment as well as giving the team real insight into the service. A dedicated user researcher on the team would help with this.\n\n#### The Team\n\nAs noted above, the lack of dedicated skills in certain areas in the team has made it difficult for them to reach the service standard. At the assessment it was made clear that there is available resource to create the right team for the VAT Mini One Stop Shop service going forwards. This is positive and the team should think carefully about the skills required to create the best possible service. Our recommendations would include user research, design, assisted digital and data/performance analysis.\n\n#### Security, Privacy, Tools and Standards\n\nThe service team spoke at the assessment about expanding the Mini One Stop Shop application. It is the assessment team’s recommendation that future development should be based on the HRMC Tax Platform as this offers more flexibility for building and iterating. It would also enable the service to better meet the standard with regards to open source and technology choices. While a limitation of the existing architecture, it would be good to see the live service demonstrated at assessments.\n\n#### Assisted Digital and Channel Shift\n\nAssisted digital support for this service should be clearly and wholly owned within the service team who should proactively seek out users of the service with the lowest digital skills and carry out research to understand their specific needs and numbers. With this knowledge, the service team should design a model of assisted digital support for those users and then test and iterate it to show the support is meeting user needs and volumes. The service team should put in place mechanisms to measure performance of the assisted digital support when live, and plan to iterate the support in line with that feedback.\n\nWith regards to digital take-up, the service team should contact the digital take-up team at GDS to review planning and ensure all is being done to reduce avoidable non-digital contact from potential users using non-digital channels to contact HMRC about the service.\n\n#### Analysis and Benchmarking\n\nThe service team needs to better use available data and make sure there are systems in place to record insights from the service. This will help to instill a culture of decision making based on data. Alongside user research, it will also help validate or better understand assumptions the team is making about the service. The team must display the four KPIs as set out in the service manual on the Performance Platform.\n\n### Next Steps\n\nYou should follow the recommendations made in this report and see the [Government Service Design Manual](https://www.gov.uk/service-manual/digital-by-default) for further guidance. In order for the service to proceed we require a full reassessment.\n\n### Summary\n\nGiven the challenges faced, like EU legislation and legacy systems, there are positives for the team to take from this assessment.\n\nThe lack of user research on this product really hampers its ability to meet the service standard. However, the assessment team believe with the right additions to the team and user research in place, the service could meet the standard, with the exemptions as previously agreed. It is good to know that recruitment is within the service team's control and that it could help them meet the standard.\n\nThe example given about the automatically calculated VAT total not being popular is an example of the invaluable insight that can be found with user research. The more the service is properly tested, the more insight that will be gained.\n\nThe fact that the team can act quickly to iterate copy is good news and will enable the team to respond to feedback from users. Releases are much more regular than expected meaning that iterative improvements are possible. Similarly, it was very good to hear that the team had worked in an agile way through the build and it was good to have the backlog owner at the assessment to give an account of that experience.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | No | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | N/A |\n| 7 | No | 8 | No |\n| 9 | No | 10 | No |\n| 11 | No | 12 | Yes |\n| 13 | No | 14 | No |\n| 15 | No | 16 | Yes |\n| 17 | No | 18 | Yes |\n| 19 | No | 20 | No |\n| 21 | No | 22 | No |\n| 23 | No | 24 | No |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/blood-donation-service-voluntary-service-assessment/",
    "title": "Blood Donation Service - Voluntary Service Assessment",
    "summary": "The online blood donation service ([http://www.blood.co.uk](http://www.blood.co.uk)) provides the public searching for blood donation sessions real time booking and the ability to view donation history. Bookings are based on the donors eligibility (time since last donation and health) and preferences (location). The service provides information and access to support channels and simple registration for online access and registration as a blood donor for new donors. Donors can also connect their account to Facebook and Twitter logins for ease of access.",
    "body": "The users are Whole Blood donors, members of the public and internal support teams. The service is currently in live. The current service replaced a prior version of an online booking system (having gone live in November 2013).\n\n**Department / Agency:**  \nDH\n\n**Date of Assessment:**  \n7/10/2014\n\n**Assessment stage:**  \nLive - Voluntary\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nP. Ferris\n\n**Service Manager:**  \nR. Creighton\n\n**Digital Leader:**  \nW. Cavendish\n\n* * *\n\n**Assessment Report**\n\nThe Blood Donation service was assessed against the standard to conform to a Cabinet Office spend control requirement. This was a voluntary assessment in order to help you assess performance and to identify areas for improvement.\n\n**Summary**\n\nThe assessment panel thought your presentation was strong and demonstrated a clear understanding of what the business aim was. The team had a clear understanding of the 26 points of the standard to a level that we would wish other assessments to aspire too. The panel were also very impressed with the passion across the whole team to deliver the new service, and the depth of knowledge of the product and thinking behind the decision making of all those attending.\n\nThere are a number of points where the panel would suggest you give some additional thinking as follows:\n\n**User needs**\n\nThe service has a number of mechanisms in place for gathering user data (surveys, focus groups, analytics, etc.). The service team has broken down the experience into 7 user journeys – tested through a build and QA environment. These had been subject to sprint testing and built in an integration environment and subsequently into UAT.\n\nThe panel noted the service had completed 2 user research sessions so far – 1 at wireframe stage. The service has a slight bias to gaining user feedback via survey, although it was clear the team is highly responsive to the evidence that has come out of this methodology. The multiple browser capability testing and that your site was mobile friendly was good.\n\nThe panel welcomed the decision of Blood Service to have an onsite Product Manager and Behaviour Insight Team that led thinking and you had a good understanding of your product and the needs it was intended to meet and were planning iteratively to continue your development towards this.\n\n**Recommendation:** increase the face-to-face user feedback opportunities, prioritise the feedback from these over high level survey feedback.\n\n**The team**\n\nThe service has a Service Manager who sits on the Project Board and is able to influence project direction and thinking. He demonstrated clear knowledge of his field and the potential challenges associated with delivery of this new channel and we were impressed with the link to the Portal Manager role which acted as the ’voice of the customer/donor’. A team was in place to deliver the project with a clear accountable executive role. However the panel did note that the team was not fully cross functional - different functions were not co-located and development was separate from the business.\n\nThe service highlighted the work underway to respond to this specifically recognising that design was a current gap in provision and this is dealt with further under the design area. The description of the move from Portal 1 to Portal 2 and the differing operating arrangements to be put in place (including moving to more agile approaches and blending current support provision with an in-house team) which the panel thought showed clear direction in terms of ownership of the service.\n\n**Recommendation:** the approach to a more in-house team is absolutely right and will benefit the success of the product in terms of future development.\n\n**Security, privacy, tools and standards**\n\nThe assessment panel were convinced the service had clearly communicated to the right people early and kept an engaged conversation to inform development. Where challenged, the service had responded promptly to incorporate feedback and had acted on recommendations promptly. It was clear the service had integrated security into the development and testing process from the start. Overall the panel were convinced your approach exemplified exactly how this area should be done. The panel also thought the technical representative demonstrated strong knowledge and had clearly thought through the issues around information assessment and threat effectors etc. The service team has also ensured the security policy had been fully signed off by the relevant Project board and a full&nbsp;mitigation plan was in place for identified risk areas.\n\nIn terms of being able to test the end-to-end service in an environment identical to that of the live version on all common browsers and devices, it was clear that the service team had undertaken layered testing and there was excellent browser and capacity device testing capability.\n\nThe panel suggests in the future this may prove onerous in terms of development but, that the service team were thinking of the opportunities for improving automated testing as a future response and that this would ensure less potential impacts on the agility of the release process.\n\n**Improving a service**\n\nThe current approach would benefit from greater agility - particularly in relation to the release cycle. The service team stated that the latency that currently exists between the code being completed and deployed was measurable in days however, currently achieved 4 big releases per year. The panel would suggest that wherever it is achievable for completed code to be deployed this should be done regularly and iterated as needed.\n\n**Recommendation:** the future success of this service is in part reliant on the organisation adopting an agile methodology. The organisation should also be clear regarding the responsibility for sign off as the change management process seemed to require several steps to achieve and no single individual appeared to have complete risk management / response authority.\n\n**Design and content**\n\nThe Blood Donation service is exempt from the GOV.UK look and feel as described in the Digital by Default service standard, but the panel have a few general recommendations to put in place for the future.\n\n**Recommendation:** Currently, the design and content resources are provided by a third party. It would be beneficial to the overall consistency of the service to bring that in-house, ideally under the umbrella of a digital team who could maintain and own the style.\n\nThe confirmation emails and website copy would benefit from a light proof read. Avoid switching between first and third person and using 'click here' as link text. Make sure you follow Plain English ([www.plainenglish.co.uk](http://www.plainenglish.co.uk/)) standards throughout and consider the GOV.UK style guide ([https://www.gov.uk/guidance/style-guide](https://www.gov.uk/guidance/style-guide)) as the language has been tested with users of all digital capabilities.\n\n**Assisted digital**\n\nThe service team demonstrated an emphasis on good customer service for donors regardless of the channel used for registration or appointment booking. Currently the service provides a high quality offline support for users through several channels, including talk through by telephone. Support was easy to access and awareness was good, with the service being joined up with other areas of the NHS, through GP surgeries. The service team are on the right track with their thinking behind assisted digital support but needed to demonstrate how the support meets user needs and be further ahead with testing and implementation.\n\n**Recommendation:** that the service team undertakes research through their current support channels (face to face and telephone, rather than online) to understand the barriers and needs of the full range of their assisted digital users, including people who are unable to use or access the digital service independently.\n\nBased on analysis of this research, the offline support should then be iterated and tested. Research and testing of the support should include other elements of the assisted digital standard which have not yet been fully explored (eg digital inclusion) to assess appropriateness, given the nature of this service.\n\n**Digital take-up**\n\nThe panel considered the service being provided was intended to fill the aims of digital take up as the targeted demographic. The service is not altering your current provision in terms of phone and face to face support and are introducing this new digital channel to promote digital take up amongst your altruistic customer base, providing an additional channel for bookings, customer information etc.\n\nThe service team has seen significant digital take-up through self-selection since the digital service went live and have plans in place for scaling up the digital service and work proposed for the next phase (the ‘paperless donor journey’, enhancements to capability and information related to appointments) which will continue to have a positive impact on digital take up. There is also a plan to undertake research into why users aren’t using the digital service and develop your plan to shift more users on to the digital service over the next five years. The service team should also consider that over time a greater shift to a paperless donor journey may provide a need to assess future assisted digital and digital inclusion requirements as part of reaching the entire public demographic able to register to become a blood donor, as well as reassessing the future reliance on more traditional offline contact channels.\n\n**Recommendation:** the assessment panel thought the digital take up approach was excellent and clearly providing an additional channel to your customers, although it was important that research into why people weren’t using the digital service was considered as part of future thinking and development.\n\n**Analysis and Benchmarking**\n\nThe service team demonstrated a mature well developed digital analytics system and an approach to good data culture using a mix of actionable analytics data, along with user research to drive improvements.\n\nThe only element of the Service Standard the service would have been deemed to not meet would have been that of Standard 10 (Assisted Digital) as this had not formed part of your thinking to date and no processes to consider the implications of this workstream had been put in place.\n\nHowever, overall the panel was very impressed with the online service and thought it was an excellent example of a new digital channel that should benefit its users.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/prison-visit-booking-service-assessment-2/",
    "title": "Prison Visit Booking - Service Assessment",
    "summary": "The Prison Visit Booking service meets the needs of prison visitors to book social visits easily and at their convenience. It does this by improving the booking experience by making it easier to book, being available 24/7 unlike booking phone lines, and making the booking process quicker. It also meets the needs of prisoners by supporting rehabilitation through increased social visits as staff can process more visits more quickly. Visitors can submit details of the prisoner, up to six visitors and select three alternative booking slots to increase the likelihood that a visit can be booked. Submission results in an auto notification email being received by the visitor and an email with all the relevant details being received by prison visits booking staff in the prison social visits mailbox. HMPS staff then make a booking in the backend system and reply to the visitor's booking request email with booking confirmation details.",
    "body": "[https://www.gov.uk/transformation/book-prison-visit](https://www.gov.uk/transformation/book-prison-visit)\n\n**Department / Agency:**  \nMOJ\n\n**Date of Assessment:**  \n29/8/2014\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nN. Williams\n\n**Service Manager:**  \nT. Duarte\n\n**Digital Leader:**  \nM. Coates\n\n* * *\n\n## Assessment Report\n\nThe Prison Visits Booking service is seeking permission to be branded a live, Digital by Default service on the&nbsp;[service.gov.uk](http://service.gov.uk/) domain.\n\n**Outcome of service assessment**\n\nThe assessment panel can confirm the service has shown sufficient evidence of meeting the standard, and should go live as a service on&nbsp;[GOV.UK](http://gov.uk/). This means the service can now remove its Beta branding.\n\n**Reasons**\n\nThe service was assessed against, and has met, all 26 points of the Digital by Default Service Standard.\n\nIt was clear that the service team have put users at the heart of every decision in developing the service as it progressed from alpha to live. The team demonstrated that the service is technically safe to operate, and that the team has the skills, capacity, infrastructure and processes in place to operate a high quality service and continually monitor and improve it - including detailed plans to integrate with p-NOMIS to provide real-time bookings. The assessment panel were pleased with the level of commitment from the team, and MOJ, to support and iterate the service on an ongoing basis. The assessment panel’s recommendations from the beta assessment have been addressed, and the team is now doing very good work to gather, publish, interpret and act on analytics data in order to improve the service.\n\nOf particular note, the assessment panel felt that the team’s approach to designing assisted digital (AD) support has been exemplary. The team demonstrated a strong focus on user needs for AD, basing support on findings from significant user research across potential channels. It was encouraging that MOJ has a user researcher dedicated to AD user needs, ensuring consistency of AD support across MoJ services. The AD support meets the cross-government assisted digital model, including clear communication of the support, user needs assessment and performance measurement. The team showed that they were committed to improving this support when live, through a user survey and ongoing analysis of call metrics. The service is ahead of its target for digital take-up and has plans to review this.\n\n**Recommendations**\n\nThe assessment panel observed a number of specific ways in which the service’s content and user interface design could be improved. The assessment panel have documented these and sent them to the service team separately. The document includes a few points which we require the service team to address **before** they remove the Beta branding from the service, and some further suggestions which should be addressed or discussed with us as soon as possible thereafter.\n\nWith regards to AD and digital take-up, the assessment panel also recommend that the service team:\n\n- continue to monitor AD support closely in the first few months and keep in contact with staff on the ground to make sure the service team pick up on any points for improving the support\n- work with the GDS AD team to develop performance measurement criteria for assisted digital, to be included on the performance platform\n- develop the digital take-up plan further to show how you will encourage your service users to take-up and become independent users of your digital service and to build in clear profiling which takes into account planned improvements to the digital service\n\n**Next steps**\n\nThis service has been given approval to go Live as a Digital by Default service. It is already operating at a&nbsp;[service.gov.uk](http://service.gov.uk/) subdomain, so this is just a matter of removing the Beta branding after addressing the recommendations as above.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/civil-claims-accelerated-possession-service-assessment/",
    "title": "Civil Claims (Accelerated Possession) - Service Assessment",
    "summary": "Civil Claims allows the public to solve a wide range civil legal disputes. Civil Claims can be applied to numerous scenarios - from disputes with a neighbour to personal injury - but are predominantly used when trying to obtain money or property owed. One of the many claims available to the public is the accelerated possession claim.",
    "body": "Accelerated property possession is used when people refuse to leave a property and have been given the appropriate notice to leave. They are used when a tenant won’t leave a property. The landlord cannot use this service to claim any money owed. Instead the court will tell the tenant they must leave.\n\nThis accelerated possession service is the start of making all civil claims digital-by-default.\n\n[https://www.gov.uk/transformation/court-claims](https://www.gov.uk/transformation/court-claims)\n\n**Department / Agency:**  \nMoJ / HMCTS\n\n**Date of Original Assessment:**  \n15/7/2014\n\n**Date of submission of additional evidence:**  \n8/8/2014\n\n**Assessment stage:**  \nLive\n\n**Result following additional evidence:**  \nPass\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nE. Fineberg\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## Service assessment team update following submission of additional evidence\n\nThe original assessment of the Civil Claims (Accelerated Possession) service identified several areas where further work was needed to be able to fully meet the requirements of the service standard, and for the service to move to Live.\n\nFollowing the assessment the team worked with GDS to address these areas and submit further evidence to support this development. Following consideration of this evidence the Lead Assessor is content for this phase of the Civil Claims (Accelerated Possession) service to move to live.\n\n**Summary**\n\nThe commitment that the team demonstrated in the original assessment continued to be demonstrated through their focus on quickly addressing the requirements from the original assessment and making the necessary changes.\n\nThe team plan to continue to develop the current service and over time add additional products and features. When a payment mechanism and further developments are made to the accelerated claims service, these should return to GDS for assessment. The panel will expect to the team to be able to discuss user satisfaction results and to be assured that following the changes made to the method of collection that a sufficient level of feedback is being received.\n\n* * *\n\n## Original Assessment Report\n\nThe Civil Claims (Accelerated Possession) service is seeking permission to be branded a Live Digital by Default service on the [service.gov.uk](http://service.gov.uk/) domain.\n\n**Outcome of service assessment**\n\nAfter completing our assessment the assessment panel have concluded the Civil Claims (Accelerated Possession service is on track to remove beta branding and launch on a [service.gov.uk](http://service.gov.uk/) domain as a Live Digital by Default service. The service should go through a short reassessment once the issues detailed below have been addressed.\n\n**Reasons**\n\nThe assessment panel were really impressed with the way in which the service has been built to meet user needs, and the agile way in which the team is continuing to improve the service based on user research and data.\n\nThe strong multidisciplinary team will remain in place throughout the next phase of development and the appropriate safety and security measures are in place.\n\nThe assessment panel were also impressed to see the evidence based approach to iterating the beta service with data analysis embedded into the team allowing the data gathered through the funnels set up to measure drop off points and potential problems.\n\nThe service manager has a good appreciation of the service’s assisted digital users and has put in place appropriate support to meet the specific needs of those users for this low volume service. Assisted digital users are considered to be an integral part of the full user base, not a bolt on, and they are treated no differently in terms of service delivery. The service has tested assisted digital support during the beta and is iterating it according to feedback from providers.\n\n**Recommendations from initial assessment:**\n\n- The assessment panel would like to see a greater number of transactions through the beta service from real-world users. Currently a low percentage of transactions have been completed; a bigger sample would help the team be more confident of the behaviour of different user groups in more significant volumes\n\n- Plan with GDS for the phasing out of existing channels as digital take up increases to ensure the cost per transaction is reduced\n\n- Plans, which are already in progress, to integrate with the performance platform should be completed before the service is branded as live\n\n- The issues with the way that user satisfaction is currently being measured should be addressed. So far, of the users who have completed the form, only a few pieces of feedback and ratings have been submitted. The service team should work with GDS to look at other ways of collecting this data\n\n- The footer links should be specific to the service (rather than linking to [GOV.UK](http://gov.uk/) policies and standards)\n\n- The cookies content and terms and conditions should be reviewed to ensure they are accurate\n\n**Recommendations**\n\nEnsure that assisted digital support is provided at appropriate times when users have access to the digital service. This will enable the user to build their digital skills and recognises any time sensitivities they may have.\n\nBuild on processes to measure assisted digital support, to encourage full and frank user feedback on both their satisfaction with the service and their ability to complete the service independently in future.\n\nConduct further research with assisted digital users who are unable to use or access the online service, rather than users who are attempting but struggling to use the online service, and are therefore more relevant to digital inclusion or channel shift strategies.\n\n**Summary**\n\nThe assessment panel would like to thank the service team for their well-informed and detailed answers during the assessment.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/view-driving-record-service-assessment/",
    "title": "View Driving Record - Service Assessment",
    "summary": "The service allows users to view information on their driving record including driving entitlements, penalty points and personal information  \n[https://www.gov.uk/transformation/driving-record](https://www.gov.uk/transformation/driving-record)",
    "body": "**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n14/07/2014\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nS. Bennett\n\n**Service Manager:**  \nR.Gye\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## Assessment Report\n\nView Driving Record service is seeking permission to be branded a Live Digital by Default service on the&nbsp;[service.gov.uk](http://service.gov.uk/) domain.\n\n**Outcome of service assessment**\n\nAfter completing our assessment, the assessment panel can confirm the View Driving Record service has shown sufficient evidence of meeting the Digital by Default Service Standard and should go Live as a Digital by Default service on&nbsp;[GOV.UK](http://gov.uk/). The service can now remove any Beta branding.\n\n**Reasons**\n\nThe service was assessed against and has met all 26 points of the Digital by Default Service Standard. The team has demonstrated service development through:\n\n- researching and understanding users’ needs of the service\n- improving it based on evidence and making decisions informed by data.\n- establishing a skilled multi-disciplinary team working in an agile way\n- using appropriate methodologies, tools, techniques and processes to deliver working software early and often\n- choosing the right tools and systems on which to host and operate the service\n- collecting, measuring and analysing performance data to help make improvements to the service.\n- benchmarking and comparing the performance data to other channels\n\n**Recommendations**\n\nThe assessors recommend that the team pursues the following recommendations as soon as practicable.\n\n**User needs**\n\n- Ensure that the service name is consistent throughout the user journey before going live\n- Review and clarify how users might express their user need for this service with respect to 'What vehicles can I drive' as part of work the team are undertaking with content owners to review and improve user journeys on&nbsp;[GOV.UK](http://gov.uk/)\n- Establish plans to regularly iterate and improve the service using many different methods of research to understand what users are doing and why they are using this service - in-service surveys, in-page events tracking, true A/B testing\n- Include a method for users to give in-page feedback throughout the service\n- create a plan for regular browser testing, as well as regular user research on many kinds of devices\n- Investigate areas where users are not succeeding in using the service first time, such as user failure on address look-up and especially with the transition to IDA\n- meet all Service Manual mandations (e.g. working cookie policy and privacy policy pages, completion rate measured from the service start page rather than the&nbsp;[GOV.UK](http://gov.uk/) start pages and the use of a Robots.txt file to hide the service from search engines so that the route to the service is via the&nbsp;[GOV.UK](http://gov.uk/) start page) and follow design guidance provided by GDS\n- Word the HMRC and DWP disclaimer more clearly and as far as possible move it to the terms and conditions or privacy policy. (No other exemplar, including the HMRC services, have such a disclaimer)\n\n**Technical improvements**\n\n- increase risk understanding by the team, through making IT security documents available to responsible members of the team (so they can be confident they are taking appropriate actions to mitigate the risks)\n\n**Analytics**\n\n- establish &nbsp;a plan for building capability and training on analytics, user research and other disciplines\n- introduce event tracking to analyse use of the different parts of the service offer (individual’s details, vehicles they can drive and penalties or disqualifications)\n\n**Assisted digital and digital take-up**\n\n- make the telephone number for assisted digital support visible on&nbsp;[GOV.UK](http://gov.uk/) before going live (and test with a subsection of users through A/B testing)\n- conduct further research targeted on assisted digital users who are unable to use or access the online service to confirm that support remains appropriate for when the paper counterpart is abolished (2015)\n- work with GDS assisted digital team to conduct a pilot to test out assisted digital triage and measurement, using the DVLA contact centre\n- feed findings from this research and pilot into other DVLA and wider government services to ensure that the user journey is consistent for assisted digital users\n- continue to work with the GDS Digital Take-up team to draw up a robust plan for realising benefits from the project and reducing the use of traditional channels and assisted digital support year on year\n\n**Next Steps**\n\nThis service has been given approval to go Live as a Digital by Default service.\n\n**Summary**\n\nThis service meets the Digital by Default Service Standard. The work carried out during the alpha and beta centred on users’ needs of the service. The team are developing approaches to build continuous improvement into the service.\n\nThe service assessed here is relatively limited in scope. For the future this service needs to be considered in the wider context of driving licence needs and transactions and should not be developed separately from the share driving record functionality and services meeting other user needs such as change of name or address details. The service will come under increasing pressure from the autumn with the proposed abolition of the paper counterpart of the driving licence, which will make the provision of assisted digital for this group of services ever more important.  \nGiven this, the assessment panel recommend that a full pilot is carried out on assisted digital support to test out AD triage and measurement, using the DVLA contact centre, which will support this group of services. When the Share Driving Record service returns for its beta assessment the panel will expect to see evidence that the pilot has been completed and acted upon.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/register-to-vote-individual-electoral-registration-service-assessment/",
    "title": "Register to Vote (Individual Electoral Registration) – Service Assessment",
    "summary": "Individual Electoral Registration (IER) is part of the wider electoral registration transformation programme being undertaken by the Cabinet Office, aimed at increasing the accuracy of the electoral register.",
    "body": "IER will reform how individuals register to vote. &nbsp;Instead of the ‘head of the household’ supplying the details of all people living at the same address (which can result in fraud and errors), IER will require people to register individually. In line with legislative changes, IER goes live in England and Wales on 10 June 2014, and in Scotland after the referendum on 19 September 2014.\n\nThe IER digital service (IER-DS) allows us to meet the needs of people that arise out of these changes in legislation. &nbsp;IER-DS allows people to submit online applications for the first time ever, as well as mechanisms for verifying details of people on existing electoral registers (46 million) and those that apply online, over the phone and on paper.\n\n[https://www.gov.uk/transformation/register-to-vote](https://www.gov.uk/transformation/register-to-vote)\n\n**Department / Agency:**  \nCO\n\n**Date of Assessment:**  \n21/05/2014\n\n**Moving to:**  \nLive\n\n**Result:**  \nPass\n\n**Lead Assessor:**  \nL. Scott\n\n**Service Manager:**  \nD. Kirsch-Mills\n\n**Digital Leader:**  \nP. Maltby\n\n* * *\n\n## Assessment report\n\nAfter completing the assessment the panel can confirm the Individual Electoral Registration (IER) service has shown sufficient evidence of meeting the Digital by Default Service Standard and should go Live as a Digital by Default service on [GOV.UK](http://gov.uk).\n\nThe team have built a service so good, people should prefer to use it.\n\n**Reasons**\n\nThe service was assessed against and has met all 26 points of the Digital by Default Service Standard.\n\n**User needs**\n\nThe service clearly demonstrated how they have built and developed the service by starting with user needs. Tackling the “no chance for a Beta” blocker with continuous user research with well-identified user groups. Feedback has been sought and input from both end-users of the digital service, and backend users (Electoral Registration Officers, department colleagues).\n\nThe service team gave good examples of how they designed and iterated the service with the needs of users in mind. Collaborating with and contributed to the GDS-wide user centred design community.\n\nThe team has a user-led iteration plan in place, and have reliable sources of user feedback. The Service Manager and Product Manager are responsible for and empowered to take user feedback to a dedicated development team to enable continuous improvement.\n\n**The team**\n\nThe service team is an excellent example of how a multi-disciplinary team, sat together, using agile delivery principles, can design and build a user-focused service quickly and flexibly. There were excellent examples of team collaboration, demonstrating how the whole team are involved in research analysis and story writing, and hence have a real understanding of the context and value of their work.\n\nGDS were encouraged and impressed by the dedication, particularly when challenging legislation to overcome stumbling blocks in the service for users. This is a great example of user-focused service design influencing policy and legislation.\n\nGDS note that there is a phased transition plan in place to hand the service over to a Cabinet Office team later in 2014. GDS would urge that the expertise and understanding the current service team has accrued is thoroughly handed over to the new team.\n\n**Security, Privacy, Tools and Standards**\n\nThe service team demonstrated a thorough understanding of and commitment to Data Protection laws, and have thought carefully and conducted research around handling the question about inclusion on the Open Register.\n\nThe service is using Open Source throughout, restricting SaaS to peripheral features, eg GitHub for code control, and can switch suppliers easily. As the service is seasonal, agreements are in place so the service can scale up and down easily, saving money in periods of low usage.\n\nThere are plans to open up the code once the service is Live. The assessment panel were very pleased to hear you're moving non-sensitive source code into a public repository. The team is building a cross-government platform for address lookups which will be very useful. There are multiple environments, and have tested across multiple browsers and devices (determined by stats), either physically or using emulation. The service is designed ‘mobile-first’.\n\nThe service team has tested resilience and worked out plans for ‘worst case scenarios’, particularly during the 3-week lead time before a general election. Bandwidth issues have been addressed and the service has flexible operational support contracts in place.\n\nThe service team has detailed plans in place for various gradations of failure of the digital service. During the assessment the service manager explained how the service could be deployed elsewhere, or a fallback to the current manual system could be employed in the case of extreme emergency.\n\nThe service has a flexible deployment process allowing for very frequent deploys if needed. Current estimates for a fix to live are in under an hour without the need for downtime releases.\n\n**Design**\n\nTo compensate for no Beta, the service team have carried out intensive user research over the last 6 months, focusing on reluctant or less confident users. The research (allowing for the slight bias of moderated research) gave the panel confidence that this service is so intuitive that users will succeed first time. The inline help text was thoroughly researched and tested, helping people move through the service. The panel particularly liked the approach to this - only adding Help where research had indicated it was useful. The intention is to take it away if stats show few people are using it.\n\nThe assessment panel was really impressed with the efforts around the non-digital aspects of the service, constrained currently by legislation dictating provision of the paper form. The service team have gone to extra lengths to work with partners on calls to action to encourage takeup of the digital service, collaborating with other service teams facing similar issues.\n\nThe benefits of having a content designer and designer embedded in the service team are demonstrable by the quality of the copy and design, and adherence to the GDS Style Guide and Design Patterns Toolkit.\n\n**Analysis and Benchmarking**\n\nThe service showed expert knowledge of setting KPIs and interpreting data, especially around completion rates and successful journeys. Currently the service is collecting its own analytics, the panel speculated if it was an option to remove Google Analytics if any privacy concerns made this something to seriously consider. The team is collaborating with GDS on the Performance Platform dashboard, start and done page, and the user satisfaction survey.\n\nThe service team has plans for increasing digital takeup, currently predicted to start at ~60%. GDS acknowledge the complexity in determining a cost-per-transaction, and the lack of a comparable current service, making any benchmarks somewhat arbitrary. However the panel encourage the team to work with the GDS Analytics team to determine some figures, detailed in the recommendations section below.\n\n**Assisted Digital and Channel Shift**\n\nThe service team has worked with the Electoral Commission to turn the aboutmyvote website into a resource for local authorities, with relevant public user needs met on GOV.UK.\n\nDespite legislative restrictions, the service team and the Cabinet Office have put in place comprehensive assisted digital support for this service through a broad range of 3rd party providers, in line with GDS guidance. The team have briefed and trained providers, who are expected to have more time for assisted digital due to the new digital service.\n\n**Recommendations**\n\n**1. Closely monitor plans for Assisted Digital (AD) delivery of this service.**\n\nThe Assisted Digital service has not been tested, as the digital service could not be fully tested during Beta (by law). The panel recommend that assisted digital provision is closely monitored in the early stages of Live and iterated if it is found not to meet user needs.\n\nAs an exemplar, the service must work with the GDS Assisted Digital team as the cross-government model for assisted digital support is developed, to share their best practice and ensure that the service’s provision remains consistent with the government standard.\n\n**2. Gauge the current satisfaction rate with the current, offline, register to vote service.**\n\nGDS understands the concerns that any comparison of completion rate would be comparing different policies. However, a more detailed look at current completions may give a benchmark for similar issues that may arise with the new service. GDS note the service teams concerns about surfacing value without context. Work could be done to ascertain current baseline costs and projected ones dictated by paths through the new version. The GDS Analytics team would be happy to advise on this.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/patent-renewals-service-assessment/",
    "title": "Patent Renewals – Service Assessment",
    "summary": "The patent renewal service allows customers to pay for renewal of their patent online. &nbsp;The service has in-built validation: If the patent is renewable, the service will return patent details for the number entered, together with the renewal fee due. If the patent is not renewable an appropriate error message is given.  \n[https://www.gov.uk/transformation/renew-patent](https://www.gov.uk/transformation/renew-patent)",
    "body": "**Department / Agency:**  \nBIS / IPO\n\n**Date of Assessment:**  \n16/5/2014\n\n**Moving to:**  \nLive\n\n**Result:**  \nPass\n\n**Lead Assessor:**  \nB. Andrews\n\n**Service Manager:**  \nG. Court\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## **Assessment report**\n\nThe Patent Renewal service is seeking permission to be branded a Live Digital by Default service on the&nbsp;[service.gov.uk](http://service.gov.uk/) domain.\n\n### **Outcome of service assessment**\n\nAfter completing our assessment GDS can confirm the Patent Renewal service has shown sufficient evidence of meeting the Digital by Default Service Standard and should go Live as a Digital by Default service on&nbsp;[GOV.UK](http://gov.uk/). The service can now remove any Beta branding.\n\n### **Reasons**\n\nThe service was assessed against and has met all 26 points of the Digital by Default Service Standard.\n\nThe team demonstrate good user research practices. They've conducted user research with all their user groups, and are using this insight to shape their service.\n\nThey have access to call centre data, and paper renewals to act as a benchmark for the online service.\n\nThe service provided evidence that AD user research was undertaken, that the service understands their users needs and that appropriate channels are available for people who are unable to use the digital service independently, including the potential for face to face support at several locations across the UK.\n\nThey achieved a good reduction in cost per transaction when compared to the paper based service.\n\n### **Recommendations**\n\n- The service should work more closely with the patent libraries to ensure that face to face provision of assisted digital is in line with GDS guidance in the Service Manual. This should include an element of digital inclusion and a mechanism for gathering feedback and monitoring user satisfaction.\n- The service should continue to monitor and be prepared for a potential increase in assisted digital users if / when the paper channel is withdrawn completely.\n- The service should continue to work with the GDS assisted digital team as the cross-government model for assisted digital support is developed, to share best practice and ensure that provision remains consistent with the government standard.\n- There are some design and content issues which mean the service is less simple and intuitive than it could be. These issues should be addressed at the earliest opportunity and GDS will share some detailed recommendations on how to fix these issues.\n- As discussed in the assessment the service should enhance its current analytics package in the next few weeks, so that this will allow them to map the user journey more effectively. This includes tracking how many people reach certain parts of the form, and differentiating between users who exit or click on an external link. This is necessary to give the team the more granular view of their service to identify problems, and determine whether changes made as a result of user research insights have the desired effect.\n- As part of its IT Infrastructure Roadmap or within 6 months, the IPO should introduce a new analytics package for patent renewals producing data required by the performance platform, and comply with Service Standard guidance.\n- The service manager should provide GDS with a url for their github repository.\n\n### **Next Steps**\n\nThis service has been given approval to go Live as a Digital by Default service.\n\n&nbsp;"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/lasting-power-of-attorney-service-assessment/",
    "title": "Lasting Power of Attorney – Service Assessment",
    "summary": "The service is aiming to make it simpler and faster to apply for a lasting power of attorney by guiding users through the service.  \n[https://www.gov.uk/transformation/lasting-power-of-attorney](https://www.gov.uk/transformation/lasting-power-of-attorney)",
    "body": "**Department / Agency:**  \nMOJ / Office of the Public Guardian\n\n**Date of Assessment:**  \n28/4/2014\n\n**Moving to:**  \nLive\n\n**Result:**  \nPass\n\n**Lead Assessor:**  \nM. Sheldon\n\n**Service Manager:**  \nK. Collingwood-Richardson\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## **Assessment report**\n\nThe lasting power of attorney service is seeking permission to be branded a live Digital by Default service on the&nbsp;[service.gov.uk](http://service.gov.uk/) domain.\n\n### **Outcome of service assessment**\n\nAfter completing our assessment GDS can confirm that the service has shown sufficient evidence of meeting the Digital by Default Service Standard and can go live as a Digital by Default service on&nbsp;[GOV.UK](http://gov.uk/)&nbsp;when the final preparations the lasting power of attorney team discussed with us are complete.\n\n### **Reasons**\n\nThe service was assessed against and has met all 26 points of the Digital by Default Service Standard.\n\nThe lasting power of attorney service team have shown that they are:\n\n- researching and understanding the users' needs of the service. Improving it based on evidence and making decisions informed by data.\n- clearly and concisely capturing user needs and prioritising, developing and improving them based on feedback from user testing.\n- a skilled multi-disciplinary team working in an agile way. Using appropriate methodologies, tools, techniques and processes to deliver working software early and often.\n- working with the CLAS consultant, IAO and SIRO to assess the associated risks and legal responsibilities around the data held.\n- using an appropriate amount of security to not degrade the service experience for its users.\n- choosing the right tools and systems on which to host and operate the service.\n- putting automated processes in place for scaling the service and responding to incidents.\n- using many environments to allow full end-to-end testing of the service.\n- planning to allow the release of improvements to the service on a daily basis.\n- making source code open and reusable, publishing, sharing and reusing it with other departments. The team provided convincing evidence on why some source code is not open; eg authentication libraries. They were also able to provide evidence of how they will continue to review that position.\n- collecting, measuring and analysing performance data to help make improvements to the service.\n- benchmarking and comparing the performance data to the paper based service.\n- concentrating on the KPIs of the standard and reporting these through the Performance Platform. The service has many states of \"done\", completed over a longer than usual period of time and requires \"wet signatures\". The team are working with GDS to measure the correct completion rate and with wider government to change legislation.\n- working with 3 external partners to offer assisted digital support, either by phone or in person.\n- planning for market and channel shift and working with intermediaries to promote the service.\n\nGDS were particularly pleased to hear about the way the team is working when not co-located. With the Product Owner spending the majority of her time with the contact centre, collecting and collating feedback from users. Then using video chat, instant messaging and group collaboration tools to remain in contact with the wider team.\n\nThe Service Manager and Product Manager have the correct division of responsibilities. The Service Manager is senior, skilled and empowered to make decisions within Office of the Public Guardian that allow the service and team to improve. She removes blockers where necessary and shields the team from any outside influence. The Product Owner for the service has day-to-day responsibility for leading the team. She can make product decisions without the need for approval by the service manager or senior management. This division gives the product team the autonomy and space to self-organise so that they can focus on delivering a service so good that users will prefer to use it.\n\n### **Recommendations**\n\nGDS recommend that the service team:\n\n- concentrate on filling the skills gaps identified in the team as soon as possible. These were:\n  - Digital analyst\n  - Designer\n  - User researcher\n- continue risk assessment of potential attack vectors and address them with appropriate security measures.\n- continue improving tooling and automation once the planned move to the new hosting provider is complete. Take full advantage of the benefits of their offering, over the current provider’s offering.\n- work with GDS to help showcase their code around wider government.\n- review the risks identified that informed the decisions to not release all source code.\n- ensure that any publicly offered APIs are consistent with developing standards.\n- improve the layout and presentation of the service emails to aid readability.\n- continue reviewing and improving the design patterns used throughout the service. The lack of a designer in the team has introduced minor inconsistencies and design stagnation since the previous assessment.\n- put a plan in place to allow A/B and multivariate testing using the govuk\\_frontend\\_toolkit.\n- upgrade to Google Analytics Universal Analytics tracking code, use IP anonymisation and use goals and funnels to model user journeys.\n- work with the Performance Platform team to collect user satisfaction and feedback at the right points throughout the service.\n- work with the&nbsp;[GOV.UK](http://gov.uk/) Content team to improve the current service start page on&nbsp;[GOV.UK](http://gov.uk/).\n- test the live service with the current minister, Simon Hughes.\n- ensure the&nbsp;assisted digital support is sustainable following the expiry of the agreed pilot with the 3 external partners\n\n### **Next Steps**\n\nThis service has been given approval to go live as a Digital by Default service.\n\n### **Summary**\n\nIn summary GDS are pleased to report that the service meets the Digital by Default Service Standard. The work carried out during the alpha and beta started with the users' needs of the service. The team already have a plan in place to run regular user research of the live service and measure its performance so that it can be improved further."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/report-an-immigration-or-smuggling-crime-service-assessment/",
    "title": "Report an Immigration or Smuggling Crime - Service Assessment",
    "summary": "The Report an Immigration or Smuggling Crime service allows for the public to submit information about foreign nationals working or living illegally in the UK or any kind of smuggling.",
    "body": "**Department / Agency:**  \nHO\n\n**Date of Assessment:**  \n23/04/2014\n\n**Assessment Stage:**  \nLive assessment\n\n**Result of Assessment:**  \nNot passed\n\n**Lead Assessor:**  \nN. Chowdhury\n\n**Service Manager:**  \nD. Pennant\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## Assessment report\n\nThe Report an Immigration or Smuggling Crime service is seeking permission to be branded a Live Digital by Default service on theservice.gov.uk domain.\n\n**Outcome of service assessment**\n\nAfter completing our assessment GDS has concluded the service should not be given approval to launch on aservice.gov.uk domain as a Live Digital by Default service.\n\nGDS were pleased to see significant progress has been made since the first assessment with regards to putting users first and undertaking user research. However, there are a number of areas which need to be addressed in order for the service to meet the criteria for becoming a Live Digital by Default service.\n\n**Reasons**\n\n- In the assessment it was unclear who was undertaking the duties of thedefined service manager role as knowledge and responsibility seemed to be shared across a number of people. Also, requirements for development appear to be agreed at project board level and as a panel, we were uncertain on whether there was flexibility for requirements to be approved outside of this process.\n- The service has no interaction design/content design support, or access to an in-house user researcher. GDS were not assured how the current team would be able to design/test/code quickly without this support being in place, particularly for a Live service.\n- There are no digital analytics in place to measure the service, therefore it will be difficult to see how the service is performing and iterate based on data. The current version of this service has not gone through a Beta phase so only a small sample of users have tested the service so far.\n- It was encouraging to see the work to enhance the current telephone service and the commitment to assisted digital support. For the service to move to Live, the service manager will need to provide evidence of assisted digital user research. This involves demonstrating an understanding of who the assisted digital users are, including the demographic and the barriers they face in accessing the digital service.\n- Running the service requires co-ordination of 8 different suppliers, with the technical stack either completely proprietary or run entirely by suppliers. This makes it difficult to make quick changes or improvements to the service in an agile way.\n\n**Recommendations**\n\nGDS recommends the service team focuses on designing the service for reassessment targeting a Beta launch, with the plan to go for a Live assessment by the end of the year. This approach will enable more users to go through the service and give the team time to work through other recommendations.\n\nService manager and service team:\n\n- Ensure the service manager has good knowledge of end-to-end operations and is suitably empowered to decide and prioritise requirements. This role should be able to take the lead in responding and providing evidence in service assessments.\n- The service should immediately seek to supplement their current team efforts by establishing routine input from an Interaction Designer, Content Designer and User researcher. This is key for improving user experience of the service and ensuring the service can be iterated, based on user needs.\n- The interaction designer should focus on the form format and style (form field length, readability, etc). The content designer should review the form copy and ensure it is clear and easy to understand. Both roles should be basing decisions on regular user research sessions and analytics data.\n\nWorking with suppliers:\n\n- Consider the relationship with your supplier and see if they can co-locate developers for you (to our knowledge one of your current suppliers do offer this service). It will improve your ability to test with users and develop in an agile way.\n- The service manager must be fully aware of the contingency plans and methods used by your supplier to run your service, particularly with regard to disaster recovery or the ability to react to denial of service type attacks. The detail of their ability to do so should be part of the procurement and tender process, and their operational capacity and ability should be part of the way you consider potential suppliers.\n\nAnalytics and KPIs:\n\n- The service team should talk to the GDS Product Analytics team for advice on sourcing an alternative to analytics package for their service. Analytics across the service will need to be in place before the service launches as a Beta.\n- Data on how your service is performing, including the 4 core KPIs, will need to be available on the Performance Platform.\n\nAssisted digital:\n\n- Undertake research to establish who their assisted digital users are and test their channels with real assisted digital users.\n- Establish a means to measure the assisted digital service and to gather feedback in order to iterate their assisted digital support offer.\n\n**Summary**\n\nThe Report an Immigration or Smuggling Crime service development sits upon a complex structure consisting of a number of suppliers, working to a pre-established delivery plan. It is very encouraging to see the efforts the in-house team have made so far to align with the development methods outlined in the service standard. GDS recommends the team continues this approach by working towards a Beta as the ‘next step’ of this service development. GDS also encourages the Home Office to consider how they can ensure the team has the full complement of roles and support required to design the service through to Beta and Live.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | No | 6 | Yes |\n| 7 | No | 8 | Yes |\n| 9 | No | 10 | No |\n| 11 | No | 12 | N/A |\n| 13 | No | 14 | No |\n| 15 | N/A | 16 | No |\n| 17 | Yes | 18 | No |\n| 19 | Yes | 20 | No |\n| 21 | No | 22 | No |\n| 23 | No | 24 | No |\n| 25 | No | 26 | No |\n\n| **Details of criteria that are not applicable to this service** |\n| 12 - there are no non-digital steps to this service  \n15 - software is proprietary and off-the-shelf, there is little benefit in sharing the front (HTML) code |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/national-archives-discovery-voluntary-service-assessment/",
    "title": "National Archives Discovery - Voluntary Service Assessment",
    "summary": "Discovery is The National Archives' catalogue, providing a way to explore our collections and - where available - download digital copies of our records. Discovery has been designed to host, search and display the many different databases and datasets held at The National Archives.  \n[http://discovery.nationalarchives.gov.uk/](http://discovery.nationalarchives.gov.uk/)",
    "body": "Currently at Beta stage with the next version of Discovery, working on integrating a further 5 digital services.&nbsp;[http://beta.discovery.nationalarchives.gov.uk/](http://beta.discovery.nationalarchives.gov.uk/)\n\n**Department / Agency:**  \nMoJ / National Archives\n\n**Date of Assessment:**  \n22/04/2014\n\n**Assessment Stage:**  \nLive assessment\n\n**Result of Assessment:**  \nPassed\n\n**Lead Assessor:**  \nP. Ferris\n\n**Service Manager:**  \nE. Bayne\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\nThe National Archives Discovery service is not considered within the remit of the Digital by Default Service Standard, however the service team wanted to ensure they were aligned to it. The voluntary assessment was completed in the same way any assessment held by GDS would be, with a panel of assessors representing the different disciplines at GDS.\n\n* * *\n\n## Assessment report\n\nThe National Archives (TNA) Discovery beta was reviewed against the Digital by Default Service Standard and the service is proposed to go Live during Summer 2014. This was a voluntary assessment against the standard as TNA is outside the remit of GOV.UK.\n\nThe presentation was strong and demonstrated a clear understanding of what the business aim was. There was a clear understanding of the 26 points of the standard, other services should aspire to comprehend and apply this into their development. GDS was very impressed with the passion across the whole team to deliver the new Discovery service.\n\n**Does the service meet user needs?**\n\nTNA has a number of mechanisms in place for gathering user data (surveys, focus groups, analytics, paid user feedback etc.) and this was used to inform the programme of changes currently underway. &nbsp;We noted a slight bias to focus on your specialist user groups, the service dealt with over 350,000 visits per month (over 4 million annually). Feedback mechanisms are used to support your decision making around changes this includes a plan to remove the 'browse’ option from your homepage as less than 5% of users accessed the service this way.\n\nThe panel noted that TNA tended to operate this as a bi-monthly user feedback opportunity, rather than approaching user groups each time a new product/process was proposed. The panel considered the largest challenge facing your service was search and usability and how your users would navigate to the content they needed on the site. From our use of the service in preparation for this review, we found common journeys can be complex, with significant use of filtering needed.\n\nAccess to an onsite user research team was excellent. The panel felt that you had a good understanding of your product, the needs it was intended to meet and were planning iteratively to continue your development towards this.\n\nRecommendation: consider increasing your user feedback opportunities to align with product releases to gain faster insight on success and operate to fail fast principles.\n\n**Can the service be iteratively improved?**\n\nCriteria 6 of the Service Standard insists services use of Agile methodologies for the quick, cost effective delivery of user-centred digital projects. TNA does use a mixture of agile methodology and Kanban and has separated out its business as usual processes from this. There are regular retrospective processes and the learning from these inform future sprints. TNA also works towards the principle of a high level three-weekly release cycle, rather than an ongoing release process and was working towards a stable system where you could deploy every day which is in line with agile methods of delivery. The panel suggested you could streamline your processes to use the same systems for tracking work and suggested that Kanban was a strong tool for managing business as usual tracking.\n\nTNA have a separated User Insight team that it recognises moves to a rapid prototypes position faster than the digital team but, this was known and accounted for within working arrangements. The team set up by TNA to deliver the project was focused and in place with the Service Manager supporting delivery being a strong element. A significant amount of knowledge was demonstrated by the Service Manager on the overall product and deeper technical knowledge.\n\nRecommendation: consider the opportunity to align processes to be the same across ' business as usual ' and project delivery.\n\n**Is the service safe?**\n\nTNA spoke briefly about security risks and the need to protect user data. &nbsp;In particular, TNA goes through an annual penetration test and there is a process in place to acquire SIRO sign-off for the use of non-standard data. TNA were very aware of wider reputational risk and also operated a high level of informal internal testing. TNA had an agile privacy impact assessment and worked closely with their department security officer. In terms of a denial of service attack TNA were confident about taking their processes and have a mirror site in place.\n\nTNA spoke about its 3-tier technical stack which utilised Mongodb (because its open), Solr, Net WCF and Mongo Management capsule. &nbsp;It also advised that TNA hosted onsite as it had the facilities to achieve this, although, it was looking at some cloud-related use opportunities. In terms of open code TNA had released some to Github as part of an open approach but, noted that its use was specialist and almost bespoke in terms of statutory and legislative response and unlikely to be of significant benefit to many other organisations. TNA also uses an open API for data. TNA operate a test environment with full scripting for end-to-end testing and use a browser stack testing system to check accessibility for devices.\n\nTNA have a clear disaster recovery plan in place and have the ability to rebuild its entire product as part of this. The service was also aware of GovCert reporting requirements and have a clear rota of staff as part of disaster response and management. Data backups are completed on a regular basis and there is an offsite data system arrangement in place.\n\n**Design**\n\nTNA used a conversion funnel to test design and this has resulted in achieving improvements on customer dropout rates demonstrating customers are now successfully buying records. Design and filtering systems are in place to assist users to filter to their specific need (e.g. academic s/journalist) and TNA demonstrated a good understanding of its niche audience needs. The products offered are a mix of online and offline and this will remain the case going forward , although significant growth of the online aspect is anticipated. Future design improvements proposed include order tracking. TNA recognise that its mobile device audience was growing at a great pace. TNA are exempt from GOV.UK and therefore th e website was not built to the same design, TNA have published its own patter n s on GitHub. Some of the wording demonstrated was known to be confusing and was currently under consideration.\n\nRecommendation: consider speaking to the GDS Content Team on language issues and recommendations to help with challenges faced by TNA.\n\n**Analysis**\n\nTNA have a mature well developed digital analytics implementation. They use webtrends and have shown that they have a good data culture of using a mix of actionable analytics data, along with user research to drive improvements. The analytics implementation has been approved by their SIRO and they do not collect any personal data.\n\nRecommendation: TNA demonstrate their innovative webtrends dashboards at a future GDS Show & Tell as a learning opportunity for the GDS and government digital analytics community .\n\n**Assisted Digital**\n\nTNA understood the need for assisted digital and provided a variety of channels to access assisted digital support to access its services, The service has a longer term plan to increase digital channel use particularly in relation to viewing its most popular collections.\n\nRecommendation: consider speaking to the GDS Assisted Digital Team on this area when at a stage to look at more opportunities.\n\n**Summary**\n\nThe assessment panel very much enjoyed hearing about this important and fascinating service and it adherence to the service standard, this is a challenge to other government services to reach the same level of quality and user focus.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | N/A | 8 | Yes |\n| 9 | Yes | 10 | N/A |\n| 11 | Yes | 12 | Yes |\n| 13 | N/A | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | N/A | 22 | N/A |\n| 23 | N/A | 24 | N/A |\n| 25 | Yes | 26 | Yes |\n\n| **Details of criteria that are not applicable to this service** |\n| 10 - broadly the plan to provide Assisted Digital support was appropriate for the service  \n13 - this service does not sit on GOV.UK, however much of the design and content are aligned  \n21 to 24 - the service is not obliged to publish data to the performance platform, the service is considering the possibility in publishing relevant data |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/the-queens-awards-for-enterprise-self-certification-2/",
    "title": "The Queen's Awards for Enterprise - Self Certification",
    "summary": "The Queen’s Awards for Enterprise is a replacement service for an existing 100% digital service that enables UK businesses, including those based in the Channel Islands and the Isle of Man, to apply for a corporate award recognising their outstanding achievement in:",
    "body": "- Innovation\n- International Trade\n- Sustainable Development\n\nThere is also an award for individuals, The Queen’s Award for Enterprise Promotion, which individuals are nominated for to recognise their outstanding role in promoting the growth of business enterprise and/or entrepreneurial skills in others.\n\nThe Queen’s Awards for Enterprise competition is run annually and applications and nominations can be made from April to September. Following this, entrants are assessed and shortlisted, with recommendations made by the Prime Minister’s Advisory Committee. Winners are decided by Her Majesty the Queen and announced each April.\n\n**Department / Agency:**  \nBIS\n\n**Date of Assessment:**  \n1/4/2015\n\n**Assessment Stage:**  \nBeta\n\n**Lead Assessor:**  \nJ. Jones\n\n**Service Manager:**  \nL.&nbsp;Stephens\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## Assessors Summary\n\nAfter consideration the assessment panel have concluded that the service has sufficiently met the Digital by Default Service Standard to launch as a Beta service.\n\nThe panel recognise that the service is low volume, expecting around 500 applications to be made during the time limited period of April to September 2015.\n\nThe panel was impressed by the service team’s thorough preparation and their presentation, and by the progress made since the alpha assessment in December.\n\nParticular areas of strong performance against the standard included:\n\n- Frequent and ongoing user research, testing used to good effect to improve the service, and examples given of how this has challenged and changed the design. For example, inclusion of the eligibility checker at the start of the application, the option to include a collaborator and the ability of users to edit applications, even those submitted, right up to the deadline.\n- Use of open standards and open source code; the team have made use of open source code and contributed their own.\n- Collaborative working across the team and different locations (using Podio).\n- Although not a mobile first service, the service is responsive, and BrowserStack has been used to test on a variety of devices (Blackberry to be investigated).\n- Substantial development in the areas of data analytics and performance analytics, with robust plans for use of the Performance Platform.\n\nHowever, the panel also identified a number of areas for further development:\n\n- Content requires further review to ensure it is clear and succinct, and that terminology is easily understood by the user. For example, the consent and declaration appears very text heavy and consideration should be given to shortening this section. More use of collapsible text should also be considered.\n- Confirm with the Data Protection Officer the sensitivity of the personal data held.\n- Service Manager to further develop her skills and experience by completing the GDS training course, and to consider more widely promoting the service through show and tells as there is a good story to tell.\n- Further consideration should be given to how identity assurance might be incorporated into the application process rather than later at the assessment stage, and how sharing of data could further remove some current process steps.\n- Consider further how changes will be made during beta, and work with BIS and GDS to develop a plan for progression to Live, given that the end-to-end service (application and assessment) will not be completed until April 2016.\n- Develop a more formal process / journey for assisted digital.\n\nIn particular the following should be completed prior to beta launch:\n\n- Review guidance on cookie policy and ensure compliance.\n- Carry out additional penetration on receipt of SSL certification.\n- Finalise GOV.UK start and end pages.\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | N/A |\n\n| **Details of criteria that are not applicable to this service** |\n| 26 - not applicable to service with fewer than 100k transactions p.a. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/centre-for-defence-enterprise-portal/",
    "title": "Centre for Defence Enterprise Portal - Self Certification",
    "summary": "An online portal which allows organisations and individuals to submit science and technology innovations and proposals to MOD (in response to specific competitions or general invitations) and for these bids to be assessed by MOD subject matter experts.",
    "body": "**Department / Agency:**  \nMOD\n\n**Date of Assessment:**  \n27/8/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nR. Riley\n\n**Service Manager:**  \nD. Hazleton\n\n**Digital Leader:**  \nM. Stone\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration, the assessment panel have concluded that the Centre for Defence Enterprise Portal service is on track to meet the Digital Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service currently meets the requirements of the standard for an alpha service. Areas of good performance against the standard included:\n\n_User needs and assisted digital_\n\n- Strong understanding of users and their needs, extensive programme of research including significant face-to-face element.\n- Good understanding of user devices/behaviours and assisted digital needs.\n\n_Security, privacy, tools and standards_\n\n- Understood that applicants' intellectual property was the key asset that needs to be protected.\n\n_Design_\n\n- Following GOV.UK pattern.\n\n**Recommendations**\n\n_User needs and assisted digital_\n\n- Review what similar needs are being met on GOV.UK and learn from these.\n\n_The team_\n\n- Need succession planning for key team roles.\n- Will likely need dedicated sysadmin role as project moves to live.\n\n_Security, privacy, tools and standards_\n\n- Threat modelling needs to be more rigorous. May need more specialist knowledge on security threats.\n- Don’t be complacent on choice of tools; consider different tools during move to  \nbeta.\n- Need to look into static analysis, and improved automated testing.\n\n_Improving the service_\n\n- Need to flesh out the plan for outages more before moving to live phases.\n- Look at end-to-end testing (e.g. Cucumber).\n- Need to consider test coverage reporting (e.g. X% of the codebase is covered by tests) and static analysis / code-quality metrics (e.g. CodeClimate).\n\n_Open source_\n\n- Project needs a clearer plan of what code will be released and when.\n\n_Design_\n\n- Will need to review pinch points of failure as prototype is developed.\n\n_Analysis and benchmarking_\n\n- Need to be on top of server metrics - the beta phase should include visibility and alerting on server performance & metrics, as well as business key performance indicators (KPIs).\n- Must complete registration asap with Performance Platform.\n\n_Hosting_\n\n- Need to resolve hosting provision.\n- Solicit opinions from other government teams on their proposed options for hosting.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/view-vehicle-record-service-for-fleet-companies-self-certification/",
    "title": "View Vehicle Record Service for Fleet Companies - Self Certification",
    "summary": "The View Vehicle Record Service for Fleet Companies is a digital service that provides information to DVLA registered fleet operators about the vehicles they are responsible for. The operators will be able to see the information contained on the vehicle’s V5C documents (vehicle log books) as well as the current tax and MOT status of the vehicles. The service is aimed at fleet operators that have between 50 and 650,000 vehicles registered with the DVLA.",
    "body": "The service forms part of the DVLA’s Red Tape Challenge commitment to stop issuing V5C documents to fleet operators by allowing them to view this information online rather than securely storing many paper documents. The View Vehicle Record service will allow fleet companies which have opted-in to not receive V5C documents to request individual documents where required.\n\n**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n24/2/2015\n\n**Assessment Stage:**  \nbeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nD. Vaughan\n\n**Service Manager:**  \nR. Gye\n\n**Digital Leader:**  \nO. Morley\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter completing the self certification assessment, the assessment panel is happy to recommend to the Digital Leader that this service is given approval to continue launch as a public beta service.\n\n**Reasons**\n\nThe service was assessed against all 26 points of the Digital by Default Service Standard and the panel were particularly impressed with:\n\n- The service manager and product owner showed a good understanding of the needs of the users within the different types and sizes of fleet companies and in particular the data they required from the V5C documents.\n- The service team has conducted user research with a large number of fleet companies during the alpha and beta stages.\n- The team is running a private beta with 13 fleet companies to gather feedback and identify further improvements.\n- The team has the ability to make changes to the service quickly and can deploy updates regularly. The team has also reused a number of components built for the View Driving Licence service.\n- Since alpha, the team have worked to build in the ability for fleet companies to request a physical V5C document when needed. This is being integrated with the DVLA legacy technology estate.\n\n**Recommendations**\n\nThe panel noted the following recommendations. The team should:\n\n- Continue regular user research with fleet company staff using real data.\n- Further investigate the potential user need to provide the data to fleet companies via an API.\n- Investigate whether the service can be better integrated with other digital services. For example, passing users directly into the Vehicle Tax service.\n- Look to re-use the email sending service built for the Vehicle Management and Personalised Registrations projects instead of operating it’s own email service.\n- Continue to work with the GDS Performance Platform team to ensure performance data from the service is published and appropriate Key Performance Indicators (KPIs) are measured.\n- Ensure the service has evaluated all the risks around privacy and security given the service allows access to vehicle keeper information.\n\n**Summary**\n\nIn summary, the assessment panel are pleased with the progress of the service. The work carried out since the alpha assessment to improve the service is very encouraging and the panel looks forward to seeing the service improve as it is opened up to more fleet companies.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | N/A |\n\n| **Details of criteria that are not applicable to this service** |\n| Criteria 26 – the service will be tested with the minister during the beta phase. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/the-innovation-funding-service-self-certification/",
    "title": "The Innovation Funding Service - Self Certification",
    "summary": "Innovate UK provides funding via a range of funding mechanisms; the largest of which focuses on attracting applications for collaborative research and development (CR&D) projects from business led consortiums.",
    "body": "The Innovation Funding Service will initially replace the current CR&D service enabling business led consortiums to apply for public sector funding. All Innovate UK services will subsequently transition to the new service.\n\nThe Innovation Funding Service covers the end-to-end service:\n\n- Businesses applying for funding under a themed competition.\n- Independent assessment of application by sector experts.\n- Due diligence by Innovate UK staff and if appropriate, grant award.\n- The monitoring of live projects and payment.\n\n**Department / Agency:**  \nBIS / Innovate UK\n\n**Date of Assessment:**  \n8/10/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nA. Jackson\n\n**Service Manager:**  \nS. Vodden\n\n**Digital Leader:**  \nE. Stace\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nThe panel previously assessed the service in April 2015 and at this time concluded that the service was not yet ready to move to the beta stage.\n\nThe panel were impressed by the progress made since this assessment and conclude that the service now meets the alpha service standard.\n\n**Reasons**\n\nThe team had clearly prepared for the assessment and the panel were impressed by both the pre-assessment briefing and the presentation during the assessment itself.\n\nThe Innovation Funding Service agile team have built an excellent alpha service using a wide range of open source tools which can be taken through to the beta stage.\n\nThe panel were particularly impressed by:\n\n- A strong co-located team working collaboratively, self-organising and fully supported by the service manager.\n- The service manager clearly owns the service and exhibits all the behaviours required in such a role.\n- The delivery manager, technical architect and user researcher representing the team were clearly competent in their specialist areas, able to provide considerable evidence across the service standard.\n- Evidence was also presented of the wider business areas of Innovate UK being engaged in the planned transformation.\n- The panel were impressed by the wide ranging iteration and improvement made based on user research and user testing with the different user types.\n- Since the first assessment, the design has been greatly improved - more clear and simple - and usability testing and iteration of some features will continue during the beta.\n- The team’s research approach recognised the complexity of gathering the needs of all relevant sectors for example business users with different roles within a company.\n- It was good see that the architecture had been considered from the enterprise viewpoint ensuring loose coupling of services which should make future integrations easier, for example plugging in the GDS notify platform. The team should continue to keep in view the development of common government platforms and how these could be deployed for this service.\n\n**Recommendations**\n\nThe panel have the following recommendations to be progressed during the beta phase:\n\n- Introduction of a web analytic tool as soon as possible for user journey start points, as this will provide another source of user analytics.\n- The assisted digital procedures need to be reviewed and tested with identified assisted digital users. It would be good to see analytics performed around expected numbers in each of the defined user groups.\n- To penetration test the service and support model early in the beta phase to ensure any identified risks can be understood and considered in the design and coding rather than becoming an add-on at the end.\n- As the service has been designed responsively, the panel suggest the use of automated test tools to test a range of browsers and devices rather than the manual approach adopted in alpha.\n- Consideration should also be given to retention of knowledge, given the changes in the beta team and to smooth the transition for any future churn in resources.\n- To continue to research the user needs and user experience, particularly for the finance user within larger companies.\n- To continue to develop the service in line with the GOV.UK style guide and test the design with users. The panel observed that the difference between “my applications” and “my projects” in the dashboard may not be clear to the user; the meaning of the flag and timer icons may not be obvious; and the format of the deadline and time left infographics may need to be further iterated.\n- Whilst the team had initiated engagement with the GDS Performance Platform team, further discussions should be progressed in order to ensure a dashboard is ready for the launch of the service, with a clear understanding of all available data and how this will be used to monitor and improve the end-to-end service.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/extractives-reporting-file-and-search-self-certification/",
    "title": "Extractives Reporting – File and Search - Self Certification",
    "summary": "This is a new service to allow companies in the extractives industries (e.g. oil, coal) to file reports to meet the legal obligations under the Reports on Payments to Government Regulations 2014. The service will also include a search facility to enable interested parties such as the Civil Society and media to access the information. Publishing of information will increase transparency around the extractives industry. Data will also be available to intermediaries via an API.",
    "body": "**Department / Agency:**  \nBIS / Companies House\n\n**Date of Assessment:**  \n23/9/2015\n\n**Assessment Stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nP. Turner\n\n**Service Manager:**  \nP. Reynolds\n\n**Digital Leader:**  \nE. Stace\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded that the service has passed the service standard at this early stage of development.\n\n**Reasons and recommendations**\n\nThis is a small niche service with a limited number of users. There are 184 known registered entities which will be required to file. It has been developed in parallel with legislative changes which means that there is a degree of uncertainty around the final design e.g. the definition of non-registered entities, (companies working in partnership) that may be required to file.\n\nThe service manager and team demonstrated clear evidence against the service standard with particular areas of note including:\n\n- Good engagement with industries and civil society to develop the schema and service design.\n- Strong evidence of agile working practices e.g. changes to stand up and show & tells to better meet the team and stakeholder needs; co­location of team; clear sprint planning; retrospectives; collaborative tools (JIRA).\n- Strong evidence of visual management e.g. Kanban, visibility of personas.\n- Good evidence of iterative development from early prototypes to the current alpha version evolved through 8 iterations.\n- Open source technical solutions with the potential to repurpose.\n- Pragmatic use of existing Companies House technical infrastructure and tools (e.g. payment and ID authentication) providing assurance and resilience.\n\nAreas for particular focus in the beta phase, recognising the service needs to be publicly available from January 2016 are:\n\n- Whilst the team has developed a good understanding of the service for registered entities, further work is needed to design and test for non-­registered entities e.g. authentication needs to be worked through, paying particular attention to the process for non­-registered entities.\n- Further research to confirm the Assisted Digital (AD) need, and to provide supportive evidence at the beta assessment. This also includes evidence on how they are measuring the AD support offered against the four key performance indicators (KPIs).\n- Given timescales, a decision should be made early during beta on live service deployment to mitigate any risks.\n- The current test coverage was suitable for an alpha phase, but test environments appeared limited given a single environment was in use for development and test. The panel recommend that in beta the numbers of environments are expanded and a continuous integration pipeline is established.\n- The current deployment environment will be different from the live rollout, so demonstration will be required in beta of testing in an environment that mimics it, in addition to integration with test harnesses of existing authentication/access and payment solutions.\n- To work with GDS on the start/end pages for the service on GOV.UK including revisiting existing content to reflect the new service.\n- The service should be reviewed to ensure consistency with GOV.UK style and design.\n- Further analysis to identify a clear baseline to monitor performance e.g. target expectations on completion rates and how they compare with other services.\n- The team acknowledged plans to develop the Performance Platform dashboard and this should be pursued during beta.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/charities-registration-self-certification-2/",
    "title": "Charities Registration - Self Certification",
    "summary": "Charities need recognition from HMRC to claim gift aid. The digital service allows users to make their applications online with validations in the service filtering out non­-valid applications.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n4/7/2015\n\n**Assessment Stage:**  \nlive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nR. Morgan\n\n**Service Manager:**  \nI. Atkin\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nFollowing assessment against the new 18 point service standard, the HMRC assessment panel can confirm that the Charities Registration service has shown clear evidence of meeting the Digital Service Standard and should move to live.\n\n**Reasons**\n\nThe panel were pleased to see the continued progress of this service during public beta and it is clear that plans are in place for continued development in live.\n\nParticularly notable is evidence that since the start of public beta analytics show that the ’not eligible’ page has been deployed some 660 times. Whilst end users may have gone on to use the service at a later stage it is likely that as many as 660 applications for recognition have been filtered out by the digital service.\n\nTo date some 762 completed submissions have been received. These have landed on the Enterprise Tax Management Platform (ETMP) as the transaction number played back to the user on submission is actually the ETMP Form Bundle number. This number is also recorded and a daily update passed to Specialist PT.\n\nAt the beta assessment, the panel recommended that the time out message of ‘not authorised’ should be researched further. This has been completed and changed. The message now informs the user that the session has expired for security reasons and redirects to the 'retrieve application' link.\n\n**Recommendations**\n\nThe Panel make the following recommendations­:\n\n- Investigate the value of putting a suggested completion time on the start page, given the established user need for an in service progress bar.\n- Continue the investigation work begun of assisted digital (AD) users through contact with customers who request a paper form in preference to the digital service; using this insight to further develop the service.\n- Continued monitoring of the 'Save and Retrieve' element of the service to identify any sticking points users may be experiencing. There may be additional benefit in developing an understanding of customers who start but do not return to complete the registration within the 28 day retention period.\n- Supports the continued exploration/development of digital submission of supporting documentation and links to The Charity Commission. The Panel is pleased to see that following public beta, a specialist PT is now also keen to work with the team on this point reducing further unnecessary contact and costs, and improving the user experience.\n- Monitor the feedback of customers who leave ‘Get recognition from HMRC for your Charity’ start page to register for Gateway services to ensure customers continue to successfully negotiate this journey.\n\nThe Digital Service Manager (DSM) provided an overview of the service and gave a summary of the progress the service had made throughout its early days and through public beta.\n\nUser research has been ongoing since January 2014 and no typical user has been identified; with many different types within the audience for this service – volunteers, charity paid administrators, scout groups etc. Initial research showed that when setting up a charity the customer could communicate with The Charity Commission online but for recognition from HMRC it was a paper process. Users felt that the online experience was far superior and welcomed HMRC’s move to digital.\n\nListening to the user has been at the core of service development designing such features as 'Save and Retrieve', summaries, ability to edit and return to the leaving point to continue data entries, errors and omissions identified during completion saving user and departmental time and costs, acknowledgements, dynamic listing of supporting documentation required based on details entered, saving unnecessary contact as HMRC receives the right information.\n\nWhen moving to public beta in January 2015 Specialist Personal Tax (SPT) Operational staff had a 6 week turnaround to deal with applications; this is now down to two weeks as the correct supporting documentation is received and the number of applications being filtered out through upfront eligibility questions.\n\nThe panel viewed a demonstration of the service. The demonstration ran well and clearly showed a logical flow for the user journey. Questions asked by the panel were confidently answered by the DSM and all the team members.\n\nThe panel were pleased to see that the thorough user research demonstrated at the beta Assessment has continued and that plans are in place for research in live. Personas created have evolved over time.\n\nThe team asked users to describe a typical day to understand more about their activities, when and where they do things, and what tools and information they use. There has been difficulty identifying an AD group and TNS have also tried to obtain AD customers for the service.\n\nLloyds Bank research has been read but there still remains a problem getting to this alleged group. The team believe that there is a need out there but it is covered by someone else within the charity’s organisation dealing with online applications etc. Since moving into public beta, the paper form has been removed from GOV.UK with users being directed to the digital service – there have been only three calls querying this but it has not led to AD requirement. Whilst the form has been removed from GOV.UK it does not mean that a copy has not been saved by a user and could be shared with others. The team will be informed by the business area in the event that a paper form is received the user researcher is then keen to work with that Charity in expanding its AD offering. An AD call line is in place with support, and the team have provided a questionnaire for feedback to ensure that they get the type of information in line with inclusion scales required to aid decision making in this important area. It is clear that the user researcher and team have a good understanding of AD and the researcher attends AD Forums and discussions within the research community.\n\nWhilst registration of details is now digital, the charity official must submit charitable status documents to HMRC. The team are now to look at submission by digital means or to create links to The Charity Commission to negate the need to submit documents. This would also remove the need to have an internal linking process and although the delivery team informed the panel that all documentation is voluntarily sent in, there is a potential need to contact the user for outstanding or missing documentation. During public beta this has been monitored and all but two users had submitted on time. Operational areas are now keen to develop this further having already seen benefits.\n\nThe good team dynamic already set up during alpha and beta has continued to develop. The team structure during beta was explained and clearly shows that key roles are being covered by different people. It is the intention that the team will remain the same in live. The Team work closely together and skills are shared through working together and the good communication set up by the DSM.\n\nAgile methodologies continue to be used i.e. daily stand ups to discuss progress/blockers, show & tells, and the sprint cycle – including planning and retrospectives. Business representatives attend the monthly show & tells, the benefits of which have already been highlighted.\n\nThe team take part in the various community groups within the Design Centre in Newcastle and London e.g. Researcher, Design etc. There is a good relationship with web ops in London and team members have spent time with web ops learning to code and then shared that knowledge.\n\nThe service has been tested on all devices. Whilst the majority of users are completing on a Desktop PC some Tablet submissions have been made – no negative feedback has been received. The paper print & post version of the registration document has been archived from GOV.UK to move users to the digital service. A link to the service is available from the archived form page. Google Analytics has not identified any drop out points but the service team are monitoring the 'Save and Retrieve' functionality; at times there are 300 items saved.\n\nAD strategy is in place using the telephone but the service team are working with the business, Deskpro and helpline to identify further need. A template to collect feedback has been provided to Helpdesk in line with inclusion levels for all direct contact to be analysed. In the dashboard shown to the panel­, cost per transaction is outstanding – the team are working with Finance to get the figure for HMRC as it will involve costs for the Tax Platform.\n\nIn addition to the four mandatory key performance indicators (KPIs), the team will measure:\n\n- Reduction in ineligible applications.\n- Submission of supporting documentation on time.\n- Number of cases passing straight to the operational decision maker without further intervention.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/office-for-national-statistics-website-self-certification/",
    "title": "Office for National Statistics Website - Self Certification",
    "summary": "The Office for National Statistics (ONS) is the UK’s largest independent producer of official&nbsp;statistics and is the recognised national statistical institute for the UK. It is responsible for collecting&nbsp;and publishing statistics related to the economy, population and society at national, regional and&nbsp;local levels. It also conducts the census in England and Wales every ten years. The website is the&nbsp;primary channel for dissemination of these statistics.",
    "body": "**Department / Agency:**  \nONS\n\n**Date of Assessment:**  \n8/07/2015\n\n**Assessment stage:**  \nbeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nC. Foster\n\n**Service Manager:**  \nM. Jukes\n\n**Digital Leader:**  \nT. Makewell\n\n* * *\n\n## **Assessment Report**\n\nThe ONS website has been reviewed against the 18 points of the Service Standard at the point of seeking to progress to a public beta of the service.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel have concluded the ONS website demonstrates the level of progress and evidence expected against the Digital Service Standard criteria and should proceed to launch as a public beta service.\n\n**Reasons**\n\nThe team provided evidence to demonstrate that the service meets all the points of the service standard for beta.\n\nParticular areas of strength included:\n\n- The Service manager’s thorough understanding of the service and how it is meeting user needs.\n- Clear evidence that the team is doing the hard work to make it simple, both with the website and also the internal publishing system.\n- The service manager and team’s clear commitment to putting the user first and constantly improving the service.\n- A strong commitment to open sourcing the code (with all code being placed on Github), as well as to open data with each page being able to be uniquely referenced and called through an API.\n- The site has been developed with a strong focus on progressive enhancement and responsive design, and as such naturally performs well across browsers, settings and devices.\n- The colocated team is working at pace and effectively, and using appropriate agile approaches to deliver value early and often.\n- The site design is clear and well presented\n- Clear evidence of a strong relationship and support from senior managers and boards.\n- The team are clearly always trying to do the ‘right thing’, even if on some occasions that makes it harder for the team themselves.\n\n**Recommendations**\n\nThe team has demonstrated a high level of commitment to user testing during the alpha, which is planned to continue with the beta. As well as focusing on the primary personas, it is recommended that it does also include the other user types to a lesser extent (e.g. the ‘Inquiring Citizen’). Opportunities should also be explored to do more user-testing outside of lab conditions and constraints, including accessibility testing.\n\nThere have been issues with recruiting permanent staff into some key roles, but much effort and imaginative approaches are being used to address that. It is recommended that plans for transferring skills and knowledge from the largely contractor resourced development team, to the internal staff (once in place) are continued and strengthened. Clear, and testable, criteria should be put in place for determining success of those skills and knowledge transfer.\n\nAs the beta will shortly be moving cloud service provider, the planned full restore from back-up should be treated as a priority.\n\nThe already understood main challenges around ‘search’, and ‘9.30 publishing’ remain the largest factors that will determine success of this project, and so the assessment panel supports the intentions in place for focusing on those elements during the beta phase.\n\nThere is evidence of a strong continuous delivery process in place, which (as planned) needs to be strengthened with the introduction of additional automated and manual code quality assessment approaches and tools.\n\nThe team has clearly felt that it has needed to work somewhat in isolation from other projects within the organisation in order to deliver at pace and seeking to avoid the use of (or conversations about) tools that are not specific to the project’s needs. While this is understandable, it is recommended that time should be sought to step back slightly, and see if there are any learnings that can be taken from other teams within ONS.\n\nIt is recommended that internal senior stakeholders consider whether they could do more to support the team by being more proactive and ‘going and seeing’ rather than ‘waiting and hearing’.\n\nThe decision on whether to report on the GDS Performance Platform or separately needs to progressed and concluded, and metrics reported publicly from as soon as possible after the beta goes live publicly.\n\n* * *\n\n## Digital Service Standard criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | N/A |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n|\n| |\n\n&nbsp;"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/employment-related-securities-ers-reporting-service-self-certification/",
    "title": "Employment Related Securities (ERS) Reporting Service - Self Certification",
    "summary": "Under Employment Related Securities (ERS) legislation changes that come into effect from April 2015, companies running share and security schemes must send their end-of-year returns online.",
    "body": "This ERS Returns Service is a digital service that allows those employers or their agents to provide HMRC with end-of-year ERS returns for schemes and arrangements operated (Company Share Option Plan (CSOP), Share Incentive Plan (SIP), Save As You Earn (SAYE), Enterprise Management Incentives (EMI), and ‘Other’).\n\nThe returns are in spreadsheet format based on an ODS template that is available to download from the HMRC portal for each scheme. Employers and Agents compile required data throughout the year using the spreadsheet. CSV files are now accepted based on the outcome of customer research.\n\nBetween 6 April 2015 and 7 July 2015, there is a three month window allowing users to submit their end of year returns. The service can still be used beyond July, however, if users submit their return outside of this window they will receive a late penalty.\n\n**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n04/02/2015\n\n**Assessment stage:**  \nbeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nR. Morgan\n\n**Service Manager:**  \nI. Atkin\n\n**Digital Leader:**  \nM. Potter\n\n* * *\n\n## Assessment Report\n\nAfter consideration the assessment panel concludes that the ERS Reporting service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a beta service on a service.gov.uk domain in April 2015. The demonstration showed that the service is simple, quick and easy to use.\n\n_User needs_\n\nClear use of research establishing the user need was demonstrated through the introduction of .csv file uploads. HMRC provide an ODS template for customers but research found that most users used Excel spreadsheets and preferred .csv. Research showed that users downloaded the ODS template to view it but didn’t in fact use it. Both options to upload files are provided in the service.\n\nTwenty one user research sessions had been held covering focus groups, guerrilla, lab testing, lab and video. Skype has been used successfully to record user testing sessions. The team can readily see user reaction to content/design and flow of the service and all observe together. At the same time this has given the opportunity to share user research sessions with the business.\n\nA really good user network has been established giving confidence that the service will meet the needs of the customer.\n\n_The team_\n\nThe service manager talked through the team working on the service. It is clear that the entire team work well together and have a good team ethic. Working closely with Delivery Centre Management, any resource changes can be anticipated and handovers through shadowing are put in place to give continuity. The DSM has also used Pair Programming and the team come together as a group to problem solve and share knowledge and experience. In addition to this Delivery Centre Management have created Communities for designers, architects, DSMs etc. to come together and share wider knowledge across projects and the team make full use of this facility. This also provides a link to our other Deliver Centre in London.\n\nA good working relationship with Specialist PT line of business is in place and has been developed through fortnightly Show and Tells and weekly meetings/updates and workshops. The usual agile methodologies and techniques are being used and the service manager has suitable input and prioritisation over the backlog.\n\n_Security, privacy, tools & standards_\n\nThe DSM confirmed that all relevant security credentials have been signed off.&nbsp;Examples of the tools being used were given – Jenkins, Git, Jira; all industry standard and in common use for agile delivery.&nbsp;Open source code is used but as recommended above, the panel want to see new open source code published at the earliest opportunity.&nbsp;Users will be using the Government Gateway until identity assurance for organisations is delivered.&nbsp;Deployment and testing routine was explained – down time is not required and testing is undertaken as iterations are delivered.&nbsp;The service has been tested on a variety of browsers including IE6 upwards, Safari, Linux and Windows 8.&nbsp;Mobile devices have been tested. Although the audience for this service will be office based as a nil return is also mandatory it has been tested on other devices.&nbsp;Disaster Recovery is in place.\n\n_Improving the service_\n\nThe team can respond to issues/bugs and iterate quickly. The team respond quickly to user research and ensure that they are aware of trends from feedback and Deskpro. The service manager has no preconceived ideas of how the service will be used during beta and is looking forward to observing user behaviour in real time. A user survey carried out in June 2014 will provide a benchmark to measure user experience of the service.\n\n_Design_\n\nThis service has no non-digital steps as online return submission is mandatory and there will be no paper alternative. Data will populate backend systems and be stored in readiness for compliance activity. Accessibility of the service has been tested/reviewed by the HMRC Accessibility Champion.\n\nThe GDS style guide/Design patterns have been used throughout with the exception of the file upload, as the guide does not contain anything for this situation. Although the format used is widely available it has not been formally agreed with GDS and the panel would like to see evidence that the style used is acceptable. The team did refer to GDS for advice on the use of a pdf Error Report which users preferred to the HTML versions. Users preferred the pdf as the individual submitting the return is not normally the person who would correct the spreadsheet data – the pdf Error Report can be easily passed on. Agreement has been reached with GDS to use pdf as first option with HTML versions also being made available. This will suit all user needs.\n\n_Assisted digital & channel shift_\n\nTo date there is no evidence of assisted digital need. However a support model is in place and need will be monitored via the Helpdesk. Whilst there is no paper alternative for this service Helpdesk staff are briefed to either talk callers through the process or complete on their behalf. A relationship exists between the line of business and ERS employers this will be exploited/expanded to meet any AD needs which may arise.\n\nThe benefits/use of the service have been published in bulletins. The Service Manager and team members have spoken at SPT events and a variety of forums to deliver the message around this service. There will also be a Ministerial launch of the service in March 2015.\n\n_Analysis & benchmarking_\n\nThe service team has made a good start by getting analytics installed, and has some good ideas for future analytics have been put forward.&nbsp;Google Analytics will be used to measure the four core Key Performance Indicators (KPIs).\n\nFor the year 2013/14 22,000 ERS returns were received, half of those by the deadline – having said that the deadline was across a weekend and many users submitted their returns on the first working day of the week. Submissions are expected to be higher in 2014/15 as nil returns have been mandated. The stats used to benchmark submissions for 2014/15 have been collated from the line of business and KAI. The stats profile has not been returned to KAI to ensure robust figures are being used and the panel asked that this is done at the earliest opportunity.\n\n_Service testing end-to-end_\n\nThe HMRC Digital Leader has been invited to test the service before Live and the Team are awaiting his response to arrange the appointment.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | N/A |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | N/A | 22 | N/A |\n| 23 | N/A | 24 | N/A |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/provider-digital-service-service-assessment/",
    "title": "Provider Digital Service - Service Assessment",
    "summary": "The Skills Funding Agency (SFA) fund skills&nbsp;training for further education (FE) in England.&nbsp;The service will enable education and&nbsp;training providers to manage their contracts&nbsp;with the SFA. This will offer a single place&nbsp;where education and training providers can&nbsp;manage their online funding relationship with&nbsp;the SFA to find information to: plan, register&nbsp;and bid for skills funding; agree, vary and&nbsp;grow their contracts; get help to recruit and&nbsp;enrol learners and make data returns to&nbsp;receive payments and measure performance.&nbsp;The service will support approximately 1,000&nbsp;education and skills providers as follows: 500&nbsp;training organisations, 320&nbsp;colleges and universities, 135 Local Authorities&nbsp;and 60 employers.&nbsp;The SFA currently host a number of digital&nbsp;portals to services. The service will&nbsp;complement and replace some of these&nbsp;existing skills funding services, in particular a&nbsp;service for submission of contracts and a&nbsp;document exchange portal.",
    "body": "**Department / Agency:**  \nBIS / SFA\n\n**Date of Assessment:**  \n06/07/2015\n\n**Assessment stage:**  \nalpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nA. Graham\n\n**Service Manager:**  \nD. Williams\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## **Assessment Report**\n\nThe Provider Digital Service has been reviewed&nbsp;against the 18 points of the Digital Service&nbsp;Standard at the end of the alpha development.\n\n**Outcome of service assessment**\n\nThe assessment panel have concluded that the&nbsp;service is on track to meet the service standard at&nbsp;this stage of development and should proceed to&nbsp;beta.\n\n**Reasons**\n\nA good multi-disciplinary team is in place, led by a competent and enthusiastic service manager, who showed a strong understanding of the service standard.\n\n- User research showed evidence of a clear understanding of the design principles underpinning the service standard. Evidence of regular research using a variety of techniques was heard. Feedback of user research happens during sprints and has enabled the alpha service to be tested and iterated on a frequent basis.\n- The team have re-used elements of the SFA exemplar project to support technology decisions identifying technical risks at an early stage and mitigating risks – an issue that has been identified regarding challenges to attract the correct skills for some technologies has influenced decisions indicating flexibility of approach to ensure that the team is capable of delivering.\n- A strong understanding of privacy requirements and security and evidence of engagement with the wider BIS family to understand the SFA role within the government grants ecosystem.\n- The team have made use of the design tool kits available and are aware of the prototyping kit on GitHub.\n- Analytics have been implemented at an early stage and engagement with the Performance Platform is evident.\n\n**Recommendations**\n\n_Understand user needs_\n\nThe user base for the service is clearly defined and understood and we heard that evidence of an assisted digital need has been actively sought and not identified. The panel recommend that the service must continue to research assisted digital (AD) requirements throughout the duration of the beta to continually validate the working assumption. In addition we recommend that the team should be able to show that they have a plan for how they would rapidly provide the capability to support AD should the need arise.\n\n_Build the service using agile methods_\n\nThe service manager had a good understanding of the velocity of sprints. In beta we recommend work should be undertaken to understand user story cycle time to evaluate team performance.\n\n_Build a service consistent with the user experience of the rest of GOV.UK_\n\nThe alpha includes elements of content currently hosted on GOV.UK. The panel heard that feedback had shown that users want some of this content within the transactional service. We recommend that the service team should continue engagement regarding the content element of the service with GOV.UK looking at how and where it is presented.\n\n_Build a service consistent with the user experience of the rest of GOV.UK_\n\nAs the alpha has worked upon a part of the larger digital presence of Skills Funding Agency there are a number of elements of the user journey that are outside of the scope of this work, for example a legacy identity assurance system. These will form part of the user journey for this service, but also support a number of other services. The panel recommend that work should be undertaken to visualise a clear end-to-end user journey, including these inconsistent elements, to fully identify issues with the fact that these elements are not consistent with the user experience the rest of the service will deliver. While the panel acknowledge that the team may not be in a position to change the legacy dependencies, understanding the effect on the user journey will offer a clearer view of what needs to be done and support the need for change if it has a detrimental impact.\n\n_Put in place a sustainable multidisciplinary team_\n\nThe team recently lost resource of a visual designer. As the team has a content designer who has skills in this area this was not considered a significant concern but consideration should be given to how peer review will be conducted when both roles are fulfilled by one person. During beta this approach should be reviewed to ensure that the stated aim to make changes on the fly during research can be supported when both roles are being fulfilled by the same team member.\n\n_Evaluate what tools will be used and how to procure them_\n\nThe panel understand the reasons for the choices of tools made for the service and the service manager was confident in presenting the rationale. A number of these choices have been influenced by previous work undertaken by the SFA in their exemplar project and technology capabilities within the department. The panel felt that they would have liked more assurance that the choices were not driven too much by current capability and that open source software was considered on a level playing field given its limited adoption in the alpha. We recommend that the service manager reviews the choices to assure himself (perhaps with guidance from GDS) that platform choices have not been limited by capabilities to the detriment of the service and that the current proposal will deliver a service that meets the user need.\n\n_Evaluate what tools will be used and how to procure them_\n\nThe service manager demonstrated a sound knowledge of Verify and the limitations in relation to identity assurance of corporate identities which are required by the Skills Funding Agency. The panel agree with the approach taken given no citizen identity is required, but recommend that the SFA should assess their ability to decouple the identity and access elements of the legacy service to avoid lock-in should the Verify solution offer suitable identity management and assurance in future iterations.\n\nThe panel recommend that the team understand the implications of an exit strategy to off-board from the current platform from a cost and technical complexity perspective. This should assure the service manager that there are not any unpalatable barriers to exit, thus avoiding single vendor lock-in. Conducting this early in beta will provide an opportunity to consider ways of de-risking anything identified.\n\nWe recommend that the team should prioritise the implementation of the shared continuous integration environment to enable end-to-end testing in beta.\n\n_Make all new source code open and reusable_\n\nThe team explained that they would look to publish source code under the appropriate license where it would be useful. The panel are assured that the SFA fully support the principle of open source code but recommend that the team should aim to publish all source code and should not attempt to evaluate usefulness. By doing this the SFA can allow other departments and users to determine whether the code is useful.\n\nWe recommend confirming the availability of and adding a GitHub plugin to the existing source code repository early in beta to support the publishing of open source code as soon as possible.\n\n_Encourage all users to use the digital service alongside an appropriate plan to phase out non-digital channels and services_\n\nThe service manager was able to demonstrate that good planning was already underway supporting channel shift. During the assessment it was mentioned that consideration was being given to forcing users to use the new digital service by removing all other options. The panel recommends that this should be carefully considered bearing in mind that the guiding principle for new services is to build 'digital services so good people prefer to use them'. If the new service is allowed to run in parallel with existing channels for at least a small amount of time to allow a tipping point to be realised it will be easier for the service manager to evaluate the success of the new service in conjunction with other KPI measurements.\n\n_General comment_\n\nDuring the beta the panel recommends work should continue to review the name of the service with users, as it was felt that the current working title may not be appropriate.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | N/A |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/fee-remission-self-certification/",
    "title": "Fee Remission - Self Certification",
    "summary": "Fee Remission is a HM Courts & Tribunal Service (HMCTS) service for users in receipt of state benefits or on low income. The service offers users a simple way either to exempt themselves from paying court or tribunal fees or to have refunded the fees users have already paid.",
    "body": "Of the c. 500,000 paper applications to HMCTS for fee remission each year, approximately 75 percent are currently being rejected. Many of that number are themselves resubmissions. Often the people applying are eligible for fee remission, but they fail to fill out the form correctly, so their application is rejected.\n\nThe Fee Remission service under assessment will have three interrelated parts:\n\n1. a user-centric and more easily completed paper application form; which feeds into\n2. a software application for court staff to check with the Department of Work & Pensions (DWP) whether the applicant is in receipt of benefits or on low income; then based on learning from 1) and 2)\n3. a digital form to replace the paper form\n\nHMCTS was already undertaking work to redesign the existing paper form in parallel with the creation of the Fee Remission service. The team took the opportunity to collaborate with their HMCTS colleagues.\n\nThrough this collaboration, the team were able to use feedback from the redesign of the paper form to inform the design of the digital service. The team was also able to start collecting the applicant’s National Insurance number on the paper form, a necessary step for the creation of the court-facing app.\n\n**Department / Agency:**  \nMOJ\n\n**Date of Assessment:**  \n6/3/2015\n\n**Assessment stage:**  \nAlpha Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Busuttil\n\n**Service Manager:**  \nA. Woodcock\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## **Assessment Report**\n\nThe Fee Remission service has been reviewed against the 26 points of the Service Standard at the end of the alpha development.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Fee Remission service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service was assessed against all 26 points of the Digital by Default Service Standard.\n\nThe service currently meets the requirements of the standard for an alpha. Areas of good performance against the standard included:\n\n_User needs_\n\nThe assessment panel felt that the service team’s research into user needs was particularly strong for this relatively early stage of development. The team has been working with the Personal Support Unit (PSU), a charity that provides free, independent advice to litigants in person, witnesses, victims, their family members and supporters, and the Citizens’ Advice Bureau (CAB).\n\nThe team has conducted interviews, comparative usability testing of paper forms, and guerilla research with members of the public, PSU and CAB staff, and court staff in Birmingham, Bristol, Salford, Wolverhampton and the Central Family Court in London.\n\nBy the date of the alpha assessment, the team had spoken to 35 users, observed 36 forms being filled out, of which 7 were members of the public making actual applications for fee remission.\n\n_The team_\n\nThe team has also been working closely with their colleagues in HMCTS in an agile manner. They have shared their research findings with them, and are helping them to redesign the paper form to be more user-centric based on the evidence gathered so far.\n\nOne example of this approach was to remove the need for the public to write down the applicable court fees on the paper form. The fee amount varies and court staff are better placed to record the correct fee required. Making this change is expected to remove one of the main causes of form rejection.\n\n_Analysis and benchmarking_\n\nThe assessment panel liked how the team was using the redesign and testing of the paper form as a method of gathering user needs for the design of the court-facing app.\n\n**Recommendations**\n\n_Security, privacy, tools and standards_\n\n- Although the Information Asset Owner (IAO) and Accreditor are acting as the team’s conduits to the Senior Information Risk Officer (SIRO), the team still needs to obtain a risk appetite statement directly from the SIRO.\n- Check whether the service will be subject to assessment using the Requirements for Secure Delivery of Online Public Services (RSDOPS).\n- When delivering the public-facing digital form later in development, re-engage with GDS to assess whether user needs prompt the use of GOV.UK Verify\n- Ensure the team is familiar with the roles and responsibilities of data protection.\n- Be clear on what the cookie policy needs to be for the Fee Remission service, rather than assuming it will be the same as for GOV.UK\n- Work with central web ops team to clarify and document how the new deployment processes will work for the Fee Remission service.\n- Carry out capacity and load testing on the digital service, even though traffic patterns to the service are predictable and anticipated to be of low volume.\n- Carry out CESG’s IT Healthcheck Service (CHECK) initially, and whenever there are significant changes to the technical architecture.\n\n_Open source_\n\n- Add the Massachusetts Institute of Technology (MIT) open source source licence to the public code repositories.\n\n_Assisted digital and channel shift_\n\n- Check the assisted digital needs of court staff with HMCTS and HR.\n\n_Analysis and benchmarking_\n\n- Ensure the method of assessing staff time before and after does not rely on reporting methods outside of the team’s control, or which may become difficult to compare consistently if changed (BMS codes).\n- Use scorecarding methodology to track user satisfaction on the paper form, the staff-facing app, and the subsequent digital form.\n- Consider measuring the reduction in amount of time people spend with PSU or CAB assistants to complete a form successfully.\n- Consider what organisational support (training etc.) HMCTS may need to provide for the phased roll-out through the 150 courts.\n- Identify sources for and start gathering data for digital take-up in advance of the creation of the digital form replacing the paper form.\n- In advance of establishing the public-facing digital service, consider creating an operational dashboard to monitor key metrics and make it available to HMCTS.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/make-a-plea-self-certification-2/",
    "title": "Make A Plea - Self Certification",
    "summary": "The Make a Plea service will allow people to enter their pleas online for summary traffic offences; which would not result in a prison term for the defendant if convicted. This service aims to:",
    "body": "- reduce the number of defendants attending court unnecessarily\n- create a public plea entry for traffic offences\n- provide a fee payment mechanism for guilty pleas\n- show results of cases and notify defendants online\n\nThe Make a Plea service is starting with Greater Manchester Police, with a commitment to deliver a nationally scalable service, on behalf of the HM Courts & Tribunals Service (HMCTS) Common Platform Programme in 2015.\n\n**Department / Agency:**  \nMoJ\n\n**Date of Assessment:**  \n18/03/2015\n\n**Assessment Stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Busuttil\n\n**Service Manager:**  \nN. Gallon\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Make a Plea service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and should proceed to launch as a beta service on a service.gov.uk domain. This means the service can now replace its alpha branding with beta branding.\n\n**Reasons**\n\nThe service currently meets the requirements of the standard for beta. Areas of good performance against the standard&nbsp;are as follows.\n\n_User needs_\n\nSince the alpha assessment, the team has continued to conduct in-depth user research with the service, including user experience with the Single Justice Procedure notice. Of particular note:\n\n- Assessing how the needs of other police forces differ from those of Greater Manchester, which in turn feeds into changes needed in the service to facilitate national deployment.\n- Researching and testing use cases for company directors and officers to enter pleas on behalf of employees.\n\n_Assisted digital and digital take-up_\n\nThe team has been extremely effective in determining and delivering an appropriate plan to cover assisted digital (AD) user needs. The team brought an AD call centre into operation on 11th February 2015 and offered 500 users the option to make a plea by telephone. All users were defendants in the Greater Manchester area who had court hearings scheduled in the first half of April 2015.\n\nSince mid-February, the AD call centre has received 72 calls (14% of the 500 user sample), of which 37 were queries for information by users who had already successfully entered their plea through the digital service. The remaining 35 calls received were representative users with AD needs.\n\nFrom the data gathered from the AD call centre, the team is planning to make improvements to the service. These improvements will include:\n\n- Providing users with clearer information to pre-empt queries.\n- Emphasising use of the digital channel by default in the documentation used to initiate the use of the digital service (the police’s requisition pack).\n- Providing clearer guidance on the most appropriate number to call for information should users still have a query.\n\n**Recommendations**\n\n_Security, privacy, tools and standards_\n\n- A number of architectural improvements have been made to the service recently in the development environment but have not yet been deployed to the production environment. Consider how these changes could be deployed to production incrementally rather than all at once. The assessor panel notes that the incremental approach may not be as straightforward from a technical standpoint.\n- Seek recommendations from other service teams to identify possible choices for an alternative provider for hosting static holding pages in an entirely separate location.\n- Ordinarily for live running, the anticipated first and second line support service level agreement (SLA) for the Make a Plea service would cover working days, 9am to 5pm. Consider putting in place an extended support SLA during beta, particularly while making the service available to additional police forces.\n- Consider reusing the London WebOps team’s templates for provisioning and service management.\n- Ensure that any member of the development team can trigger a load testing run through the continuous integration server.\n- Load test the service to the point of failure, and check that the service recovers when load subsides.\n- Do a full walk-through of the disaster recovery plan, either in the staging environment or in the production environment at a point of very low traffic, when a short period of downtime would be acceptable.\n\n_Improving the service_\n\n- Form a plan for supporting the service via the newly created second line support team based in London.\n\n_Design_\n\n- Change the service domain to www.makeaplea.service.gov.uk on passing beta assessment from www.makeaplea.justice.gov.uk with appropriate redirects.\n\n_Assisted digital and digital take-up_\n\n- Seek advice from other service teams already making use of the call centre channel for AD (e.g. the Visit Someone in Prison service) to form a plan for what to do when the call centre is closed.\n\n_Analysis and benchmarking_\n\n- Seek examples from the Civil Legal Advice team for how to reduce unnecessary calls to the AD call centre. Work with your stakeholders to define the correct path for people wishing to phone in.\n- Use the trends in types of unnecessary calls coming into the AD call centre as a source of input to determine possible improvements to the service.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/complete-the-deputy-report/",
    "title": "Complete the Deputy Report - Self Certification",
    "summary": "When a person loses mental capacity and has no appointed attorney, the Court of Protection will appoint a deputy to manage the financial affairs, health and welfare of that person (the client). A deputy can be a:",
    "body": "- lay deputy, i.e. a trusted family member or friend of the client\n- professional deputy, e.g. an accountant, solicitor or a specialist from an approved charity\n- representative of the local authority\n\nDeputies are obliged to report annually to the Office of the Public Guardian (OPG) on how they have managed their client’s finances. This is a measure to prevent fraud. Currently, the only way for deputies to submit this annual report is via a paper form.\n\nThe first iteration of the Complete the Deputy Report service will allow lay deputies to compile and submit online to OPG their annual report of how they have managed their client’s finances. The scope of the service does not yet include:\n\n- the Court of Protection’s process to appoint a deputy\n- the initial assessment and guidance provided by OPG to a newly-appointed deputy\n- support for professional deputies\n- processes relating to a deputy’s management of their client’s health and welfare\n\nNote that user research into the name of the service is ongoing.  \n  \n**Department / Agency:**  \nMoJ\n\n**Date of original assessment:**  \n09/04/15\n\n**Date of Reassessment:**  \n28/04/2015\n\n**Assessment Stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nJ. Busuttil\n\n**Service Manager:**  \nK. Collingwood-Richardson\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Complete the Deputy Report service is on track to meet the Digital by Default Service Standard at this early stage of development.\n\n**Reasons**\n\nThe service currently meets the requirements of the standard for an alpha. Areas of good performance against the standard&nbsp;are as follows.\n\n_User needs_\n\nThe user needs mapping from discovery is clear and pragmatic, with good user personas and journey maps. It is evident that discovery was very thorough and that the product owner was closely involved.\n\nThe team has worked collaboratively on user research and used a variety of quantitative and qualitative techniques. These have included surveys, interviews, lab-based testing, contextual research and guerilla testing. These have allowed the team to discover and understand user needs well, which in turn have informed the design of the service.\n\nAmongst other findings, the results of the ongoing research has prompted the team to redesign the navigation and bookkeeping aspects of the prototype service during the alpha phase to be measurably more intuitive for users.\n\n_The team_\n\nDespite having a delivery team spread across a few locations in the UK, the team has been successful in working collaboratively and remotely.\n\nIt is also notable that a business stakeholder from OPG co-locates with the delivery team periodically and is anticipated to become more involved soon as a deputy product owner.\n\n**Recommendations**\n\n_User needs_\n\n- Continue to research and understand in more detail the needs of OPG staff users, who receive, review, reject or accept a report submitted by a deputy, then process that information in the case management system. Their interaction with the service has a knock on effect on the deputies’ use of the service, and in turn on the ultimate beneficiary of the service, the client.\n- Once these needs are better understood, create personas for OPG staff users and use them to inform the design of the administrative functions of the service.\n- When researching needs of administrative users, be aware that it is a common pattern for users to tend to express what they want the service to do in terms of their current processes, rather than articulating their underlying problem needing to be solved by the service.\n- For the beta phase, bring more focus to research by stating up front and more clearly the questions the team needs to answer through research. Incorporate these research goals into the ongoing research plan and find ways to reduce the turnaround time from research to design to implementation. This will allow development in beta to continue at pace.\n- Define and select a private beta segment and create a pilot plan based on what the team feel the challenges could be and iterating it in stages.\n\n_Security, privacy, tools and standards_\n\n- Speak to technical architects in MOJ Digital about the possible reuse of the existing postcode lookup API.\n- Separate the service’s user interface into two distinct parts on separate domain names: the citizen-facing service; and the administration interface for OPG staff. This will simplify security, user privilege separation, and will allow a&nbsp;reduction in the set of web browsers the admin interface needs to support to the set OPG staff use in practice.\n- Complete the Requirements for Secure Delivery of Online Public Services (RSDOPS) assessment.\n- Implement smoke tests as part of the deployment process to the production environment.\n- Implement health checks, accessible securely by external monitoring systems, which can determine the health of the overall service and the health of key components.\n- Carry out capacity and load testing on the digital service, even though traffic patterns to the service are predictable and anticipated to be of low volume. Run Distributed Denial of Service (DDoS) stress tests to exercise the service to breaking point.\n- If not already, use BrowserStack or equivalent to test the service’s web browser compatibility.\n\n_Improving the service_\n\n- Be careful not to overload the staging environment with performance testing when acceptance testing is underway. Consider a dedicated acceptance environment.\n- Ensure that any member of the delivery team, technical or otherwise, is able to perform a successful release of the service to the staging and production environments.\n\n_Design_\n\n- Consider ways to reduce the amount of guidance text needed on the overview page, and elsewhere in the digital service, ideally by making the service itself more intuitive, or perhaps by using an alternative medium to show users what to do rather than having to tell them.\n- There appears to be still a lot of jargon in the microcopy, particularly around the bookkeeping information requested. Definitions, e.g. ‘opening balance’ will need refinement in the future. Look for ways to improve the experience for users by simplifying or rewording these prompts.\n- There are several recent commercial bookkeeping products that users feel have intuitive interfaces for explaining financial transactions, and for locking transactions partially and permanently. If helpful, consider reviewing their approach.\n\n_Assisted digital and digital take-up_\n\n- Meet with GDS assisted digital (AD) leads regularly.\n- Seek best practice from GDS on surveying user satisfaction for AD channels and frequency of surveys, and describe how this will inform performance and channel shift plans.\n- Arrange for the contact centre to log as much AD information as possible to uncover where users are on the spectrum of digital inclusion (DI); seek guidance from GDS to ensure the right things are being&nbsp;measured.\n- Carry out a more precise analysis of proportions of each type of users on the spectrum of digital inclusion and how they will change over time.\n- Determine whether OPG staff users have any AD or digital inclusion needs.\n\n_Analysis and benchmarking_\n\n- Look into measuring satisfaction in ways in addition to the ‘done’ page - perhaps other satisfaction surveys in the header or a pane.\n- Survey existing users to gauge channel shift percentages and needs, i.e. ‘Why wouldn’t you use the online service? ‘ and provide them with several options to answer.\n- Establish what successful interactions with the service look like for users of all types performing different tasks. Break them down into specific tasks for success, e.g. successfully adding a new bank account, then assess satisfaction scores by task.\n- Be able to assess satisfaction across segments of users both with and without AD needs.\n- Define anticipated conversion funnels before move into beta. Best guesses will suffice if there is no initial data to define them. Ongoing analysis will test any assumptions made and highlight any areas requiring qualitative testing to uncover why users are dropping out at a particular stage of the funnel.\n- Based on the breakdown of specific user tasks and conversion funnels (see earlier points), define other operational and functional KPIs that allow the current success of the service to be assessed at a glance.\n- In addition to metrics that can only be measured infrequently (e.g. results from an annual survey), identify meaningful metrics for the service that can be monitored monthly, weekly, daily. A meaningful metric is one that prompts a change in behaviour in response.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/apply-for-a-design-self-certification/",
    "title": "Apply for a Design - Self Certification",
    "summary": "The Apply for a Design service is a new online service that enables people or businesses to apply for the registration of a design.",
    "body": "Design rights refer to the appearance, physical shape, configuration and decoration of a product. The product can be registered by the owner to prevent other people copying or stealing it.\n\nRegistering a design gives you exclusive rights to use it for up to 25 years and makes taking legal action against infringement and copying more straightforward.\n\n**Department / Agency:**  \nBIS / Intellectual Property Office\n\n**Date of Assessment:**  \n27/1/2015\n\n**Assessment stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nM. Fairhurst\n\n**Service Manager:**  \nL.&nbsp;Adams\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## Assessment Report\n\nThe Apply for a Design service has been reviewed against the 26 points of the digital by default service standard at the end of the Alpha development. It should be noted that it was only the web application that was assessed and the back office application was deemed out of scope.\n\nAfter consideration the assessment panel have concluded that the part of the service which was assessed is on track to meet the service standard at this stage of development.\n\n**Areas of good performance against the standard**\n\n_User needs_\n\nThe assessment panel were pleased to see that user needs are being considered, with a wide range of user research across their user demographic; individuals, SME’s and a small number of users who specialise in design rights.\n\n_Design_\n\nThe team are clearly focused on designing a service that will be simple and intuitive for users, clearly based on adopting consistent GOV.UK styling and language. They have performed a great deal of insight looking at language, and since October 2014 have used this insight not only to iterate on the Alpha service, but also to make changes to the legislation supporting the service to enable digital transformation and overall efficiencies. Changes to the paper form alone has resulted in a reduction of first time rejects from 88% to 47%. There is also a clearly described strategy for digital by default adoption, making a digital service so good that users prefer to use it, leading to organisational and user efficiencies.\n\n_The team_\n\nA good multi-disciplinary team is in place, driven by an empowered service manager. The service manager is new to the position and its responsibilities, but clearly has all the skills necessary to fulfil the role and is enthusiastically moving the service into the Beta phase.\n\n**Recommendations**\n\n_User needs_\n\nIt was agreed that during the Beta phase that users on the lower spectrum of the digital inclusion scale would be identified, and the service tested with them. It was also agreed that specific research would be undertaken to investigate needs from the 16% of users who stated they would not use an online service. Both sets of research would be instrumental in agreeing the assisted digital (AD) strategy. It is strongly encouraged that during Beta, the team should have users embedded within the development team so that the service can be iterated frequently. The team will also benefit from building a relationship with real users rather than being detached via a research group.\n\n_Open source_\n\nThe code has not been open sourced. As there are no barriers to opening up reusable assets, and the Intellectual Property Office (IPO) are happy to do so, the panel recommends that it should be considered and implemented during the Beta phase.\n\n_Assisted digital_\n\nThe team have started to define the assisted digital strategy but this needs further work and will need to be put in place for the Beta phase. A number of options are under consideration and need to be finalised into the strategy. It was recommended that IPO should engage initially with IPO’s AD lead and then, if required, with the GDS Assisted Digital team to assist with this work.\n\n_Analysis and benchmarking_\n\nMore robust analytic tools will need to be employed for the Beta phase to measure service take-up and performance against success criteria. The plan to use PIWIK would be deemed a necessity by the assessment panel. The panel commended the ongoing dialogue with the Performance Platform for IPO services.\n\n**Summary**\n\nIt was noted by the team that the service specifically focused on the capture of information but lacked the ability for a user to “monitor” the submission once made. Without this facility, the issue of avoidable calls and progress-tracking updates will remain unresolved for IPO and users. There is a strategic programme of work underway geared towards transforming IPO digitally, which is looking at these specific features globally, “MYIPO” for example. The team felt that as part of Beta, a much clearer plan of these integration points is required to provide assurance that the full user journey has been considered and presents a good, consistent user experience.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | N/A |\n\n| **Details of criteria that are not applicable to this service** |\n| 26 – not applicable to service with fewer than 100k transactions p.a. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/make-a-plea-self-certification/",
    "title": "Make a Plea - Self Certification",
    "summary": "The Make a Plea service will allow people to enter their pleas online for summary traffic offences; which would not result in a prison term for the defendant if convicted. This service aims to:",
    "body": "- Reduce the number of defendants attending court unnecessarily.\n- Create a public plea entry for traffic offences.\n- Provide a fee payment mechanism for guilty pleas.\n- Allow the re-scheduling of hearings.\n- Show results of cases and notify defendants online.\n\nThe scope of the initial Minimal Viable Product (MVP) is for summary, non-imprisonable traffic offences in Greater Manchester. The subsequent goal is to deliver a nationally scalable service (on behalf of the HM Courts & Tribunal Service (HMCTS) Common Platform Programme) by March 2015.\n\n**Department / Agency:**  \nMOJ\n\n**Date of Assessment:**  \n28/1/2015\n\n**Assessment stage:**  \nAlpha\n\n**Lead Assessor:**  \nJ. Busuttil\n\n**Service Manager:**  \nN. Gallon\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## Assessors Summary\n\n**Assessment Report**\n\nThe service was assessed against all 26 points of the Digital by Default Service Standard. We asked questions from the prompts and evidence for assessors, supplied by GDS. This document has questions and the evidence sought for alpha, beta and live phases. The assessment panel asked questions from the alpha section.\n\nThe service currently meets the requirements of the standard for an alpha. Areas of good performance against the standard included:\n\n_User needs_\n\nThe team has been particularly good at understanding user needs. The initial assumption about the digital service was that it would reduce unnecessary court attendance, but the team’s research found that most people attending court did in fact need to be there.\n\nThe team therefore shifted focus onto:\n\n- Making the information provided to defendants (the “requisition pack”) easier to understand.\n- Simplifying the process of submitting a plea with the required supporting information.\n\nThe team has conducted frequent user research during discovery and alpha phases to create and iterate the prototype. They conducted 30 user interviews in discovery and have been running one user research session (with 6-8 users) each month.\n\nOngoing research is planned, with assisted digital (AD) being a significant area to investigate further.\n\n_The team_\n\nThe team was initially comprised of London-based MOJ Digital Service (MOJDS) staff, who have since handed over to a MOJDS team based at Manchester Coroner’s Court. The handover was completed fully with minimal disruption. The current team is empowered, multidisciplinary, has separation of key roles and is working with their counterparts on the Common Platform programme.\n\nStakeholder communication is good: two key stakeholders are co-located with the team; they share information from the wider organisation and participate in the team’s daily standups 2-3 times per week. The team provides a weekly update to a wider group of stakeholders, and monthly show and tells with HMCTS.\n\n_Design_\n\n95% of users are successfully completing the process unaided and first time with the alpha service. Dropouts were primarily because users did not wish to answer questions relating to their employer (users were worried their employer would find out about the traffic offence) and their finances. The service was accordingly redesigned to request financial information only when required rather than for all cases.\n\nThe team will have an opportunity to feed changes into the content of Greater Manchester Police’s requisition pack in April. As an interim measure, the team has used a yellow paper insert to direct users to the digital service first. The digital service then guides users to locate the required information in the requisition pack allowing them to respond online more easily.\n\nThe team will also be sharing their user research and design work with the Metropolitan Police to help them iterate on and simplify the content of their own requisition pack, though this work is outside the planned scope and timescales of this iteration of the digital service.\n\n**Recommendations**\n\n_User needs_\n\n- Bring examples of the requisition pack, yellow paper inserts and yellow envelope sticker to the beta assessment. Include details of end user demographics (including AD needs survey results and service development) and show personas for all users of the service.\n\n_The team_\n\n- Introduce more objective prioritisation techniques for non-functional backlog items to ensure they are balanced appropriately with functional user stories.\n\n_Security, privacy, tools and standards_\n\n- Advise stakeholders on likelihood, duration (40 minutes, assuming complete rebuild and restore) and impact of service outage, and seek their sign-off.\n- Abbreviate user’s surname to an initial in the optional confirmation email to users to remove personally identifiable information.\n- Have an alternate / fallback email delivery system to current system.\n- Introduce GOV.UK Verify (already on backlog) for identity assurance of defendants making a plea online.\n- Establish anticipated levels of load for a national deployment of the service and run appropriate load tests during beta phase.\n- Mitigate email noise and anomalous submissions by validating case uniform resource names (URNs) during the process.  \nDocument the disaster recovery plan from the knowledge already within the team; include steps to recover from a hosting failure.\n- Create Domain Name System (DNS) based holding pages for outage and forced shutdown.\n\n_Improving the service_\n\n- Automate the integration and smoke tests.\n- Work with the policy team to start the process of identifying and potentially removing legislative barriers.\n- Check if people are searching for information on how to make a plea online on GOV.UK as a potential alternative entry point to the service.\n\n_Open source_\n\n- Code in the open; nothing is stopping the team from opening up the source, so they should do so at earliest available opportunity.\n\n_Design_\n\n- Update the GOV.UK design patterns and toolkit in use to the most recent version.\n- Consider improving the layout and text size of the information on the first screen that lets users know that there’s a 33% saving if pleading guilty.\n\n_Assisted digital and channel shift_\n\n- Create a plan for AD channels, including details of costs and funding.\n- Seek best practice from GDS on surveying user satisfaction for AD channels, frequency of surveys and describe how this will inform performance and channel shift plans.\n- Focus on creating AD scripts to triage people efficiently in the call centre; make room in sprints for that kind of iteration.\n- Ensure the survey is robustly estimating the number of transactions; consider sample size during the beta trial with the call centre, use assistance from Analytical Services to ensure robust statistics and data.\n\n_Analysis and benchmarking_\n\n- Ensure there is data available in the beta phase for the results of the user satisfaction survey.\n\n_Testing with the minister._\n\n- The team has demonstrated the alpha service to Shailesh Vara MP on 15th January 2015 and plans to test it again with the minister before going fully live.\n- \n* * *\n\n## Digital by Default Service Standard criteria\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/charities-registration-self-certification/",
    "title": "Charities Registration - Self Certification",
    "summary": "Charities need recognition from HMRC to claim gift aid. Charities currently do that on a paper form. The digital service will allow customers to make a validated application online. The team are working toward a public beta date in January 2015.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n8/1/2015\n\n**Assessment stage:**  \nBeta\n\n**Lead Assessor:**  \nR. Morgan\n\n**Service Manager:**  \nI. Atkin\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessors Summary\n\nFollowing assessment against the 26 Digital by Default Service Standards the HMRC Assessment Panel can confirm that the Charities Registration service has shown clear evidence of meeting the Digital by Default Service Standards at beta.\n\nThe panel were pleased to see how the service had developed since the alpha assessment and are interested to see continued progress along the same lines during public beta.\n\nIt was clear that the team had addressed the comments of the panel made at the alpha assessment and made great progress in developing this service.\n\nThe panel had two key recommendations:\n\n- Monitoring of feedback on the standard ‘time out’ message – ‘not authorised’ may confuse users of this service\n- Supporting the exploration/development of digital submission of supporting documentation and links to Charities Commission to reduce additional contact and improve the user experience.\n\n**Assessment report**\n\nThe panel viewed a demonstration of the service. The demonstration ran well and clearly showed a logical flow for the user journey.\n\n_User needs_\n\nThe panel were pleased to hear of the thorough user research conducted so far and the plans made for public beta research.\n\nUser research has been undertaken with over 200 charities in 50-60 sessions involving lab testing, surveys&nbsp;and&nbsp;guerrilla testing. At alpha assessment the panel had been concerned about some of the terminology used on the screens; this has been addressed and a card matching exercise proved particularly useful. End-to-end testing has been undertaken to get most benefit for service development. Users have been invited into the Digital Delivery Centre (DDC), been visited at their place of work and even in their homes. At alpha the panel noted that the digital service manager&nbsp;had been challenging the business to understand the concept of building services for user needs. Since then research sessions have been recorded and shared with the business at monthly show and tells and business representatives were invited to user research sessions. This has brought about a change of mindset for the business and there is now greater understanding of the importance of user needs.\n\nA user research plan is in place for the next stage of development including a specific exit survey for this service and continued use of analytics.&nbsp;Increased value will be added as more users have access to the service. The user researcher is investigating the use of Skype to watch users completing their registration in real time.\n\nFollowing registration of details the charity official must submit charitable status documents to HMRC. The team are now to look at submission by scanning or other digital means or to create links to the Charities Commission to negate the need to submit documents.\n\nGift Aid has been made mandatory online so the team have linked in to that research also.\n\nA great deal of information has been collected about the users for this service and this has challenged the personas in place.\n\nAccessibility testing has been carried out.\n\nThe panel saw strong evidence to support changes being made to the service as a direct consequence of user feedback, for example the three eligibility questions at the start of the service. The feeling was that the user should drop out of the service as soon as their answer to a question made them ineligible for registration – user research has shown that users prefer to work through the three questions and then be told the reason for their ineligibility. In that way they can see the exact cause and know what information they need to collect for eligibility rather than working through one item at a time.\n\nSave and retrieve is now in place for this service. The landing page provides a list of details required to complete the registration and the team will be adding a completion guide time.\n\nThe panel would recommend monitoring user feedback on the use of the wording ‘not authorised’ in timeout text. Although this is standard content it could prove confusing given the nature of the service.\n\n_The team_\n\nThe good team dynamic set up during alpha has continued to thrive.\n\nAgile methodologies continue to be used i.e. daily stand ups, show and tells, use of agile tools and the sprint cycle. Business representatives attend the monthly show and tells, the benefits of which have already been highlighted.\n\nRelationship with the business has continued to develop and as mentioned above the user needs mindset being developed by the business is down to the excellent work of both the team and goodwill from the business.\n\nTransfer of skills is taking place within the team and has also improved the overall capability of the DDC. Following alpha assessment, the team had a lot of work to develop the service and further additional capacity was identified in another scrum team. The additional resources were new to the DDC and HMRC. The digital service manager&nbsp;successfully included these resources into his team, sharing knowledge whilst meeting deadlines. At the completion of the work the additional resources returned to their original scrum team and were able to hit the ground running having had the benefit of working with this team. A win-win situation all round, and a credit to the digital service manager&nbsp;and the team ethic developed.\n\n_Security, privacy, tools & standards_\n\nA Risk Management and Accreditation Documentation Set (RMADS) is&nbsp;in place and passed for beta. The Business Impact Assessment is signed off. Requirements for Secure Delivery of Online Public Services (RSDOPS) is in place and updated in readiness for Change Framework Gates.&nbsp;The service team is engaged with the Chief Technology Officer (CTO)&nbsp;and&nbsp;data guardians. Information Management Service Project and Digital Fraud Group has had sight of the service.\n\nStandard DDC-Newcastle tools such as Google Analytics and Splunk will be used to monitor and measure the service. Current estimates suggest that 300 digital registrations will be received weekly. The team are confident of the service's capacity to meet user demand in public beta. Performance testing has proved this. In addition concurrency testing has been undertaken successfully with 200 concurrent users.&nbsp;The service sits on the tax platform, and uses the&nbsp;platform's established disaster recovery procedures. Users are notified of service downtime ahead of scheduled maintenance. In the event of any incidents with the service, the team will obtain details/feedback from Deskpro.\n\nThe service is using standard DDC-Newcastle tools e.g. Splunk, and has transaction monitoring in place.&nbsp;A local environment is used for testing. No security concerns were identified with the service's existing kit.\n\nThe service is supported on all devices, and there has already been a submission by phone.\n\nOpen source code will be published on GitHub in the very near future.\n\nThe service complies with HMRC Cookie Policy.\n\n_Improving the service_\n\nThe process for deployment was explained, along with the changes and testing of new iterations. No down time is required to make changes.&nbsp;ASPIRE reports show that submissions are delivered to the back end systems/lists correctly. Deployment of changes to the front end service can be made quickly. It is envisaged that in the future with enhancements to the existing process that the digital service manager&nbsp;will have authority to deploy.\n\nPlans are in place to develop the service through user research and analysis (Key Performance Indicators (KPIs)).\n\n_Design_\n\nEnd-to-end testing has been undertaken. Drop out points have been identified and actioned.\n\nNon-digital steps are the submission to HMRC of legal and supporting/supplementary documentation, and the manual review of the documents on receipt. The panel where please to learn&nbsp;that the digital service manager&nbsp;is working with the business and operational area to review all these aspects and look at digital solutions.\n\nThe team are monitoring the effectiveness of free text boxes remaining on the service, with a view to replacing them with, for example, radio buttons.\n\nScreens have been created in accordance with the GDS style guide; this was also evidenced during the demonstration.\n\n_Assisted digital & channel shift_\n\nIt is clear that there is a good understanding of assisted digital (AD) across the team. Whilst it had been a challenge to identify an AD user to date, the team are working with key AD stakeholders and have developed a strategy and plan to take this forward.\n\nThe service team has been engaged with the strategy team and the dedicated charities support unity.\n\nA plan to increase digital take-up is in place.\n\n_Analysis & Benchmarking_\n\nAnalytical tools have been identified; Google Analytics and Splunk.\n\nIn addition to the four core KPIs, the team will be measuring:\n\n- Reduction in ineligible applications (working with Specialist PT for a baseline figure)\n- Time to&nbsp;completion\n- Customers using the 'save for later' function\n- Submission of paperwork on time\n- Reduced number of calls\n- Where any paperwork is missing – what is it and why – (to reduce follow up telephone calls)\n- Cases passing straight through to operational decision makers\n\n_End-to-end service testing_\n\nThe digital leader, Mark Dearnley, has been invited to test the service.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | N/A | 22 | N/A |\n| 23 | N/A | 24 | N/A |\n| 25 | Yes | 26 | N/A |\n\n| **Details of criteria that are not applicable to this service** |\n| 21, 22, 23, 24, 26– not applicable to service with fewer than 100k transactions p.a. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/people-finder-service-assessment/",
    "title": "People Finder – Self Certification",
    "summary": "People Finder aims to be provide an accurate, easy to maintain search service for staff to find where, when and with whom staff work within MOJ HQ. Currently used by MOJ Digital Services, the service is expanding to include an additional 700 users from two other teams within MOJ as a beta service. After completion of the beta phase, the service will roll out to several thousand users across MOJ HQ&nbsp;at 102 Petty France.",
    "body": "**Department / Agency:**  \nMOJ\n\n**Date of Assessment:**  \n9/1/2015\n\n**Assessment stage:**  \nBeta\n\n**Lead Assessor:**  \nT. Dolan\n\n**Service Manager:**  \nM. Maddon\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## Assessors Summary\n\nPeople Finder service is seeking permission to launch as an beta service.&nbsp;After consideration the assessment panel have concluded the People Finder service has shown sufficient progress and evidence of meeting the Digital by Default Service Standard criteria and&nbsp;should proceed to launch as a beta service within the MOJ.\n\n**Reasons**\n\nThe service was assessed against all 26 points of the Digital by Default Service Standard and&nbsp;the assessment panel were particularly impressed with:\n\n- User needs and scenarios of use clearly identified and expressed for user journeys&nbsp;through the service.\n- Extensive testing in the target users’ real working environment.\n- The mandate for change that the service manager had obtained from senior&nbsp;stakeholders to overcome any inertia - that managers will be responsible and&nbsp;accountable for populating and keeping the service up to date.\n- The work the service team&nbsp;had done in designing a service so as to overcome the cultural, technical and organisational issues that had led to previous projects in this space becoming out of date.\n- The thorough documentation and evidence the team had prepared for the assessment.\n- The carefully balanced view taken when gathering feedback on a tool that is designed to&nbsp;encourage cultural change.\n- Great practice in alignment with general HQ needs across assisted digital (AD) and&nbsp;accessibility, and identifying a target group for the next phase.\n- Collaboration with GDS to reuse the code on a different project.\n- The team’s close working spirit and ability to fully represent themselves in the&nbsp;assessment, despite the assessment&nbsp;occurring within a short period without a product manager.\n\nThe team have a very detailed understanding of their users and a strong roadmap for service&nbsp;improvements, some of which were already visible in the demonstrated service. They identified&nbsp;that AD users would become an increasingly large part of the user base, were the service to be&nbsp;released more widely.\n\nWe are also pleased that the need for a product manager had already been addressed, with the&nbsp;appointee due to start within days of the assessment.\n\n**Recommendations**\n\nWe strongly recommend that the team carefully consider their release strategy to ensure initial&nbsp;user satisfaction and expectations are met. While the service is easy to use, it will still be&nbsp;unfamiliar and benefits will not be seen until more user data has been added. A cold launch to&nbsp;700 users at once with no training may limit sustained channel shift; a more gradual release&nbsp;should be investigated as this would allow additional iteration and can create advocates for the&nbsp;new product.\n\nIn advance of the live release the team must:\n\n- Create a clear statement for 'what success looks like' for the service users - it may take&nbsp;several forms.\n- Ensure that you carefully plan the engagements of the proposed departments for public&nbsp;beta, and include clear research/communication elements to tackle behavioural change&nbsp;in use of Firefox away from IE, as the team have stated.\n- Investigate implementation of search once higher volumes of data are in the system -the current approach of partial matching strings within words can lead to noisy results,&nbsp;and searching across different data fields could also potentially confuse (e.g. a person&nbsp;named Ruby vs. the programming language Ruby).\n- Clarify the security accreditation status - whether authority to operate has been granted,&nbsp;and/or final security accreditation has been received.\n- Verify with GDS and/or your security accreditor or information asset owner whether or&nbsp;not a full cookie policy is required.\n- Ensure that the service has monitoring in place before expanding the service out to more&nbsp;users - at a minimum server load (CPU/memory/disk etc.) and traffic volumes (requests&nbsp;per sec etc.) should be actively monitored, with automated alerts to the technical team,&nbsp;alongside existing Pingdom setup.\n- Establish with your security consultant or accreditor&nbsp;how security incidents should be reported.\n- The technical team must investigate the feasibility of zero (or near zero) downtime deployments.\n- Complete the documentation of forced shutdown scenarios, so that a member of a&nbsp;different team would be able to perform this task and escalate as appropriate.\n- Gather feedback on icons in the organisational chart feature to determine whether these meet a&nbsp;real user need and if there are better ways to denote this.\n- Test the ‘show everyone in this department’ feature, which could easily be missed. If this&nbsp;is an important feature it should be emphasised.\n- Continue to test the skills and expertise tagging feature, changing it so that it avoids&nbsp;becoming cumbersome or full of duplicates.\n- Perform specific AD&nbsp;needs and accessibility testing in good time for live&nbsp;assessment in order to demonstrate a reasonable AD service as part of the public beta (if&nbsp;the AD needs testing demonstrates an AD route through the service is necessary).\n- Expand the HQ personas used to include specific&nbsp;personas - for live assessment&nbsp;we will expect to see People Finder user needs and documentation influencing the overall&nbsp;HQ shared documentation. The panel would love for People Finder user&nbsp;needs/scenarios/personas to influence the knowledge the department gathers about users&nbsp;for future HQ products and services.\n- Ensure the team have a sustained period where they are able to concentrate on making&nbsp;rapid improvements on one single service as the userbase expands, rather than being&nbsp;divided across two HQ projects.\n\n**Summary**\n\nIn summary the assessment panel are pleased to report that the service is ready to progress to&nbsp;a public beta stage. The work carried out during alpha and private beta to iterate and improve&nbsp;the service based on the needs of users was very encouraging and we are looking forward to&nbsp;seeing how the service further improves now that a larger number of users will be able to&nbsp;access it.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| Criteria | Passed | Criteria | Passed |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | N/A |\n\n| **Details of criteria that are not applicable to this service** |\n| 26 - not applicable to service with fewer than 100k transactions p.a. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/the-queens-awards-for-enterprise-self-certification/",
    "title": "The Queen's Awards for Enterprise - Self Certification",
    "summary": "The Queen’s Awards for Enterprise is a replacement service for an existing 100% digital service that enables UK businesses, including those based in the Channel Islands and the Isle of Man, to apply for a corporate award recognising their outstanding achievement in:",
    "body": "• Innovation  \n• International Trade  \n• Sustainable Development\n\nThere is also an award for individuals, The Queen’s Award for Enterprise Promotion, which individuals are nominated for to recognise their outstanding role in promoting the growth of business enterprise and/or entrepreneurial skills in others.\n\nThe Queen’s Awards for Enterprise competition is run annually and applications and nominations can be made from April to September. Following this, entrants are assessed and shortlisted, with recommendations made by the Prime Minister’s Advisory Committee. Winners are decided by Her Majesty the Queen and announced each April.\n\n**Department / Agency:**  \nBIS\n\n**Date of Assessment:**  \n17/12/2014\n\n**Assessment Stage:**  \nAlpha\n\n**Lead Assessor:**  \nM. Fairhurst\n\n**Service Manager:**  \nL.&nbsp;Stephens\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## Assessors Summary\n\nThe Queen’s Awards for Enterprise service has been reviewed against the 26 points of the digital by default service standard at the end of the Alpha development.\n\nAfter consideration the assessment panel have concluded that the service is on track to meet the service standard at this stage of development.\n\n**Areas of good performance against the standard**\n\n_User needs_\n\nThe assessment panel were pleased to see that user needs are being considered, with a good understanding of the service's user demographic. The panel were impressed that feedback from a number of sources including the existing service, user research, surveys and usability testing, had been used on a daily basis throughout the alpha to iterate the service.\n\n_The team_\n\nA good multi-disciplinary team is in place, using the development services of an SME but being driven by an empowered service manager.\n\n_Open source_\n\nIt was pleasing to see that the code base was in open repositories on GitHub, although they need to be moved from the supplier to a secure repository for BIS.\n\n**Recommendations**\n\n_The team_\n\nThe team are working in an agile way with weekly iterations and collaboration across sites. They have tried to use collaborative tools such as Trello, but browser issues have made this difficult. The team have overcome these problems with the use of email, telephone contact and face-to-face meetings. They are aware that a collaborative tool would aid delivery and are actively looking into a solution that they can all use. The panel recommend that they make this a priority as they move into the beta phase, which will involve greater collaboration with internal staff within BIS.\n\n_User needs_\n\nIt was agreed that during the Beta phase, users on the lower spectrum of the digital inclusion scale would be identified and the service tested with them, which would also be instrumental in agreeing the assisted digital (AD) strategy.\n\n_Security, privacy, tools and standards_\n\nIt was agreed that the infrastructure in place today was sufficient for the alpha, but a more robust and scalable infrastructure will need to be put in place before moving to private beta. It was also acknowledged that performance testing and penetration testing will need to be performed once the supplier of the infrastructure is identified and their services procured.\n\n_Assisted digital_\n\nThe team have started to define the AD strategy which will need to be put in place for the Beta phase. Conclusions need to be reached on options such as:\n\n• The ability for a member of BIS staff to complete over the telephone.  \n• On-site visit to the BIS office to complete.\n\n_Analysis and benchmarking_\n\nMore robust analytic tools will need to be employed for the Beta phase and the plan to use Google Analytics would be deemed a necessity by the assessment panel. Further consideration should be made on the use of the existing service analytics and how they can be compared with the new service, particularly in the area of user satisfaction. This will provide evidence that the service has been improved, whilst being a source of insight into where further improvements could be made.\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | N/A |\n\n| **Details of criteria that are not applicable to this service** |\n| 26 - not applicable to service with fewer than 100k transactions p.a. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/academic-technology-approval-scheme-self-certification/",
    "title": "Academic Technology Approval Scheme - Self Certification",
    "summary": "Academic Technology Approval Scheme (ATAS) is a vetting service for foreign students who come to the UK to study proliferation-sensitive topics.",
    "body": "**Department / Agency:**  \nForeign & Commonwealth Office\n\n**Date of Assessment:**  \n17/11/2014\n\n**Assessment Stage:**  \nBeta\n\n**Lead Assessor:**  \nA. Bye\n\n**Service Manager:**  \nD.&nbsp;Grzenda\n\n**Digital Leader:**  \nP. Buckley\n\n* * *\n\n## Assessors Summary\n\nATAS is a vetting service for foreign students who come to UK to study proliferation-sensitive topics. About 20,000 applications are made a year. The assessment panel were given a walkthrough of the service. The transaction consists of an online form which applicants complete combined with a backend which the FCO uses as it processes applications. A login is required to the system. It replaces a previous system which is now well out of date.\n\n**The team**\n\nThere is a dedicated service manager who is also the policy lead official.\n\nThe service was developed by an external supplier experienced in agile development, alongside GDS who took on a role helping FCO manage the contract (at that point, FCO had limited internal expertise in service transformation). An additional supplier took on work to finalise development and will also maintain the service.\n\n**User needs**\n\nThe team drew on customer feedback on the previous system and also tested the new transaction with around 20 students who had also used that system. Feedback fed into user stories that went back to the developers and led to changes to the service, e.g. clarifying some of the requirements; making improvements to the back end of the service. Several important user stories remain outstanding.\n\nPost launch the team will continue monitoring feedback to their service mailbox. There will also be a schedule of user testing as part of the broader user testing arrangements being putting in place by the Digital Transformation Unit.\n\n**Security, data, testing and standards**\n\nData protection arrangements have been defined and approved by the Senior Information Risk Owner and internal IT security advisers. There is a high data protection requirement given that some data is kept indefinitely to compare with previous applications.\n\nSecurity tests have been carried out and outstanding issues are being rectified. The requirement for future tests is built into maintenance arrangements.\n\nHosting arrangements reflect the high data protection requirement.\n\nThe source code was peer reviewed by GDS before being finalised by the supplier. At present security requirements are too entangled with the general code to allow general open source release. This is something that could be reviewed in the future.\n\nA login is required for the service. The service is targeted exclusively at foreign nationals, and therefore out of scope of the Verify service.\n\nA development site will be in place post live.\n\nIn terms of major problems, the team can, in extremis, tolerate some outages or fall back to a non-digital service. The maintenance contract with the supplier provides SLAs on dealing with different levels of service problem.\n\n**Assisted digital and digital take-up**\n\nThe service is fully digital. The Digital Transformation Unit will be looking at assisted digital needs more broadly over the coming year.\n\n**Design**\n\nThe system has been designed in line with the GOV.UK style guide (though see below) and is fully responsive.\n\n**Analysis and benchmarking**\n\nThe service will provide data on the number of applications, while the supplier is standing by to install the PIWIK web analytics used by the Digital Transformation Unit.\n\nThe team have had some contact with GDS on integration of this data into the performance platform.\n\nA done page will be worked on with GDS, providing satisfaction rates.\n\n**Testing the service with the minister**\n\nThe team intend for the minister to test the service shortly before it goes live.\n\n**Conclusion**\n\nThe assessors concluded the new transaction was a very significant improvement on the previous service – better designed, responsive, underpinned by a service level agreement in place and analytics. The service has also been developed in line with the Digital by Default Service Standard.\n\nThe assessors noted, however, a number of actions that needed to be taken before the service could go live. Subject to those actions being completed they approved the service for launch in live beta (with the previous service being decommissioned). This reflects the scope for more user testing to further refine the transaction before full live.\n\nThe Assessors would like to be updated on progress against these actions before live beta and again before full live.\n\n**Actions required before live beta**\n\n- The transaction,&nbsp;including guidance around the service,&nbsp;should be double checked by a content designer to ensure text is as streamlined as possible and the entire transaction is in line with the GOV.UK style guide (e.g. in terms of footers; positioning of key actions; headers; buttons etc).\n- The team should develop a clearer user testing schedule, taking advantage of the live beta period as well as the May-September peak period for service use. The team should make sure they have arrangements in place to iterate the service based on user testing.\n- The team should fix, or ensure acceptable mitigation, for the few outstanding medium/high security issues.\n\n**Actions required before full live**\n\n- The team should ensure that the incoming service manager has completed GDS service manager training.\n- The team should collect metrics on how their ongoing suppliers are performing so they can make future decisions e.g. on hosting.\n- The team should resolve some minor styling issues around making the service fully responsive.\n- The team should consider offline statistics they could add to the performance platform, e.g. how long it is taking an application to be processed and approval/rejection rate.\n- The team should work up cost per transaction figures that are comparable with the old system.\n- The team should engage with GDS on how to surface ATAS in internal GOV.UK search.\n- The team should formalise their plan for what they will do in the event the service is temporarily offline;&nbsp;the service should have been tested with minister.\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |\n\n&nbsp;"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/tier-2-visa-service-self-certification/",
    "title": "Tier 2 Visa Service - Self Certification",
    "summary": "The service allows applicants already in the UK to extend their Tier 2 Visa using a simple online process.",
    "body": "**Department / Agency:**  \nHO\n\n**Date of Assessment:**  \n21/10/2014\n\n**Assessment stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nE. Charles\n\n**Service Manager:**  \nT.&nbsp;Buck\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## Assessment Report\n\nThe service has been designed using extensive research on the ongoing service and has used a user survey to sample sentiment and wider feedback from the Private Beta group. This has been used to deliver further service improvements. The feedback received has been overwhelmingly positive.\n\n**Recommendations**\n\nThere were no actions that were required for sign-off. The following areas for discussion should be addressed.\n\n- SIRO sign-off should be secured.\n- The service requires a firmer outline plan about how it will use analytics and further user testing with the public beta to drive further improvements before going to into the live stage.\n\n**Next steps**\n\n- SRO sign-of will be secured prior to launch.\n- Work is underway to identify sections of code for publication in open source repositories.\n- Work is underway to integrate with the GOV.UK performance platform.\n- Arrangements are being made to test&nbsp;the service with the minister&nbsp;responsible for the service.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/gambling-tax-online-stage-1-self-certification/",
    "title": "Gambling Tax Online (stage 1) - Self Certification",
    "summary": "As the gambling industry has become more international and internet focused, some gambling operators can, and do, base themselves 'offshore' which means they do not have to pay UK gambling taxes. It is estimated that the remote gambling industry market in the UK is worth over £2 billion p.a.",
    "body": "HMRC is implementing new rules to reflect these changing times, by introducing changes to the law from 1st December 2014. The new rules will ensure remote operators pay UK gambling taxes on gambling profits generated from people in the UK, no matter where in the world the operators and based. The Government announced these changes at Budget 2012. Under current tax rules, gambling activities are subject to UK gambling taxes on a place of supply basis. Changing to a place of consumption basis means remote gambling operators will pay UK tax on gross gambling profits generated from UK persons no matter where in the world the operator is located.\n\nThe first stage of the service will require new operators who have to pay General Betting Duty (GBD), Pool Betting Duty (PBD), and Remote Gaming Duty (RGD) to register for the online service. The second stage of the service will provide the facility for operators to file their returns, make payments, and make changes.\n\n* * *\n\n**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n17/10/2014\n\n**Assessment stage:**  \nLive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nR. Morgan\n\n**Service Manager:**  \nJ.&nbsp;McDonald\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment Report\n\nAfter completing the assessment the HMRC Assessment Panel confirm that the Gambling Tax Online service has shown sufficient evidence of meeting the Digital by Default Service Standard to go live, enabling the registration of operators from 1st December 2014.\n\nWith a niche audience, user research was conducted with representatives from across the gambling industry and contact with the Association of British Bookmakers. This enabled the team to work with a range of businesses, from major international operators to family run businesses. The team will continue to work with the assisted digital team to develop assisted digital support going forward.\n\nCurrent policy does not make registration and online filing mandatory, however the team have put together a robust communications plan for traders and embassies to drive take-up.\n\nIt was clear throughout the assessment that the team had worked well together and used the expert knowledge of account managers and their contacts to develop this service.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | N/A |\n| 7 | Yes | 8 | N/A |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | N/A | 14 | N/A |\n| 15 | N/A | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | N/A | 20 | Yes |\n| 21 | N/A | 22 | N/A |\n| 23 | N/A | 24 | N/A |\n| 25 | Yes | 26 | N/A |\n\n| **Details of criteria that are not applicable to this service** |\n| 6, 8, 13, 14, 15, 19 - not applicable to inflight projects as per GDS&nbsp;Operations Board agreement.  \n21, 22, 23, 24, 26 - not applicable to service with fewer than 100k transactions p.a. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/intelligence-management-system-ims-self-certification/",
    "title": "Intelligence Management System (IMS) - Self Certification",
    "summary": "This is a replacement for the current form for reporting an immigration or customs crime.",
    "body": "**Department / Agency:**  \nHO\n\n**Date of Assessment:**  \n22/10/2014\n\n**Assessment stage:**  \nBeta - Voluntary\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nC. Williams /&nbsp;E. Charles\n\n**Service Manager:**  \nD. Pennant\n\n**Digital Leader:**  \nN. Driskell\n\n* * *\n\n**Assessment Report**\n\nThis service has been redesigned in line with the GOV.UK style guide. The user research shows that the form is simple to use and can be completed unaided first time.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/student-course-information-tool-self-certification/",
    "title": "Student Course Information Tool - Self Certification",
    "summary": "This is a new, time-limited, tool to support approximately 5,500 overseas students to find an alternative sponsor and place to study if the institution they were studying at has had its licence to sponsor international students revoked.",
    "body": "Each affected student will be issued a curtailment letter and have 60 days from receipt to find and enrol on an alternative course; otherwise they will need to leave the country.\n\nThe letter details a number of options and sources of information and support available to the affected students.\n\nOne of the options is to use this Student Course Information Tool to identify available courses, which they can separately apply for. Access to the tool is via a unique ‘student key’ provided in their letter.\n\nThe tool has been developed by the Higher Education Funding Council for England (HEFCE) on behalf of UK Visas and Immigration (UKVI).\n\nIt is designed to provide a simple and quick way for the affected students to identify available courses and find further information on the institutions and the courses on offer.\n\nThe tool is an online, read-only register, and re-uses information already held by HEFCE, which will be refreshed and updated regularly. Students do not need to input any personal information to use the tool and no personal information is saved.\n\nIt is currently anticipated that the tool will not be required beyond February 2014, as all affected students will have by then found alternative courses or left the country.\n\n[https://www.gov.uk/find-course-sponsor](https://www.gov.uk/find-course-sponsor)\n\n**Department / Agency:**  \nBIS / Higher Education Funding Council for England (HEFCE)\n\n**Date of Assessment:**  \n19/11/2014\n\n**Assessment stage:**  \nBeta - Voluntary\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nA. Graham\n\n**Service Manager:**  \nA.&nbsp;Bowman\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## Assessment Report\n\nThe service assessment was completed on 19th November and the assessors considered the tool against the standard within the context that:\n\n- It was a rapid development to ensure support was available for the affected students in-line with the issuing of the curtailment letters;\n- It is a limited transactional service; and\n- It currently has a finite life and is unlikely to be required beyond February 2014.\n\nOn this basis the assessment panel were content that the tool sufficiently meets the service standard, subject to a number of actions being completed and further recommendations, should the service continue beyond February 2014.\n\nActions to be completed now:\n\n- Continue to work with security advisers.\n- Accessibility checks should be completed. At a minimum the tool should be run through the W3C accessibility checker and any deficiencies made compliant. It would also be advisable to check basic parts such as tab order with a screen reader, to&nbsp;ensure no users are disadvantaged.\n- HEFCE should work with UKVI and establish Google Analytics data and user feedback via the UKVI helpline in order to monitor use of the tool and user satisfaction. If take-up is very limited then it should be reviewed as a matter of urgency and remedial action taken.\n- Given the shared responsibilities for the tool, the Service Manager should seek assurance from both the HEFCE and UKVI SIRO and ensure there is joint accountability for any risks.\n\nRecommendations for further iterations of the service:\n\n- An understanding of users was evident but future iterations of the service must include direct user research with students to ensure user needs are fully met.\n- The terminology used is reviewed and amended as appropriate based on user feedback, e.g. consider using \"Filter:\" instead of \"Search\".\n- Similarly the value of telling users how many places are available should be investigated and whether a last updated date should be displayed and whether the student key is needed.\n- There should be clear ownership of any future versions of the tool, with clear channels and responsibilities to manage and respond to user feedback and insight.\n- A review of the success of this tool should be undertaken and used to influence any future service. The design of which must be designed and implemented as a more \"digital first\" solution based on user needs.\n- An end to end service offering in the future should seek to address the entire user need rather than just the identification of available courses.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | N/A | 8 | No |\n| 9 | Yes | 10 | Yes |\n| 11 | N/A | 12 | N/A |\n| 13 | Yes | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | No | 20 | No |\n| 21 | Yes | 22 | N/A |\n| 23 | N/A | 24 | N/A |\n| 25 | Yes | 26 | N/A |\n\n| **Details of criteria that are not applicable to this service** |\n| 7. Given the limited lifespan of the service this criteria was felt to be unnecessary.  \n8. Whilst a prototype was developed it was not fully tested with real users.  \n11. The service is to address an immediate and specific issue and is a new service – not replacing an existing one.  \n12. No non-digital steps were identified.  \n15. Whilst HEFCE have confirmed they are happy to release the code they do not believe there is value in doing so due to the limited nature of the service.  \n19., 20. Currently there are no plans to continue the service beyond February 2014.  \n22.-24. This is a simple “two step” service with a limited audience therefore measuring completion rates, costs per transaction and digital take up are not considered necessary.  \n26. This is not considered applicable for the size and lifespan of the service. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/trade-challenge-partner-accreditation-service-self-certification/",
    "title": "Trade Challenge Partner Accreditation Service - Self Certification",
    "summary": "Self Certifications are run internally by each department, organised through their responsible Digital Leader. The Digital Leader will certify the service meets the&nbsp;[Digital by Default](https://www.gov.uk/service-manual/digital-by-default/)&nbsp;service standard criteria. The Self Certification process is currently in Alpha, and will continue to be iterated on. Services with over 100,000 transactions a year will continue to be assessed by GDS.",
    "body": "* * *\n\nUKTI Trade Challenge Partner Accreditation is a new service to support applications for three separately-funded programmes that Trade Challenge Partners can apply for:\n\n1. Tradeshow Access Programme (TAP)\n2. Events and Missions\n3. Sector Partnership initiatives\n\nThere are two levels of accreditation.\n\n- Mandatory, first level - all current Trade Challenge Partners must complete this first layer of accreditation to commit to a selection of activities promoting UKTI’s services, the benefits of exporting, and sharing best practice with other Trade Challenge Partners.\n- Optional, second level – only applicable to those who wish to be accredited to participate in the separately-funded programmes. To be successful in this layer of accreditation Partners will need to provide additional information such as financial viability and their capability to deliver to their specific market.\n\nIt is anticipated that around 100 Trade Associations will apply for accreditation but the service will be able to support up to 300.\n\n**Department / Agency:**  \nBIS\n\n**Date of Assessment:**  \n7/11/2014\n\n**Assessment Stage:**  \nBeta\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nP. Turner\n\n**Service Manager:**  \nC. Leaver\n\n**Digital Leader:**  \nT. Knighton\n\n* * *\n\n## Assessment report\n\nThis service was originally assessed against the standard on 9 September 2014. At that point the assessment panel were unable to pass the service without further assurance and clarification against a number of the criterion.\n\nUKTI have since provided further information against the outstanding criterion and further iterated the service in order for the service to be reassessed.\n\nSubject to the following conditions, the assessment panel are content that the service sufficiently meets the standard and can be launched in November.\n\nUser Needs\n\n- UKTI have a dedicated person for the Trade Challenge Partnership, tasked with proactively obtaining user feedback. Users will also be able to submit feedback at any time via the ‘feedback’ button on the Beta banner.\n- Feedback will be gathered continuously through all stages of the process and reviewed at regular intervals providing the momentum, where appropriate, to inform the services next iteration (Criterion 20).\n\nThe Team\n\n- UKTI assign a dedicated User Researcher to lead on identifying user need from research and feedback and where appropriate directing that towards an iterative improvement of the service.\n- The development capability within the team is retained in order that the service can be iterated further and promptly as directed by user feedback (Criterion 2).\n\nSecurity, Privacy, Tools and Standards\n\n- UKTI ensure that support for the service, i.e. the service tool itself and any issues around functionality failure, is contractually in place (Criterion 5).\n- UKTI ensures that the source codebase is open and available for re-use going forwards (Criterion 15).\n- A test environment is in place which will be developed in parallel during each iteration (Criterion 17).\n\nAssisted Digital (AD)\n\n- UKTI have identified how they will approach AD and the panel are content to accept this at this stage. However if this activity does highlight a need for greater levels of prolonged AD support then engagement with GDS Assisted Digital team is recommended to understand how the proposals will fit with other developments and whether there are opportunities to learn from this (Criterion 10).\n\nAnalysis and Benchmarking\n\n- UKTI will use Google Analytics to provide the service team with informed performance data (Criterion 18).\n- The panel recommend that in addition to using the feedback button on the Beta banner to capture qualitative user satisfaction data, UKTI capture quantitative data similar to that captured on GOV.UK at the completion of a service (Criterion 21).\n- As a general recommendation for measuring KPI’s, UKTI should consider the value of sharing metrics on the performance platform (Criterion 21-24).\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | N/A | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | N/A |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/employment-related-securities-ers-checking-service-service-assessment/",
    "title": "Employment Related Securities (ERS) Checking Service - Self Certification",
    "summary": "Under Employment Related Securities (ERS) legislation changes that came into effect in April requires companies that run share and security schemes to submit their end of year returns online (which includes NIL returns).",
    "body": "This is the first time that this information will be sent digitally and zero tolerance on formatting errors will be in place. As part of the user flow, the end of year submissions service will check the formatting of return files, and give a list of errors that the user must correct before they submit.\n\nThe checking part of the service is being released to customers early so they can check the ERS data they are compiling is in the right format well in advance of needing to submit their return.\n\nBy encouraging customers to use the Checking Service to compile information in the right format from the start, will enable employers to complete the required end of year submission service using a simple and efficient process.\n\n**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n25/09/14\n\n**Assessment Stage:**  \nbeta\n\n**Result of Assessment:**  \nPassed\n\n**Lead Assessor:**  \nR. Morgan\n\n**Service Manager:**  \nI. Atkin\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment report\n\nThe Assessing Panel consider that the service has met the GDS Digital by Default Service Standards and approve the launch of the product at Private and Public Beta in October 2014.\n\nAfter completing our assessment the HMRC Assessment Panel, can confirm that the ERS Checking Service has shown sufficient evidence of meeting the Digital by Default Service Standards and should move to Private and Public Beta.\n\nThe DSM and team clearly understand the user and the service being developed.\n\nFrom the data shared by the team, there are great opportunities to gather a wide range of data to inform further improvements to both the customer journey and service. Further work should be undertaken to define what data is to be initially tracked and gathered in addition to KPIs.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | N/A | 22 | N/A |\n| 23 | N/A | 24 | N/A |\n| 25 | N/A | 26 | N/A |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/department-of-health-intranet-self-certification/",
    "title": "Department of Health Intranet - Self Certification",
    "summary": "Self Certifications are run internally by each department, organised through their responsible Digital Leader. The Digital Leader will certify the service meets the&nbsp;[Digital by Default](https://www.gov.uk/service-manual/digital-by-default/)&nbsp;service standard criteria. The Self Certification process is currently in Alpha, and will continue to be iterated on. Services with over 100,000 transactions a year will continue to be assessed by GDS.",
    "body": "* * *\n\nThis is the new Intranet for the Department of Health (DH).\n\nThis replaces an old intranet called Delphi which started in 2003 and was rebuilt in 2008. The rebuild cost was £3m with large ongoing maintenance costs.\n\nThe new intranet was launched on 10th September to 2,500 staff. The content is similar to the old intranet – i.e. is the sort of corporate information which DH staff need to know – but has been rewritten and greatly simplified. It is now 90% migrated and navigation is easier.\n\nAs with the old site, the homepage is enforced; though the homepage has been greatly improved and optimised around how people use it.\n\n**Department / Agency:**  \nDepartment of Health\n\n**Date of Submission:**  \n13/10/2014\n\n**Assessment Stage:**  \nLive\n\n**Lead Assessor:**  \nP. Buckley&nbsp;/ A.&nbsp;Knell\n\n**Service Manager:**  \nJ.&nbsp;Caplin\n\n**Digital Leader:**  \nM. Davies\n\n* * *\n\n## Assessors Summary:\n\n**User Needs**\n\nThe team gave strong answers about the research into user needs they had done - they had collected statistics, run user groups, drawn on their network of existing Digital Champions, and done floorwalking. The service design above was informed by this.\n\nThe assessment panel had strong confidence that the team knew their users well and were developing the system in conjunction with them.\n\n**The Team**\n\nThe assessment panel all noted that the people representing the DH Intranet looked and sounded like a team who respected each other and worked together well. They had a very strong answer around who was responsible for which jobs, being able to provide names against each role necessary to continue the intranet.\n\nAs is common with a lot of projects, there will be a period of change post-launch. The assessment panel agreed that this lack of continuity is probably the biggest risk to the project going forward. However, the team have planned against this and hopefully the Intranet board and the team spirit will enable continuity of the quality of work done so far.\n\n**Security, Privacy, Open Standards**\n\nFor security, the intranet is hosted in Ireland with Amazon. The SIRO understands these risks and has signed them off and even issued the team with a certificate. All data held will be IL2 or below: personal data held but not personal sensitive. Penetration testing done by InfoAssure, medium and low bugs that came up which were all resolved for launch and re-tested, also signed off by DH Security team. In sum then, security is very strong though there is one point to note in the Channel Shift section below.\n\nMeanwhile, although the intranet is on a commercial platform (WordPress), where there has been bespoke development, the source code will be made available on Github. The team also said that they will be blogging about the work they have done.\n\nThe panel would be delighted to see the team presenting at the Service Managers group or Digital Leaders as there are some useful experiences and lessons here for all Government.\n\n**Assisted Digital, Channel Shift, Accessibility**\n\nIn what was a first for the panel, the team were able to say that they knew every user who had accessibility needs and had tested with them personally. They even had a process in place whereby they would be alerted when new people with assistance needs joined the DH.\n\nIn terms of channel shift, there is a plan to replace all all non-digital forms with direct to email digital forms. This is great for efficiency but presents a potential security challenge to ensure that staff don't start collecting inappropriate data which would push the Impact Level above the old IL2. This is not an insuperable problem but the team would do well to think of a process here to minimise the risk of collecting too much information.\n\n**Analytics and benchmarking**\n\nThe analytics from the old Delphi system are very poor, only really having data of a user satisfaction of 26%. However, this is a useful metric and it would be good to hear how the new intranet compares.\n\nOther than that, the panel were impressed at how many different sources of information were being used to take decisions as to development (Google Analytics, Word Press, Content Thumb up/down, user panels and so on). There is a nice idea to have users represented on the intranet board too.\n\nThe intranet board will receive weekly updates on stats.\n\n**Testing with the Minister**\n\nThe team have invited the Minister to test it but he has not as yet taken them up on this. However, the Permanent Secretary has tested it and has given enthusiastic feedback.\n\n**Recommended actions**\n\nIn general the assessment panel were very impressed with the hard work done by the team. We were particularly impressed by the work done rationalising and improving the content, by the way that everyone seemed to have a deep knowledge of the usage data, and also by the way the people in the meeting room looked and sounded like a team with mutual respect and shared goals.\n\nAs the team knows, when a site goes live it can be easy to lose a little bit of momentum, and the team face maybe 3 or 4 challenges going forwards:\n\n- Staff continuity\n- Testing of the back end as more people use it\n- What will happen when both iteration sprints have been used! It is the panel’s experience that there are normally many more requests than can be met, so the team may find themselves having to ask for more money in the future; it would be good if possible to find a way to secure a limited amount of maintenance funding for the intranet for the foreseeable future\n- There is also a potential security risk when forms are made widely available to DH staff\n\nHowever, the assessment panel believe that the Development team are aware that these are potential problems and have processes in place to deal with them. The challenge therefore becomes not so much thinking of processes to ensure good practice, but ensuring that the processes are followed. Their close teamwork will be a huge asset as they negotiate this period, hopefully developing into a well-functioning project board which gives continuity of quality.\n\nIn summary, the assessment panel would like to thank the team for their time in showing off the system, and to congratulate them on the work done so far. We would love to see you continue to share your experiences across and beyond the DH so that other interested parties can see for themselves how your agile and user-centred approach, along with buying software as a service, can yield excellent and efficient outcomes.\n\nWe wish you good luck in keeping the quality over in the next period, and recommend that they give a further update on the 4 items above to the panel in perhaps 4-6 months time.\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |\n\n&nbsp;"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/us-foreign-account-tax-compliance-act-fatca-self-certification/",
    "title": "US Foreign Account Tax Compliance Act (FATCA) - Self Certification",
    "summary": "Self Certifications are run internally by each department, organised through their responsible Digital Leader. The Digital Leader will certify the service meets the&nbsp;[Digital by Default](https://www.gov.uk/service-manual/digital-by-default/)&nbsp;service standard criteria. The Self Certification process is currently in Alpha, and will continue to be iterated on. Services with over 100,000 transactions a year will continue to be assessed by GDS.",
    "body": "* * *\n\nThe UK has negotiated a bi-lateral Inter Governmental Agreement with the US to exchange tax compliance information to facilitate UK Financial Institutions compliance with the US Foreign Account Tax Compliance Act (FATCA) and enable them avoid severe financial penalties. A steering group chaired by the Director TPA oversaw the negotiations and established that the implementation would be funded through the Policy Delivery Programme. The FATCA Project was set up in Enforcement & Compliance when the agreement was signed in 2013 and is charged with implementing the IT service needed to meet the UK commitment to collect, collate, and receive the required information, with the first exchange due to take place in October 2015. The project is part of a wider Offshore Data Programme which is coordinating the response to wide ranging framework of Automatic Exchange of Information agreements being negotiated under the auspices of the G5 group, the EU, and the OECD. The first phase of the FATCA IT solution is the facility for financial institutions to submit information about relevant accounts via a new digital service.\n\n**Department / Agency:**  \nHMRC\n\n**Date of Submission:**  \n3/10/2014\n\n**Assessment Stage:**  \nLive\n\n**Lead Assessor:**  \nR. Morgan\n\n**Service Manager:**  \nT. Jenkins\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessors Summary:\n\nThe project has been inflight since late 2012. Throughout the build cycle high street financial institutions have been involved in the development of this service and their feedback has been used in the development of this service. Assisted Digital has been addressed based on HMRC research and support is in place should need arise. The Assessing Panel consider that the service has met the digital by default service standards as agreed by the GDS Operations Board and approve the launch of the product. The assessment team therefore recommend to the Digital Leader that the FATCA service moves to live to meet the International Agreement deadlines.\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | N/A |\n| 7 | Yes | 8 | N/A |\n| 9 | Yes | 10 | Yes |\n| 11 | N/A | 12 | Yes |\n| 13 | N/A | 14 | N/A |\n| 15 | N/A | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | N/A | 22 | N/A |\n| 23 | N/A | 24 | N/A |\n| 25 | Yes | 26 | Yes |\n\n| **Details of criteria that are not applicable to this service** |\n| 6, 8, 13, 14, 15, 19 - Not applicable to Inflight Projects per GDS Operations Board Agreement  \n11 – this is a new service developed to support the Inter Government Agreement  \n21, 22,23, 24 - Not applicable to services with less than 100k transactions a year |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/employer-checking-service-self-certification/",
    "title": "Employer Checking Service - Self Certification",
    "summary": "Self Certifications are run internally by each department, organised through their responsible Digital Leader. The Digital Leader will certify the service meets the&nbsp;[Digital by Default](https://www.gov.uk/service-manual/digital-by-default/)&nbsp;service standard criteria. The Self Certification process is currently in Alpha, and will continue to be iterated on. Services with over 100,000 transactions a year will continue to be assessed by GDS.",
    "body": "* * *\n\nThe Employers Checking Service will be an online tool where employers can check their employees and potential employee’s right to work in the UK and can request a right to work check should it be required.&nbsp;\n\n**Department / Agency:**  \nHO\n\n**Date of Submission:**  \n29/9/2014\n\n**Assessment Stage:**  \nBeta\n\n**Lead Assessor:**  \nC. Williams / E. Charles\n\n**Service Manager:**  \nA. Sharpe\n\n**&nbsp;Digital Leader:**  \nN. Driskell\n\n* * *\n\n## Assessors Summary:\n\nThe assessors considered that the service had been built to be consistent with style and content used on GOV.UK.\n\nThe service is simple and intuitive to use.\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | No | 24 | Yes |\n| 25 | Yes | 26 | No |\n\n| **Details of criteria that are not applicable to this service** |\n| 10 - no AD identified but will continue to monitor during the beta phase.  \n12 – no non-digital steps.  \n26 – to be completed. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/orphan-works-licensing-service-self-certification/",
    "title": "Orphan Works Licensing Service - Self Certification",
    "summary": "Self Certifications are run internally by each department, organised through their responsible Digital Leader. The Digital Leader will certify the service meets the&nbsp;[Digital by Default](https://www.gov.uk/service-manual/digital-by-default/)&nbsp;service standard criteria. The Self Certification process is currently in Alpha, and will continue to be iterated on. Services with over 100,000 transactions a year will continue to be assessed by GDS.",
    "body": "* * *\n\nAn Orphan Work is a creative work/ performance subject to copyright, such as a diary, a photo, film or a piece of music, for which one or more of the rights holders (owners of the copyright) cannot be located following a diligent search.\n\nAt present, such works cannot be copied for use in exhibitions, books, TV, documentaries, websites etc.\n\nHowever legislative changes, which come into effect from October 2014, mean the Intellectual Property Office (IPO) can offer a new licensing service to enable the legal commercial and non-commercial use of all types of orphan creative works within the UK. The interests of the potential right holder will be protected by ensuring before a licence is issued due diligence has been undertaken to identify and find the rights holders. Where the right holder cannot be found and a licence is issued the details will be held on an electronic register, thus allowing an opportunity for someone to quickly identify if their work has been licensed as an orphan and claim the associated licence fee.\n\nThere are two elements to the service:\n\n- checking the register; and\n- applying for a licence\n\n**Department / Agency:**  \nBIS / IPO\n\n**Date of Submission:**  \n25/9/2014\n\n**Assessment Stage:**  \nBeta\n\n**Lead Assessor:**  \nP.&nbsp;Turner\n\n**Service Manager:**  \nA.&nbsp;Graves\n\n**&nbsp;Digital Leader:**  \nT. Knighton\n\n* * *\n\n## Assessors Summary:\n\nAfter consideration, the assessment panel were content that the Orphan Works Licensing Service meets the Digital by Default Service Standard and should proceed to launch as a Beta service.\n\nThe panel were impressed with the thoroughness of the service team’s preparation and presentation. There is clear evidence throughout that they have designed and developed the service in line with the service standard.\n\nPrior to launching the beta service, the panel requests that:\n\n- work ongoing to review the service and ensure the GOV.UK design patterns and style guide are met is completed. This should include reviewing and revising the wording of some of the questions as identified during the assessment;\n- it is made clearer which information is mandatory or optional for the user and which information will be included in the register; and\n- if possible, a progress bar is included to enable users to understand how far they are through the process\n\nIn addition, the panel recommends that during the beta phase the following points are considered: to enhance and strengthen the service.\n\n**Security, Privacy, Tools and Standards**\n\n- Continue to identify and assess any risks and involve the SIRO, Information Data Owner and Accreditor as appropriate (criterion 3).\n- Continue to make it clear what the procedure is for personal data that is not on the public register; and ensure there is clear understanding of the data flows through the service (criterion 4).\n- Load testing will be completed prior to the beta launch. However given the uncertainty on the number of users that are likely to use the service it is recommended that load testing with reasoned volumetrics is performed (criterion 25).\n\n**Design**\n\n- Follow through the intention to setup a specific content/UI team.\n- Be clearer about the split of roles across the multidisciplinary team specifically the content design role, which appeared not to be specifically assigned (criterion 12).\n\n**Assisted Digital**\n\n- Develop a clearly defined Assisted Digital (AD) strategy in beta ensuring that research is conducted with AD users (both Business to Customer and Business to Business as appropriate) for the service. The B2B element of the service appears well understood. The IPO has an established contact centre and an option to use the contact centre to walk through the service with AD users was mentioned. However the panel felt this needed more consideration during the beta to ensure it is the optimal solution (criterion 10).\n\n**Analysis and Benchmarking**\n\n- Give further consideration to the 4 key KPIs and how the Performance Platform can support monitoring of the service and how business KPIs (as well as page navigation type events) will be measured.\n\nTo reiterate, these recommendations have been made to help IPO further strengthen what is already a strong proposition.\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | N/A | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |\n\n| **Details of criteria that are not applicable to this service** |\n| Criteria 11 – this is a new digital service. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/consular-service-online-appointment-booking-self-certification/",
    "title": "Consular Service Online Appointment Booking - Self Certification",
    "summary": "Self Certifications are run internally by each department, organised through their responsible Digital Leader. The Digital Leader will certify the service meets the&nbsp;[Digital by Default](https://www.gov.uk/service-manual/digital-by-default/)&nbsp;service standard criteria. The Self Certification process is currently in Alpha, and will continue to be iterated on. Services with over 100,000 transactions a year will continue to be assessed by GDS.",
    "body": "* * *\n\nForeign Office Embassies and Consulates provide a range of services to British nationals overseas.&nbsp; The online appointment booking service would allow members of the public to book appointments for those services online and would also allow Consular staff to manage those bookings.&nbsp; Previously 40% of posts used the free “clickbook” service, while others took walk-ins or appointments by telephone.&nbsp; The team have delivered a closed alpha of the service and are seeking permission to move the service to a limited public beta starting with 5 countries overseas, increasing to other countries over time.\n\n**Department / Agency:**  \nFCO\n\n**Date of Submission:**  \n22/9/2014\n\n**Assessment Stage:**  \nAlpha\n\n**Lead Assessor:**  \nA. Bye/A. Ainsworth\n\n**Service Manager:**  \nM. Barlow\n\n**Digital Leader:**  \nA. Bye\n\n* * *\n\n## Assessors Summary:\n\n**User Needs**\n\nThe service team have carried out significant discovery with both consular customers and internal users.&nbsp; For consular customers, this has included surveying British nationals who called the FCO’s contact centres and surveying those who had successfully booked appointments.&nbsp; For internal users, this has included separate surveys of posts currently using Clickbook and of those not using the service.&nbsp; In addition the team collected quantitative data on the FCO’s appointments, enabling them to analyse the demographics of those attending appointments, which services were most used, and other factors.&nbsp; It was clear that this research has already significantly influenced the design of the service.\n\nThe team already had initial plans for user testing of the beta service, and intend to roll that testing out further based on lessons learned (as much of the user testing will be carried out overseas the team want to assess how it is progressing).&nbsp; The team also planned a second survey of internal users.&nbsp;\n\nThe team intend to Have a limited beta starting with 5 posts which will cover a range of locations and volumes (Muscat, Rabat, New York, Madrid and Jakarta). Will than expand to 15 during period.\n\n**The Team**\n\nService manager and product owner are currently the same role with development outsourced to a Gcloud supplier.&nbsp; While the development team has not been collocated with the business, there has been extensive close work – including joint development and prioritisation of user stories; close sharing and monitoring of the backlog; regular face to face meetings.&nbsp; Project overseen by the Foreign Office Digital Transformation Unit who intend to gradually integrate the service manager role into the policy team.&nbsp; Team are also putting in place other support via the Gcloud, including user testing and resource for ongoing service iteration post-live.&nbsp; The team have worked closely with GDS on a number of aspects, including user testing and performance platform integration, and have also worked closely with the MOJ prisoner appointment booking team (see below).\n\n**Security, Privacy, Open Standards&nbsp;**\n\nTeam is on course to have full security testing completed and full SIRO sign off before beta is launched.&nbsp; Supplier is also on course to have full professional ISO-27001 accreditation before the service goes live.&nbsp; The team are lining up an additional penetration test day before the beta is launched.&nbsp; Cookies not currently being collected but may be introduced as team puts in place PIWIK web analytics.&nbsp; Supplier has a number of measures in place to ensure resilience and minimise downtime - multiple availability zones; duplicated databases; hourly backups; load balancing. If service completely failed customers could still use telephone booking.&nbsp; Service iterations are developed in test environment.\n\nThe team have worked very closely with MOJ, using their open source calendar picker (part of the prison visits exemplar). The supplier have taken MOJ code and ported to angular.JS; hooked it up to their API; and&nbsp; made it time zone aware. The supplier will open source these enhancements so they can benefit future services.\n\n**Assisted Digital, Channel Shift, Accessibility**\n\nGOV.UK and FCO Contact Centres will encourage customers to book appointments using the online service.&nbsp; But Contact Centres will also be able to directly book appointments using the service for customers having difficulty.&nbsp; Those bookings will be labelled as assisted digital bookings to provide reliable metrics on assisted digital need.&nbsp; The developers are currently working on a version of the service which will work with screen readers.\n\n**Analytics and benchmarking**\n\nThe system has been designed to provide a range of reliable management information on how customers are progressing through the transaction at both individual Embassy, regional and&nbsp; global level.&nbsp; The team are also working to ensure full performance platform integration; a GOV.UK end page to collect satisfaction statistics; and are putting in place PIWIK web analytics.\n\nLooked at over two years the team estimate a cost per transaction of 73p, compared to over 10 times that for non-digital appointments. The team have targets in place for completion rate and user satisfaction.\n\n**Testing with the Minister**  \nThe team intend to test the live version of the service with the Minister.\n\n**Recommended actions**\n\nThe team have worked extremely closely with policy leads and should continue to look for opportunities to expose those leads to the agile, user focussed analytics driven approach they have taken. &nbsp;\n\nFollowing their initial round of user testing, the team should rapidly put in place a user testing schedule and ensure the development team and policy leads are also exposed to user testing.\n\nThe team should blog on their evolving experience delivering software as a service projects in a digital by default framework.\n\nThe team should work with the FCO's technology department to look at ways to streamline IT security approvals. &nbsp;\n\nGiven that the tool will significantly improve user experience and internal management information, the FCO policy leads should consider methods to oblige/encourage as many posts as possible to use the service.\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/view-vehicle-record-for-fleets-self-certification/",
    "title": "View Vehicle Record for Fleets - Self Certification",
    "summary": "Self Certifications are run internally by each department, organised through their responsible Digital Leader. The Digital Leader will certify the service meets the&nbsp;[Digital by Default](https://www.gov.uk/service-manual/digital-by-default/)&nbsp;service standard criteria. The Self Certification process is currently in Alpha, and will continue to be iterated on. Services with over 100,000 transactions a year will continue to be assessed by GDS.",
    "body": "* * *\n\nThe View Vehicle Record service for Fleets is a digital service that provides information to DVLA registered fleet operators about the vehicles they are responsible for. The operators will be able to see the information contained on the V5C documents (vehicle log books) as well as the current tax and MOT status of this vehicles. The service is aimed at fleet operators that have between 10 and 600,000 vehicles registered with the DVLA.\n\nThe service forms part of the DVLA's Red Tape Challenge commitment to stop issuing V5C documents to fleet operators by allowing them to view this information online rather than securely storing many paper documents.\n\n**Department / Agency:**  \nDVLA\n\n**Date of Submission:**  \n25/7/2014\n\n**Assessment Stage:**  \nAlpha\n\n**Lead Assessor:**  \nD.&nbsp;Vaughan\n\n**Service Manager:**  \nR. Gye\n\n**Product Owner:**  \nN.&nbsp;Morgan\n\n**Digital Leader:**  \nO.&nbsp;Morley\n\n* * *\n\n## Assessors Summary:\n\nOverall the assessment team were impressed by the prototype demonstrated to us and the work that has gone into the Alpha phase of development. The service team provided good responses to the questions on the 26 Digital by Default Standard criteria and were able to demonstrate they've worked in an iterative, agile manner. We were pleased to see the engagement with fleet managers during the Alpha and also the thought that has gone into re-using existing services/patterns.\n\n**The assessment team noted the following recommendations.**\n\nThe team should continue to undertake user research in each sprint and should look to embed a dedicated user researcher into the team. We were pleased to hear that members of the team have been observing the research undertaken during the alpha. The Service Manager should ensure that there is appropriate time given to the team to allow this to continue.\n\nThe team should undertake more work to identify which users may require assisted digital support and look at how this support could be provided. They should engage with the Assisted Digital team at the Government Digital Service.\n\nThe team should consider the privacy implications of the service and include appropriate access control. The Service Manager should continue their engagement with the GDS Identity Assurance team.\n\nThe team should undertake further work in planning how to encourage users to switch from the existing paper and phone channels to the new digital service.\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | N/A |\n\n| **Details of criteria that are not applicable to this service** |\n| 26 - The service will be tested with the minister during the Beta phase. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/chevening-scholarships-application-self-certification/",
    "title": "Chevening Scholarships Application - Self Certification",
    "summary": "Self Certifications are run internally by each department, organised through their responsible Digital Leader. The Digital Leader will certify the service meets the&nbsp;[Digital by Default](https://www.gov.uk/service-manual/digital-by-default/)&nbsp;service standard criteria. The Self Certification process is currently in Alpha, and will continue to be iterated on. Services with over 100,000 transactions a year will continue to be assessed by GDS.",
    "body": "* * *\n\nChevening Scholarships are the UK government’s global scholarship programme, funded by the Foreign and Commonwealth Office (FCO) and partner organisations. The programme makes awards to outstanding scholars with leadership potential from around the world to study postgraduate courses at universities in the UK.\n\nThe new application service replaces an old and complicated legacy system.\n\n**Department / Agency:**  \nFCO\n\n**Date of Submission:**  \n11/8/2014\n\n**Assessment Stage:**  \nLive\n\n**Lead Assessor:**  \nA. Bye / A. Ainsworth\n\n**Service Manager:**  \nP. Buckley\n\n**&nbsp;Digital Leader:**  \nA. Bye\n\n* * *\n\n## Assessors Summary:\n\n**User Needs**  \nThe service team have testing the new application with a range of former scholars, both at Association of Commonwealth Universities (ACU) and at a Chevening 30th Anniversary event. The application was also tested by staff in the embassy in China (who citizens make up the largest number of Chevening applications). ACU also drew on feedback from previous application rounds. Feedback from testing was very positive, generally users found it a much easier journey. The service team have committed to review as application, fixing smaller problems immediately and any more fundamental issues between scholarship application rounds (to ensure fairness for candidates).\n\n**The Team**  \nService manager and product owner same role with an outsourced to GCloud supplier for the development who are used to integrating into other websites. Development team co-located with ACU during development. Oversight by Foreign and Commonwealth Office (FCO) Digital Transformation Unit (DTU). Development team were not present at user testing, instead having results relayed to them. Not completely Agile but the commodity project was excellent value for money. Logic text and design are quite agile within the application.\n\n**Security and Privacy**  \nFCO has full security testing completed with SIRO sign off. Supplier has professional ICO-2700-1 accreditation and almost ICO-2700-2. Supplier is annually Pen tested through CHECK, weekly test for Alert Site. Extra PEN test day will take place on log in system. Three cookies stored, session cookie, cookie for identification through FaceBook, LinkedIn or WCN and a management information cookie. Supplier draws on open source and shares some code in public. New system will cost about £1.21 per transaction though there are other costs such as processing at the ACU and interviewing the shortlisted candidates. Disaster recovery plan with an SLA 99.99% uptime with multiple uptime, historically supplier they have done better with good history of load testing.\n\n**Assisted Digital and Channel Shift**  \nService only provided digitally. Telephone helpline available through the supplier on 24-hour basis. Can also contact ACU through an online form in contact section of website.\n\n**Analytics**  \nThe system via the supplier will provide range of statistics, including on how users are progressing through transaction. DTU putting in place PIWIK.\n\n**Testing with the Minister**  \nThe Minister is booked in to use transaction after recess.\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/epp-licensing-self-certification/",
    "title": "EPP Licensing - Self Certification",
    "summary": "Self Certifications are run internally by each department, organised through their responsible Digital Leader. The Digital Leader will certify the service meets the&nbsp;[Digital by Default](https://www.gov.uk/service-manual/digital-by-default/)&nbsp;service standard criteria. The Self Certification process is currently in Alpha, and will continue to be iterated on. Services with over 100,000 transactions a year will continue to be assessed by GDS.",
    "body": "* * *\n\nAs a requirement of new legislation, users who acquire, use or posses for private purposes such as a hobby, certain chemicals and other substances which can also be used to make explosives will be required to hold a licence. This service provides a means of ascertaining whether a licence is required, and if so, an application and payment process for a licence.\n\n**Department / Agency:**  \nHO\n\n**Date of Submission:**  \n4/8/2014\n\n**Assessment Stage:**  \nBeta\n\n**Lead Assessor:**  \nC. Williams / E. Charles\n\n**Service Manager:**  \nS. Tam\n\n**&nbsp;Digital Leader:**  \nN. Driskell\n\n* * *\n\n## Assessors Summary:\n\nThe assessors considered that the service had met the digital by default service standard and have approved the launch of the beta product.\n\nThe service has been built using user research and has been iterated and tested to make the service simple to use. There is a clear process to establish whether a licence is required prior to a simple application process.\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | N/A |\n| 11 | N/A | 12 | N/A |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | N/A |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | N/A |\n| 23 | N/A | 24 | N/A |\n| 25 | Yes | 26 | N/A |\n\n| **Details of criteria that are not applicable to this service** |\n| 10. No AD need established. Will remain under consideration during the beta.  \n11. New service.  \n12. No non-digital steps.  \n15. Product code not open is but all new code and functionality is reusable.  \n16. N/A at this stage. May consider IDA platform when established.  \n22-24. Do not need to report on the performance platform.  \n26. Small service – director to test the service. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/change-of-address-visas-self-certification/",
    "title": "Change of Address (Visas) - Self Certification",
    "summary": "Self Certifications are run internally by each department, organised through their responsible Digital Leader. The Digital Leader will certify the service meets the&nbsp;[Digital by Default](https://www.gov.uk/service-manual/digital-by-default/)&nbsp;service standard criteria. The Self Certification process is currently in Alpha, and will continue to be iterated on. Services with over 100,000 transactions a year will continue to be assessed by GDS.",
    "body": "* * *\n\nThis service allows visa applicants to communicate a change in their address or legal representative details to the Home Office so that their records can be updated.\n\n**Department / Agency:**  \nHO\n\n**Date of Submission:**  \n29/7/2014\n\n**Assessment Stage:**  \nLive\n\n**Lead Assessor:**  \nE.&nbsp;Charles / C.&nbsp;Williams\n\n**Service Manager:**  \nH. Day\n\n**&nbsp;Digital Leader:**  \nJ. Hawkins for M. Parsons\n\n* * *\n\n## Assessors Summary:\n\nThe assessors considered that the change of address service meets the service standards as appropriate for a public beta release. The service demonstrated was created as part of the migration of the Home Office websites to .GOV.UK. A new service is under development. Feedback and analysis of the public beta will inform the development of the new service. The team has developed, tested and revised the service resulting in a service that users can use first time unaided. There is a team in place to work with the service manager to monitor and improve the service. On-going support and knowledge sharing is supported by open source tools. The assessors recommended that the service manager agreed a benchmark against which the service could be measured. The assessors also recommended that the assisted digital needs were considered in the context of the visa applicant’s customer journey.\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | No |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | No | 24 | Yes |\n| 25 | Yes | 26 | No |\n\n| **Details of criteria that are not applicable to this service** |\n| 10. Alternate channel in place  \n15. Code is not open source but templates are shared  \n23. Not reported on the performance platform during beta  \n26. Not at present |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/domestic-renewable-heat-incentive-income-calculator-self-certification/",
    "title": "Domestic Renewable Heat Incentive Income Calculator – Self Certification",
    "summary": "Self Certifications are run internally by each department, organised through their responsible Digital Leader. The Digital Leader will certify the service meets the&nbsp;[Digital by Default](https://www.gov.uk/service-manual/digital-by-default/)&nbsp;service standard criteria. The Self Certification process is currently in Alpha, and will continue to be iterated on. Services with over 100,000 transactions a year will continue to be assessed by GDS.",
    "body": "* * *\n\nCo-funded by the Scottish Government/ DECC and delivered via EST, the service will offer a Renewable Heat Incentive (RHI) calculator based on the Government’s Standard Assessment Procedure (SAP). This will give consumers and renewable heating installers an estimate of the RHI income received if a given renewable heat technology eligible for the Domestic RHI scheme is installed.\n\n**Department / Agency:**  \nDECC\n\n**Date of Submission:**  \n21/05/2014\n\n**Moving to:**  \nBeta\n\n**Lead Assessor:**  \nL. Diep\n\n**Service Manager:**  \nA. Boon / L. Longstaff\n\n**&nbsp;Digital Leader:**  \nJ. Boss\n\n* * *\n\n## Assessors Summary:\n\nMain objectives of this service is to provide an independent, authoritative voice that provides reliable and realistic cost benefits for RHI schemes, in contrast with unauthorised sources that provide exaggerated estimates. It is hoped that this service will rebuild trust in the schemes and build confidence in the industry.\n\n**Panel discussed/noted:**\n\n- Submission not clear on who are the users of this service are?\n  - Users include:\n    - People who want to know what their potential income could be from installation(s)\n    - Installers – to help them provide customers with trusted estimates\n- Calculator has 6 questions, 2 main customer journeys – with and without EPC data.\n- Agreement with Scottish Government to follow GOV.UK style, as long as they are acknowledged. Also aligned with Ofgem website due to RHI Domestic hosting.\n- Privacy Impact Assessments and DPA considerations – noted no personal data will be stored.\n- 2 front ends being developed – localisation needed for Scotland where policies differ\n- Understand DECC has taken opportunity to ‘piggyback’ off a project from Scottish Government and tried to collaborate rather that duplicate.\n\n**Considerations:**\n\n- No evidence of long term plans beyond launch. Important that calculator continues to evolve with changes in policy and continuously improved if team are to achieve objective of rebuilding trust and confidence in the schemes/industry.\n- Better understanding of user needs and an agile approach for the service to be meet the required standards\n\n* * *\n\n## Results Against the Digital by Default Criteria:\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | N/A | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | N/A | 12 | N/A |\n| 13 | Yes | 14 | No |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | No | 20 | No |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |\n\n| **Details of criteria that are not applicable to this service** |\n| This is a small service, with no existing channels funded by DECC. Service is building on an existing tool created by Scottish Government and procured via Scotland. |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/rod-catch-returns-self-certification/",
    "title": "Rod Catch Returns – Self Certification",
    "summary": "Self Certifications are run internally by each department, organised through their responsible Digital Leader. The Digital Leader will certify the service meets the&nbsp;[Digital by Default](https://www.gov.uk/service-manual/digital-by-default/ \"Digital by Default\")&nbsp;service standard criteria. The Self Certification process is currently in Alpha, and will continue to be iterated on. Services with over 100,000 transactions a year will continue to be assessed by GDS.",
    "body": "* * *\n\nAnglers are required by law to complete salmon and sea trout catch returns by 31 December each year; if they fished, how much fishing they did and what they caught. 35,000 rod licence owners will be eligible to use the service.\n\n25,000 rod catch returns are currently returned annually. The online service will aim to increase number of returns received up to 80%, improve data accuracy and reduce the costs of managing the existing service, although the online service will only partly replace the current paper returns form.\n\n**Department / Agency:**  \nDEFRA / EA\n\n**Date of Submission:**  \n26/03/2014\n\n**Moving to:**  \nBeta\n\n**Lead Assessor:**  \nS. Lang\n\n**Service Manager:**  \nA. Sadler\n\n**Digital Leader:**  \nI. Trenholm\n\n* * *\n\n## Assessors Summary:\n\nThe Rod Catch Return (RCR) team provided very good responses to the questions on the 26 GDS Digital by Default criteria and were able to demonstrate that they had followed Agile methodology.\n\nHowever the assessment team noted that user centred design was introduced late into the project, and early iterations were only tested with internal staff. Only during later sprints were a wider external group engaged to test prototypes remotely, although the team have made very good progress with these users.\n\nA number of bugs and usability issues were noted when the Alpha service was demonstrated during the assessment. The RCR team have since responded quickly to deal with priority actions. The updated service will be demonstrated to the assessment team again on 25/03/14. The other issues identified should not be considered show stoppers and therefore wouldn’t prevent the service going live, as long as the RCR team remain committed to addressing them.\n\nThere are minor concerns over the clarity of a plan for continuous improvement, especially as there are now a number of items in the project backlog. Although the assessment team have passed the criteria for CI and there is a budget allocated, the RCR Service Manager will need to demonstrate clearly how CI is working in practice when the service applies to move into Live. They have also agreed to provide a statement to the assessment team on their CI plan.\n\nThe assessment team recommend to the Digital Leader that the RCR service moves to Live Beta.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | N/A | 22 | N/A |\n| 23 | N/A | 24 | Yes |\n| 25 | Yes | 26 | Yes |\n\n| **Details of criteria that are not applicable to this service** |\n| 15 – No. Publishing Environment Agency source code is an outstanding issue with the EA and waiting on a Corporate decision |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/civil-service-jobshare-internal-service-assessment/",
    "title": "Civil Service Jobshare - Internal Service Assessment",
    "summary": "Civil Service Jobshare is an online job-share register designed to capture, manage and match prospective civil servant job sharers. The functionality of the service allows users who have securely registered to create a profile on the service, search for other compatible potential job share partners across Civil Service Departments and make contact to initiate a job share partnerships.",
    "body": "**Department / Agency:**  \nCO\n\n**Date of Assessment:**  \n27/09/2015\n\n**Assessment Stage:**  \nlive\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nL. Sands\n\n**Service Manager:**  \nB. Stanislas\n\n**Digital Leader:**  \nC. Bullock\n\n* * *\n\n## **Assessment Report**\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel can confirm the Civil Service Jobshare service has shown sufficient evidence of meeting the Digital Service Standard and should go live as a service on GOV.UK. The service can now remove any beta branding.\n\n**Reasons**\n\nThe panel could see the potential of the service to contribute to improving diversity within the Civil Service workforce and to significantly increase both the visibility and uptake of job sharing within the organisation.\n\nThe panel found the design of the service to be broadly consistent with the GOV.UK style guidelines. The service was thoroughly reviewed with a content editor following beta assessment, which resulted in several sensible changes, including the renaming of functionality throughout the interface and improvements to key user journeys.\n\nThe panel were impressed with the breadth of user research undertaken in reaction to feedback from the beta assessment, with a renewed focus on task based usability testing. The thorough capture of data throughout the sessions, the subsequent analysis, and the changes implemented to the service as a result of the research clearly justify the additional time spent  \nduring beta.\n\nIt was equally clear that the service team had made efforts to improve the channels used to recruit participants for research, focusing on attracting contributions beyond the existing network of job sharers, and making full use of the Civil Service diversity groups such as the Black, Asian and Minority Ethnic (BAME) Network, Home Office Women’s Network and Civil Service Disability Network (CSDN).\n\nThe panel were pleased to see specialist expertise had been brought into the team, to support both user research and analytics, and were encouraged by the steps taken by Civil Service Resourcing (CSR) to deliver the service within tight timescales.\n\n**Recommendations**\n\nThe panel have the following recommendations.\n\n_Engagement with the service_\n\nWhilst the service is still very new, there is concern amongst the panel that usage is fairly low and that the service is not yet delivering value for money. The panel would strongly advise that the team focus their energy on growing usage and improving engagement with the service across the organisation.\n\nThe service team should consider using specialist expertise to help develop a stronger engagement plan, and would encourage particular focus on the following areas:\n\n- Expanding usage outside of London and beyond traditional policy roles.\n- Evaluation of how recruitment practices and job specifications can be utilised to further raise awareness of job sharing and the service itself.\n- Reviewing diversity data collected by the service to determine where usage does not reflect the composition of the Civil Service as whole.\n- Investigating opportunities for the Job Sharing and Job Search services to be integrated now or in the future.\n- Targeting recruiting managers, senior leadership, fast streamers and new entrants with effective communications about job sharing and the service.\n\n_Collecting quantitative data_\n\nThe panel would encourage the service team to increase the scale at which they gather quantitative data, and generally be more ambitious in how they recruit participants. The validity of the methodology improves proportionally to the quantity of responses received, and the panel would expect several thousand survey responses from potential users of the service. The relatively low numbers of respondents suggest that the channels used to publicise the survey were inadequate.\n\n_Sharing code_\n\nThe agency responsible for the delivery of the service has published the entire source code of the service to their GitHub account. This should ideally be moved to an account managed and owned by CSR. Whilst the code is open and the team are accepting contributions, the panel would encourage the team to ensure that the project is publicised effectively and they are fully realising the benefits of sharing code.\n\nThe team should also carefully consider what can be reused or repurposed from Civil Service Job Share in future products managed by CSR, particularly the new Job Search and Fast Stream recruitment services.\n\n_Capacity planning_\n\nThe panel recommends that the capacity planning undertaken during beta be reviewed given current and planned usage. Whilst the service is deployed on cloud infrastructure there is no elastic scaling of resources in place. Given the current usage of the service, scaling capacity elastically based on demand would help ensure the team are getting value for money from hosting and infrastructure.\n\n_Regression testing_\n\nThe panel identified a bug during the assessment whereby the “Dashboard” page was not shown to users following a successful login.\n\nThe service team described using manual exploratory and manual scenario based testing to validate changes prior to deployment, and characterised this as a relatively low burden for the team. The panel suggests that some degree of basic automated testing could have helped identify the regression prior to deployment to the live environment, as well as offering improved confidence during engineering and deployment.\n\nThe panel were also unsure whether the team's manual testing scenarios are documented in sufficient detail to facilitate transfer of knowledge. The panel recommends that the service team review the scenarios in detail, and ensure service documentation is appropriately shared.\n\n_Transferring knowledge_\n\nAs the service enters a less intensive period of development, the service team must ensure that key knowledge is maintained or transferred appropriately, particularly given the reliance on external agencies for development.\n\n_Utilising the performance platform_\n\nThe panel expect to see the service report their performance data to the Performance Platform prior to the removal of the beta branding.\n\n**Summary**\n\nThe assessment team identified several areas where there is scope for improvement but the service broadly met the requirements for a live service.\n\nIn coming to this decision, the panel took into account the internal nature of the service, the recent application of service assessments to internal services, and the significant improvements undertaken following the beta assessment.\n\nThe panel wish to congratulate the service team on their success and wish them well for the future.\n\n* * *\n\n## Digital Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/civil-service-jobshare-finder-internal-service-assessment/",
    "title": "Civil Service Jobshare - Internal Service Assessment",
    "summary": "The Civil Service Jobshare Finder will provide a service for civil servants who are interested in a job-share to create a profile, search for potential job share partners and contact them.",
    "body": "**Department:**  \nCivil Service Resourcing - HMRC/Cabinet Office\n\n**Date of Assessment:**  \n11/2/2015\n\n**Assessment stage:**  \nBeta (Internal service, trial period)\n\n**Result of Assessment:**  \nMay proceed (see below)\n\n**Lead Assessor:**  \nS.&nbsp;Bennett\n\n**Service Manager:**  \nD. Sullivan\n\n**Digital Leader:**  \nM. Dearnley/P.Maltby\n\n* * *\n\n## **Assessment Report**\n\nAfter consideration, the assessment panel has concluded that the Civil Service Resourcing Jobshare Finder service would not pass a service standard assessment. However, because the assessment process for non-public facing services is currently in a trial period, as agreed by Digital Leaders, the service may proceed, since overall (subject to the caveats below) it :\n\n- is safe and secure\n- can be iterated and improved\n- meets a user need.\n\nBefore moving into beta there are five actions the service team must take, and report back on. These are listed under ‘next steps’.\n\n**&nbsp;**** Reasons**\n\n**&nbsp;**** User Needs**  \nThe team were very clear on the importance of setting this service up to support the Civil Service’s commitment to more flexible working. However, while the team identified some potential user needs and user stories from early workshops with stakeholders such as job sharing network leads, and has collected some user feedback via a feedback-form within the service, the volume of user engagement needs to be increased, and extended to a wider range of people beyond those already more engaged and knowledgeable about job sharing. No research plan is yet in place for the next phase of development.\n\n**&nbsp;** The assessment panel felt that the service would benefit from a review by an experienced content designer as a matter of urgency, as they felt that guidance and flow through the service was weak, especially in terms of providing advice or pointers to the next steps once a job share partner had been found. This should be undertaken and the revised version tested with end users before the service proceeds into beta.\n\n**&nbsp;** There has been no usability testing for accessibility. In addition, non-subject area experts have not been engaged for user research. This needs to be undertaken at an early stage in beta. This should form part of a broader research plan for the beta phase.\n\n**&nbsp;**** Safety and Security**  \nThe service has been developed with appropriate levels of security, and user research covered attitudes to disclosure or anonymity of potential job-sharers’ personal details.\n\n**&nbsp;** The source code needs to be published in a public repository before the service proceeds further, in line with Government’s commitment to openness and sharing; and penetration testing needs to be completed successfully.\n\n**&nbsp;**** Iteration and Improvement**  \nThe service needs to do more to develop its use of analytics to inform future development and iteration. Although they use Google Analytics, the service team have not engaged an analytics expert to work with them to identify performance issues and patterns which should inform future work priorities.\n\n**&nbsp;** Similarly, the service team need to identify expertise in other areas (especially user research and content design) which can be deployed on a regular basis to identify and respond to user needs to ensure that the service continues to iterate and improve.\n\n**&nbsp;**** Recommendations**  \nThe assessment panel believes that the service should be reviewed by an experienced content editor and the revised version tested with a range of users before the service proceeds to beta.\n\n**&nbsp;** A user researcher should be embedded within the team, and a clear plan put in place for user research in the next phase.\n\n**&nbsp;** The research carried out during development to date appears to have been ad-hoc, and remote. The assessment panel recommends that future user research should be conducted in-person, and should be primarily task-based. The panel believes that it is more important that users can complete the tasks they need to, than focussing on gathering opinions on wording and layout.\n\n**&nbsp;** User-generated tasks should be used to understand what users expect to do with the service. This will more accurately reflect the experience of users who are less familiar with job sharing. The assessment panel also suggest that other names for the service are tested with users to make it more clear that the service is about finding a job share partner. This should be undertaken alongside further work to ascertain whether the user need extends beyond this, to cover guidance on the process of applying for a job (although recognising that this currently is outside scope).\n\n**&nbsp;** A mix of recruitment methods should be used to test with a wide range of people – too heavy a reliance on existing networks in the user panel will bias results to people who are familiar with job sharing, and those more likely to understand what they can do with the beta service.\n\n**&nbsp;** Usability testing for accessibility needs to be undertaken as soon as possible once the service is in beta.  \n**&nbsp;** While the assessment panel believes that the service in general is following GOV.UK patterns, there are a few places where it is not, for example cancel buttons and filter dropdowns. The panel recommends that the service be reviewed by a designer for consistency with GOV.UK style and patterns.\n\n**&nbsp;** Penetration testing and cookie page updates need to be undertaken before proceeding to beta.\n\n**&nbsp;** The service team needs to identify expert analytics resources that can be engaged to advise the team on usage patterns and potential areas to concentrate on to improve user experience.\n\n**&nbsp;**** Next Steps**  \nThe service team should follow the recommendations made in this report and see the Government Service Design Manual for further guidance.\n\n**&nbsp;** In order to launch as a beta, the service must do the following:\n\n- have an experienced content editor review the service pages and test the revised version with a range of users\n- embed user research and analytics resource within the team\n- have a clear plan for beta phase user research in place\n- publish source code in a public repository\n- complete penetration testing and cookie page updates\n\n**&nbsp;** Action taken on these must be confirmed with the GDS Assessment Team in writing before the service will be given authority to proceed to beta launch.\n\n**&nbsp;**** Summary**  \nThis service has been developed in tight timescales by a small team, who have limited resources. Their commitment to launching a service which helps those starting to look at job share possibilities was very clear.\n\n**&nbsp;** However, to improve the service, the assessment panel believes that the team needs to look more deeply into user needs to understand how to link the process of identifying a job share partner more seamlessly into the overall user journey. The service team also need to identify specialist expertise (in user research, analytics and content design) which can be deployed regularly as the service develops and iterates, and finalise a number of technical testing and steps.\n\n* * *\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | No |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | N/A | 8 | Yes |\n| 9 | No | 10 | N/A |\n| 11 | N/A | 12 | N/A |\n| 13 | Yes | 14 | Yes |\n| 15 | No | 16 | Yes |\n| 17 | No | 18 | No |\n| 19 | Yes | 20 | No |\n| 21 | N/A | 22 | N/A |\n| 23 | N/A | 24 | N/A |\n| 25 | Yes | 26 | N/A |\n\n| **Details of criteria that are not applicable to this service** |\n| Points 7, 10, 21, 22, 23 and 24 are not applicable to internal services.\n\nPoints 11, 12 and 26 not applicable to this assessment the service was being assessed against three core criteria (safe and secure, user needs and iteration and improvement).\n\n |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/scs-360-tool-digital-by-default-service-standard-assessment-result/",
    "title": "SCS 360 Appraisal Tool Digital by Default Service Standard assessment result",
    "summary": "The SCS 360 Appraisal Tool service is seeking permission for Beta Assessment approval.",
    "body": "**Department / Agency:**  \nMOJ\n\n**Date of Assessment:**  \n17/12/2014\n\n**Assessment stage:**  \nBeta Review\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nT. Duarte\n\n**Service Manager:**  \nM. Madden\n\n**Digital Leader:**  \nM. Coates\n\n* * *\n\n## **Assessment Report**\n\nThe Agent Online Self Serve service has been reviewed against the 26 points of the Service Standard at the end of the Alpha development.\n\n**Outcome of service assessment**\n\nAfter completing our assessment we have concluded that the service has shown sufficient evidence of meeting the required standard at the Beta Assessment stage. Beta branding can be added to the service.\n\n**Reasons**\n\nThe service was assessed against all 26 points of the Digital by Default Service Standard. We asked questions from the prompts and evidence for assessors, supplied by GDS. This document has questions and the evidence sought for Alpha, Beta and Live phases. We asked questions from the Beta section.\n\nThe service has passed on all the points of the standard though we have some recommendations that follow.\n\n**Recommendations**\n\nWith regards to user research we recommend that you:\n\n- confirm new researcher\n- ensure effective handover from current user researcher\n\nWith regards to analytics and product performance we recommend that you:\n\n- agree the use of data for effective service evaluation and improvement\n\nWith regards to design we recommend that you:\n\n- address handling of expired sessions and bookmarked URLs so that users don't receive generic error pages\n- re-evaluate display of form validation errors so that they're more prominent to users\n- emails should be sent from the initiating user so that emails can be replied to, not [notreply@gitlab.dsd.io](mailto:notreply@gitlab.dsd.io \"notreply@gitlab.dsd.io\")\n- new windows opened via 'more info' links contain 'back' links which open in the same new window resulting in duplicate pages; 'more info' links should either open in the same window, or 'back' links should close the new window.\n\n**Next steps**  \nThis service has been given approval to adopt Beta branding, but should address the recommendations during Beta.\n\n**Summary**  \nThank you for your thorough and well-prepared answers to our questions. Your team deserves to feel proud of the service and the work you have undertaken which has obvious potential for reuse across Government.\n\nThe service has passed the Beta Assessment and can adopt the Beta branding.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\nThe following table shows the result- where asking if the service passes- as against each of the 26 criteria. 22 of the criteria are relevant to this product- six were not applicable.\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | N/A | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | N/A | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | N/A | 24 | N/A |\n| 25 | Yes | 26 | N/A |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/parliamentary-questions-tracker-tool-self-certification/",
    "title": "Parliamentary Questions Tracker Tool - Self Certification",
    "summary": "Parliamentary Questions (PQs) are a mechanism by which MPs can ask questions of&nbsp;government departments on behalf of their constituents or for their own political needs.&nbsp;Within the Ministry of Justice, the distribution tracking and answering of PQs is&nbsp;managed by the Parliamentary Branch.",
    "body": "The bulk of PQs received are written and submitted to parliament daily, with roughly 100&nbsp;received per week. They must be answered within an allocated time (2 - 10 days), which can&nbsp;vary depending on the type of question.\n\nThe primary users of the Parliamentary Questions Tracker service are the members of&nbsp;Parliamentary Branch administering the process. The service has a wider audience of “action&nbsp;officers” who receive the questions and author the responses. In total the service has&nbsp;approximately 400 users, of which 40 are frequent and active.\n\n**Department / Agency:**  \nMOJ\n\n**Date of Original Assessment:**  \n19/09/14\n\n**Date of Reassessment:**  \n29/04/15\n\n**Assessment Stage:**  \nLive\n\n**Result of Original Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nG. Sheldrake (Original) / E. Fineberg (Reassessment)\n\n**Service Manager:**  \nM. Madden (Original) / R. Waite (Reassessment)\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## Reassessment Report\n\n**29th April&nbsp;2015**\n\nThe service was assessed against all 26 points of the Digital by Default Service Standard.\n\n**Outcome of service assessment**\n\nAfter consideration the assessment panel has concluded the Parliamentary Questions (PQs)&nbsp;Tracker service has shown sufficient evidence of meeting the standard. This means the&nbsp;service can now remove its beta branding.\n\n**Reasons**\n\nAreas of&nbsp;good performance against the standard included the following.\n\n_Security, privacy, tools and standards_\n\nSince previous assessment the team have acted on recommendations to introduce an&nbsp;automated suite of tests and continuous integration processes. They now perform small&nbsp;releases (usually daily or more frequently) rather than big releases. Parliamentary Branch&nbsp;have access to the staging environment for approval of features etc.\n\nThe team has completely rebuilt the state machine logic internally, and has refactored the&nbsp;code base for legibility. The code now is well structured.\n\nTest coverage has improved vastly from having no existing tests to around 80% coverage.&nbsp;The team has focused on user-centric feature tests. All new code developed is unit tested.&nbsp;The working practices of the team enable continuous delivery and improvement.\n\n_Design_\n\nThe panel was impressed with the implementation of responsive design for an&nbsp;internally-facing application. This makes mobile working much easier. Analytics had shown&nbsp;that users accessed the tool via mobile browsers during the beta phase.\n\nGDS design standards have been applied for the most part where appropriate.\n\n_A​nalysis&nbsp;and benchmarking_\n\nBy tracking how quickly Parliamentary Questions are answered, the service is continually&nbsp;tracking Parliamentary Branch’s key performance indicator. This was a great addition as it&nbsp;tracks the business value of the tool in a clear and measurable way.\n\nMore detailed metrics are now also in place to measure where bottlenecks are occurring in the process. Focusing on these metrics will support more data-driven design decisions in&nbsp;future iterations.\n\n**Recommendations**\n\n_User needs_\n\nThe main focus of the of the work since the last assessment has been to stabilise the code,&nbsp;with user research and subsequent action on the findings considered to be of lower&nbsp;importance.\n\nAs such, the levels of research so far can be considered to be minimally adequate. The&nbsp;assessment panel recommends that future iterations focus much more on user needs and&nbsp;that only features in the backlog that are known to be of value are deployed.\n\nUser research has been adequate given the small size of primary user base (approximately 40 users).&nbsp;Efforts should be made to complete user research with those who are completely unfamiliar&nbsp;with the process. Doing so will help to ensure that the service is part of a wider process&nbsp;transformation, rather than simply an automation of current processes.\n\n_The team_\n\nFrom now on the team will depend on ad hoc design and research support rather than a&nbsp;dedicated designer and user researcher on the team. As such the panel recommends that&nbsp;this is planned and orchestrated with a documented research plan in order to ensure a&nbsp;genuinely well-thought-out outcome.\n\nThe panel was shown evidence that the product will be moved into the product team that&nbsp;supports and iterates services internal to MoJ. Efforts should be made to pair with this team&nbsp;so that knowledge is transferred in such a way that there are no gaps in the product&nbsp;management of the tool. This is especially important given the value of the features in the&nbsp;backlog.\n\n_Design_\n\nThe design patterns remain consistent visually, functionally and at an interaction level with&nbsp;the version of the service previously assessed.\n\nThe panel recommends that outstanding design, UX and interaction improvements&nbsp;recommended at the last assessment should be made. There should be particular focus on&nbsp;improving:\n\n- early bird view\n- filtering\n- bulk actions\n- layout and navigational hierarchy\n\nThere are UI/UX design inconsistencies around Trim Link upload between the dashboard&nbsp;and PQ details pages that should be addressed. Navigation between the following pages should be clarified:\n\n- PQ dashboard to PQ&nbsp;detail page\n- PQ dashboard to address lists\n- PQ dashboard to report pages\n\n_A​nalysis and benchmarking_\n\nThe panel recommends that effort is put into analysing user journeys through the&nbsp;application using web analytics packages. The panel appreciates that this is a difficult goal&nbsp;given the non-linear nature of the application. However, in the absence of high volumes of&nbsp;users to research, this quantitative data would highlight appropriate UI or design&nbsp;improvements.\n\n* * *\n\n## Summary of Original Report\n\n**19th September 2014**\n\nThe service was assessed against all 26 points of the Digital by Default Service Standard.\n\n**Outcome of service assessment**\n\nAfter completing the assessment of Parliamentary Questions (PQs) we have concluded that the service does not show sufficient evidence of meeting the standard. This means the service should not remove its beta branding.\n\n**Reasons**\n\nThe assessment panel felt that the product team had not had the opportunity to go through alpha and beta assessment which would have helped them in preparation for ‘live’ assessment. Because of this some assumptions have been made in planning, external to the team, that meant the product owner and team were not empowered to sufficiently answer many of the assessment points.\n\nSome successes of the project included:\n\n- Developing engagement with stakeholders by co-building the product. The team achieved getting a previously disengaged team to feed-in on weekly sprints.\n- The team delivered design changes in an agile way, feeding research into design iteratively.\n- The service challenge meant the team had to resolve design challenges outside of those provided by GDS and developed new patterns and elements.\n- The team demonstrated a good understanding of the service journey and its challenges and had mapped the service-end to-end.\n\n**Recommendations**\n\n_Point 1_\n\nThe team has suffered from not having a researcher. They were not able to demonstrate sufficient understanding of their secondary users or enough usability testing to back up their design decisions.\n\n_Points 2, 14, 19, 20_\n\nThe product owner was not empowered to answer any questions on the future state of the product or the team. This affected the teams ability to sufficiently answer many questions on these points in the service assessment.\n\n_Point 13_\n\nDesign developments on the elements or patterns were not sufficiently backed up by research or demonstrated as being actively shared, discussed or worked with other teams either MOJ / GDS. Because of this consistency and logic felt underdeveloped and could be an issue in handing over to a new team.\n\n_Points 21, 22_\n\nThe team were not able to clearly demonstrate benchmarks for success as either completion or satisfaction.\n\n- The product owner was not empowered to get access to a full team or full phases of process. Discovery and alpha appear to be merged. Throughout the project various team members have been missing including a researcher, content designer and delivery manager. Going forward ensure the product owner can demonstrate that a full team will be available.\n- The product owner was not empowered to answer how the service will be developed and supported in the future as they have been told they are coming off the project. Ensure the product owner is empowered to answer how product developments can be enabled on an on-going basis.\n- Further research required to have a more complete understanding of users in particular secondary users’ needs. More user testing is required to build this understanding and the team will need a user researcher.\n- Plan to test the service with new primary users recruits prior to their onboarding to see if the service is intuitive to use.\n- Demonstrate design consistency with a logic for new elements backed up with usability testing on the product.\n- Demonstrate how the team has developed new patterns and elements. Show that they have worked with other similar MOJ / GDS products, shared learnings and are active on the hackpad and other cross government tools.\n- Plan for a baseline means for measuring success of the service. Monitor and show if PQs are answered on time (completion, progress rates, commissioning within the service) with a view on how this should be made visible.\n- Map the service change so that the benefit of change can be better understood and shared. Demonstrate the benefits that have been delivered from this.\n- Ensure the product owner is empowered to answer and can demonstrate a vision for the future of the product. What features are in the backlog? What are the benefits (user and business) these address? How will future service developments and proposals for Minimum Viable Products (MVPs) be made possible?\n\n**Summary**\n\nThe panel were impressed by the service, the complexity of the challenge, and the level of quality at which it has been delivered in a short time. However, because many of the standard points could not be answered sufficiently, the product is not ready to move from beta to a ‘live’ service.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | Yes | 8 | Yes |\n| 9 | Yes | 10 | Yes |\n| 11 | Yes | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | Yes | 24 | Yes |\n| 25 | Yes | 26 | Yes |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/the-staff-intranet-service-assessment/",
    "title": "The Staff Intranet - Service Assessment",
    "summary": "A new portal for MOJ where information is easy to find and content is easy to publish.",
    "body": "- Provide a common platform for content and publishing for internal information\n- Initial tagging by department enables departmentalisation of content\n- Single homepage that surfaces global MOJ news & department / ALB news whilst providing easier access to tools and pages  \nFocus is on Global, HQ and OPG content\n\n**Department / Agency:**  \nMOJ\n\n**Date of Assessment:**  \n21/11/14\n\n**Assessment stage:**  \nAlpha\n\n**Result of Assessment:**  \nPass\n\n**Lead Assessor:**  \nT.Duarte\n\n**Service Manager:**  \nT.Abedin\n\n**Digital Leader:**  \nM.Coats\n\n* * *\n\n## Assessment Report\n\n**Outcome of service assessment**\n\nAfter completing our assessment we have concluded that the service has shown sufficient evidence of meeting the required standard at the Alpha Review stage. Alpha branding can be added to the service.\n\n**Reasons**\n\nThe service was assessed against all 26 points of the Digital by Default Service Standard. We asked questions from the prompts and evidence for assessors, supplied by GDS. This document has questions and the evidence sought for Alpha, Beta and Live phases. We asked questions from the Alpha section.\n\nThe service has passed on all the points of the standard though we have some recommendations that follow.\n\n**Recommendations**\n\nWith regards to user research we recommend that you:\n\n- ensure some user testing with non-HQ based users who are remote working to evaluate if they should be included in personas/scenarios within the MVP scope\n- test with users of IE7 that include end-to-end testing\n- ensure alpha testing participants see the iterations evolving so they feel their feedback and time is providing value\n- engage with GDS to gather feedback from them and get accessibility support\n\nWith regards to the team you should:\n\n- increase your researcher’s time from two days a week to three days a week\n- confirm the start date of a backend developer\n- break user stories down in pivotal\n- talk to other teams about effective concurrent use of physical boards and pivotal\n- review DbD standard evidence for Beta assessment to reassess whether 3 weeks Alpha is sufficient time\n\nWith regards to security you should:\n\n- confirm the Information Asset Owner\n- agree penetration testing date\n- seek advice form other teams regarding procurement and lead times\n\nWith regards to open source reusable code you should:\n\n- ensure that code is opened as first priority when a new developer starts; if the repo is not public from the start there is a greater risk that configuration secrets will be added to this repository which makes opening it in the future more work\n\nWith regards to creating a service that is simple to use and intuitive enough for users to use first time unaided you should:\n\n- define what 'success' for a non-publishing user looks like\n- review/revise colour contrast and font size from accessibility point of view\n\nWith regards to assisted digital:\n\n- continue to consider the different user needs around MoJ for access to digital environment\n- continue discuss with your stakeholder and develop appropriate routes to assist less able users in a digital environment.\n\nWith regards to assisted analytics:\n\n- install Google Analytics for Alpha\n- With regards to establishing performance benchmarks and KPIs:\n- agree KPIs and targets with stakeholders and gather data for them so there is a clear consensus of what success looks like  \ndetermine how to measure user satisfaction and track during Alpha if possible\n\nIn addition:\n\n  - plan for redirecting any bookmarks people might have to redirect existing URLs onto equivalent pages for the new service\n\n**Next steps**\n\nThis service has been given approval to adopt Alpha branding but should address the recommendations during Alpha.\n\n**Summary**\n\nThank you for your thorough and well-prepared answers to our questions. Your team deserves to feel proud of the service and the work you have undertaken to discover assisted digital needs within the MoJ that will be of great value to other internal services.\n\nThe service has passed the Alpha Review and can adopt the Alpha branding. Though some service standard points are not applicable, recommendations have been made regarding benchmarking and user satisfaction as it will benefit the service.\n\nWe are looking forward to seeing you again and are as keen to see this move into Beta when it can be iterated further with greater numbers of users.\n\n* * *\n\n## Digital by Default Service Standard criteria\n\n| **Criteria** | **Passed** | **Criteria** | **Passed** |\n| 1 | Yes | 2 | Yes |\n| 3 | Yes | 4 | Yes |\n| 5 | Yes | 6 | Yes |\n| 7 | N/a | 8 | N/a |\n| 9 | Yes | 10 | Yes |\n| 11 | N/a | 12 | Yes |\n| 13 | Yes | 14 | Yes |\n| 15 | Yes | 16 | Yes |\n| 17 | Yes | 18 | Yes |\n| 19 | Yes | 20 | Yes |\n| 21 | Yes | 22 | Yes |\n| 23 | N/a | 24 | N/a |\n| 25 | Yes | 26 | N/a |"
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/tax-credit-renewals-service-assessment/",
    "title": "Tax Credit Renewals – Service Assessment",
    "summary": "This service will allow tax credit customers to renew their tax credit claim online.",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n27/3/2014\n\n**Date of Reassessment:**  \n9/4/2014\n\n**Moving to:**  \nPublic Beta\n\n**Result of Assessment:**  \nNot passed\n\n**Result of Reassessment:**  \nPass\n\n**Lead Assessor:**  \nS. Edwards\n\n**Service Manager:**  \nB. Price\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## **Reassessment report**\n\nThe Tax Credits Renewals Service is seeking permission to continue development as it moves to Public Beta.\n\n### **Outcome of service assessment**\n\nAfter consideration we have concluded that Tax Credits Renewals Service has shown sufficient progress and evidence of meeting the pre-April 2014 criteria. The serviceshould proceed to Public Beta subject to the conditions detailed below.\n\n### **Reasons**\n\nAll&nbsp;[26 points of the service standard](https://www.gov.uk/service-manual/digital-by-default)&nbsp;were considered during the assessment. However, before April 2014 the primary considerations are:\n\n- does the service meet user needs?\n- can it be rapidly improved?\n- is it safe, i.e. are appropriate security and privacy protections in place?\n\nThe Tax Credits Renewals team have shown that:\n\n- The service meets the minimum user needs for a public beta and is rapidly improving the user experience towards the long term goal of a Digital by Default service for Tax Credits Renewals.\n- They have conducted an extraordinary amount of formal and informal user research since the previous service assessment and have detailed plans for continuing user research during the public beta phase.\n- The service has been improved, and has the potential to continue to be improved on a very frequent basis based on user research.\n- The service has improved following input from an experienced content designer who was collocated with the service team. This has improved the language in the service such that it is simpler, clearer and concise. The service has improved almost beyond recognition from what the assessment team reviewed only two weeks before.\n\n### **Conditions to be met during Beta stage**\n\nGDS are seeking written confirmation by the 31 May 2014 that the following actions have been taken by that date:\n\n1. That the service implements a feedback mechanism from other channels, such as contact centres, and that this is informing the continuous service development.\n2. User research has continued to inform the service development, broadly in accordance with the plan outlined to the assessors.\n3. That progress has been made on recruiting the remainder of the service team so as to ultimately reduce their reliance on staff not collocated with the service team.\n4. That the service team have put in place a disaster recovery and business contingency plan and have tested both plans.\n5. That the service team have engaged with the Performance Platform in GDS to build a dashboard for the service.\n\n### **Next Steps**\n\nThe assessment has shown that Tax Credits Renewals service meets the pre-April 2014 criteria of the Digital by Default Service Standard and should proceed to Public Beta.\n\n### **Summary**\n\nIn summary we are very pleased to report that this service can proceed to Public Beta.\n\nThe team are clearly aware of the importance of the work they have ahead of them and the planning they have done over the last two weeks should ensure that the service continues to improve.\n\n* * *\n\n## **Assessment report**\n\nThe Tax Credits Renewals service is seeking permission to launch as a Public Beta.\n\n### **Outcome of service assessment**\n\nWe have concluded that the Tax Credits Renewals service should not be given approval to launch on the&nbsp;[service.gov.uk](http://service.gov.uk/)&nbsp;domain as a Public Beta service.\n\n### **Summary of reasons**\n\nThe current service does not meet the pre April 2014 criteria for passing a digital by default service assessment. The service does not pass on the following grounds:\n\n1. There are issues with service usability that need to be addressed before it goes into public beta (and reviewed in a follow-up service standard assessment before permission to go live will be granted).\n\n2. Any service that is expected to have a high profile and/or high volume of transactions needs to be user tested before it goes live; there has not yet been sufficient testing with real users, and consequently it has some usability problems.\n\nHMRC have an exciting and ambitious programme of reform for transforming their services and creating new digital services. GDS understand that the Tax Credits Renewals service team was brought together in January, with work commencing in February, and have therefore had only 8 weeks to organise their team and deliver a major new online digital service for this service assessment. This is an ambitious timescale and the team have evidently worked extremely hard in the most difficult of circumstances to deliver the service to the current state.\n\nNevertheless, given the current usability issues and lack of user testing, GDS do not believe this service is ready to move into public beta. GDS found that the service team have built a set of web-based forms that aims to replicate the paper form for tax credits renewal, without taking the opportunity to use the digital service to improve the experience of tax credits renewal for users. Until the team makes changes to the digital renewals system, it may make more sense for a user to fill in the paper form than to complete the digital service. Although the scope of the tax credits renewal service is narrow, there is still an opportunity to make the service easier to use than the paper form or the phone service as detailed below.\n\n### **Detailed reasons**\n\nUser Needs\n\n- The service does not have a sufficiently clearly defined user need and not enough time was spent analysing the user needs before the project was implemented.\n- The service team have not taken the opportunity to fully understand their users or their needs. We understand that 60 tax credit recipients were surveyed and a report was produced which appears to have been used to scope out service development based on departmental needs.\n- As a result, the service team had a narrow scope of work that focused on digitising part of an existing paper form and building the digital service to fit around existing HMRC business processes.\n\nUser Research and User Feedback\n\n- The service team were not present during the small number of formal user research sessions that have taken place. This means the service team, and in particular the Service Manager, missed a valuable opportunity to gain insight into how users were interacting with the service. &nbsp;A learning point is that the quality of this service will be directly related to the number of hours each and every team member is exposed directly to real users interacting with the team's designs.\n- More user research needs to be carried out. GDS understand that only 19 individuals have been involved in testing the service and that some of these users were stakeholders rather than end users. Although it would have been preferable to have an experienced user researcher in the team, the service could conduct informal user research which should pick up some of the usability issues with the service.\n- User research has been outsourced to 3rd party organisations and then largely consumed by report. This has not allowed the service team enough chance to gauge how users are interacting with the service. There wasn’t enough evidence of the user research being used as real insight into how users would interact with the service.\n- GDS were concerned that there was no clear plan to conduct further research. GDS were told that the team had conducted some initial research involving making contact with public libraries in and around Newcastle, but this had not yet led to any firm plans for user research to take place. GDS recommends that the key area for improvement is the need for more stringent user research, with as many real users as possible, before the service is re-assessed.\n- A further area for improvement is the support service for users. The current proposal is to use a &nbsp;telephone based helpdesk (rather than the digital support service established for the exemplar services). The proposal needs to include feedback mechanisms so that the service can continue to iterate based on feedback from end users.\n\nUsability and Content\n\n- The service is built using the&nbsp;[GOV.UK](http://gov.uk/)&nbsp;visual design and typography, but the interaction design needs more work to have the feel or tone of a service built for hosting on&nbsp;[GOV.UK](http://gov.uk/).\n- Written content needs to be reviewed as it is not consistent with the&nbsp;[GOV.UK](http://gov.uk/)&nbsp;style guide. The assessment team were left with concerns following the first review of content. The content included highly technical information, that produced a more business led content design than was appropriate. GDS felt that it would make the content more difficult for a user to understand than if it had met the&nbsp;[GOV.UK](http://gov.uk/)&nbsp;style guide. A learning point is the need for highly capable content writers to ensure to ensure that content going into an alpha service does not need to be rewritten. There have been some steps in the right direction. During the service assessment we were shown revised content that had been produced following a content review. There is however, still a lot of work to do before the end to end service is easy to understand and use. GDS recommend focusing on this as a high priority.\n- GDS felt that more use should be made of interaction design of the service. For instance, typing in a 15 digit number could have been broken into a number of smaller text blocks, with a few alternatives tested to see what was best for the user. Another example: at various points the user is asked to perform calculations on paper working sheets and then type in the sum of several numbers into the screen. It would not be reasonable to expect the user to write down numbers on paper working sheets and then use a calculator to obtain the sum, when a small modification to the service would replace a complex calculation step which could generate &nbsp;errors.. We recommend focusing on this as a high priority.\n- The service is provided across multiple channels and departments within HMRC. However, the Service Manager exists within only one channel - the digital channel - and so is not empowered by HMRC to effectively change the whole service.\n\nThe service team and service support:\n\n- The service team is not yet complete, recruitment to complete the team is still in very early stages. There are gaps within the team for a Product Analyst, Interaction Designer, Content Designer, User Researchers, and Web Operations Engineers. Currently, the team are reliant on staff in different locations (Preston, Belfast, Dorset House in London and Newcastle), making collaborative working harder.\n- The service team are expecting that the HMRC Tax Platform team in London will provide operational support. During the assessment it became apparent that there is a lack of clarity about what support is available. It is really important that the service team are clear about exactly how they expect the service to be operated and test those assumptions with their London colleagues before the service goes into public beta. In particular this should include (1) how out of hours support will work; (2) the degree to which they expect their London colleagues to understand how the system is built; and (3) how the team expects to deploy changes to the live service. GDS recommend focusing on this as a high priority.\n\nAgile ways of working and frequent iteration:\n\n- The service team showed evidence of their intention to work in an agile way and we would recommend that they are supported with an agile coach who will be able to give immediate help with process issues.\n- The Service Manager should ensure that the legal team have access to the service’s “preview environment” and can review and approve the text in the actual service as it is iterated. Experience shows that this will reduce the rate of errors and increase the rate of change.\n\nSource code\n\n- The service team should ensure that the approach to source code is open by default, in line with broader government policy, and we expect to see the source code made available under a suitable open source license unless there is a compelling reason to keep it closed.\n\nProduct analytics\n\n- We were encouraged by evidence that the Service Manager will be analysing data from the service using Google Analytics reports in conjunction with HMRC colleagues in Preston. The Service Manager has planned to receive training in Google Analytics, although this will be an additional burden for the Service Manager at a very busy time. A Product Analyst could be appointed to provide support and expertise to the Service Manager.\n\n### **Next Steps**\n\nThe assessment has shown that the Tax Credits Renewals service is not yet on track to meet the Digital by Default Service Standard. Tax Credit Renewals should follow the recommendations made in this report and see the&nbsp;[Government Service Design Manual](https://www.gov.uk/service-manual/digital-by-default)&nbsp;for further guidance. In order for the service to proceed to Public Beta, GDS require a full reassessment.\n\n### **Summary**\n\nThe tax credits renewals service team have made considerable progress in a very short time under tight constraints. The challenge of building the service to meet the standard was incredibly difficult and it is a testament to their hard work that they have made so much progress in such short timescales. The challenges that remain are considerable, but in no way insurmountable, even in the limited timescales available. The HMRC team in Dorset House have access to interaction designers, content designers and software developers who we understand have already started to help to address some of the problems. GDS recommend that you continue working with them and focus on making this a service designed around the needs of the user, rather than attempting to replicate the existing paper form. Simultaneously, HMRC should consider how to ensure your team is properly supported to ensure you can continue to iterate this service throughout the summer and into the 2015 renewals period."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/your-tax-account-service-assessment/",
    "title": "Your Tax Account – Service Assessment",
    "summary": "The tax account brings together everything someone running a business needs to manage their business's tax affairs. From a personalised homepage, which provides an overview of all their tax records, showing a summary of their current liabilities, users will be able to: access via direct links the actions they need to take and transactions they need to complete; and access help, education and interactive tools.  \n[https://www.gov.uk/transformation/business-tax-account](https://www.gov.uk/transformation/business-tax-account)",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n24/3/2014\n\n**Moving to:**  \nPublic Beta\n\n**Result:**  \nPass with conditions\n\n**Lead Assessor:**  \nS. Edwards\n\n**Service Manager:**  \nM. Cornford\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Conditions met since assessment\n\nYour Tax Account were given approval to move to Public Beta subject to meeting two conditions (see report below). Since the assessment, Your Tax Account have taken appropriate actions to address these conditions and GDS are satisfied that they can now move to Public Beta.\n\n* * *\n\n## Assessment report\n\nYour Tax Account is seeking permission to continue development as it moves from Private Beta to Public Beta.\n\n### Outcome of service assessment\n\nAfter careful consideration GDS have concluded that Your Tax Account has shown sufficient progress and evidence of meeting the pre-April 2014 criteria. The service should proceed to Public Beta after meeting the specific conditions detailed below.\n\n### Reasons\n\nAll[&nbsp;26 points of the service standard](https://www.gov.uk/service-manual/digital-by-default)&nbsp;were considered during the assessment. However,[&nbsp;before April 2014](https://www.gov.uk/service-manual/digital-by-default/assessments-before-2014.html)&nbsp;the primary considerations are:\n\n- does the service meet user needs?\n- can it be rapidly improved?\n- is it safe, i.e. are appropriate security and privacy protections in place?\n\nThe Your Tax Account team have shown that:\n\n- The service is meeting user needs and they have done extensive user testing with real users. The team explained a wide range of techniques they had used to research and understand the user needs for the service, and had used multiple techniques including card sorting, early prototyping, informal testing and extensive formal user research.\n- The service has been, and has the potential to continue, to be improved using agile methodologies on a very frequent basis based on user data (although see condition 1 below). GDS were very impressed by the team’s examples of where they had improved the product as a result of user research.\n- The service has undertaken a comprehensive IT health check and has taken appropriate action based on findings to ensure the service is safe.\n- The service has worked with a GDS content designer to ensure that the language in the service is as simple and concise as possible.\n- The service recognises the importance of learning from early failures and demonstrated how this had informed and improved the product development.\n\n### Conditions for approval\n\nThe service was reviewed against the pre-April 2014 criteria of the Service Standard and must meet the following conditions before proceeding to Public Beta.\n\nCondition 1 - Rapid iteration of services and shared backlog\n\nThe assessment team have concerns that Your Tax Account will be unable to iterate or support the tool past the present point. Point 2 of the service standard requires: \"[...] a multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with full authority and decision-making responsibility.\"\n\nGDS understand that HMRC has now moved to a new operating model where user stories across the exemplars and all other digital projects are pooled into one single HMRC backlog. User stories are then prioritised across all HMRC projects, meaning it is difficult for the Your Tax Account Service Manager to maintain a multidisciplinary team and prioritise their own work within their own project.\n\nFrom discussion in the assessment it was clear that there is a high contention for limited shared resources (developers, UX, and researchers) and these restrictions mean that it appears to us that the Service Manager, despite demonstrating to us a high level of knowledge and capability, is not 'empowered' to prioritise the Your Tax Account user stories against the competing priorities within HMRC.\n\nThe result of this is that the Service Manager is unable to access resources to iterate and develop their service, leading to blocked delivery and features that should have been built for the public beta, not being delivered. If a Service Manager is unable to iterate their service then it should not pass the service standard.\n\nGDS are reluctant to be prescriptive about how HMRC use their resources and recognise that the operating model is for HMRC to decide. GDS also recognise the ambitious and exciting programme of reform that HMRC have for transforming their digital services. However, the operating model must ensure that the Service Manager is empowered to prioritise their own backlog and iterate their service through the development stages and, just as importantly, after the service has gone live.\n\nCondition 2 - Rapid iteration of services\n\nGDS are also concerned that the Service Manager appears restricted in their ability to iterate the service due to the internal HMRC change approvals process. We understand and accept the importance of such a process for the existing HMRC online services and any other business critical backend processing systems. We also recognise that there will be a balance to be made between the desire to rapidly iterate a new service and at the same time protect the integrity of any existing mission critical systems.\n\nHowever, it appears that even deploying a minor change to the service that doesn't impact mission critical systems is a drawn out process, and we would like assurance that the change control process can distinguish between different types of change and enable the Service Manager to make rapid iterations without going through an overweight process that doesn't vary across types of change.\n\n### Other Recommendations\n\nThe lack of a log retention policy in Splunk, considering it contains personally identifiable data, is something to consider, and a plan to address that should be defined and scheduled before proceeding to public beta.\n\nThe Your Tax Account team should make plans to integrate reporting of the service into the Performance platform.\n\n### Next Steps\n\nThe assessment has shown that Your Tax Account does not fully meet the pre-April 2014 criteria of the Digital by Default Service Standard. Your Tax Account should meet the conditions and follow the recommendations made in this report and see the[&nbsp;Government Service Design Manual](https://www.gov.uk/service-manual/digital-by-default)&nbsp;for further guidance. In order for the service to proceed to Public Beta, GDS require written confirmation of the actions taken to meet the conditions above.\n\n### Summary\n\nIn summary GDS are very pleased to report that, subject to completing the above conditions, this service can proceed to Public Beta. Your Tax Account have made considerable progress with building an exemplar service at the core of HMRC’s digital transformation and with the appropriate support in place around this team they have every reason to continue along their previous trajectory of delivering well researched and proven solutions to meet user needs."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/digital-self-assessment-beta/",
    "title": "Digital Self-Assessment – Beta Assessment",
    "summary": "Digital Self Assessment will replace the letters HMRC sends to self assessment customers with email alerts asking them to log in to the new tax account and see the same calls to action in a simpler, clearer way online.  \n[https://www.gov.uk/transformation/self-assessment](https://www.gov.uk/transformation/self-assessment)",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n21/3/2014\n\n**Moving to:**  \nPublic Beta\n\n**Result:**  \nPass\n\n**Lead Assessor:**  \nM. Sheldon\n\n**Service Manager:**  \nT. Smith\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment report\n\nThe Digital Self-Assessment service is seeking permission to launch on the&nbsp;[GOV.UK](http://gov.uk/)&nbsp;service platform, as it moves from Private Beta to a Public Beta.\n\n### Outcome of service assessment\n\nWe are pleased to say that the Digital Self-Assessment service has shown sufficient evidence of meeting the pre-April 2014 Digital by Default Service Standard and can launch as a Public Beta service. However, the assessment team did agree that the service in its current form is a feature of “Your tax account”, rather than a service in its own right.\n\n### Reasons\n\nThe Digital Self-Assessment team have shown that they are:\n\n- following good user research practices and have plans for and ongoing testing with real users\n- working with a GDS content designer to ensure the language is as simple and concise as possible\n- following agile methodologies and aim to improve the service based on user feedback\n- considering the service’s safety by carrying out IT health checks and addressing issues raised\n\n### Recommendations and comments\n\nThere have only been small improvements to Digital Self-Assessment service during the Private Beta. Yet this may be due to the fact it is currently a feature of “Your tax account” and only partially complete.\n\nThe team shared improvements to the sign-up screen and the \"Your tax account\" interstitial pages. But these were not part of the demonstration as they were incomplete. It was noted that a high proportion (third to half) of users of the service had not understood what they were signing up for. So it is important that the team iterate on the feedback of these improvements to reduce this number.\n\nThe team have been working with CESG to ensure the safety of the service. But there were some instances where usability had been sacrificed. The assessment team felt that these areas should be reviewed:\n\n- Routes through the service where users can navigate to dead-end pages with no obvious way of returning.\n- Email content not addressed to the user and with little substantive content\n\nAlthough the team have an aim to update and improve the service on a frequent basis. There was a lack of clarity as to how frequently, especially within the constraints of HMRC's release process. It is important that the Service Manager is in control of and owns the priority of what is released to the live service and when.\n\nFinally, the assessment team are concerned by HMRC’s restructure of their product teams, into a central delivery team. Points 2, 14 & 19 of the standard emphasise the importance of having a team that can update and improve a service on a frequent basis, led by an empowered Service Manager. Having a central shared delivery team does not allow for this. Users’ needs of the Digital Self-Assessment service will have to be prioritised against the needs of all other exemplars and services. If the Service Manager is unable to iterate their service, then it will not pass the service standard when seeking to move from Public Beta to Live.\n\n### Summary\n\nIn summary, the Digital Self-Assessment service is currently on track to meet the pre-April 2014 Digital by Default Service Standard. The team have continued to user test while building the Private Beta and have improved the service based on feedback."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/foreign-operator-payment-system-service-assessment/",
    "title": "Foreign Operator Payment System – Service Assessment",
    "summary": "The service allows HGV operators and drivers to pay the new road use levy before foreign owned HGVs enter the UK.",
    "body": "**Department / Agency:**  \nDfT\n\n**Date of Assessment:**  \n11/02/2014\n\n**Date of Reassessment:**  \n14/03/2014\n\n**Moving to:**  \nPublic Beta\n\n**Reassessment Result:**  \nPassed\n\n**Lead Assessor:**  \nJ. Stewart\n\n**Service Manager:**  \nS. Kendall\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## **Reassessment report**\n\nProgress has been made on reviewing the service management approach for this service and of the plan now in place to bring it within DVLA, appoint a new dedicated service manager and work toward a more integrated team. The developer has significantly demonstrated the ability to continually improve the beta site over a short period focused on issues raised at the first assessment. Further work is continuing with DVLA and Crown Commercial Services to enable long term continual development of the service led by user feedback. GDS understands there is&nbsp; a commitment&nbsp; to continue iterative development once the service is launched.\n\nGDS notes the progress that the team has made on improving the user interface for the service, particularly making it work responsively for mobile. The response had questions about the changing advice provided by GDS on the design of the service, while an individual may have differing preferences in design assumptions should be tested with users regularly and often. GDS is working on new design guides that will help services to develop services that will meet the service standard. A significant amount of user research with real users has been carried out to date, much of the feedback gathered was incorporated into the services design. There is a commitment to visit operators and observe the use of the service for back office workers, this is crucial to further development and meeting the user needs of largest groups of expected users. Full accessibility testing has been completed&nbsp; and there is a commitment to achieve accreditation from the Shaw Trust once the service is publicly available. GDS are now convinced that the multidisciplinary team have all the skills in place to continue the development of the service. The team will be able to continue the work on user research already completed, developing the service based on user research in an iterative way.\n\nGiven the progress on both of those areas GDS has concluded that the service can proceed to Public Beta on the[&nbsp;service.gov.uk](http://service.gov.uk/)&nbsp;domain, pending a full re-assessment within the next three months.\n\n**Recommendations**\n\nWhile progress has been made in other areas many of our previous recommendations detailed in the original assessment report remain and GDS would hope to see progress on any outstanding&nbsp; points by the re-assessment.\n\nIn particular GDS looks forward to hearing about progress on building the multi-disciplinary team around the service manager (rather than at arms-length) and will be keen to see what insights are gained from user research and testing with the projected 94% of users working in back office roles.\n\n**Other observations**\n\nGDS are grateful to all involved for the rapid work to respond to the outcome of the previous assessment and to address some of the challenges that were identified then. It is extremely encouraging to note the quick progress on both systemic and more immediate user-facing improvements.\n\n**Next Steps**\n\nThis re-assessment has shown that the Foreign Operator Payment System (FOPS) is sufficiently on track to meet the Digital by Default Service Standard and can proceed to Public Beta.\n\nGiven the tight timescales involved a GDS Technical Architect will co-ordinate the next steps.\n\n* * *\n\n## **Summary of Original Assessment report**\n\nThe Foreign Operator Payment System (FOPS) is seeking permission to continue development as it moves from Alpha to Public Beta.\n\n**Outcome of service assessment**\n\nThe assessment panel have concluded the Foreign Operator Payment System (FOPS) should not be given approval to launch on the&nbsp;[service.gov.uk](http://service.gov.uk/)&nbsp;domain as a Public Beta service at this time.\n\n**Reasons**\n\nThe assessment panel’s main reservation is the lack of a fully empowered service manager with day-to-day responsibility for running and improving the service, leading the team, and ensuring that the service is performing well against KPIs and meeting the user needs it sets out to fulfil.\n\n**Recommendations**\n\nThe assessment panel recommended a number of areas for further development and completion to ensure compliance with the full standard.&nbsp; These included:\n\n- Continuing user research and accessibility testing to ensure a fully responsive service;\n- Working further with GDS on content design, a cookie policy, open data, analytics, identity assurance; and design patterns;\n- Removing the HGV levy logo;\n- Ensuring support for java script;\n- Taking forward arrangements for a skilled and empowered service manager and support team;\n- Developing arrangements for responding to feedback during the beta period;\n- Setting appropriate KPIs and information on costs.\n\n**Other observations**\n\nThe assessment panel were impressed by the thorough knowledge of the haulage industry demonstrated by the service team and the detailed investigations made to work out the impact of the new legislation.\n\nThe assessment panel noted the great efforts made to conduct user research in the field and source real users on ferries. As outlined in the recommendations, it would be excellent if this thorough approach were extended to the primary users of the service based in administrative offices in large haulage companies.\n\nThe assessment panel noted the significant improvements made from the alpha and the hard work from the service team to prepare the beta in time for this assessment.\n\n**Next Steps**\n\nThe assessment has shown that the Foreign Operator Payment System (FOPS) is not yet on track to meet the Digital by Default Service Standard. The service team should follow the recommendations made in this report and see the Government Service Design Manual for further guidance. In order for the service to proceed to Public Beta, we require a full reassessment."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/civil-service-resourcing-e-recruitment-system-service-assessment/",
    "title": "Civil Service Resourcing e-Recruitment System – Service Assessment",
    "summary": "This is a Pan Government service which allows vacancy holders and recruiters to manage individual vacancies and large recruitment campaigns for both internal and external recruitment. It also provides an improved candidate experience for individuals when searching for and applying for jobs.",
    "body": "**Department / Agency:**  \nHMRC / Civil Service Resourcing\n\n**Date of Assessment:**  \n12/3/2014\n\n**Moving to:**  \nLive\n\n**Result:**  \nNot passed\n\n**Lead Assessor:**  \nJ. Thornett\n\n**Service Manager:**  \nL. Whelan\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## **Update following the assessment**\n\nFollowing the assessment Civil Service Resourcing have taken steps to address a number of the issues raised in the assessment report (see below) in very a short timescale.\n\nGDS have subsequently given the service approval to move to Public Beta.\n\nSome of the actions taken include:\n\n- appointing a Service Manager to run the service and implement a service improvement plan during the Beta.\n- conducting a small survey of applicants who have had access to the new candidate portal. Overall the feedback was positive in comparison to the previous service, particularly on navigation and new features. The survey also identified areas for improvement which will feed into the service improvement plan for the Beta.\n- branding the service as a Beta and will utilise the ability to capture user feedback during the Beta.\n- testing the service against a number of browsers and will do more work during the beta to ensure the service is accessible via tablets and mobiles.\n- moving towards bringing the look and feel of the service in line with GOV.UK using the GDS design patterns.\n\nCivil Service Resourcing recognise they have further work to do to meet the standard and will implement a service improvement plan to address any outstanding issues during the Public Beta.\n\n* * *\n\n## **Assessment report**\n\nThe Civil Service Resourcing e-Recruitment system is seeking permission to launch a new service to replace the existing recruitment service.\n\n### **Outcome of service assessment**\n\nGDS have concluded the Civil Service Resourcing e-Recruitment system should not be given approval to launch on the service.gov.uk domain as a Live Digital by Default service.\n\n### **Reasons**\n\n1. The service consists of a back-end admin tool for use by internal recruiters, a job search facility for people to search for vacancies, and an online application process for a user to apply for a role. Whilst evidence was given on the understanding of user needs for the admin interface there was little evidence that research or data had been gathered to sufficiently understand the needs of the users accessing the job search service and applying for a vacancy.\n\n2. &nbsp;Further to this, the system being replaced does not currently collect user data via an analytics tool and there is also no analytics data collection within the new service. Collecting and analysing data on end user behaviour is therefore very difficult, if not impossible, and this is vital in ensuring the service can be iterated and improved through development stages and after live release.\n\n3. The service demonstrated at the assessment does not use any of the GOV.UK design patterns and has not been designed to look and feel like GOV.UK. &nbsp;We would expect the site to use the crown logo, the GOV.UK typeface, and the same header and footer as other GOV.UK services. &nbsp;More detail on the requirements can be found on the service manual: &nbsp;[https://www.gov.uk/service-manual/user-centered-design/service-look-and-feel.html](https://www.gov.uk/service-manual/user-centered-design/service-look-and-feel.html)\n\n4. The service has been tested on IE6 and IE8 browsers but we would expect the service to have been tested on a wider range of devices and browsers, including mobiles and tablets, before it is ready to go live. &nbsp;More information here:&nbsp;[https://www.gov.uk/service-manual/user-centered-design/browsers-and-devices.html](https://www.gov.uk/service-manual/user-centered-design/browsers-and-devices.html)\n\n5. &nbsp;The ability to make quick changes or improvements to the service in an agile way is dependent on the contract with the supplier although it is noted that the development on the service has used a more waterfall process of specification, build, and release rather than a more agile, sprint based approach.\n\n6. &nbsp;There is no-one in a defined service manager role at present although the central team do report to a Deputy Director within Civil Service Resourcing who can act as a point of escalation. It is also still unclear who the minister responsible for the service is, and so is yet to be tested from end to end by a suitable minister.\n\n### **Next Steps**\n\nThe assessment has shown that the Civil Service Resourcing e-Recruitment system is not yet on track to meet the Digital by Default Service Standard. The service should follow the recommendations made in this report and see the&nbsp;[Government Service Design Manual](https://www.gov.uk/service-manual/digital-by-default)&nbsp;for further guidance. In particular, the advice on using cookies ([https://www.gov.uk/service-manual/making-software/cookies.html](https://www.gov.uk/service-manual/making-software/cookies.html)) and the standard KPIs ([https://www.gov.uk/service-manual/measurement/other-kpis.html](https://www.gov.uk/service-manual/measurement/other-kpis.html)) are very relevant, in addition to other pages mentioned above.\n\nThe service may also find it useful to review the standard web schema for job advert posting which would be a good addition to the code on the job search element of the service -&nbsp;[http://schema.org/JobPosting](http://schema.org/JobPosting)\n\n### **Summary**\n\nThis is a complex service with a large number of internal and external users who each access very different parts of the system and have quite different requirements. Some good work has been done to understand the needs of the internal users and make improvements to the admin interface to improve their experience of the service. Also, the work on security and data privacy has been very thorough and planned in good time ahead of release. However, before the service can meet the criteria set out in the service standard there are improvements needed in understanding the needs of the users accessing the job search and application part of the service, the ability to capture performance data and make quick improvements to the service, and to ensure it has the overall GOV.UK look and feel."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/vehicle-management-service-assessment/",
    "title": "Vehicle Management – Service Assessment",
    "summary": "Vehicle Management will provide an online facility for motorists to notify changes to their vehicle registration details. This will include notifying a change of keeper and change of name and address, which will allow tens of millions of motorists each year to transact via digital channels rather than the existing paper based channels.  \n[https://www.gov.uk/transformation/manage-vehicle](https://www.gov.uk/transformation/manage-vehicle)",
    "body": "**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n3/3/2014\n\n**Moving to:**  \nPrivate Beta\n\n**Result:**  \nMet\n\n**Lead Assessor:**  \nS. Bennett\n\n**Service Manager:**  \nR. Gye\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## Assessment report\n\nThe Vehicle Management Service is seeking permission to continue development as it moves from Alpha to Private Beta.\n\n### Outcome of service assessment\n\nAfter reviewing the assessment report GDS are pleased to say we have concluded the Vehicle Management has shown sufficient progress and evidence of meeting the pre-April 2014 criteria and should proceed to Private Beta.\n\n### Reasons\n\n- The team show commitment to developing this as a user-focused service and have clear plans in place to extend and act on their user research.\n- The team showed a commitment to designing a system which will keep customer information secure and safeguard against potential fraud\n- The team has demonstrated the potential to iterate and improve the service rapidly to enhance the user experience. There is evidence that they have already made changes in response to user feedback.\n\n### Recommendations\n\nWhilst GDS were happy for the service to proceed to Private Beta, GDS suggest the following actions should be taken by the team during the next phase of development:\n\n- Strengthen their team by hiring a designer and content designer who can help make the service look and feel more like&nbsp;[GOV.UK](http://gov.uk/). At present the service is still using ‘trade’ language and terms, which could be confusing for the general public; and the current screen layouts need to be revised to follow&nbsp;[GOV.UK](http://gov.uk/)&nbsp;practice\n- Similarly, ensure that the team has dedicated user insight and data analysis resources allocated from the central DVLA teams to work as an integral part of the service development team\n- Revise team job definitions and titles in line with the Service Design Manual around the roles where&nbsp;[development and operation](https://www.gov.uk/service-manual/operations/devops.html)&nbsp;come together\n- Extend testing rapidly to cover individual users (as opposed to the preponderance of trade users in testing to date)\n- Work with CESG to determine any potential new fraud/phishing/spam relay risks arising from taking this service online\n- Ensure that DVLA, over and above the third party supplier, fully understands the legal implications of the choice of open source licence and are aware of the Government Open Standards process and existing standards adopted\n- Ensure that all links are unbroken, or link to the right places, where code has been adapted from other projects\n- Carry forward plans to understand future assisted digital needs and who might provide support (especially in phases where sales fall between individuals rather than being to or from trade organisations)\n- Think about how to measure user satisfaction for this service (including a concluding survey)\n- Obtain and implement an analytics package (in consultation with the GDS Performance Platform) and ensure you can provide accurate KPI data for each element of the vehicle management service\n- Start to consider how management of digital and other channels would be integrated; and develop plans (including targets) to encourage channel shift and achieve high digital take-up\n\n### Next Steps\n\nThis service has been given approval to launch as a Private Beta service.\n\n### Summary\n\nGDS were very pleased to see the team’s commitment to developing and continually improving a user-focused service that will meet the stringent demands of the Service Standard."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/civil-claims-service-assessment-2/",
    "title": "Civil Claims – Service Assessment",
    "summary": "Civil claims are a way for the public to solve civil legal disputes or obtain money or property owed. The exemplar aims to create a digital service for all types of claims, improve user experience and save money.  \n[https://www.gov.uk/transformation/court-claims](https://www.gov.uk/transformation/court-claims)",
    "body": "**Department / Agency:**  \nMOJ\n\n**Date of Assessment:**  \n27/2/2014\n\n**Moving to:**  \nPublic Beta\n\n**Result:**  \nNot passed\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nE. Fineberg\n\n**Digital Leader:**  \nM. Coats\n\n* * *\n\n## Assessment report\n\nThe Civil Claims service is seeking permission to continue development and move to Public Beta.\n\n### Outcome of service assessment\n\nGDS have concluded the Civil Claims service should not be given approval to launch on the&nbsp;[service.gov.uk](http://service.gov.uk/)&nbsp;domain as a Public Beta service.\n\nGDS were really impressed with the team and the sound, clear and informed answers to our questions. It was evident that the service is meeting the pre-April 2014 criteria for an alpha/private beta service. The multidisciplinary team is in place and the plans for future iterations were clearly explained which GDS are confident will ensure that the service is on track to meet the standard and proceed to public beta.\n\nHowever, as the assessment process is evidence based the current iteration of the service does not meet the criteria required to launch as a beta on&nbsp;[service.gov.uk](http://service.gov.uk/).\n\n### Reasons\n\nPre-April 2014 criteria\n\n1. Does the service meet user needs?\n\n- The team has a research plan in place to test the service at the end of each sprint. At this stage not enough users have been through the service for it to proceed to public beta.\n- The first iteration is a non-JavaScript version which is a good approach, but means that the current form is very long with some sections not relevant to all users. The team’s plan to implement a JavaScript version would solve this.\n- The form uses complex “legalese” language and doesn’t conform to the style guide in relation to use of plain English. Essential legal terminology should also be explained in plain English. Good examples already resolved include adding ‘(tenant)’ after ‘defendant’, but other legal terminology such as 'demoted tenancy' and 'accelerated property possession' need to be explained as appropriate to the expected users.\n- The service is currently not responsive at smaller screen sizes.\n\n2. Can the service be rapidly improved?\n\n- The current iteration is a non-JavaScript version, which means there are limits to what can be tracked using analytics (eg drop off points). Plans (which we are aware are already in place) to add JavaScript to the next iteration would address this.\n- There is no current continuous integration or continuous deployment process - this has been estimated as 2 weeks' work but not in place yet. Currently only a single developer can deploy.\n\n3. Is the service safe, ie are there appropriate security and privacy protections in place?\n\nPlans are in place to implement the appropriate security and privacy protections, but at this stage:\n\n- There is no SSL or production hardware in place.\n- Similarly, no IT Health Check has been done at this stage because it is not yet on production hardware.\n- The team has plans in place for the service to be assessed by the SIRO, but this should be completed before moving to public beta.\n\n### Next Steps\n\nThe assessment has shown that the Civil Claims service is not yet on track to meet the Digital by Default Service Standard. Before the service can proceed to public beta, GDS require the service to be reviewed against the failed criteria.\n\n### Summary\n\nGDS were impressed with the work completed so far and the team’s plans to iterate and improve the service based on user needs. GDS look forward to seeing how the service develops."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/visit-visa-tier-2-service-assessment/",
    "title": "Visit Visa (Tier 2) – Service Assessment",
    "summary": "If you need a visa to visit the UK you will be able to apply using a simple online service.  \n[https://www.gov.uk/transformation/apply-visa](https://www.gov.uk/transformation/apply-visa)",
    "body": "**Department / Agency:**  \nHO\n\n**Date of Assessment:**  \n04/02/2014\n\n**Moving to:**  \nPrivate Beta\n\n**Result:**  \nPass\n\n**Lead Assessor:**  \nM. Sheldon\n\n**Service Manager:**  \nT. Bruck\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## Assessment report\n\nThe Tier 2 Visit Visa service is seeking permission to continue development as it moves from Alpha to Private Beta.\n\n**Outcome of service assessment**\n\nAfter reviewing all the evidence GDS have concluded that the Tier 2 Visit Visa service has shown sufficient progress, is meeting the pre-April 2014 assessment criteria, and should proceed to Private Beta once a full IT health check has been passed and signed off by the SIRO.\n\n**Reasons**\n\nThe Visit Visas service team demonstrated that they are:\n\n- following good user research practices and have plans for in depth interviews and ongoing testing with real users\n\n- collaborating with an accessibility expert to regularly review and improve the service\n\n- working with a content designer to ensure the language is simple and concise, and is collating feedback for the GDS style guide around multilingual support\n\n- following an agile methodology and can improve the service iteratively and quickly based on user feedback\n\n- considering the service’s safety and security by carrying out early IT health checks and addressing issues in a timely manner\n\n**Recommendations**\n\nThe Visit Visas service team should consider the following recommendations:\n\n- the Service Manager ensures they understand the service as fully as the Product Manager.\n\n- the team find a dedicated person to focus on service analytics and analysis. As the service scales its user base, it could become increasingly harder for the Product Manager to fulfil this function.\n\n- plan to make all the code open, regardless of its usefulness to a wider audience. The only exceptions are configuration management code, code that contains sensitive information (e.g. fraud detection components) or can pose a security risk if open. Publishing the source code will be a mandatory requirement when the service is seeking approval to go Live.\n\n- continue to work closely with a GDS Content Designer and make the language used on the service as simple and easy to follow as possible, incorporating improvements based on user feedback.\n\n- consider the long term approach to service notification emails and how these will be managed as the service scales.\n\n- link to the Privacy Policy from a prominent place on the service.\n\n**Next Steps**\n\nThis service has been given approval to launch as a Private Beta.\n\n**Summary**\n\nIn summary GDS is pleased to report that this service is meeting the Digital by Default Service Standard. The work carried out so far has been driven from real user needs. GDS is pleased to hear that the team have continued to regularly user test while building the Alpha and Beta and have iterated and improved the service based on feedback. With a plan already in place to continue in this vein and carry out in depth interviews with private beta users, GDS looks forward to seeing the continued development of this service. GDS are very pleased with the work so far that has clearly demonstrated it is a service so good users will prefer to use it."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/identity-assurance-service-assessment/",
    "title": "Identity Assurance – Service Assessment",
    "summary": "The Identity Assurance service allows users to access secure government services after being accredited by a third party (such as the Post Office or Verizon). The service will act as a platform and work across many government departments on GOV.UK.  \n[https://gds.blog.gov.uk/2014/01/23/what-is-identity-assurance/](https://gds.blog.gov.uk/2014/01/23/what-is-identity-assurance/)",
    "body": "**Name of Service:**  \nIdentity Assurance\n\n**Department / Agency:**  \nCO / GDS\n\n**Date of Assessment:**  \n28/01/2014\n\n**Moving to:**  \nPrivate Beta\n\n**Result:**  \nPass\n\n**Lead Assessor:**  \nN. Williams\n\n**Service Manager:**  \nS. Dunn\n\n**Digital Leader:**  \nP. Maltby\n\n* * *\n\n## **Assessment report**\n\nThe Identity Assurance Service is seeking permission to continue development as it moves from alpha to private beta.\n\n**Outcome of service assessment**\n\nThe assessment panel concluded the IDA service has shown sufficient progress and evidence of meeting the pre-April 2014 criteria and should proceed to private beta.\n\n**Reasons**\n\nThe service is meeting user needs has done extensive user testing with real users. The assessment panel were impressed with the frequency of testing and the degree to which the team is making iterative, frequent changes based on user feedback.\n\nThe assessment panel were also satisfied that the service is secure and users’ privacy is being protected. The service has planned to undertake a comprehensive IT health check and will take appropriate action based on findings to ensure the service is safe.\n\n**Other recommendations**\n\nDuring the private beta, GDS recommend the IDA team holds a workshop with GOV.UK interaction designers and content designers to ensure that the service is as closely aligned and integrated as possible with start and done pages for relying party services on GOV.UK.\n\nGDS recommend that you put resources in place to regularly review and interpret the analytics data you collect and use it in combination with user research to improve the service.\n\nThe service team should ensure that third party identity providers are made aware of their responsibilities under the law (data protection, cookies, etc).\n\nFollowing discussions around the establishment of trust in the privacy protections in place GDS would recommend establishing a formal third party audit mechanism. The suggested ombudsman may fulfil this role and GDS would expect something in place, or a clear plan of action, at the next assessment.\n\n**Next steps**\n\nThis service has been given approval to launch as a private beta service.\n\n**Summary**\n\nThe assessment panel were very impressed with the work so far and expect this to continue for the ongoing development of the service."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/all-service-assessments-and-self-certification/hmrc/digital-self-assessment-alpha/",
    "title": "Digital Self-Assessment – Alpha Assessment",
    "summary": "Digital Self Assessment will replace the letters HMRC sends to self assessment customers with email alerts asking them to log in to the new tax account and see the same calls to action in a simpler, clearer way online.  \n[https://www.gov.uk/transformation/self-assessment](https://www.gov.uk/transformation/self-assessment)",
    "body": "**Department / Agency:**  \nHMRC\n\n**Date of Assessment:**  \n24 January 2014\n\n**Moving to:**  \nPrivate Beta\n\n**Result:**  \nMet\n\n**Lead Assessor:**  \nP. Buckley\n\n**Service Manager:**  \nT. Smith\n\n**Digital Leader:**  \nM. Dearnley\n\n* * *\n\n## Assessment report\n\nThe Digital Self Assessment team were looking to move their service to private beta.\n\n### Outcome of service assessment\n\nAfter reviewing the service GDS are pleased to say that the assessment team concluded the service has shown sufficient progress and evidence of meeting the pre-April 2014 criteria and should proceed to Private Beta (with one important condition - see below).\n\nOf the 17 pre-April 2014 criteria, GDS agreed that the Digital Self-Assessment team were passing 13 of them and had made progress on the remaining 4. GDS also felt that the team were aware of the areas which require further development and have plans for them.\n\n### Reasons\n\n1. The development team have clearly made a good service which has been heavily tested and will potentially improve the lives of people needing to self-assess.\n\n2. The assessors were impressed by the team's ability to deliver improvements to the service, both in the skills of the team and in the delegated power they had within a complex technical environment.\n\n### Condition\n\nAt the time of the assessment the security checks were not complete, and as discussed, the site cannot go live until these are complete and any recommendations implemented. GDS require written confirmation that these have been completed before moving to private beta.\n\n### Other Recommendations\n\n- \n\nThere is a large upcoming risk as the service is moved to Newcastle. Continuing the good work started by the current team will be crucial and GDS wish the team luck with the transition.\n\n- \n\nAll the assessors believed that there will come a time when the management of the offline service will need to be combined with that of the online service, in order to have a holistic plan for business transformation. GDS understand that there is a long way to go here but ask the team to keep GDS informed of this as they move to public beta and live.\n\nOn content, there are also a couple of small points about the wording:\n\n- \n\nThere were still a few 'Go Paperless' headings in the emails sent out and on the email verification page which seems a slight over-sell as GDS understood that there will still be some paper sent out.\n\n- \n\nThe opt out page (/account/account-details/sa/opt-out-email-reminders) could perhaps do more of a sell to stay on the service, e.g. by explaining what is to be gained by email and by making the go back button more enticing than the opt out button.\n\n### Next Steps\n\nThis service has been given approval to launch as a Private Beta service as and when the security tests have been made and any recommendations implemented.\n\n### Summary\n\nIn summary, the assessors were impressed with the work done so far and were pleased with how well it is matching the standard. GDS share the team’s optimism that it will improve the lives of self-assessors and also save taxpayers money."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/car-tax-statutory-off-road-notification-sorn-and-vehicle-enquiry-service-assessment/",
    "title": "Car tax, Statutory Off Road Notification (SORN) and Vehicle Enquiry – Service Assessment",
    "summary": "Users will be able to apply for a new tax disc, take their vehicle off the road by declaring Statutory Off Road Notification, or use the vehicle enquiry service to check what information DVLA holds on it’s database about a vehicle.",
    "body": "**Department / Agency:**  \nDfT / DVLA\n\n**Date of Assessment:**  \n15/1/2014\n\n**Moving to:**  \nPublic Beta\n\n**Result:**  \nPass\n\n**Lead Assessor:**  \nH. Garrett\n\n**Service Manager:**  \nN. Walters\n\n**Digital Leader:**  \nB. Etheridge\n\n* * *\n\n## Assessment report\n\nThe Car tax, SORN & Vehicle Enquiry service was seeking permission to continue development and move to Public Beta.\n\n### Outcome of service assessment\n\nAfter reviewing the service GDS have concluded the Car tax, SORN & Vehicle Enquiry service has shown sufficient progress and evidence of meeting the pre-April 2014 criteria and should proceed to Public Beta.\n\nGDS were very impressed by the pace at which the new service has been delivered and the capacity to iterate quickly.\n\n### Reasons\n\n1. The new service is a significant improvement on the legacy service and has focused on meeting user needs, acting on customer feedback and usability issues associated with the legacy service.\n\n2. The service can be iteratively improved at pace and the existing team will continue to develop the service, with plans to iterate based on analysis of data following beta launch.\n\n3. The service has the appropriate security and privacy protections in place.\n\n### Recommendations\n\nTo be addressed as soon as possible after the service has passed to public beta and a condition of making the beta the default option on the&nbsp;[GOV.UK](http://gov.uk/)&nbsp;service start pages.\n\n1. Design and content snag list feedback to be actioned to ensure departures from the style guide are addressed.\n\n2. The team should establish a regular series of face-to-face user research, integrated into sprint cycles.\n\n3. The team should carry out testing of the beta service with people with a range of disabilities and consult the GDS accessibility team for recommendations.\n\n### Other Recommendations\n\n1. Design resource should be brought within team to ensure someone owns the design and design changes (as a result of feedback/data analysis) can be delivered quickly.\n\n2. Implement plan to separate secret code separate from platform and publish non-sensitive code as open source on GitHub or a similar public repository.\n\n3. It is not currently possible to bookmark or link to the results page (state maintained via secret code passed back and forth in page/form). &nbsp;This should be addressed to enable a change in state to show a new URL.\n\n4. Fix the style 404 page.\n\n### Next Steps\n\nThis service has been given approval to launch as a Public Beta service.\n\n### Summary\n\nIn summary GDS are very pleased to report that this service is on track to meet the service standard. GDS are very pleased to be adding a digital service to&nbsp;[GOV.UK](http://gov.uk/)&nbsp;that is on track to demonstrate it is so good users will prefer to use it."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/patent-renewals-service-assessment-2/",
    "title": "Patent Renewals – Service Assessment",
    "summary": "We are&nbsp;[publishing](https://gds.blog.gov.uk/2014/01/31/publishing-digital-service-assessments/ \"Publishing Digital Service Assessments\")&nbsp;the reports from assessments against the&nbsp;[Digital by Default Service Standard](https://www.gov.uk/service-manual/digital-by-default)&nbsp;on this blog, starting with the Intellectual Property Office’s Patent Renewals service below. More reports for other services will follow over the next few days. After that we’ll be publishing the reports on every assessment shortly after they take place.",
    "body": "* * *\n\nCompanies, intermediaries and individuals will be able to Renew apply their Patents in a simple to use and integrated on-line service that is far easier, more cost effective and more convenient to use than the current paper based approach.  \n[https://www.gov.uk/transformation/renew-patent](https://www.gov.uk/transformation/renew-patent)\n\n**Department / Agency:**  \nBIS / Intellectual Property Office\n\n**Date of assessment:**  \n10/1/2014\n\n**Moving to:**  \nPublic Beta\n\n**Result:**  \nPass with conditions\n\n**Lead assessor:**  \nB. Andrews\n\n**Service manager:**  \nG. Court\n\n**Digital leader:**  \nC. Smith\n\n* * *\n\n## Assessment report\n\nThe Patent Renewals service is seeking permission to continue development as it moves from Private Beta to Public Beta.\n\n### **Outcome of service assessment**\n\nPass with conditions.\n\nAfter consideration GDS have concluded the Patent Renewals has shown good progress and evidence of meeting most pre-April 2014 criteria. The service should proceed to Public Beta after meeting the specific conditions detailed below.\n\n### Reasons\n\n- The team demonstrate good user research and analytics practices. They have plans for ongoing user research in a designated lab.\n- Similarly with analytics, they are retrieving data that shows entrance and completion rates, and also drop-out rates that will reveal how to improve performance.\n- This is a good, simple to use service and use of the front-end toolkit has ensured most of the correct design patterns have been followed. With some very minor adjustments, the site would be in line with the current design patterns and would also render properly on a mobile.\n- The team have a properly set up development, release and deployment infrastructure and processes in place.\n- Plans to open sourcing the .NET version of the template will be a great value for the rest of government.\n\n### Conditions for approval\n\nThe Patent Renewals service was reviewed against the pre-April 2014 criteria of the Service and must meet the following conditions before proceeding to Public Beta:\n\n- The Patent Renewals service should pass an IT Health Check with the Senior Information Risk Officer signing off (which usually means addressing any critical issues).\n- The service needs to be reviewed by the GDS Accessibility Digital Lead, before moving to public beta.\n- On the knowledge that Urchin was discontinued in 2012, the Patent Renewals service should ensure it is satisfied by its contractual arrangements for this package regarding data security, data ownership and privacy and service level agreements.\n- The service should provide a link to a privacy statement, but GDS understands that this is just pending legal review\n\n### &nbsp;Other recommendations\n\n- GDS would like to see all code open sourced, regardless of usefulness to a wider audience or not. The only exceptions are configuration management code, code that contain sensitive information (e.g. fraud detection components) or can pose a security risk if open sourced. Publishing the source code will be a mandatory requirement when the service is seeking approval to go fully Live.\n- One open source Analytics platform that the service can have a look into is Piwik. GDS has commissioned a market overview and are happy to share the output when this is available.\n- A GDS content designer with experience in transactions should review the service to ensure that lessons learnt from other services are used to enhance usability.\n- It would be good to hire a designer in the team, possibly to share resource with other projects.\n- Discussions with the GDS Performance Platform team should continue, to ensure that the data necessary for a holistic view of government service performance can be provided.\n- Patent Renewals service should look into an automated browser and device testing service like Browserstack or Saucelabs. The latter can just run your Selenium scripts.\n- The service should set up it’s own cookie page and not use the standard&nbsp;[GOV.UK](http://gov.uk/)&nbsp;page\n\n### Next steps\n\nThe assessment has shown that the Patent Renewals service does not yet fully meet the pre-April 2014 criteria of the Digital by Default Service Standard. Patent Renewals service should meet the conditions and follow the recommendations made in this report and see the Government Service Design Manual for further guidance. In order for the service to proceed to Public Beta, GDS require written confirmation of the actions taken to meet the conditions above.\n\n### Summary\n\nIn summary GDS are pleased to report that, subject to completing the above conditions, this service can proceed to Public Beta."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/student-loans-company-full-time-and-sponsored-applications-service-assessment/",
    "title": "Student Loans Company Full Time and Sponsored Applications – Service Assessment",
    "summary": "The service allows full time students to apply for tuition fee loans as well as loans and non-repayable grants to help with their living costs while studying.",
    "body": "**Department /Agency:**  \nBIS / Student Loans Company\n\n**Date of Assessment:**  \n8/1/2014\n\n**Moving to:**  \nPublic Beta\n\n**Result:**  \nPass with conditions\n\n**Lead Assessor:**  \nD. Wilks\n\n**Service Manager:**  \nL. Brown\n\n**Digital Leader:**  \nC. Smith\n\n* * *\n\n## Assessment report\n\nThe Student Loans Company (SLC) full-time and sponsored applications service is seeking permission to continue development as it moves from Alpha to Public Beta. The service was assessed against all pre-April 2014 criteria of the Digital by Default Service Standard.\n\n### &nbsp;Outcome of service assessment\n\nGovernment Digital Service (GDS) has decided to give the SLC full-time and sponsored applications service approval to launch as a Public Beta subject to the conditions below.\n\nGDS were very encouraged by technical improvements since the previous session, and that SLC are working on the organisational changes needed to support frequent iteration.\n\nGDS recognise the request to launch the service without the BETA logo and reaffirm that this exemption has been allowed due to SLC’s unusual circumstances. This request has also started a wider discussion within GDS as we learn from the varied users of the assessment process.\n\n### &nbsp;Conditions\n\nAll these conditions are points which should be addressed as soon as possible during beta (none are a pre-condition to beta launch).\n\n1. Security - please raise the issues below with CESG - assuming CESG are content, GDS will also be happy to accept their steer:\n\n- whether the sponsor email contains the right credentials to establish its own authenticity\n- whether the fact that users expect emails of this type from government agencies creates an environment where phishing attacks become easier\n\n2. Ensure that the future budget allows for at least the current level of research with ordinary external users to continue\n\n3. SLC plan to make several improvements in light of exploratory testing by the minister and also by the assessment team. GDS will share separately a list of all the minor content issues which they have found. No amount of testing will ever make the service perfect, and iterative improvement will continue during live running. However, detailed exploratory testing by people with digital skills is likely to uncover significant issues relating to edge cases. SLC should therefore do more content analysis and exploratory testing: GDS could help with this. SLC should also consider the use of search analytics to help match users' language and help frame potential points where users have questions.\n\n4. Improve User Interface on mobile devices (especially for the “speed bump” screens)\n\n5. Improve the aesthetic design of the user interface where students select university and course\n\n### &nbsp;Other observations\n\nAreas of improvement since previous assessment:\n\nThe service manager seemed generally more empowered to lead service delivery. GDS were pleased to hear that responding to analytical inputs is now part of product manager job descriptions, that the service manager now has direct access to customer feedback data, and that the service manager can arrange rapid deployments. GDS’ understanding is that SLC normally deploy one release per fortnight, but that SLC recently had a period of two releases per week, and that SLC can deploy releases even more rapidly where they are very urgent.\n\nOther points to reflect on:\n\nWhen applying as an EU student, the drop down flags to the user that they can obtain finance by providing their ID card rather than their passport. But in some countries, the national identity card is not very robust against fraud. This is really a matter for SLC to take advice from the appropriate policy and security experts, but SLC may perhaps want to consider digitally nudging nationals of countries with less robust ID cards towards providing passports, and ID cards only by exception. Clearly, for UK nationals, it would be helpful for you to include Identity Assurance (IDA) as soon as this is convenient.\n\nTwo issues where GDS is still developing further guidance are relevant to SLC:\n\nDigital Analytics: SLC should ensure it is satisfied by its contractual arrangements for its analytics solution regarding data security, data ownership and privacy and SLAs. GDS has commissioned a market overview and we will be happy to share the output when this is available.\n\nJavascript: the full time application uses javascript, and SLC’s broader digital transformation does so even more heavily. Applications which depend on javascript functionality are less resilient than those which can work on an HTML only basis, but several factors need to be balanced (i.e. cost, functionality, accessibility, resilience). GDS is urgently discussing this area, and SLC need to stay involved in that conversation."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/redundancy-payments-service-assessment/",
    "title": "Redundancy Payments – Service Assessment",
    "summary": "When an employer becomes insolvent employees are often owed money (especially for redundancy pay). The Redundancy Payments Service processes claims for statutory redundancy payments, which are paid from the National Insurance Fund (NIF). The current claim process is largely paper based, which leads to unnecessary cost and increased potential for errors and delays. The scope of the exemplar is to create a digital claim process that will reduce the handling of paper, identify potential problems within claims so that they may be resolved more quickly, and increase confidence and trust in the system for both claimants and insolvency practitioners.  \n[https://www.gov.uk/transformation/redundancy-payment](https://www.gov.uk/transformation/redundancy-payment)",
    "body": "**Department / Agency:**  \nBIS / Insolvency Service\n\n**Date of Assessment:**  \n18/12/2013\n\n**Moving to:**  \nPrivate Beta\n\n**Result:**  \nMet\n\n**Lead Assessor:**  \nN. Williams\n\n**Service Manager:**  \nG. Ecart\n\n**Digital Leader:**  \nC. Smith\n\n* * *\n\n## Assessment report\n\nThe Redundancy Payments Service is seeking permission to continue development as it moves from Alpha to Private Beta.\n\n### Outcome of service assessment\n\nWe are pleased to say that the Redundancy Payments Service has passed the service assessment. The service has shown sufficient evidence that it has either met, or is on track to meet the 17 pre-April 2014 criteria of the Digital by Default Service Standard.\n\n### Recommendations\n\nAs the service moves into the private beta phase, the Government Digital Service (GDS) strongly recommend the following.\n\n- The service must be tested frequently with claimants in real world conditions, as their heightened emotional state from being made redundant will have a significant impact on their experience and ability to process what is being asked of them.\n- The service team should seek input from GDS designers and content designers, to ensure the content and information design follows&nbsp;[GOV.UK](http://gov.uk/)&nbsp;style and design patterns.\n- The team must come to an evidence-based decision about what browsers and devices the service will support, and ensure browser testing takes place. (GDS’ feeling is that it will be important to provide a good mobile experience for claimants, but the Redundancy Payments service should form an evidence-based plan).\n- Analytics software must be put in place early, so that the service can be iterated upon based on this data in addition to planned user research. The Redundancy Payments service should ensure that each step of the user journey is measured, and the data is interpreted, so that drop-out points and other problems can be identified and fixed.\n- The new hosting arrangements needed to support continuous deployment must come to fruition. It is essential that the team which owns the service is able to deploy code rapidly in response to user needs.\n- A privacy assessment must be conducted.\n\nAs the service moves beyond private beta and begins to be used in the public domain, it will be important to have robust disaster recovery arrangements in place.\n\n### Next steps\n\nThe Redundancy Payments service should follow the recommendations made in this report and see the&nbsp;[Government Service Design Manual](https://www.gov.uk/service-manual/digital-by-default)&nbsp;for further guidance.\n\n### Summary\n\nThere was compelling evidence that the Redundancy Payments service is being developed with a focus on meeting its users’ needs. GDS were also convinced that the team has the skills and tools to continue to iterate the service. It was particularly encouraging to hear that, the service manager is fully empowered to make decisions about the service using evidence as the basis for those decisions; and that there is commitment from the team and strong senior support for putting the right hosting infrastructure and operations in place to allow for rapid, continuous improvement of the service."
  },
  {
    "original_url": "https://gdsdata.blog.gov.uk/registered-traveller-service-assessment/",
    "title": "Registered Traveller – Service Assessment",
    "summary": "E-passport gates are a secure and convenient self-service alternative to the conventional border control process. The registered traveller scheme will provide scheme members the facility to use the e-passport gates where they have made an online application prior to travel.  \n[https://www.gov.uk/transformation/apply-registered-traveller](https://www.gov.uk/transformation/apply-registered-traveller)",
    "body": "**Department:**  \nHome Office\n\n**Date of Assessment:**  \n13/12/2013\n\n**Moving to:**  \nPrivate Beta\n\n**Result:**  \nMet\n\n**Lead Assessor:**  \nA. Greenway\n\n**Service Manager:**  \nJ. Brady\n\n**Digital Leader:**  \nM. Parsons\n\n* * *\n\n## Assessment report\n\nThe Registered Traveller service was seeking permission to continue development as it moves from Alpha to Private Beta.\n\n### &nbsp;Outcome of service assessment\n\nAfter reviewing the assessment report, the Government Digital Service (GDS) have concluded Registered Traveller has shown sufficient progress and evidence of meeting the pre-April 2014 criteria and should proceed to Private Beta. However, there are number of areas for the team to make significant progress on before the service will be ready to launch as a public beta on[&nbsp;GOV.UK](http://gov.uk/).\n\n### &nbsp;Recommendations\n\nThe Registered Traveller service has clearly made some real steps forward from the initial pilot phase, and both the service and caseworker tool are strong platforms for the development of a good service. Although the points that follow are largely focused on improvements for the beta, GDS want to recognise here that a lot of positive things have happened already.\n\n### 1. The service is meeting user needs has done extensive user testing with real users.\n\nThe alpha service has had some user testing, but relatively little formal work at this stage. For a beta, GDS would expect the service and caseworking tool to have been tested end-to-end with a much larger sample of representative users. The team’s addition of a user testing expert is a good step in the right direction. More testing is essential for underpinning the project’s approach to other areas where there is more to do for beta, such as analysis, assisted digital approaches, performance benchmarks, and iteration based on user feedback.\n\nThe look and feel of the service was good for an alpha, though some of the content was jargon heavy and very long. GDS would expect the team to look at this issue as part of their user testing, and point to that evidence when working with policy colleagues to ensure that user experience rather than business norms informs the language used in the service and the caseworking tool.\n\nBoth the service and caseworking tool should ensure sufficient accessibility testing is carried out.\n\nBefore it launches as a public beta, the service should make provision for carrying out A/B testing on the live service.\n\n### **2. The service can be iteratively improved on a very frequent basis**\n\nThe Registered Traveller service is aware that it has capability gaps in web ops and technical testing that will need to be addressed. The current management structure has allowed the team to flourish without being encumbered by excessive governance and process. However, GDS would encourage the team to ensure that the Service Manager role in particular is kept under review as the service expands and becomes operational - the role will be a challenging and increasingly technical one, and having continuity from build phases through to operational service will be important.\n\nThe Registered Traveller service should conduct some analysis on the technical changes they may need to accommodate in the future and ensure they have the systems / capability to act on them.\n\nThe Registered Traveller service should push strongly to make as much of the service and caseworking tool’s code open, or provide a very strong justification why specific areas should not be.\n\nThe Registered Traveller service needs to ensure it has the analytical tools and user research data to feed into the iterative development process; this is there at an early stage, but GDS would expect it to be much more extensive by public beta.\n\n### **&nbsp;3. The service has taken appropriate action based on findings to ensure the service is safe.**\n\nIt’s unclear what IL-level system will ultimately be: GDS recommend starting these conversations early, especially because retention policy isn’t yet known. This is not a blocker now but needs to be addressed for the beta.\n\nFrom the assessment it seems the system is reliant on load balancing for distributing load and recovering from errors - the Registered Traveller service need to better plan for loss of components or total loss of connectivity. This is not a blocker now but needs to be addressed for the beta.\n\nThe use of email to connect systems is fragile and should be looked at before public beta. It’s also a single point of failure that’s subject to trivial denial of service if the email address was to be discovered.\n\nThe team need to have a robust plan for dealing with contingency, particularly in terms of email. The current process flow is reliant on relatively fragile email steps, and the team must have fail-safes to cover dataloss, etc.\n\n### **4. KPIs, Assisted Digital, etc**\n\nThe Registered Traveller service must establish performance targets / benchmarks, using (as a minimum) the four KPIs set out in the service standard.\n\nWe understand Registered Traveller’s view is that there is little requirement for assisted digital provision because the service is aimed at users from overseas. GDS recommend further analysis working with GDS and on the basis of user testing, as assisted digital provision may enable more people to register.\n\nAt end of the new service, the user receives confirmation, reference number, email and PDF of application. The team needs to ensure there is an incentive for users to go through to the 'transaction done' page on[&nbsp;GOV.UK](http://gov.uk/), to ensure user satisfaction and transaction completion data can be captured.\n\nRegistered Traveller mentioned difficulties of distinguishing between those who drop out because they are ineligible for the scheme, and those who drop out for other reasons. A solution to consider is separating eligibility from the transaction itself, so that only eligible users can start a transaction. Eligibility criteria could be contained in a separate smart answer, although there are possible problems with tying the smart answer to the service catalogue.\n\nThe Registered Traveller service should develop a method of calculating cost per transaction, covering the cost of receiving applications, through the validation process, up to accepting a traveller onto the scheme.\n\n### &nbsp;Next Steps\n\nThis service has been given approval to launch as a Private Beta service."
  }
]
